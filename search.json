[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R入門",
    "section": "",
    "text": "はじめに\nその昔（2000年代初頭）、Rを初めて学ぶときには、CRANのホームページから英語のマニュアルを入手し、読むしかありませんでした。いくつかのRの教科書がすでに出版されていましたが、多くの教科書はプログラミングの入門については取り扱っておらず、統計手法の使い方、高度な統計について、あるいはパッケージのマニュアルなどについての説明が記載されていました。2000年代初頭に大学生であった私にはRはとても難しく、英語のマニュアルも読めず、インターネットに落ちているコードをコピペしては自分のデータを入力し、使い方もよくわからずに統計の計算をしていたものでした。簡単な統計はExcelや、怪しげなフリーソフトを用いて行っていました。どのソフトにも手法がないような統計の手法にだけ、Rを用いたのです。\n時は流れ、2010年代、私は再びRと向き合うことになりました。その当時、研究で得たデータに対して、最小二乗法を用いて回帰を行い、測定できないパラメータを計算したかったのです。当時は最小二乗法しか回帰の方法を知らず、最小二乗法を解くためにRubyを勉強していました。Rubyでも二乗誤差の計算できることは分かっていましたが、配列（Rでいうところのベクターみたいなもの）の計算には繰り返し計算を使うしかなく、二乗誤差の計算を組むだけでも大変でした。二乗誤差を計算しても、最小値を求めることがどうしてもできず、今でいうところのグリッドサーチで最小値を求めようとしていました。\nグリッドサーチでは到底最小値が求まらないことは分かっていました。そこで、私はRという統計学の言語のことを思い出したのです。しかし、当時の私は海外におり、教科書を買うこともできませんでした。\nその時、Rを学ぶ光明となったのは、R-tipsというホームページでした。R-tipsはデザインこそ昔ながらのHTMLでしたが、Rを一から学ぶための情報がすべて含まれており、始めから最後まで読み通し、学ぶことでRの使い方を覚えることができました。その後、Rを用いてマイクロアレイ（今でいうところの高速シークエンサーによるトランスクリプトーム）のデータを取り扱うようになり、(Rで)マイクロアレイデータ解析 (門田幸二 2022)というホームページに書かれているコードを読むようになりました。R-tipsで学んだことを参考に、「(Rで)マイクロアレイデータ解析」のコードを読み解き、やがて私はRがある程度使えるようになりました。この2つのホームページがあったから、私はRを使えるようになったと言えます。\nそして時は流れ202X年、私はしがないサラリーマンになりました。(Rで)マイクロアレイデータ解析のホームページはまだ更新されており、生き残っています。しかし、R-tipsのホームページはもうありません。R-tipsは教科書 (舟尾暢男 2016) になったのです。日本語でどこでも読めて、Rを一から学べるホームページはなくなってしまいました。今でこそ私は英語のマニュアルを読み、理解することができます。しかし、Rも英語も何も知らない若年の初学者であったなら、Rを学ぶことを躊躇したでしょう。もちろん、昔と比べるとRについての情報はネット上にたくさん転がっており、落穂ひろいしながらRを学んでいくことはできます。しかし、R-tipsがそうであったように、一つのホームページで、広告などもなく、いちいち検索することもなくRについての情報を一度に得ることは（教科書を除けば）できなくなってしまいました。\n私も稀にRの初学者に使い方を教えようとすることがあります。しかし、一か所にRの基本的な使い方に関する情報が集まったような資料はあまりありません。プレゼンテーションを用いて教えるにしても、プログラミング言語の学習にはプレゼンテーションはあまり向いていません。すべてをプレゼンテーションで伝えようとするととても時間がかかってしまいます。ですので、大したR使いではない私がこのようなものを作るのはどうかとは思いつつ、R-tipsのようなものを作ることにしました。\nRでホームページを作る、教科書を作ることは昔は現実的ではありませんでした。しかし、今ではRを使って簡単なWebアプリを作ったり、教科書を作ったりすることは比較的簡単にできます。この文書もRで作成しています。私が学び始めたときのように、統計しかできないプログラミング言語ではないのです。\nとは言え、Rは統計のプログラミング言語です。Webを使った本格的なサービスを作りたい、データベースに保存されたデータを常時解析し、オンライン上でダッシュボードを表示したいなど、もっと複雑なことがしたいなら別の言語、例えばPythonを学ぶとよいでしょう。ad hocな、その場一回限りの統計や計算こそ、Rが最も生きる場面です。眼の前にある統計データを解析したい、統計の手法を試したいというのであれば、Rは最適な言語のひとつであると言えます。\nこの文書を読むことによって、皆さんがRに親しみ、データやグラフを自由自在に扱えるようになれば、そして私がR-tipsに助けられたように、Rの初学者のためになれば、これ以上の喜びはありません。",
    "crumbs": [
      "はじめに"
    ]
  },
  {
    "objectID": "index.html#著作権について",
    "href": "index.html#著作権について",
    "title": "R入門",
    "section": "著作権について",
    "text": "著作権について\nこの文書はクリエイティブ・コモンズ CC BY-NC-SAに従い、複製、頒布、展示、実演を行うにあたり、著作権者の表示を要求し、非営利目的での利用に限定し、作品を改変・変形・加工してできた作品についても、元になった作品と同じライセンスを継承させた上で頒布を認めます。\n元々無料の資料を提供することが目的であるため、非営利目的で、読みやすく、より良い資料に加工してもらえるのであれば、どのように利用していただいても問題ありません。",
    "crumbs": [
      "はじめに"
    ]
  },
  {
    "objectID": "index.html#記載の方針",
    "href": "index.html#記載の方針",
    "title": "R入門",
    "section": "記載の方針",
    "text": "記載の方針\nこのページでは、基本的にプログラミング初学者を対象として、プログラミングの基礎から統計・グラフ作成の基礎までを取り扱います。複雑な統計手法については、別の資料を参照しつつ、紹介程度に留めます。参考資料の一覧は参考文献に示します。\n普通の教科書では、同じ内容を複数の章に繰り返し記載することは避けます。紙に印刷する教科書では、反復があるとそれだけ教科書が厚くなり、持ち運びにも印刷等のコスト面にもデメリットがあるからです。しかし、オンラインの無料の教科書ではこのようなコストはほぼ無視できます。\n同じ内容を何度も繰り返すうちに、物事は自然と憶えられるものです。家から学校までの道のりを初めて通る時には道に迷うこともありますが、何度も往復を繰り返すうちに道を憶え、間違えなくなります。学習でも同じことが起こります。このページでは、重要な内容は繰り返し出てくるような記載にしています。何度も同じことを目に入れることで、記憶が定着し、その内容を覚えられることを期待したものです。\nと、良くいうと上記のようなことになりますが、実際には重複を個人ですべて叩き潰すのは大変だからやっていない、というだけです。「この内容は前にも見たことがあるなあ」と思ったら、飛ばして読んでもらっても特に問題はありません。",
    "crumbs": [
      "はじめに"
    ]
  },
  {
    "objectID": "index.html#表記方法",
    "href": "index.html#表記方法",
    "title": "R入門",
    "section": "表記方法",
    "text": "表記方法\nRのスクリプトは以下のようなコードブロックに記載します。\n\n\n\nコードブロック\n\nv &lt;- c(1, 2, 3, 4, 5)\nmean(v)\n## [1] 3\n\n\n上記のうち、表示の始めに##が付いている部分は、スクリプトを実行したときの結果です。\nRの関数や引数、パッケージ名は、functions、arguments、packagesのように、網掛けの文字で表示します。\n本文で説明する内容に付け加えて、参考情報として追加する内容については、以下のようにクリックすると開くブロック（callout）に表示します。\n\n\n\n\n\n\ncalloutの表示\n\n\n\n\n\nクリックすると開き、内容が表示されます。\n\n\n\n\n\n\n\n\n\n舟尾暢男. 2016. The R Tips 第3版 データ解析環境Rの基本技・グラフィックス活用集. オーム社. https://www.amazon.co.jp/dp/B0719QS6KG/.\n\n\n門田幸二. 2022. バイオインフォマティクス: Web連携テキスト基礎から応用. 培風館. https://www.amazon.co.jp/dp/4563078328/.",
    "crumbs": [
      "はじめに"
    ]
  },
  {
    "objectID": "chapter1.html",
    "href": "chapter1.html",
    "title": "1  Rのインストール",
    "section": "",
    "text": "1.1 Rのインストール\nRを使い始める前に、まずはRをインストールする必要があります。CRAN（The Comprehensive R Archive Network）のホームページからRのインストーラーをダウンロードし、Rをインストールします。ホームページの「Download and Install R」の部分から、ご自身のPC環境（Windows、MacOS、Linux）を選択します。",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Rのインストール</span>"
    ]
  },
  {
    "objectID": "chapter1.html#rのインストール",
    "href": "chapter1.html#rのインストール",
    "title": "1  Rのインストール",
    "section": "",
    "text": "図1：CRANのページ:Rのインストール\n\n\n\n1.1.1 windowsでのインストール\nWindowsであれば、上の図に示したリンクから次のページに移動し、さらに「base」を選択します。\n\n\n\n図2：CRANのページ:Windowsでのインストール\n\n\n移動すると、Rのダウンロードリンクが表示されますので、リンクをクリックしてRのインストーラーをダウンロードします。\n\n\n\n図3：CRANのページ:Windowsのインストールファイルのダウンロード\n\n\nダウンロードされたインストーラーを開き、「次へ」を押していけばインストールが完了します。\n\n\n\n図4：CRANのページ:インストーラーを起動した画面\n\n\n\n1.1.1.1 Rtoolsのインストール\nRを使うときには、時にC言語のコードをコンパイル（機械語に変換）する必要があります。このような場合に用いられるのがRtoolsです。図2で示したページに、「Rtools」というリンクがありますので、ココからRtoolsのページに移動します。移動するとRのバージョンに合わせたRtoolsへのリンクが表示されます。最新のRをインストールした場合には、Rtoolsも最新のRに対応したものになりますので、一番上のRtoolsのリンクを開きます。Rのバージョンが最新ではない場合には、Rのバージョンを確認した上で対応したRtoolsを選択します。\n\n\n\n図5：CRANのページ:Rtools\n\n\nRのバージョンに対応したRtoolsのリンクに移動すると、下のように表示されます。「Rtools installer」のリンクを開くと、Rtoolsのインストーラーがダウンロードされます。インストーラーを開いてRtoolsをインストールしましょう。\n\n\n\n図6：CRANのページ:Rtoolsのインストーラーのダウンロード\n\n\n\n\n\n1.1.2 MacOSでのインストール\nMacOSの場合もWindowsと同じように、図1でMacOSのリンクを選択してインストーラーをダウンロードします。MacOSの場合はCPUによってインストーラーが異なります。Apple Silicon（M1/M2）で動いているMacOS11以降のMacでは、上のリンクを選択してダウンロードし、IntelのCPUで動いているMacの場合は下のリンクを選択してダウンロードします。インストーラーを起動すると、Windowsと同じようにRをインストールすることができます。\n\n\n\n図7：CRANのページ:R for Macのダウンロード\n\n\n\n\n1.1.3 Linuxでのインストール\nLinuxでのインストールでは、特にCRANのホームページに移動してダウンロードを行う必要はありません。apt install(Ubuntuの場合)でRをインストールするだけです。\nsudo apt update\nsudo apt install r-base",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Rのインストール</span>"
    ]
  },
  {
    "objectID": "chapter1.html#rstudioのインストール",
    "href": "chapter1.html#rstudioのインストール",
    "title": "1  Rのインストール",
    "section": "1.2 Rstudioのインストール",
    "text": "1.2 Rstudioのインストール\nWindows版のRには、RGuiと呼ばれるグラフィカルユーザーインターフェース（GUI）が始めから登録されています。Rを起動するとまず表示されるのはこのRGuiです。\n\n\n\n図8：RGui\n\n\nこのRGuiを用いて、Rのスクリプト（プログラム）を書いて、実行することができます。ただし、このRGuiはRが利用され始めてすぐに開発されたものであり、最近のプログラミング環境では標準的に備わっている、シンタックスハイライト（プログラムの要素によって色やフォントを変化させる機能）や入力補助（関数の一部を入力すると入力候補を提案してくれる機能）、コードのバージョン管理（gitなどのバージョン管理ソフト）との連携などの機能が備わっていません。このような機能を持つ、プログラミングを快適に行うための環境のことを、統合開発環境（IDE、Integrated Development Environment）と呼びます。\n統合開発環境として有名なのは、Visual Studio Code（VScode）などです。VSCodeはRだけでなく、他の言語もサポートしています。Rでは、ほぼR専用の統合開発環境として、RStudioというものがあります。\nRを使う時には、もちろんRGuiやVSCodeなどを用いても問題はありませんし、R言語だけでなく、他の言語（Pythonなど）を同時に利用するのであれば、むしろVSCodeなどを利用する方が良いこともあります。ただし、Rを学び、Rで統計を行うのが主な目的であれば、RStudioを使うのが最もよいでしょう。\nRstudioはPositのホームページからダウンロードすることができます。まず、Rを上記の手順でインストールし、その後、Rstudioのインストーラーを以下の図の手順でダウンロードしましょう。\n\n\n\n図9：Rstudioのダウンロード（右上からリンクへ移動）\n\n\n\n\n\n図9：Rstudioのダウンロード（左のリンクからダウンロード）\n\n\nRstudioのインストーラーを起動し、Rstudioがインストール出来たら準備は完了です。Rstudioを起動し、Rを使ってみましょう。\n\n\n\n\n\n図1：CRANのページ:Rのインストール\n図2：CRANのページ:Windowsでのインストール\n図3：CRANのページ:Windowsのインストールファイルのダウンロード\n図4：CRANのページ:インストーラーを起動した画面\n図5：CRANのページ:Rtools\n図6：CRANのページ:Rtoolsのインストーラーのダウンロード\n図7：CRANのページ:R for Macのダウンロード\n図8：RGui\n図9：Rstudioのダウンロード（右上からリンクへ移動）\n図9：Rstudioのダウンロード（左のリンクからダウンロード）",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Rのインストール</span>"
    ]
  },
  {
    "objectID": "chapter2.html",
    "href": "chapter2.html",
    "title": "2  Rを使ってみよう",
    "section": "",
    "text": "2.1 Rstudioのパネル\nRstudioを開くと以下のような画面が表示されます。Rstudioでは、1つのウインドウの中に、4つのパネルが配置されます。ただし、インストールしてすぐに開くと、左側は1つのパネルになっているかもしれません。\nRstudioのそれぞれのパネルについて説明していきます。図2の左上のパネル①はテキストエディタと呼ばれるものです。テキストエディタは、「File → New file → R script」を選択し、新しいR script を作成すると表示されます。テキストエディタにはプログラムを書き込んでいきます。書き込んだプログラムは、①の右上にある、「run」という部分を押すと実行されます。少し長めのプログラムを書く場合には、このテキストエディタを使用します。\n左下のパネル②はコンソールと呼ばれる部分です。このコンソールには実行されたプログラムが表示されます。プログラムから何かを表示するよう指示した場合には、結果がこのコンソールに表示されます。Rでは、このコンソールに直接プログラムを書き込んで実行することもできます。1行程度のプログラムの挙動を調べたり、今取り扱っているデータを確認するときには、このコンソールにプログラムを直接書き込みます。\n右上パネル③には現在Rが取り扱っているオブジェクトについての情報が表示されます。オブジェクトについては次の章で詳しく説明します。右下のパネル④には、Rで描写したグラフや、ヘルプ、フォルダの情報などが表示されます。",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rを使ってみよう</span>"
    ]
  },
  {
    "objectID": "chapter2.html#rstudioのパネル",
    "href": "chapter2.html#rstudioのパネル",
    "title": "2  Rを使ってみよう",
    "section": "",
    "text": "図1：Rstudioを開いたところ\n\n\n\n\n\n\n\n\n図2：Rstudioを開いたところ\n\n\n\n\n\n\n\n\n対話的プログラミング\n\n\n\n\n\nプログラムを直接書き込み、すぐに実行し、結果を得るような仕組みのことを対話的プログラミングと呼びます。Rでは今書いているプログラムに干渉する形で対話的プログラミングを行うことができます。プログラミングでは、プログラムが思ったように動かない、バグが常に生じます。Rでは対話的プログラミングを通じてバグを修正し、プログラムが思った通りに動くよう修正していくことができます。",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rを使ってみよう</span>"
    ]
  },
  {
    "objectID": "chapter2.html#コンソールに入力",
    "href": "chapter2.html#コンソールに入力",
    "title": "2  Rを使ってみよう",
    "section": "2.2 コンソールに入力",
    "text": "2.2 コンソールに入力\nでは、まずコンソール、左下のパネル②に直接プログラムを書き込んでみましょう。とは言っても、書き込むプログラムは以下の通り、非常に簡単なものです。以下のプログラムをコピーペーストでコンソールに張り付け、エンターキーを押しましょう。コードブロックの右のコピーボタンをクリックすることでもプログラムをコピーすることができます。\n\n\n\nRのプログラム（スクリプト）\n\n1 + 1\n## [1] 2\n\n\"Hello World\"\n## [1] \"Hello World\"\n\n\nプログラムの結果（出力）として、上に示したように「[1] 2」と、「[1] \"Hello world\"」が表示されたと思います。このように、簡単な計算や文字の表示程度であれば、エディタ（パネル①）に書き込まなくても実行することができます。また、スペースはプログラムでは無視されて実行されます。ですので、1 + 1のようにスペースを入れても、1+1のようにスペースを入れなくても同じように計算を行ってくれます。\nコンソールには、&gt;が表示されている場合と、+が表示される場合があります。&gt;が表示されている場合には、コンソールは入力を待っている、待機中であることを意味しています。+が表示される場合には、入力を行った際のプログラムが不完全であることを意味しています。上の行に不完全なプログラムが記載されているので、確認して追加の文字を入力しましょう。\n下の例では、&gt;が記載されている行の)が一つ足りておらず、カッコが閉じていないため、次の行で+が表示されています。+の後に)を入力し、エンターキーを押せば、プログラムが完成し、演算が実行されます。\n\n\n\n図3：コンソールの&gt;と+",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rを使ってみよう</span>"
    ]
  },
  {
    "objectID": "chapter2.html#エディタを使う",
    "href": "chapter2.html#エディタを使う",
    "title": "2  Rを使ってみよう",
    "section": "2.3 エディタを使う",
    "text": "2.3 エディタを使う\n次に、エディタ（パネル①）を使ってみましょう。まず、左上の「File」の項目から、「New file → R script」を選択し、新しいエディタのウインドウを開きます。Ctrl、Shift、Nを同時に押す（Ctrl+Shift+N）ことでも、新しいエディタのウインドウを開くことができます。\n\n\n\n図4：エディタに新しいウインドウを追加する\n\n\n次に、下のプログラムをコピーペーストでエディタに張り付けます。\n\n\n\nRのプログラム（スクリプト）\n\n1 + 1 * 5\n\"Hello R world\"\n\n\nエディタに張り付けて、エンターキーを押しても、プログラムは実行されません。エディタ上のプログラムを実行する方法はいくつかあります。\n\n実行したいプログラムの行を選択して、CtrlとEnterを同時に押す（Ctrl+Enter）\n実行したいプログラムの行を選択して、パネルの上の「Run」を押す\nエディタを選択して、Alt、Ctrl、Rを同時に押す（Alt+Ctrl+R）\n\n上の2つは一行ごとに実行する方法です。複数行を選択してCtrl+Enterで実行すると、複数行を一度に実行することができます。最後のAlt+Ctrl+Rはエディタに書き込んだプログラムをすべて実行する方法です。いずれの方法でもプログラムを実行することができます。\nまた、R GUIとRStudioではコードを実行する際のショートカットが異なります。R GUIでは、Ctrl+Rで選択したコードを実行することができます。\nエディタに書いたプログラムは保存することができます。保存するときには、CtrlとSを同時に押します（Ctrl+S）。保存する際にはファイル名を指定します。ファイルの拡張子には、「.R」を用いるのが一般的です。",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rを使ってみよう</span>"
    ]
  },
  {
    "objectID": "chapter2.html#改行",
    "href": "chapter2.html#改行",
    "title": "2  Rを使ってみよう",
    "section": "2.4 改行",
    "text": "2.4 改行\nRでは、改行した行ごとにプログラムが評価されます。改行の代わりに;（セミコロン）の記号を用いて、プログラムの区切りを示すこともできます。\n\n\n\n改行と ;（セミコロン）\n\n1 + 1 # 各行がそれぞれ評価される\n## [1] 2\nprint(\"Hello world\")\n## [1] \"Hello world\"\n\n1 + 1; print(\"Hello world\") # ;を改行の代わりに使うこともできる\n## [1] 2\n## [1] \"Hello world\"",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rを使ってみよう</span>"
    ]
  },
  {
    "objectID": "chapter2.html#コメント",
    "href": "chapter2.html#コメント",
    "title": "2  Rを使ってみよう",
    "section": "2.5 コメント",
    "text": "2.5 コメント\nプログラムを書いていると、その部分のコードが何を目的として、何をしているのかよくわからなくなることが多々あります。プログラミングではそのコードの意味を記録しておくために、プログラムの途中にコメントを挟むのが一般的です。Rでは#がコメントを示す記号になっています。#以降に記載したテキストはプログラムの一部であるとは認識されず、プログラムとして実行されません。\nこの性質を生かして、プログラムの一部を一時的に実行しないようにすることをコメントアウトと呼びます。プログラムを書いた後で、実行したくない行の頭に#をつけることでコメントアウトを行うことができます。\n\n\n\nコメント\n\n# ココはコメントなので実行されない\n# 1 + 1 \n\n1 + 1 # シャープの前は実行されるが、シャープの後はコメントとなる\n## [1] 2",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rを使ってみよう</span>"
    ]
  },
  {
    "objectID": "chapter2.html#rを終了する",
    "href": "chapter2.html#rを終了する",
    "title": "2  Rを使ってみよう",
    "section": "2.6 Rを終了する",
    "text": "2.6 Rを終了する\nRを終了する場合には、q関数というものを用います。q()と入力するとRが終了します。RStudioを使っている場合には、単にウインドウを閉じてもRを終了させることができます。\n\n\n\nRを終了する\n\nq()\n\n\n\n\n\n\n\n図1：Rstudioを開いたところ\n図2：Rstudioを開いたところ\n図3：コンソールの&gt;と+\n図4：エディタに新しいウインドウを追加する",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rを使ってみよう</span>"
    ]
  },
  {
    "objectID": "chapter3.html",
    "href": "chapter3.html",
    "title": "3  オブジェクトと変数・定数",
    "section": "",
    "text": "3.1 プログラミング言語としてのR\nR言語は統計の計算を行うために開発されたプログラミング言語です。プログラミング言語としての仕様はS言語という、ベル研究所によって開発された言語を参考としています。R言語は、「動的型付け、型推論、インタプリタ型、オブジェクト指向の関数型言語」というタイプのプログラミング言語です。プログラミング未体験の方にはすべての単語が意味不明だと思いますが、単語の意味については順々に紹介していきます。\nまずは、「インタプリタ」について説明します。インタプリタとは、プログラムをコンパイルすることなく実行することができる環境のことを指します。\nこの、「コンパイル」というのは、プログラムを機械語に置き換える変換のことを指します。\n「機械語」というのも聞き覚えがない言葉だと思います。機械語とは、コンピュータが読み取れる、1と0だけからなる数字の列のことです。コンピュータは我々の言語や画像などをそのまま処理することはできず、1ビット単位（1と0）の情報だけを取り扱うことができます。プログラミング言語のうち、例えばCやJavaでは、プログラムはまず機械語に変換、コンパイルされます。コンパイルされたプログラムだけがコンピュータ上で実行できます（下図1）。\n一方、インタプリタ型の言語では、プログラミング言語をコンパイルすることなく実行することができます。インタプリタ型の言語にはPythonやRuby、PHPなどがあります。コンパイルには通常時間がかかりますが、インタプリタ型言語ではコンパイルに時間をかけることなく、すぐにプログラムを実行することができるというメリットがあります。一方で、コンパイルを除いたプログラムを実行・完了するまでの時間はコンパイルを行うプログラミング言語よりも長くなるというデメリットもあります。\nRはインタプリタ型の言語ですので、記述したプログラム（スクリプトとも呼びます）はすぐに実行されます。一方で、Rでの計算速度はインタプリタ型言語の中でもかなり遅い部類に入ります。ただし、Rは主にad hocな（その場一回限りの）統計解析に用いられる言語です。1回限りであれば、それほど計算が早くなくても問題とはなりませんし、入力したプログラムがすぐに実行されるという性質も統計解析との相性がよいものです。コンピュータの性能も昔より遥かに高くなっており、R言語での計算が遅いと感じることは減ってきています。",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>オブジェクトと変数・定数</span>"
    ]
  },
  {
    "objectID": "chapter3.html#プログラミング言語としてのr",
    "href": "chapter3.html#プログラミング言語としてのr",
    "title": "3  オブジェクトと変数・定数",
    "section": "",
    "text": "図1：コンパイルと機械語への変換",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>オブジェクトと変数・定数</span>"
    ]
  },
  {
    "objectID": "chapter3.html#オブジェクトとは",
    "href": "chapter3.html#オブジェクトとは",
    "title": "3  オブジェクトと変数・定数",
    "section": "3.2 オブジェクトとは？",
    "text": "3.2 オブジェクトとは？\nRはオブジェクト指向（Object oriented）の言語である、とされています。この「オブジェクト指向」という言葉はプログラミング言語ではよく用いられるものですが、厳密な定義は複雑です。\nこのオブジェクトというのは、プログラミングで取り扱う「もの」すべてを指す言葉です。プログラミングでは、数値や文字などを取り扱い、数値の演算を行ったり、文字に対して検索や置換、文字の追加などを行います。このとき、取り扱う数値や文字はオブジェクト、つまりプログラミングで用いる「もの」であるということになります。Rでは数値や文字の他に、因子（factor）や論理値（booleanまたはlogical）、関数（function）などを取り扱います。これらのすべてがプログラミングで取り扱う「もの」、つまりオブジェクトです。\n上で述べたように、プログラミングで用いるオブジェクトには数値、文字、因子、関数など、様々な種類のものがあります。数値も文字もプログラミングで扱う「もの」であることは共通していますが、数値と文字に対して同じ演算をしたい、ということは通常ありません。数値なら掛け算や割り算を行うことがあっても、文字に対して掛け算や割り算はしません。プログラミング言語も、数値なら数値の演算、文字なら文字の演算を行う必要があります。このように、数値なら数値の、文字なら文字の処理を行うために、オブジェクトには「型（type）」というものがあります。\n\n\n\n型と演算の関係\n\n1 * 1 # 数値同士を掛け算することがあっても、\n## [1] 1\n\n1 * \"dog\" # 数値と文字列を掛け算できてしまうと困る（エラーが出る）\n## Error in 1 * \"dog\": non-numeric argument to binary operator",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>オブジェクトと変数・定数</span>"
    ]
  },
  {
    "objectID": "chapter3.html#型typeとは",
    "href": "chapter3.html#型typeとは",
    "title": "3  オブジェクトと変数・定数",
    "section": "3.3 型（type）とは？",
    "text": "3.3 型（type）とは？\n型（type）とは、そのオブジェクトの種類を定めるためのラベルのようなものです。例えば、Rで数値を入力すると、Rは自動的にその数値がnumericであると認識します。同様に、“（ダブルクオーテーション）で文字を囲うと、Rは自動的にその文字がcharacter（文字列型）であると認識します。Rはこの認識した型に従い、そのオブジェクトに対する演算を行います。\nオブジェクトの型はmode関数で確認することができます。関数については後ほど詳しく説明します。\n\n\n\nmode関数で型を確認する\n\nmode(1) # 1は数値\n## [1] \"numeric\"\nmode(\"Hello world\") # \"Hello world\"は文字列\n## [1] \"character\"\nmode(\"1\") # \"1\"は文字列\n## [1] \"character\"\n\n\n上記のように、「1」の数字をmode()のカッコの中に入れると、numericが返ってきます。これは、1というオブジェクトの型がnumeric（数値）であることを示しています。同様に、ダブルクオーテーションで囲まれた\"Hello world\"をmode()のカッコに入れると、characterが返ってきます。これは、\"Hello world\"の型がcharacter（文字列）であることを意味しています。では、ダブルクオーテーションで囲まれた\"1\"がどうなるかというと、これはcharacter、つまり文字列になります。\nRでは、このように「ダブルクオーテーションで囲まれている」というオブジェクトの状態を調べ、囲まれていればそのオブジェクトは文字列型であると判断します。同様に、オブジェクトが「数値でかつダブルクオーテーションに囲まれていない」場合には、そのオブジェクトが数値型であると判断します。このように、プログラム上でオブジェクトの型を特に指定していなくても、Rは自動的にそのオブジェクトの型を決定してくれます。このようなプログラムの性質を「型推論」と呼びます。\nでは、Rの代表的な型について、これから簡単に説明していきます。\n\n3.3.1 文字列（character）\n一般的なプログラミング言語で最も取り扱うことが多いオブジェクトは文字列型（character）です。文字列、つまり文章などを検索したり、一部を取り出したり、条件に合っているか確認したりすることはプログラミング利用の目的の一つとなります。\nRは統計学のプログラミング言語ですので、どちらかというと文字列よりは数値を取り扱うことが多いのですが、文字列を取り扱える仕組みも一通り備えています。\nRで文字列型のオブジェクトを作成するときには、\"（ダブルクオーテーション）もしくは'（シングルクォーテーション）で文字を囲みます。ダブルクオーテーション・シングルクオーテーションのどちらを用いても文字列のオブジェクトを作成することはできます。クオーテーションが無い場合にはエラーとなります。\n\n\n\n文字列オブジェクトの例\n\n\"Hello world\" # ダブルクオーテーションで囲った場合\n\n'Hello R' # シングルクオーテーションで囲った場合\n\nHello world # エラー\n## Error: &lt;text&gt;:5:7: unexpected symbol\n## 4: \n## 5: Hello world\n##          ^\n\n\nダブルクオーテーションとシングルクオーテーションには違いはありません。どちらを用いても問題ないのですが、Rではダブルクオーテーションを用いるのが一般的です。\nRでは、文字列を入力すればその文字列がそのまま表示されますが、文字列の表示を明示したい場合にはprint関数を用います。\n\n\n\nprint関数\n\nprint(\"Hello world\")\n## [1] \"Hello world\"\n\n\n\n3.3.1.1 エスケープ文字（エスケープシーケンス）\nプログラミング言語によっては、ダブルクオーテーションとシングルクオーテーションでエスケープ文字（エスケープシーケンス）の取扱いに違いがある場合があります。エスケープシーケンスとは、バックスラッシュ（\\、日本語キーボードでは¥）とアルファベットを組み合わせて、特定の意味を持たせる表現のことを指します。例えば、\\nは改行を、\\tはタブを示す記号です。RではC言語由来のエスケープシーケンスを利用できます。以下の表1にエスケープシーケンスの例を挙げます。\n\n\n\n\n表1：エスケープシーケンスの例\n\n\nエスケープシーケンス\nエスケープシーケンスの意味\n\n\n\n\n\\a\nアラート\n\n\n\\b\nバックスペース\n\n\n\\f\nページ分割\n\n\n\\n\n改行\n\n\n\\r\nキャリッジリターン\n\n\n\\t\n水平タブ\n\n\n\\v\n垂直タブ\n\n\n\\\\\nバックスラッシュ\n\n\n\\'\nシングルクオーテーション\n\n\n\\\"\nダブルクオーテーション\n\n\n\n\n\n\n\n\nRのデータをテキストファイルなどに書き出すときには、エスケープシーケンス、特に\\n（改行）や\\t（タブ）を用いることがあります。データ書き出しの際のエスケープシーケンスに関しては、13章で詳しく説明します。\nエスケープシーケンスを変換した文字列を表示する場合には、writeLines関数を用います。\n\n\n\nwriteLines関数で文字列にエスケープシーケンスを反映\n\nwriteLines(\"Hello world\")\n## Hello world\n\nwriteLines(\"Hello\\nworld\") # \\nは改行に変換\n## Hello\n## world\n\nprint(\"Hello\\nworld\") # print関数はエスケープシーケンスを変換しない\n## [1] \"Hello\\nworld\"\n\n\n\n\n3.3.1.2 文字列を結合する\nRで文字列を用いるときに、文字列Aと文字列Bをくっつけたい、ということがあります。このようなときに用いるのが、paste関数です。paste関数はカッコの中に2つ以上の文字列をコンマでつないで入れると、文字列をスペースを挟んでつなぎ合わせてくれます。文字列の間にスペースが必要ない場合には、paste0関数を用います。\n\n\n\n文字列をつなぐpaste関数\n\npaste(\"Hello\", \"world\")\n## [1] \"Hello world\"\n\npaste0(\"Hello\", \"R\")\n## [1] \"HelloR\"\n\n\n文字列の取扱いに関しては、9章で詳しく説明します。\n\n\n\n3.3.2 数値（numeric）\nRは統計の言語ですので、数値データを取り扱う機会が特に多くなります。グラフを記述したり、データを要約する場合にも主に取り扱うのは数値です。Rでは、数値はnumericという型を持ちます。\n\n3.3.2.1 数値型のdouble（浮動小数点）とinteger（整数）\n数値には更に詳細な型があります。詳細な型はtypeof関数で調べることができます。Rでの数値は通常doubleという型を持ちます。\n数値にはdouble以外に、integer（整数）という型もあります。Rで整数型の数値を利用する時には、数字の後ろにLをつけます。また、数値であってもダブルクオーテーションで囲うと文字列 （character）になります。\n\n\n\ndouble型とinteger型\n\nmode(1) # modeでの型はnumeric\n## [1] \"numeric\"\n\ntypeof(1) # これはdouble\n## [1] \"double\"\n\ntypeof(1L) # これはinteger\n## [1] \"integer\"\n\ntypeof(\"1\") # これはcharacter\n## [1] \"character\"\n\n\nRではintegerを取り扱う機会は非常に少なく、通常数値はdoubleとして取り扱います。\n\n\n\n\n\n\nRでの数値型\n\n\n\n\n\n多くのプログラミング言語では、小数点を含む数値は、その精度（桁数）により、single（浮動小数点型）、double（倍精度浮動小数点型）などの型を持ちます。このsingleはdoubleよりオブジェクトのファイルサイズが小さい代わりに、あまり大きい桁数の数値は取り扱えないという特徴があります。Rにはsingleという型はありません。\n\n\n\n\n\n3.3.2.2 クラス（class）\nRではオブジェクトは型以外に、クラス（class）という性質を別に持っています。Rでの数値型は、numeric（数値）というクラスを持ちます。クラスの確認にはclass関数を用います。\n\n\n\nクラス、モードとtypeof関数\n\nmode(1) # 型はnumeric\n## [1] \"numeric\"\n\ntypeof(1) # typeofだとdouble\n## [1] \"double\"\n\nclass(1) # クラスはnumeric\n## [1] \"numeric\"\n\n\n\n\n\n\n\n\nアトリビュート（attribute)\n\n\n\n\n\nRのオブジェクトは型だけでなく、アトリビュート（attribute）という性質を別に持っています。クラスはこのアトリビュートの一つです。オブジェクト指向プログラミングではクラスは非常に重要な意味を持ちますので、18章で詳しく説明します。\n\n\n\n\n\n3.3.2.3 演算子（operator）\n数値を扱う際には、四則演算等の計算を行うことがあります。この四則演算を行うための記号のことを、演算子と呼びます。Rでは以下の四則演算子を利用できます。\n\n\n\n表2：Rで使える演算子\n\n\n演算子\n演算の種類\n\n\n\n\n+\n足し算\n\n\n-\n引き算\n\n\n*\n掛け算\n\n\n/\n割り算\n\n\n%%\n剰余（割り算の余り）\n\n\n%/%\n整数の割り算\n\n\n^\n累乗\n\n\n\n\n\n演算子それぞれの計算結果は以下のようになります。演算子の意味はExcelなどで用いられているものとほぼ同じです。\n\n\n\n四則演算の例\n\n3 + 2 # 足し算\n## [1] 5\n\n3 - 2 # 引き算\n## [1] 1\n\n3 * 2 # 掛け算\n## [1] 6\n\n3 / 2 # 割り算\n## [1] 1.5\n\n3 %% 2 # 剰余（余り）\n## [1] 1\n\n3 %/% 2 # 整数の割り算\n## [1] 1\n\n3^2 # 累乗\n## [1] 9\n\n\n数値については8章で詳しく説明します。\n\n\n\n3.3.3 論理型（logical）\n論理型（logical）は、TRUE（真）とFALSE（偽）からなる2値の型です。TRUEとFALSEはその名の通り、その関係が正しいか、間違っているかを意味するものです。論理型はそのまま使用することもありますが、プログラミングでは比較演算子と共に用いることが多い型です。\n\n3.3.3.1 比較演算子\n比較演算子とは、演算子の右と左を比較して、その関係が正しい（TRUE）のか、間違っているのか（FALSE）を返す演算子です。比較演算子の例を以下に示します。\n\n\n\n表3：Rで使える比較演算子\n\n\n比較演算子\n比較演算子の意味\n\n\n\n\n==\n等しい\n\n\n!=\n等しくない\n\n\n&lt;\n小なり\n\n\n&lt;=\n小なりイコール\n\n\n&gt;\n大なり\n\n\n&gt;=\n大なりイコール\n\n\n&\nかつ\n\n\n&&\nかつ\n\n\n|\nまたは\n\n\n||\nまたは\n\n\n\n\n\n&と|は比較演算子同士を結びつけるための演算子（論理演算子）です。&と&&、|と||の違いについては、4章で説明します。\n比較演算子を用いた演算の例を以下に示します。比較演算子や論理型は主に条件分岐で用います。\n\n\n\n比較演算子\n\n1 == 1 # 等しいのでTRUE\n## [1] TRUE\n1 == 2 # 等しくないのでFALSE\n## [1] FALSE\n\n1 != 1 # 等しいのでFALSE\n## [1] FALSE\n1 != 2 # 等しくないのでTRUE\n## [1] TRUE\n\n1 &lt; 2 # 2は1より小さいのでTRUE\n## [1] TRUE\n1 &lt; 1 # 1は1より小さくないのでFALSE\n## [1] FALSE\n\n1 &lt;= 2 # 2は1より小さいのでTRUE\n## [1] TRUE\n1 &lt;= 1 # 1は1に等しいのでTURE\n## [1] TRUE\n\n3 &gt; 2 # 3は2より大きいのでTRUE\n## [1] TRUE\n2 &gt; 2 # 2は2より大きくないのでFALSE\n## [1] FALSE\n\n3 &gt;= 2 # 3は2より大きいのでTRUE\n## [1] TRUE\n2 &gt;= 2 # 2は2と等しいのでTRUE\n## [1] TRUE\n\n1 == 1 & 2 == 2 # TRUEかつTRUEなのでTRUE\n## [1] TRUE\n1 == 1 & 2 == 3 # TRUEかつFALSEなのでFALSE\n## [1] FALSE\n\n1 == 1 | 2 == 2 # TRUEまたはTRUEなのでTRUE\n## [1] TRUE\n1 == 1 | 2 == 3 # TRUEまたはFALSEなのでTRUE\n## [1] TRUE\n\n\n\n\n3.3.3.2 演算子の優先順位\n数値の計算で掛け算・割り算を足し算・引き算より前に計算するように、演算子の優先順位、計算する順番は決まっています。概ね通常の計算と同じですが、以下のような順序で演算子は計算されます。\n\nカッコでくくられている計算\n累乗（^）\n剰余・整数の割り算（%%・%/%）\n掛け算・割り算（*・/）\n足し算・引き算（+・-）\n比較演算子（==、!=、&lt;、&lt;=、&gt;、&gt;=）\n論理演算子（&、|）\n\n計算式は長くなることが多く、演算子の計算順を間違う場合も多いため、優先する計算は積極的にカッコで囲むとよいでしょう。\n\n\n\n演算子の計算順序\n\n(2 + 1) / 3 # カッコ内は最優先\n## [1] 1\n\n2 ^ 3 %% 5 # 累乗は剰余より先に計算(8/5の余り)\n## [1] 3\n\n3 / 3 %% 2 # 剰余は割り算より先に計算（3/1を計算）\n## [1] 3\n\n3 / 3 + 1 # 割り算は足し算より先に計算\n## [1] 2\n\n3 + 3 &gt; 5 # 比較演算子は足し算より後に計算\n## [1] TRUE\n\n5 &gt; 1 & 6 &gt; 2 # 論理演算子は最後に計算\n## [1] TRUE\n\n\n\n\n\n3.3.4 その他の型・クラス\n以上の3つ（文字列、数値、論理型）がRでの基本的な型になります。しかし、Rにはこの3つ以外の型を持つオブジェクトも存在します。\n\n3.3.4.1 欠損値など\nデータ分析では欠損値や、計算結果が表示できないもの、計算結果が無限大になるものなど、データとしてうまく取り扱えない値が生じることがよくあります。このような場合に対応するため、Rは欠損値、計算できない値、無限大にそれぞれNA、NaN、Infという型が設定されています。Rでは中身が何もないオブジェクト、NULLというものを作成することもできます。\n\n\n\n欠損値、非数、無限大\n\nNA # 欠損値（Not Available）\n## [1] NA\n\n0/0 # 非数（NaN、Not a Number）\n## [1] NaN\n\n1/0 # 無限大（Inf）\n## [1] Inf\n\n10000^1000000 # 大きすぎて取り扱えない数値もInfになる\n## [1] Inf\n\nNULL # 中身がないオブジェクト（NULL）\n## NULL\n\n\n\n\n3.3.4.2 複素数（complex）\nRでは複素数（整数+虚数）を取り扱うこともできます。複素数を表すときには、数値の後にiを入力します。\n\n\n\n複素数の作成と演算\n\n1 + 1i # 複素数\n## [1] 1+1i\n\nmode(1 + 1i) # 複素数の型はcomplex\n## [1] \"complex\"\n\n(1 + 1i) + (3 + 3i) # 複素数同士の足し算\n## [1] 4+4i\n\n\n\n\n3.3.4.3 日時のクラス（Date、POSIXct、POSIXlt、difftime）\n日付は数値や文字列とは異なる性質を持ちます。統計では日付や時間を演算に用いることもあります。Rでは日付はDateというクラスを持ちます。また、日時のデータはPOSIXctやPOSIXltというクラスに属します。\nDateやPOSIXct、POSIXltは引き算などの演算に用いることができます。日時の差はdulationsというクラスを持ちます。\nDate、POSIXct、POSIXlt、dulationはいずれもクラスで、データの型としてはdouble、つまり数値型のデータとして取り扱われます。\n\n\n\n日時のクラスと型\n\nSys.Date() # 現在の日付を表示する関数\n## [1] \"2025-03-29\"\n\nclass(Sys.Date()) # 日付のクラスはDate\n## [1] \"Date\"\n\ntypeof(Sys.Date()) # 日付の型はdouble\n## [1] \"double\"\n\n\nSys.time() # 現在の日時を表示する関数\n## [1] \"2025-03-29 07:46:58 +09\"\n\nclass(Sys.time()) # 日時のクラスはPOSIXctとPOSIXlt\n## [1] \"POSIXct\" \"POSIXt\"\n\ntypeof(Sys.time()) # 日時の型はdouble\n## [1] \"double\"\n\n\nSys.Date() - as.Date(\"2023-01-01\") # 2023/1/1から今日までの日数\n## Time difference of 818 days\n\nclass(Sys.Date() - as.Date(\"2023-01-01\")) # 日時の差のクラスはdifftime\n## [1] \"difftime\"",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>オブジェクトと変数・定数</span>"
    ]
  },
  {
    "objectID": "chapter3.html#変数と定数",
    "href": "chapter3.html#変数と定数",
    "title": "3  オブジェクトと変数・定数",
    "section": "3.4 変数と定数",
    "text": "3.4 変数と定数\n\n3.4.1 変数\nココまでは、数値や文字列などの、単純なオブジェクトについて説明してきました。単純なオブジェクトはプログラミングの要素として重要です。しかし、オブジェクトを毎回作成し直すのは面倒です。オブジェクトを作ったら、それを一時的に保管しておいて、後から演算に使える方が便利です。\n電卓では、このような「一時的に結果を記録する」方法として、メモリー機能があります。Excelなどでは、計算結果をセルに記録しておくこともあるでしょう。プログラミング言語にも、計算結果を一時的に保管しておくものが準備されています。この「計算結果を一時的に保管しておくもの」のことを、プログラミング言語では変数と呼びます。\n変数には名前がついています。名前付きの箱の中にオブジェクトを入れているようなものが変数です。下の図では、変数「dog」にオブジェクト「\"犬\"」を入れています。「\"犬\"」を取り出して使いたいときには、変数である「dog」を持ってくればよい、ということになります。\n\n\n\n図2：変数のイメージ\n\n\nRで変数を作成する場合には、変数名に「&lt;-」の記号でオブジェクトを代入します。\n\n\n\n変数への代入\n\ndog &lt;- \"inu\" # dogという変数に\"inu\"という文字列を代入する\nnumber &lt;- 1 # numberという変数に、1という数値を代入する\ndog # 変数dogには\"inu\"が入っている\n## [1] \"inu\"\n\nnumber # 変数numberには1が入っている\n## [1] 1\n\n\n変数には型・クラスがあり、代入したオブジェクトと同じ型・クラスを持つことになります。また、変数はそのまま演算に用いることができます。\n\n\n\n変数の型\n\nmode(dog) # dogの中身は文字列\n## [1] \"character\"\n\nmode(number) # numberの中身は数値\n## [1] \"numeric\"\n\n\npaste(dog, \"walk\") # dogの中身と\"walk\"をつなぐ\n## [1] \"inu walk\"\n\nnumber + 5 # numberの中身に5を足す\n## [1] 6\n\ndog + 1 # dogの中身は文字列なので、足し算はできない\n## Error in dog + 1: non-numeric argument to binary operator\n\n\n変数への代入は、「=」や「-&gt;」の演算子によっても行うことができます。ただし、これらを代入に用いると、プログラムを読み解くのが難しくなるため、Rでは「&lt;-」を用いることが推奨されています。\n\n\n\n=や-&gt;による代入\n\ndog = \"犬\" # イコールも代入に使うことができる\n2 -&gt; number # -&gt;も代入に使える（方向は&lt;-と逆になる）\n\ndog\n## [1] \"犬\"\n\nnumber\n## [1] 2\n\n\n定義されている変数の一覧を確認するには、ls関数を用います。\n\n\n\n変数の確認\n\nls()\n## [1] \"d\"      \"dog\"    \"number\"\n\n\n\n\n3.4.2 変数と定数\n変数のうち、一度代入したら中身を変えられないもののことを定数と呼びます。他のプログラミング言語では定数を設定できるものが多いのですが、Rには定数を設定する方法はありません。変数の中身はいつでも置き換えできます。変数を置き換えると、置き換えに用いたオブジェクトの型・クラスに従い、変数の型・クラスも置き換わります。\n\n\n\n変数の置き換え\n\ndog &lt;- \"inu\" # 変数に文字列を代入\nmode(dog) # 型は文字列になる\n## [1] \"character\"\n\ndog &lt;- 1 # 変数に数値を入れ直す\nmode(dog) # 変数の型は数値になる\n## [1] \"numeric\"\n\n\n\n\n\n\n\n\nRにおけるデータ型の変換\n\n\n\n\n\n多くのプログラミング言語では、上記のように変数の型が変化するのを抑える仕組み（型宣言）を持っています。型宣言が必要な言語では、変数は厳密に型のチェックを受けます（静的型付け）。Rにはこのような仕組みがなく、代入されたオブジェクトに従って型が決まり、型チェックされることなくプログラムが実行されます。このような言語のことを動的型付けと呼びます。\nプログラム中で変数の型が変わると、バグの原因となります。Rでは、プログラムを書いているうちに変数の型が変化していて、正しい計算結果が得られない、ということがたびたび起きます。変数の型を常に確認しながらプログラミングした方がよいでしょう。\n\n\n\n定数とは少し異なりますが、Rでは代入なしに使える変数もあります。例えば、円周率のπは「pi」という変数名で始めから登録されています。このような変数にも別のオブジェクトを代入することはできますが、後々混乱する原因となるため避けたほうがよいでしょう。\nまた、統計手法を試すためのデータが代入されている変数（データセット）もたくさん設定されています。データセットについては、14章で詳しく説明します。\n\n\n\nあらかじめ設定されている変数\n\npi # 円周率\n## [1] 3.141593\n\nletters # アルファベット（小文字）\n##  [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n## [20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\nLETTERS # アルファベット（大文字）\n##  [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n## [20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\nmonth.abb # 月（短縮表記）\n##  [1] \"Jan\" \"Feb\" \"Mar\" \"Apr\" \"May\" \"Jun\" \"Jul\" \"Aug\" \"Sep\" \"Oct\" \"Nov\" \"Dec\"\n\nmonth.name # 月\n##  [1] \"January\"   \"February\"  \"March\"     \"April\"     \"May\"       \"June\"     \n##  [7] \"July\"      \"August\"    \"September\" \"October\"   \"November\"  \"December\"\n\npi &lt;- 3 # piに3を代入する\npi # piは3になってしまう\n## [1] 3\n\n\n\n\n3.4.3 値渡しと参照渡し\nRでは、変数への代入が行われるたびに、その変数に対するメモリのアドレスを新規に作成し直す、という特徴があるため、他の言語で理解が必要となる値渡しと参照渡しの問題がほとんど起きません。\n\n\n\n値渡し\n\nx &lt;- 1 # xに1を代入\ny &lt;- x # yにxを代入（yとxはメモリを共有）\nx &lt;- 2 # xに2を代入（xのメモリのアドレスが変わる）\nx # xは新しいアドレスを参照（2が返ってくる）\n## [1] 2\ny # yは古いアドレスを参照（1が返ってくる）\n## [1] 1\n\n\n\n\n\n\n\n\n参照渡し\n\n\n\n\n\n上のコードでは、参照渡しであれば、xの値が2になった場合、xとメモリを共有しているyも2になります。Rでは、代入時にメモリのアドレスが別に準備されるため（値渡し）、参照渡しが起こることは基本的にありません。この特徴はプログラミング初心者には優しいのですが、変数の変更のたびにメモリ上にオブジェクトを新規作成するため、Rの実行速度が遅い原因になります。",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>オブジェクトと変数・定数</span>"
    ]
  },
  {
    "objectID": "chapter3.html#便利なオブジェクトクラス",
    "href": "chapter3.html#便利なオブジェクトクラス",
    "title": "3  オブジェクトと変数・定数",
    "section": "3.5 便利なオブジェクト・クラス",
    "text": "3.5 便利なオブジェクト・クラス\nここまでは、オブジェクトが一つだけの場合のデータ型や、変数について見てきました。しかし、統計で取り扱うのは、複数の数値や記録です。数値や記録がたくさんある場合には、数値や記録を一つづつ別々に取り扱うのは非効率です。多くのプログラミング言語では、このような複数の数値や記録を取り扱う専用のクラスを備えています。Rでは、複数の記録を取り扱うクラスとして、ベクター（vector）、リスト（list）、データフレーム（data.frame）、行列（matrix）の4つが用いられます。以下にこの4つについて簡単に説明します。それぞれのクラスについてはさらに別章で詳しく説明します。\n\n3.5.1 ベクター（vector）\nRで最も基本的なオブジェクトは、ベクター（vector）です。ベクターは同じ型を持つオブジェクトの集まりで、1次元の、つまり縦横の構造がないデータとして取り扱われます。ベクターはc関数（cはcombine、「結合する」の意味）で作成することができます。\nベクターは同じ型を持つデータの集まりです。ですので、ベクターの要素に文字列が交じると、自動的にすべての要素が文字列になる、という特徴があります。\n\n\n\nベクターの作成\n\nvec_n &lt;- c(1, 2, 3, 4) # 数値のベクター\nvec_c &lt;- c(\"dog\", \"cat\", \"pig\", \"horse\") # 文字列のベクター\nvec_temp &lt;- c(1, 2, 3, \"dog\") # 文字列が交じると文字列のベクターになる\n\nvec_n\n## [1] 1 2 3 4\n\nvec_c\n## [1] \"dog\"   \"cat\"   \"pig\"   \"horse\"\n\nvec_temp\n## [1] \"1\"   \"2\"   \"3\"   \"dog\"\n\n\nRでは数値1つや文字列1つの要素も、ベクターとして取り扱われます。ですので、Rのオブジェクトの最小単位はベクターとなります。要素が1つであれば、c関数でつなぎ合わせる必要はありません。\n\n1 # 数字1つでもベクター\n## [1] 1\n\n\"Hello world\" # 文字列1つでもベクター\n## [1] \"Hello world\"\n\n\n\n\n\n\n\n本文でのvectorの表記について\n\n\n\n\n\nvectorはベクトルと表記されることもあります。この文書では、Rのオブジェクトをベクター、方向と大きさを持つ量のことをベクトルと表記することとします。\n\n\n\n\n3.5.1.1 ベクターに要素を追加する\nベクターに要素を追加するために、append関数というものが用意されています。しかし、上記のc関数でもベクターに要素を追加することができます。\nappend関数では位置を特定して要素を追加することができますが、位置を特定して要素を追加することはまれです。\n\n\n\nベクターに要素を追加する\n\nappend(vec_n, 5) # 上の数値ベクターに5を追加\n## [1] 1 2 3 4 5\n\nc(vec_n, 5) # 上と同じ\n## [1] 1 2 3 4 5\n\n\n\n\n3.5.1.2 ベクターの要素を取り出す\nベクターの要素を取り出すときには、インデックスというものを用います。インデックスとは、ベクターなどの複数の値を取り扱うオブジェクトにおいて、値のある位置を示す数値のことです。インデックスはベクターの変数の後に、四角カッコ（[ ]）に数値を入れることで指定することができます。Rではインデックスは1から始まります。\n\n\n\n図3：ベクターとインデックス\n\n\n\n\n\nベクターの要素をインデックスで取り出す\n\nvec &lt;- c(4, 3, 2, 1) # 数値のベクターを作成する\nvec[1] # インデックス1には4が入っている\n## [1] 4\n\nvec[3] # インデックス3には2が入っている\n## [1] 2\n\n\n\n\n\n\n\n\n他言語でのインデックス\n\n\n\n\n\n多くのプログラミング言語では、インデックスは0から始まります。インデックスが1から始まるプログラミング言語はまれです。\n\n\n\n\n\n3.5.1.3 ベクターの要素の置き換え\nベクターの要素を置き換えるときには、置き換えたいベクターのインデックスを指定し、数値などを代入します。この時、数値のベクターの要素を文字列に置き換えると、ベクター全体が文字列に置き換わるので注意して下さい。\n\n\n\nベクターの要素を置き換える\n\nvec # 数値のベクター\n## [1] 4 3 2 1\n\nvec[3] &lt;- 5 # インデックス3の数値を5に置き換える\nvec # 3番めが2から5に置き換わる\n## [1] 4 3 5 1\n\nvec[4] &lt;- \"dog\" # インデックス4の数値を\"dog\"（文字列）に置き換える\nvec # ベクターはすべて文字列になる\n## [1] \"4\"   \"3\"   \"5\"   \"dog\"\n\n\n\n\n3.5.1.4 ベクターの要素を取り除く\nベクターの要素を取り除くときには、ベクターのインデックスをマイナスで指定します。マイナスのインデックスで指定した要素は取り除かれ、ベクターの長さが短くなります。\n\n\n\nベクターの要素を取り除く\n\nvec\n## [1] \"4\"   \"3\"   \"5\"   \"dog\"\nvec[-3] # インデックス3の要素（5）を取り除く\n## [1] \"4\"   \"3\"   \"dog\"\n\n\n\n\n3.5.1.5 ベクターの演算\nベクターは、そのまま演算に用いることができます。数値のベクターに数値を足せば、ベクターのすべての要素に数値が足されます。文字列のベクターにpaste関数で文字を継ぎ足せば、すべての要素に文字が継ぎ足されます。\n\n\n\nベクターを演算に用いる\n\nvec_n # 数値のベクター\n## [1] 1 2 3 4\nvec_n + 5 # 数値のベクターに5を足すと、すべての要素に5が足される\n## [1] 6 7 8 9\n\nvec_c # 文字のベクター\n## [1] \"dog\"   \"cat\"   \"pig\"   \"horse\"\npaste(vec_c, \"is an animal.\") # 文字のベクターにpaste関数で文字をつなぎ合わせる\n## [1] \"dog is an animal.\"   \"cat is an animal.\"   \"pig is an animal.\"  \n## [4] \"horse is an animal.\"\n\n\nベクターについては11章でさらに詳しく説明します。\n\n\n\n3.5.2 因子（factor）\n因子（factor）はR以外のプログラミング言語にはないクラスの一つです。因子とは、カテゴリを表すときに用いるクラスです。カテゴリとは、例えば男性/女性や、成人/未成年、喫煙者/非喫煙者などの、そのデータの性質を表す要素のことを指します。統計では、例えば男性と女性で分けて数値を集計する、といったシチュエーションがたくさんあります。このように、カテゴリごとの集計や統計を行いやすくするために準備されているクラスが因子です。因子はfactor関数を用いて作成します。\n\n\n\n因子型（factor）\n\nfactor(\"male\") # 男性を示す因子\n## [1] male\n## Levels: male\n\nclass(factor(\"male\")) # 因子のクラスはfactor\n## [1] \"factor\"\n\n\n\n3.5.2.1 因子のレベル（levels）\n因子には、レベル（levels）というアトリビュートが付いています。因子はカテゴリを示すものですので、通常1つだけで用いることはありません（カテゴリが1つだけであれば、カテゴリ分けする必要がありません）。つまり、因子は複数の要素を持つベクターとして作成することになります。このときのベクター内の各カテゴリ（男性・女性など）のことをレベルと呼びます。因子については10章で詳しく説明します。\n\n\n\n3.5.3 リスト（list）\n統計の計算をしていると、複数の計算結果をまとめて取り扱いたい、という場合があります。ベクターは1次元のオブジェクトで、かつすべての要素のデータ型が同じですので、ベクターでは型や長さの違う、様々な結果を一度に取り扱うことはできません。このような、型の違うデータを一度に取り扱うときに用いられるのが、リスト（list）と呼ばれるオブジェクトです。リストは、様々なオブジェクトをまとめて一つにしたようなデータ構造を持ちます。リストを作成するときには、list関数を用います。\n\n\n\nリスト（list）の作成\n\nvec1 &lt;- c(1, 2, 3, 4) # 数値のベクター\nvec2 &lt;- c(\"dog\", \"cat\", \"pig\", \"horse\") # 文字列のベクター\nnum &lt;- 10 # 数値\nchar_temp &lt;- \"Hello world\" # 文字列\n\nlist_temp &lt;- list(vec1, vec2, num, char_temp) # 色々な要素をリストにまとめる\nlist_temp # まとめたリストを表示\n## [[1]]\n## [1] 1 2 3 4\n## \n## [[2]]\n## [1] \"dog\"   \"cat\"   \"pig\"   \"horse\"\n## \n## [[3]]\n## [1] 10\n## \n## [[4]]\n## [1] \"Hello world\"\n\n\n\n3.5.3.1 リストの要素を取り出す\nリストの要素を取り出す場合には、ベクターと同様にインデックスを用います。ただし、リストのインデックスは多層化、ネストされているため、呼び出しはやや複雑です。リストの要素を取り出すときには、四角カッコを2重にして用います（[[ ]]）。[[1]]で呼び出すと、リストの1番目の要素を呼び出すことになります。ベクターと同様に[1]で呼び出すと、リストの1番目の要素を、リストとして呼び出すことになり、要素までたどり着けません。\n\n\n\nリストの要素を取り出す\n\nlist_temp[[1]] # リストの1番目の要素を取り出す\n## [1] 1 2 3 4\n\nlist_temp[[2]] # 2番目の要素を取り出す\n## [1] \"dog\"   \"cat\"   \"pig\"   \"horse\"\n\nlist_temp[1] # リストの1番目の要素を、リストとして取り出す\n## [[1]]\n## [1] 1 2 3 4\n\nlist_temp[[1]][1] # リストの1番目の要素（ベクター）の、1番目の要素を取り出す\n## [1] 1\n\n\nリストについては、12章で詳しく説明します。\n\n\n\n3.5.4 データフレーム（data.frame）\nデータフレーム（data.frame）はExcelの表のように、行と列を持ち、長方形の形に整形された表形式のオブジェクトです。データフレームはExcelの表のように取り扱うことができます。\nデータフレームは縦方向（列）に同じデータ型を持つ、ベクターの集合になっています。データフレームは横方向（行）には異なる型を持つことができますが、縦方向（列）は必ず同じ型を持つ必要があります。列はベクターですので、ベクターと同じように数値の列の1つのデータを文字列に置き換えると、その列のデータが全て文字列に変換されるという特徴があります。\nデータフレームはdata.frame関数を用いて作ることができます。データフレームを作成するときには、「列名」=「列の要素」という形でカッコの中に入力します。\n\n\n\nデータフレームの作成\n\nd &lt;- data.frame( # データフレームを作成する（各列を同じ長さにする）\n  number = c(1, 2, 3, 4), # 1列目は数値\n  animal = c(\"dog\", \"cat\", \"pig\", \"horse\"), # 2列目と3列目は動物と果物\n  fruits = c(\"apple\", \"orange\", \"banana\", \"grape\")\n)\n\nd # データフレームの表示\n##   number animal fruits\n## 1      1    dog  apple\n## 2      2    cat orange\n## 3      3    pig banana\n## 4      4  horse  grape\n\n\n\n\n\n\n\n\nデータフレームとリスト\n\n\n\n\n\nデータフレームは同じ長さのベクターをリストにしたものです。ですので、縦（列）はベクターとして同じ型を持ちます。データフレームはリストでもあるので、リストと同じように取り扱うこともできます。\n\n\n\n\n3.5.4.1 データフレームの次元（dimension）と行数・列数\nデータフレームには、次元（dimension）という性質（アトリビュート、attribute）があります。この次元とは、行の数、列の数のことです。次元を取得する時には、dim関数を用います。また、行の数、列の数はそれぞれnrow関数、ncol関数で取得することができます。\n\n\n\nデータフレームの次元を取得する\n\ndim(d) # 次元の取得（前が行の数、後ろが列の数）\n## [1] 4 3\nnrow(d) # 行の数\n## [1] 4\nncol(d) # 列の数\n## [1] 3\n\n\n\n\n3.5.4.2 データフレームのインデックス\nベクターやリストと同じく、データフレームでもインデックスで要素を取り出すことができます。データフレームのインデックスは、[行, 列]という形で指定します。行も列も、1行目・1列目のインデックスが1となります。\nデータフレームでは、行だけ、列だけをインデックスとして指定することもできます。行だけをインデックスとして指定した時（[行, ]の形で指定）には、その行がデータフレームとして取り出されます。一方、列だけを指定した時（[, 列]の形で指定）には、その列がベクターとして取り出されます。データフレームを行と列で取り出した場合には異なるものが取り出されるので、特にデータフレームの行を取り出す際には注意が必要です。\n\n\n\nデータフレームの要素を取り出す\n\nd\n##   number animal fruits\n## 1      1    dog  apple\n## 2      2    cat orange\n## 3      3    pig banana\n## 4      4  horse  grape\n\nd[2, 3] # 2行3列目のデータを取り出す\n## [1] \"orange\"\n\nd[2, ] # 2行目を取り出す（データフレーム）\n##   number animal fruits\n## 2      2    cat orange\n\nd[, 3] # 3列目を取り出す（ベクター）\n## [1] \"apple\"  \"orange\" \"banana\" \"grape\"\n\n\nデータフレームの列は、列の名前を用いても取り出すことができます。列を取り出すときには、$（ドルマーク）に列名を繋げて記述します。\n\n\n\n列を列名で呼び出す\n\nd$number # 1列目の列名はnumber\n## [1] 1 2 3 4\n\nd$animal # 2列目の列名はanimal\n## [1] \"dog\"   \"cat\"   \"pig\"   \"horse\"\n\nd$fruits # 3列目の列名はfruits\n## [1] \"apple\"  \"orange\" \"banana\" \"grape\"\n\n\n\n\n3.5.4.3 データフレームの要素の置き換え\nデータフレームの要素の置き換えは、ベクターと同じように、置き換えたい場所のインデックスを指定して、値を代入する形で行います。この時、その置き換える列の型と代入するデータの型が異なると、列の型がすべて置き換わることがあるので注意が必要です。\n\n\n\nデータフレームの要素を置き換える\n\nd[2, 3] &lt;- \"peach\" # 2行3列目の要素をpeachに置き換える\nd # 2行3列目がpeachに置き換わる\n##   number animal fruits\n## 1      1    dog  apple\n## 2      2    cat  peach\n## 3      3    pig banana\n## 4      4  horse  grape\n\nd[2, 1] &lt;- \"tomato\" # 2行1列目をtomato（文字列）に置き換える\nd # 2行1列目がtomatoに置き換わる\n##   number animal fruits\n## 1      1    dog  apple\n## 2 tomato    cat  peach\n## 3      3    pig banana\n## 4      4  horse  grape\n\nmode(d[, 1]) # 1列目が文字列に置き換わる\n## [1] \"character\"\n\n\n\n\n3.5.4.4 データフレームの行・列の削除\nデータフレームの行や列を削除する場合には、ベクターと同じように、インデックスをマイナスで与えます。インデックスをマイナスで指定することで、そのインデックスの行・列を取り除くことができます。ただし、データフレームの1つの要素だけを削除することはできません（指定した行・列がまるごと削除されます）。1つの要素だけを取り除く場合には、その要素のインデックスに対してNAを代入するとよいでしょう。\n\n\n\nデータフレームの行・列を削除する\n\nd # 元々のデータフレームは4行3列\n##   number animal fruits\n## 1      1    dog  apple\n## 2 tomato    cat  peach\n## 3      3    pig banana\n## 4      4  horse  grape\n\nd[-1, ] # 1行目を削除\n##   number animal fruits\n## 2 tomato    cat  peach\n## 3      3    pig banana\n## 4      4  horse  grape\n\nd[, -1] # 1列目を削除\n##   animal fruits\n## 1    dog  apple\n## 2    cat  peach\n## 3    pig banana\n## 4  horse  grape\n\nd[-2, -3] # 2行目と3列目を削除\n##   number animal\n## 1      1    dog\n## 3      3    pig\n## 4      4  horse\n\nd[2, 3] &lt;- NA # 1要素だけを取り除くときは、NAを代入する\n\n\n\n\n\n3.5.5 行列（matrix）\n行列（matrix）は、線形代数（高校数学での行列計算）に用いるものです。行列は基本的には一つの型の要素からなる、行と列のあるオブジェクトです。行列はデータフレームとよく似ていますが、データフレームが列方向のベクターのリストであるのに対し、行列は次元（dimension）を持つベクターに近いものとなります。\nRで行列を作成するときには、matrix関数を用います。matrix関数では、カッコの中に、ベクター、行数、列数を指定する数値を与えます。\n\n\n\n行列を作成する\n\n# 2行3列の行列\nmat &lt;- matrix(c(1,2,3,4,5,6), nrow=2, ncol=3) # nrowは行数、ncolは列数\nmat\n##      [,1] [,2] [,3]\n## [1,]    1    3    5\n## [2,]    2    4    6\n\n\n\n3.5.5.1 行列の次元とインデックス\n行列の次元とインデックスは、データフレームとほぼ同じように取り扱うことができます。行列の行・列に名前をつけることもできます。従って、列を取り出すときに列名を利用することもできます。取り出したものはいずれもベクターになります。要素・行・列の削除もデータフレームと同じ方法で行います。\n\n\n\n行列の要素の取り出し\n\nmat[1, 1] # 1行1列目の要素\n## [1] 1\n\nmat[1, ] # 1行目の要素（ベクター）\n## [1] 1 3 5\n\nmat[, 1] # 1列目の要素（ベクター）\n## [1] 1 2\n\ndim(mat) # matのdimensionを表示\n## [1] 2 3\n\nnrow(mat) # matの行数を表示\n## [1] 2\n\nncol(mat) # matの列数を表示\n## [1] 3\n\n\n\n\n3.5.5.2 行列の演算\nデータフレームとは異なり、数値の行列は演算に用いることができます。行列（線形代数）の計算のために、Rには行列積、外積、クロネッカー積に対応する演算子が準備されています。\n\n\n\n表4：Rで使える行列の演算子\n\n\n行列の演算子\n演算子の意味\n\n\n\n\n%*%\n行列の積\n\n\n%o%\n外積\n\n\n%x%\nクロネッカー積\n\n\n\n\n\n\n\n\n行列の演算\n\nmat2 &lt;- matrix(c(1, 2, 3, 4, 5, 6), nrow=3, ncol=2)\n\nmat %*% mat2 # 行列の積\n##      [,1] [,2]\n## [1,]   22   49\n## [2,]   28   64\n\nmat %o% mat2 # 外積\n## , , 1, 1\n## \n##      [,1] [,2] [,3]\n## [1,]    1    3    5\n## [2,]    2    4    6\n## \n## , , 2, 1\n## \n##      [,1] [,2] [,3]\n## [1,]    2    6   10\n## [2,]    4    8   12\n## \n## , , 3, 1\n## \n##      [,1] [,2] [,3]\n## [1,]    3    9   15\n## [2,]    6   12   18\n## \n## , , 1, 2\n## \n##      [,1] [,2] [,3]\n## [1,]    4   12   20\n## [2,]    8   16   24\n## \n## , , 2, 2\n## \n##      [,1] [,2] [,3]\n## [1,]    5   15   25\n## [2,]   10   20   30\n## \n## , , 3, 2\n## \n##      [,1] [,2] [,3]\n## [1,]    6   18   30\n## [2,]   12   24   36\n\nmat %x% mat2 # クロネッカー積\n##      [,1] [,2] [,3] [,4] [,5] [,6]\n## [1,]    1    4    3   12    5   20\n## [2,]    2    5    6   15   10   25\n## [3,]    3    6    9   18   15   30\n## [4,]    2    8    4   16    6   24\n## [5,]    4   10    8   20   12   30\n## [6,]    6   12   12   24   18   36\n\n\n\n\n3.5.5.3 3次元以上のオブジェクト：array\n行列はベクターに次元を2つ（行と列）与えたものですが、3次元以上の次元を与えることもできます。このような3次元以上のデータを取り扱う場合には、arrayというオブジェクトを使用します。arrayはarray関数で作成することができ、各次元の数（行数、列数に当たるもの）をベクターで与えます。統計やデータ解析で3次元以上のデータを取り扱うことは比較的まれです。\n\n\n\narrayを作成する\n\narray(c(1, 2, 3, 4, 5, 6, 7, 8), dim = c(2, 2, 2)) # 2行2列2シートの行列\n## , , 1\n## \n##      [,1] [,2]\n## [1,]    1    3\n## [2,]    2    4\n## \n## , , 2\n## \n##      [,1] [,2]\n## [1,]    5    7\n## [2,]    6    8\n\n\n\n\n\n3.5.6 その他のオブジェクト\nRに基本的に備わっているオブジェクトとして、ベクター、リスト、データフレーム、行列の他に、時系列（time series、ts）というオブジェクトがあります。時系列とは、例えば株価や為替相場の時間変化のような、時間とともに定期的に記録されたデータのことを指します。時系列はクラスとして設定されており、中身はベクターです。\n\n\n\n時系列データ（ts）\n\nco2[1:10] # 1959年からのCO2濃度の推移\n##  [1] 315.42 316.31 316.50 317.56 318.13 318.00 316.39 314.65 313.68 313.18\n\nclass(co2) # クラスはts\n## [1] \"ts\"\n\ntypeof(co2) # 型はdouble\n## [1] \"double\"",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>オブジェクトと変数・定数</span>"
    ]
  },
  {
    "objectID": "chapter3.html#関数",
    "href": "chapter3.html#関数",
    "title": "3  オブジェクトと変数・定数",
    "section": "3.6 関数",
    "text": "3.6 関数\nここまでに、mode関数、typeof関数、class関数、c関数、list関数、data.frame関数、matrix関数など、様々な関数を用いて、オブジェクトの型やクラスを調べたり、ベクターやリストなどを作成してきました。R言語の関数とは、オブジェクトに一定の演算を加えて、結果を表示するオブジェクトのことを指します。関数のクラスはfunction（関数）、型もfunctionです。\n\n\n\nオブジェクトとしての関数\n\nclass(typeof) # 関数のクラスはfunction\n## [1] \"function\"\n\nmode(typeof) # 関数の型もfunction\n## [1] \"function\"\n\n\nRでの関数は、引数と呼ばれる、カッコの中に記載されたオブジェクトに対して、一定の演算を加えるものです。Excelの関数をイメージしていただければ理解しやすいと思います。関数のイメージを図にすると、以下のようになります。\n\n\n\n図4：関数のイメージ図\n\n\nRにはmean関数という、数値の平均値を表示してくれる関数があります。上の図では、ベクターである、c(5, 10, 15)を引数として与えると、mean関数は引数を読み取って平均値を計算し、平均値である10を表示してくれます。この、表示される関数の計算結果のことを、返り値と呼びます。\n\n\n\n関数、引数と返り値\n\nvec &lt;- c(5, 10, 15) # 引数とするベクター\nmean(vec) # mean関数に引数vecを与えると、10が返り値として返ってくる\n## [1] 10\n\n\nRには、上記の関数以外にも、数値や文字列、データフレームを演算するための関数を数多く備えています。\n\n\n\n代表的な関数と、関数としての演算子\n\nsd(vec) # 標準偏差を計算する関数\n## [1] 5\n\nmedian(vec) # 中央値を計算する関数\n## [1] 10\n\nlog10(vec) # 常用対数を計算する関数\n## [1] 0.698970 1.000000 1.176091\n\nexp(vec) # ネイピア数の指数を計算する関数\n## [1]     148.4132   22026.4658 3269017.3725\n\nmode(`+`) # 演算子の+の型はfunction（関数）\n## [1] \"function\"\n\n`+`(2, 3) # 関数なので、引数を2つ取ると足し算になる\n## [1] 5\n\nmode(`[`) # インデックスも関数\n## [1] \"function\"\n\nmode(`if`) # if（条件分岐）も関数\n## [1] \"function\"\n\nmode(`for`) # for（繰り返し文）も関数\n## [1] \"function\"\n\n\n\n\n\n\n\n\nRでの関数\n\n\n\n\n\nRでは、演算子やインデックス指定、条件分岐、繰り返し文も関数です。\n\n\n\nこのように、Rでは多くの演算を関数によって処理しています。この性質から、Rは関数型言語であるとされています。\n\n\n\n\n\n\nRと関数型言語\n\n\n\n\n\n正確には、Rは厳密な意味では関数型言語ではないように思います。関数型言語にはHaskellなどがありますが、関数型言語では再帰的関数（関数内で関数を呼び出す）ような処理を用いて繰り返し計算を避ける場合が多く、Rのような逐次型処理に慣れていると読みにくいコードをよく書くイメージがあります。Rでも再帰的関数を用いることはできますが、頻繁には使用されません。\n\n\n\n\n3.6.1 関数を自作する\nどのようなプログラミング言語にも、関数を自作する方法が備わっています。Rでは、function文を用いて関数を自作することができます。関数を変数に代入して用いるのが一般的な関数の作成方法です。function文の書き方は以下の通りです。\n関数名 &lt;- function(引数群){引数を使った処理}\n関数の返り値は、return関数を使って明示することもできますが、単に最後に記載したオブジェクトを返り値とすることもできます。\nまた、Rではfunctionと書く代わりに、\\（バックスラッシュ）をfunctionの代わりに用いることもできます。\n作成した関数を用いて演算するときには、「関数名(引数)」という形で表記します。これはmode関数やclass関数の使い方と同じです。\n\n\n\n関数を自作する\n\n# 引数をそのまま帰す関数\nreturn_selfx &lt;- function(x){return(x)} # 返り値をreturn関数で表示\nreturn_selfy &lt;- function(y){y} # 最後に返り値を書く\nreturn_selfz &lt;- \\(z){z} # functionの代わりにバックスラッシュを用いる\n\n# どれも同じ演算をする関数になる\nreturn_selfx(1)\n## [1] 1\n\nreturn_selfy(1)\n## [1] 1\n\nreturn_selfz(1)\n## [1] 1\n\n\n実際に関数を作るときには、もう少し複雑な処理を{ }（中かっこ）の中に書きます。処理は一つ一つ改行しながら書き、最後に返り値を書きます。中かっこの中で改行を行っても問題ありませんが、引数のかっこ（「)」）の後にかっこの前側（「{」）が記載されている必要があります。\n\n\n\n関数内の処理の書き方\n\n# sum2関数を作成する\nsum2 &lt;- function(x, y, z){ # 引数はx、y、zの3つ\n  sum_of_xyz &lt;- x + y + z # 引数を足し算する\n  sum_of_xyz # 足し算したものを返り値にする\n}\n\nsum2(x = 1, y = 2, z = 3)\n## [1] 6\n\n\n上の例のように、引数を指定するときには、引数の種類を明示的に記載することもできます。明示的に記載する場合には、「引数名=値」という形で書きます。引数名を省略した場合には、記載した引数の順番に従って、引数が用いられます。\n関数を作成するときには、引数のデフォルト値を設定しておくこともできます。デフォルト値が設定されている関数では、その引数を入力しなかったときには、自動的に引数にデフォルト値が入ります。\n\n\n\n引数のデフォルト値と省略\n\nsum3 &lt;- function(x, y = 1){ # yのデフォルト値を1とする\n  return(x + y)\n}\n\nsum3(x = 1, y = 2) # 引数を明示的に記載\n## [1] 3\n\nsum3(1, 2) # xに1、yに2が入る\n## [1] 3\n\nsum3(1) # 引数yが省略されているので、デフォルト値（1）が用いられる\n## [1] 2\n\nsum3(y = 1) # xにはデフォルトが設定されていないので、省略できない\n## Error in sum3(y = 1): argument \"x\" is missing, with no default",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>オブジェクトと変数・定数</span>"
    ]
  },
  {
    "objectID": "chapter3.html#型クラスの確認と変換",
    "href": "chapter3.html#型クラスの確認と変換",
    "title": "3  オブジェクトと変数・定数",
    "section": "3.7 型・クラスの確認と変換",
    "text": "3.7 型・クラスの確認と変換\n\n3.7.1 型・クラスの確認：is.関数群\nRでは、型やクラスを確認するための関数として、typeof関数・mode関数・class関数以外に、is.関数というものを備えています。is.関数を用いると、オブジェクトの型が、ある型と一致しているかどうかを確認することができます。引数が数値であるかどうかは、is.numeric関数、is.integer関数、is.double関数を用いて確認することができます。例えばis.numeric(1)はTRUEを返し、is.numeric(\"dog\")はFALSEを返します。このis.関数には、文字列やNA、NaN等を確認する関数もあります。is.関数を以下の表2に示します。\n\n\n\n表2：xの型の確認に用いる関数\n\n\nis.関数名\nチェックする型\n\n\n\n\nis.numeric(x)\n数値型\n\n\nis.integer(x)\n整数型\n\n\nis.double(x)\ndouble型\n\n\nis.complex\n複素数型\n\n\nis.character(x)\n文字列型\n\n\nis.logical(x)\n真偽型\n\n\nis.factor(x)\n因子型\n\n\nis.atomic(x)\nベクター\n\n\nis.list(x)\nリスト\n\n\nis.matrix(x)\nマトリックス\n\n\nis.data.frame(x)\nデータフレーム\n\n\nis.na(x)\nNA\n\n\nis.nan(x)\nNaN\n\n\nis.null(x)\nNULL\n\n\nis.infinite(x)\n無限大\n\n\n\n\n\nis.関数の中では、is.na関数の使用頻度が高いです。is.na関数を用いると、ベクターやデータフレームからNAを含む要素をうまく取り除くことができます。\n\n\n\nis.関数群\n\nc(is.numeric(1), is.numeric(\"1\")) # 文字列（\"1\"）は数値ではない\n## [1]  TRUE FALSE\n\nc(is.integer(1L), is.integer(1)) # Lが付いていないとdoubleになる\n## [1]  TRUE FALSE\n\nc(is.double(1), is.double(1L)) # Lが付いているとintegerになる\n## [1]  TRUE FALSE\n\nc(is.complex(1+1i), is.complex(1+1)) # iがあると複素数になる\n## [1]  TRUE FALSE\n\nc(is.character(\"dog\"), is.character(1)) # 数値は文字列ではない\n## [1]  TRUE FALSE\n\n# 0はFALSE扱いされるが、logicalではない\nc(is.logical(T), is.logical(0), is.logical(\"dog\")) \n## [1]  TRUE FALSE FALSE\n\nc(is.factor(factor(1)), is.factor(1))\n## [1]  TRUE FALSE\n\nc(is.atomic(1), is.atomic(list(1))) # ベクターはTRUE、リストはFALSE\n## [1]  TRUE FALSE\n\nc(is.vector(1), is.vector(list(1))) # is.vectorもあるが、リストもTRUEになる\n## [1] TRUE TRUE\n\nc(is.list(list(1)), is.list(1))# ベクターはFALSE、リストはTRUE\n## [1]  TRUE FALSE\n\nc(is.matrix(matrix(1, ncol=1)), is.matrix(1))\n## [1]  TRUE FALSE\n\nc(is.data.frame(data.frame(1)), is.data.frame(list(1))) # リストはFALSE\n## [1]  TRUE FALSE\n\n# NAとNaNはNA扱い、NULLは無いもの扱い\nc(is.na(NA), is.na(1), is.na(NaN), is.na(Inf), is.na(NULL)) \n## [1]  TRUE FALSE  TRUE FALSE\n\n# NULLは無いもの扱い\nc(is.nan(NA), is.nan(1), is.nan(NaN), is.nan(Inf), is.nan(NULL))\n## [1] FALSE FALSE  TRUE FALSE\n\n# NULLを評価する\nc(is.null(NA), is.null(1), is.null(NaN), is.null(Inf), is.null(NULL)) \n## [1] FALSE FALSE FALSE FALSE  TRUE\n\n# NULLは無いもの扱い\nc(is.infinite(NA), is.infinite(1), is.infinite(NaN), is.infinite(Inf), is.infinite(NULL)) \n## [1] FALSE FALSE FALSE  TRUE\n\n\n\n\n\n\n\n\natomicなベクター\n\n\n\n\n\nベクターはis.atomic関数で評価します。これは、ベクターのことをatomic vectorと呼ぶためです。atomic vectorはvectorと同じ意味を持ちます。エラーやメッセージには時々このatomic vectorという表記が出てきますが、これは通常のベクターのことを述べているだけで、atomic vectorという特別なものがあるわけではありません。\n\n\n\n\n\n3.7.2 型・クラスの変換：as.関数群\nis.関数はデータのクラスや型をチェックし、論理型を返す関数です。Rには、関数名がよく似たas.関数があります。as.関数は、引数の型を指定した型に変換する関数です。例えば、as.numeric関数は引数をnumericに変換する関数です。as.関数の一覧を以下の表3に示します。\n\n\n\n表3：xの型の変換に用いる関数\n\n\nas.関数名\n変換する型\n\n\n\n\nas.numeric(x)\n数値型に変換\n\n\nas.integer(x)\n整数型に変換\n\n\nas.double(x)\ndouble型に変換\n\n\nas.complex\n複素数型に変換\n\n\nas.character(x)\n文字列型に変換\n\n\nas.logical(x)\n真偽型に変換\n\n\nas.factor(x)\n因子型に変換\n\n\nas.Date\n日時型に変換\n\n\nas.POSIXct\nPOSIXct型に変換\n\n\nas.POSIXlt\nPOSIXlt型に変換\n\n\nas.list(x)\nリストに変換\n\n\nas.matrix(x)\nマトリックスに変換\n\n\nas.data.frame(x)\nデータフレームに変換\n\n\nas.null(x)\nNULLに変換\n\n\n\n\n\n\n\n\nas.関数群\n\nas.numeric(TRUE)\n## [1] 1\n\nas.integer(1.1)\n## [1] 1\n\nas.double(1L)\n## [1] 1\n\nas.complex(1)\n## [1] 1+0i\n\nas.character(1)\n## [1] \"1\"\n\nc(as.logical(1), as.logical(0))\n## [1]  TRUE FALSE\n\nas.factor(c(\"dog\", \"cat\"))\n## [1] dog cat\n## Levels: cat dog\n\nas.Date(\"2022-02-22\") # わかりにくいが、日付型になっている\n## [1] \"2022-02-22\"\n\n# わかりにくいが、日時型になっている\nas.POSIXct(\"2022-02-22 15:00:00\")\n## [1] \"2022-02-22 15:00:00 +09\"\n\nas.POSIXlt(\"2022-02-22 15:00:00\")\n## [1] \"2022-02-22 15:00:00 +09\"\n\nas.list(1)\n## [[1]]\n## [1] 1\n\nas.data.frame(list(1, 1))\n##   X1 X1.1\n## 1  1    1\n\nas.matrix(data.frame(x=1, y=1))\n##      x y\n## [1,] 1 1\n\nas.null(1)\n## NULL",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>オブジェクトと変数・定数</span>"
    ]
  },
  {
    "objectID": "chapter3.html#naの取り扱い",
    "href": "chapter3.html#naの取り扱い",
    "title": "3  オブジェクトと変数・定数",
    "section": "3.8 NAの取り扱い",
    "text": "3.8 NAの取り扱い\nRでは、データに欠測値（NA）、計算できない値（NaN）、空の値（NULL）、無限大（Inf）が含まれることがあります。これらのうち、NAとNaNを取り除く関数がna.omit関数です。na.omit関数はベクターやデータフレームを引数に取り、NAとNaNを取り除いてくれる関数です。NAと異なり、Infは取り除かれません。\n\n\n\nna.omit関数\n\nvec &lt;- c(1, NA, NaN, NULL, Inf) # NULLは要素として含められない\nvec\n## [1]   1  NA NaN Inf\n\nna.omit(vec)\n## [1]   1 Inf\n## attr(,\"na.action\")\n## [1] 2 3\n## attr(,\"class\")\n## [1] \"omit\"",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>オブジェクトと変数・定数</span>"
    ]
  },
  {
    "objectID": "chapter3.html#予約語",
    "href": "chapter3.html#予約語",
    "title": "3  オブジェクトと変数・定数",
    "section": "3.9 予約語",
    "text": "3.9 予約語\n上の例では関数や変数に名前をつけていますが、関数名や変数名の付け方にはルールがあります。\n\n名前の始めに数値（1、2など）をつけることはできない\n名前の始めにアンダーバー（_）を用いることはできない\n大文字と小文字は区別される（SUMとsumは別扱い）\n演算子や記号（!や?、+、-、# など）は使えない\n予約語を用いることはできない\n\n予約語（reserved word）とは、R言語がすでに役割を与えているために、関数名や変数名には使用できない文字列です。Rで設定されている予約語は以下の通りです。\n\nif\nelse\nrepeat\nwhile\nfunction\n\nfor\nin\nnext\nbreak\nTRUE\nFALSE\nNULL\nInf\nNaN\nNA\nNA_integer_\nNA_real_\nNA_complex_\nNA_character_\n…\n..1\n..2\n\n\n\n\n\n\n\nRでのピリオドの取り扱い\n\n\n\n\n\nRでは、ピリオド（.）が予約語に含まれていないため、変数名にピリオドを利用することができます。ただし、他の言語ではこのピリオドをメソッド（method）という、関数の仲間のようなものに用いることが多く、勘違いを起こしやすい表記になります。Rでも変数名にピリオドを用いないほうがよいとされています。",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>オブジェクトと変数・定数</span>"
    ]
  },
  {
    "objectID": "chapter3.html#ヘルプ",
    "href": "chapter3.html#ヘルプ",
    "title": "3  オブジェクトと変数・定数",
    "section": "3.10 ヘルプ",
    "text": "3.10 ヘルプ\nヘルプを呼び出すことでRの関数の使い方を確認することができます。ヘルプは関数名の前に?を付けて実行することで呼び出すことができます。RStudioでは、右下のパネルにヘルプの内容が表示されます。\n\n\n\nヘルプの呼び出し\n\n?mean # mean関数のヘルプを呼び出す\n\n\n\n\n\n\n\n図1：コンパイルと機械語への変換\n図2：変数のイメージ\n図3：ベクターとインデックス\n図4：関数のイメージ図",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>オブジェクトと変数・定数</span>"
    ]
  },
  {
    "objectID": "chapter4.html",
    "href": "chapter4.html",
    "title": "4  条件判断（Control structures）",
    "section": "",
    "text": "4.1 条件判断とは？\nプログラミングでは、ある条件のときはこの処理、別の条件のときはこの処理…、といった具合に、条件によって行う処理を変えたいことがよくあります。例えば、じゃんけんでは出した手の条件によって勝ち・負け・引き分けという3つの処理を行うことになります。このように、条件によって処理を変えることを、条件判断と呼びます。",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>条件判断（Control structures）</span>"
    ]
  },
  {
    "objectID": "chapter4.html#条件と論理型logical",
    "href": "chapter4.html#条件と論理型logical",
    "title": "4  条件判断（Control structures）",
    "section": "4.2 条件と論理型（logical）",
    "text": "4.2 条件と論理型（logical）\n条件として用いられるのは、論理型（logical）です。論理型はTRUE（真）とFALSE（偽）の2つの値を持ちます。論理型はそれそのものを用いる場合と、比較演算子の演算結果として得る場合があります。Rでは、TRUEをT、FALSEをFと表記することができます。\n\n\n\n論理型\n\nTRUE\n## [1] TRUE\n\nFALSE\n## [1] FALSE\n\nT\n## [1] TRUE\n\nF\n## [1] FALSE\n\nc(T, F, T, F) # logicalはベクターにもできる\n## [1]  TRUE FALSE  TRUE FALSE\n\n1 &lt; 3 # 3は1より大きいのでTRUE\n## [1] TRUE\n\n1 &gt; 3 # 1は3より大きくないのでFALSE\n## [1] FALSE",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>条件判断（Control structures）</span>"
    ]
  },
  {
    "objectID": "chapter4.html#数値としての論理型",
    "href": "chapter4.html#数値としての論理型",
    "title": "4  条件判断（Control structures）",
    "section": "4.3 数値としての論理型",
    "text": "4.3 数値としての論理型\n論理型は、Rの内部では数字として取り扱われています。RではTRUEは1、FALSEは0と同一です。ですので、ベクター中のTRUEの数を足し算で計算することができます。また、0以外がTRUE、0がFALSEとして扱われる場合もあります。条件判断では0をFALSEとして用いる場合もあります。\n\n\n\n数値としての真偽値\n\nT + T + F # 足し算すると2が返ってくる\n## [1] 2\n\nvec &lt;- c(T, T, F, T, F, T, F)\nsum(vec) # sumはベクターの要素を足し算する関数\n## [1] 4\n\n\n\n\n\n\n\n\n他言語でのTRUEとFALSEの数値変換\n\n\n\n\n\nRではTRUEが1、FALSEが0ですが、他の言語ではFALSEが-1のものもあります。言語によりTRUE/FALSEの仕様は異なります。",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>条件判断（Control structures）</span>"
    ]
  },
  {
    "objectID": "chapter4.html#論理演算子",
    "href": "chapter4.html#論理演算子",
    "title": "4  条件判断（Control structures）",
    "section": "4.4 論理演算子",
    "text": "4.4 論理演算子\n論理型は、論理演算子による計算に使うことができます。Rでの論理演算子は&、&&、|、||の4つです。このうち、&&と||は、ベクターの始めの値だけを評価するという特徴を持っています（Rのバージョン4.3以降ではベクターを比較するとエラーが出ます）。&&と||を用いるとプログラムが予想外の挙動を取ることがあるので、できるだけ&と|だけを用いたほうがよいでしょう。RにはNAND（否定論理積）、NOR（否定論理和）などを表す専用の論理演算子はありませんが、XOR（排他的論理和）を表す関数（xor関数）はあります。XORは2つの論理型に対し、どちらかがTRUEならTRUEを、両方がFALSEならFALSEを返す演算子です。\n\n\n\n表1：Rで使える論理演算子\n\n\n論理演算子\n演算子の意味\n\n\n\n\n&\n論理積（AかつB）\n\n\n&&\n論理積（ベクターの始めの要素のみ評価）\n\n\n|\n論理和（AまたはB）\n\n\n||\n論理和（ベクターの始めの要素のみ評価）\n\n\n!\n否定演算子（真偽を反転）\n\n\nxor\n排他的論理和\n\n\nany\nいずれかが真の時に真を返す\n\n\nall\nすべてが真の時に真を返す\n\n\n\n\n\n\n\n\n論理演算子による演算\n\nlogic1 &lt;- c(T, F)\nlogic2 &lt;- c(F, F)\nlogic1 & logic2 # & は論理積（AND）\n## [1] FALSE FALSE\n\nlogic1 | logic2 # | は論理和（OR）\n## [1]  TRUE FALSE\n\nlogic1 && logic2 # 1番目の項目同士のみを比較する\n## Error in logic1 && logic2: 'length = 2' in coercion to 'logical(1)'\n\nlogic1 || logic2\n## Error in logic1 || logic2: 'length = 2' in coercion to 'logical(1)'\n\nxor(logic1, logic2) # 排他的論理和\n## [1]  TRUE FALSE\n\nany(logic1) # 片方がTRUEなのでTRUE\n## [1] TRUE\n\nall(logic1) # すべてがTRUEでは無いのでFALSE\n## [1] FALSE\n\n\n論理演算子として、!（エクスクラメーションマーク、否定演算子）も用いることができます。!は論理型の前に置くことで、論理型を反転（TRUEをFALSEに、FALSEをTRUEに）させます。\n\n\n\n!による論理値の反転\n\n!TRUE\n## [1] FALSE\n!FALSE\n## [1] TRUE\n\n!(1 &lt; 3)\n## [1] FALSE\n!(1 &gt; 3)\n## [1] TRUE",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>条件判断（Control structures）</span>"
    ]
  },
  {
    "objectID": "chapter4.html#条件分岐の文",
    "href": "chapter4.html#条件分岐の文",
    "title": "4  条件判断（Control structures）",
    "section": "4.5 条件分岐の文",
    "text": "4.5 条件分岐の文\n上記のように、比較演算子や論理演算子を用いると、論理型を得ることができます。この論理型に従い、行う処理を変えるものを、条件分岐と呼びます。条件分岐では、条件分岐の文（Control structures）というものが用いられます。Rでは、条件分岐の文として、if文とswitch文の2つが設定されています。\n\n\n\n表2：Rで使える条件分岐\n\n\n条件分岐\n条件分岐の形式\n\n\n\n\nif文\nif(条件式){TRUEのときの演算}else{FALSEのときの演算}\n\n\nifelse関数\nifelse(条件式, TRUEのときの演算, FALSEのときの演算)\n\n\nswitch文\nswitch(評価する値, 評価の既定値=既定値のときの演算)\n\n\n\n\n\n\n4.5.1 if文\nif文は最もシンプルな条件分岐の文です。if文では、条件式に従い、実行する処理が変わります。Rでのif文は、以下の形を取ります。\nif(条件式){TRUEのときに実施する処理}\n条件式をif()のカッコの中に書きます。if文は1行で書くこともできますし、複数行に渡って書くこともできます。複数行に処理を書くときには、中括弧（{}）を条件式の後に書き、中括弧の中に処理を書きます。\n\n\n\nif文の使い方\n\nif(TRUE) \"Hello R\" # 1行で書く場合（\"Hello R\"が返ってくる）\n## [1] \"Hello R\"\n\nif(FALSE) \"Hello FALSE\" # 条件式がFALSEなので、何も返ってこない\n\nif(TRUE){ # 複数行で書く時には中括弧（{}）を用いる\n  \"Hello R\"\n}\n## [1] \"Hello R\"\n\nif(FALSE){\"Hello FALSE\"} # 1行のif文で中括弧を使ってもよい\n\n\nif文の条件が0のときには、0がFALSEであると判断されて、処理が実行されません。一方で条件が0以外である場合には、TRUEであると判断されて処理が実行されます。if(0)とするとその処理が行われないので、Rではif(0)がコメントアウトに使われることもあります。\n\n\n\n条件式が数値の時のif文\n\nif(0){\"0はFALSEなので、これは表示されません\"}\n\nif(-1){\"-1はTRUE扱いなので、表示されます\"}\n## [1] \"-1はTRUE扱いなので、表示されます\"\n\nif(-0.005){\"0以外はTRUEとして処理されます\"}\n## [1] \"0以外はTRUEとして処理されます\"\n\n\n\n4.5.1.1 if else文\nif文ではさらに条件を分岐させることもできます。条件を追加する場合には、if文の後に、else if()を繋げます。else if()のカッコの中に2つ目の条件を書くことで、条件を分離させることができます。elseだけを書いて、if()の条件式をつけない場合には、どの条件にも合わない時に実行する処理になります。ですので、if else文は以下の形を取ります。\nif(条件式1){\n式1がTRUEのときの処理\n}else if(条件式2){\n式1がFALSE、式2がTRUEのときの処理\n}else{\n式1、2がFALSEのときの処理\n}\n\n\n\nif else文\n\nx &lt;- 2 # xは2\n\n# xは2なので、2番目の処理が返ってくる\nif(x == 1){ # =が1つだと代入になるのでエラーが出る\n  \"first\"\n} else if(x == 2){\n  \"second\"\n} else {\n  \"others\"\n}\n## [1] \"second\"\n\n\n\n\n4.5.1.2 ifelse関数\n条件分岐が2つしかない場合には、ifelse関数を用いることもできます。ifelse関数は3つの引数、「(条件式)、(TRUEのときの処理)、(FALSEのときの処理)」を取ります。条件が1つだけで、簡単な処理のみを行うのであればifelse関数で十分な場合もあります。\n\n\n\nifelse関数\n\n# TRUEなので2番目の処理が返ってくる\nifelse(1 &lt; 3, \"One is smaller than three.\", \"One is not smaller than three.\")\n## [1] \"One is smaller than three.\"\n\n# FALSEなので3番目の処理が返ってくる\nifelse(1 &gt; 3, \"One is larger than three.\", \"One is not larger than three.\") \n## [1] \"One is not larger than three.\"\n\n\n\n\n\n4.5.2 switch文\n条件式ではなく、特定の値に対応して処理を変えたい場合には、switch文を用います。switch文では、始めの引数が条件を指定する値、それに続く引数が条件に対応した処理となります。条件を指定する値には、数値または文字列を用いることができます。条件が数値の場合と文字列の場合では、やや使い方が異なります。\n\n\n\nswitch文（条件が数値のとき）\n\n# 条件が1のときは、2番目の引数の処理が返ってくる\nswitch(1, \"first\", \"second\", \"third\") \n## [1] \"first\"\n\n# 条件が2のときは、3番目の引数の処理が返ってくる\nswitch(2, \"first\", \"second\", \"third\") \n## [1] \"second\"\n\n# 条件が5のときは、6番目の引数の処理がないので何も返ってこない\nswitch(5, \"first\", \"second\", \"third\") \n\n\n\n\n\nswitch文（条件が文字列のとき）\n\n# 条件式に対応したもの（=で繋いだもの）が返ってくる\nswitch(\"dog\", dog = \"犬\", cat = \"猫\", monkey = \"猿\", pig = \"豚\")\n## [1] \"犬\"\n\nswitch(\"monkey\", dog = \"犬\", cat = \"猫\", monkey = \"猿\", pig = \"豚\")\n## [1] \"猿\"\n\n# horseは引数に登録していないので、何も返ってこない\nswitch(\"horse\", dog = \"犬\", cat = \"猫\", monkey = \"猿\", pig = \"豚\")\n\n\n\n\n\n\n\n\nライブラリで設定されている条件分岐\n\n\n\n\n\nインストールしたばかりのRでは、上記のif文、if else文、ifelse関数、switch文しか使えませんが、ライブラリというものを用いると、他の条件分岐（if_else関数やcase_which文、case_when文）などを用いることもできます。詳細については16章で説明します。",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>条件判断（Control structures）</span>"
    ]
  },
  {
    "objectID": "chapter5.html",
    "href": "chapter5.html",
    "title": "5  繰り返し文（Looping）",
    "section": "",
    "text": "5.1 for文\nfor文はRで、そして他の言語でもよく設定されている、最も典型的な繰り返し文の一つです。Rでは、for文は、\nfor(繰り返しの条件){繰り返す処理}\nという形で表記します。このうち、繰り返しの条件に関しては、\nfor(i in c(1, 2, 3, 4, 5))\nといった形で、「変数 in ベクター」という形で書きます。これは、ベクターの要素を前から順番に変数に入れていく、ということを意味しています。\nfor文での繰り返し処理\n\nfor(i in c(1, 2, 3, 4, 5)){print(i)} # ベクターの要素をiに入れて、iを表示する\n## [1] 1\n## [1] 2\n## [1] 3\n## [1] 4\n## [1] 5\n\nfor(i in c(\"dog\", \"cat\", \"pig\", \"horse\")){print(i)} # 文字列のベクターでも同じ\n## [1] \"dog\"\n## [1] \"cat\"\n## [1] \"pig\"\n## [1] \"horse\"\n上の例では、iにベクターの要素が前から順番に代入されているのがわかると思います。for文では、このinの後のベクターとして連続した整数を用いる場合が多いのですが、整数の数が多かったり、繰り返したい回数がとても多いと、いちいちc関数でベクターを作るのは大変です。Rでは、連続した数値のベクターを作る場合、「:（コロン）」を用いることができます。コロンを用いたベクターの作り方は以下の通りです。\n:（コロン）を用いたベクターの作成\n\n1:5\n## [1] 1 2 3 4 5\n\n10:20\n##  [1] 10 11 12 13 14 15 16 17 18 19 20\n\n0.5:5.5\n## [1] 0.5 1.5 2.5 3.5 4.5 5.5\nfor文はコロンを使用して、以下のような形で書くことができます。\nコロンを使ったfor文\n\nfor(i in 1:5){\n  print(i - 1)\n}\n## [1] 0\n## [1] 1\n## [1] 2\n## [1] 3\n## [1] 4\nベクターを変数としてあらかじめ準備しておけば、ベクターの要素に対して同じ処理を繰り返す事もできます。\n変数を使ったfor文\n\nvec &lt;- c(\"dog\", \"cat\", \"pig\", \"horse\")\nfor(i in vec){\n  isanimal &lt;- paste(i, \"is animal.\") # iに文字列をつなぐ\n  print(isanimal) # 文字列を繋いだものを表示する\n}\n## [1] \"dog is animal.\"\n## [1] \"cat is animal.\"\n## [1] \"pig is animal.\"\n## [1] \"horse is animal.\"\nfor文を用いれば。様々な繰り返し作業をRに行ってもらうことができます。for文とif文の組み合わせで、繰り返しの中で条件判断を行い、ベクターの要素ごとに異なる処理を行うこともできます。\nfor文を途中で止める場合にはbreakを、繰り返しをスキップするときにはnextを用います。\nfor文でのnextとbreak\n\nfor(i in 1:5){\n  if(i == 2){next} # iが2のときには繰り返しをスキップする\n  if(i == 4){break} # iが4のときには繰り返し自体を止める\n  print(i)\n}\n## [1] 1\n## [1] 3",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>繰り返し文（Looping）</span>"
    ]
  },
  {
    "objectID": "chapter5.html#for文",
    "href": "chapter5.html#for文",
    "title": "5  繰り返し文（Looping）",
    "section": "",
    "text": "print関数とイテレーターのアルファベット\n\n\n\n\n\n上のfor文で用いているprint関数は、オブジェクトを表示させるための関数です。for文の処理中でオブジェクトを表示させる場合にはprint関数を明示的に用いる必要があります。また、for文で用いる変数名にはiを用いるのが普通です。このiはイテレーター（iterator、繰り返すもの）の略だと思いますが、よくわかりません。for文の中でfor文を呼び出す、つまり入れ子（ネスト）にする場合には、i以降の変数として、j、k…とアルファベット順に使っていくことが多いです。\nfor文を入れ子にする場合には、Rでは以下のような表現を用いることができます。\n\n\n\nfor文を入れ子（ネスト）にする\n\nfor(i in c(1, 2)) for(j in c(4, 5)){\n  print(paste0(\"i=\", i, \", \", \"j=\", j))\n}\n## [1] \"i=1, j=4\"\n## [1] \"i=1, j=5\"\n## [1] \"i=2, j=4\"\n## [1] \"i=2, j=5\"\n\n# 以下も同じ内容のスクリプト\nfor(i in c(1, 2)){\n  for(j in c(4, 5)){\n    print(paste0(\"i=\", i, \", \", \"j=\", j))\n  }\n}\n## [1] \"i=1, j=4\"\n## [1] \"i=1, j=5\"\n## [1] \"i=2, j=4\"\n## [1] \"i=2, j=5\"",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>繰り返し文（Looping）</span>"
    ]
  },
  {
    "objectID": "chapter5.html#while文",
    "href": "chapter5.html#while文",
    "title": "5  繰り返し文（Looping）",
    "section": "5.2 while文",
    "text": "5.2 while文\nwhile文は、条件式に定めた条件がTRUE（真）である場合は繰り返し、FALSE（偽）になったら繰り返しを中止する、繰り返し文の一つです。while文は以下のように記述して用います。\nwhile(条件式){TRUEのときに繰り返す処理}\nwhile文では、for文のように繰り返し処理でベクターの要素を引き出すようなことはできないので、処理の中で要素を呼び出すような形を取ることが多いです。\n\n\n\nwhile文\n\nx &lt;- 1 # xは1\nwhile(x &lt; 5){ # xが5以下の時、以下の処理を繰り返す\n  print(x) # xを表示する\n  x &lt;- x + 1 # xに1を足す\n}\n## [1] 1\n## [1] 2\n## [1] 3\n## [1] 4\n\n\n\n\n\n\n\n\n変数を自身に代入する\n\n\n\n\n\nこの、「x &lt;- x + 1」のような表現はプログラミング初心者には変に感じるかもしれませんが、繰り返し文中で変数を1ずつ足して更新していく、プログラミング言語ではよく見る表現です。他の言語でも同じような書き方をすることが多く、変数に1を足すための演算子（インクリメント演算子）や1を引くための演算子（デクリメント演算子）を持つプログラミング言語も多いです（Rにはありません）。\n\n\n\nwhile文では条件がTRUEであれば繰り返しが続くため、条件がFALSEにならないような場合には、永遠に繰り返し処理を行うことになります（無限ループ）。Rで無限ループにハマったときには、慌てず騒がず、「stopボタン」を押しましょう。また、コンソールを選択し、Escキーを押すことでも無限ループを停止することができます。\n\n\n\nwhileを使ったときの無限ループ\n\nwhile(TRUE){ # 無限ループ\n  print(\"I`m looping infinitely.\")\n}\n\n\n\n\n\n図1：RstudioのStopボタン",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>繰り返し文（Looping）</span>"
    ]
  },
  {
    "objectID": "chapter5.html#repeat文",
    "href": "chapter5.html#repeat文",
    "title": "5  繰り返し文（Looping）",
    "section": "5.3 repeat文",
    "text": "5.3 repeat文\nrepeat文は、同じ処理を繰り返すときに使います。repeat文から抜けるときには、breakを実行します。breakは条件判断（if文など）を用いて実行することになります。breakがない場合には、無限ループすることになります。\n\n\n\nrepeat文による繰り返しと、breakによる中断\n\nx &lt;- 1\nrepeat{\n  x &lt;- x + 1 # printより前にxを1増やす\n  print(x)\n  if(x &gt;= 5){break} # xが5以上ならrepeatをやめる\n}\n## [1] 2\n## [1] 3\n## [1] 4\n## [1] 5\n\n\n\n\n\n\n\n\n無限ループ\n\n\n\n\n\nRでは繰り返し処理を行うこと自体が割と少ないので、無限ループに陥ることは稀です。無限ループはこのwhile/repeat文を使った時ぐらいにしか発生しませんし、他の言語と異なりwhile文やrepeat文自体使う機会が少なめです。どのようなプログラミング言語でも無限ループを起こすことは普通にあり、無限ループを止める方法は必ずありますので、無限ループでコンピュータが壊れるようなことはありません。\n\n\n\n\n\n\n\n\n図1：RstudioのStopボタン",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>繰り返し文（Looping）</span>"
    ]
  },
  {
    "objectID": "chapter6.html",
    "href": "chapter6.html",
    "title": "6  ライブラリ",
    "section": "",
    "text": "6.1 ライブラリとは？\nRは統計のプログラミング言語であり、インストールしてすぐに統計の計算を行うことができるよう設計されています。例えば、代表的な統計処理である、平均値や標準偏差の計算、t検定や分散分析、グラフの作図等は、Rをインストールし、起動した次の瞬間から実行することができます。\nしかし、この素の（nativeな）Rでは、近年開発された現代的な統計手法や、優れたデザインやインタラクティブ性を持つグラフの作成、複雑なデータの効率的な整理、Webページの作成など、現代のプログラミング言語に備わる機能のすべてを用いることはできません。\nRを含めた多くのプログラミング言語では、nativeな言語ではできない機能を後から追加することができます。この追加する機能のセットのことを、ライブラリと呼びます（パッケージと呼ぶこともあります）。\nRのライブラリは（基本的には）CRANで管理されており、審査が行われた上で登録されています。ライブラリはCRANのリポジトリ（データを格納する場所のこと）に保存されており、RのユーザーはこのCRANのリポジトリから、必要なライブラリをインストールして用いることになります。\nライブラリは、インストールしただけでは用いることができません。ライブラリを読み込み（ロード、load）、メモリ上に展開しておくことでライブラリの機能を用いることができるようになります。この読み込みはRを起動するたびに行います。ライブラリの機能は関連する関数群として実装されていますので、ロードすることでライブラリに登録されている関数を用いることができるようになります。",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ライブラリ</span>"
    ]
  },
  {
    "objectID": "chapter6.html#ライブラリとは",
    "href": "chapter6.html#ライブラリとは",
    "title": "6  ライブラリ",
    "section": "",
    "text": "ライブラリを毎回読み込む\n\n\n\n\n\nライブラリをいちいち読み込むのは面倒ではありますが、必要ないライブラリを読み込んでしまうと、その分メモリを食うことになります。必要ないライブラリは読み込まないことで、メモリを節約し、プログラムの動作を軽くすることができます。他の言語にも同様の機能が備わっており、必要なライブラリのみを読み込んで用いるのが一般的です。\nRでは、デフォルトのワーキングディレクトリに.Rprofileというファイルを保存しておけば、この中身のプログラムをR起動時に実行してくれるという仕組みがあります。.Rprofileにいつも使うライブラリをロードするように、スクリプトを準備しておいてもよいかもしれません。",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ライブラリ</span>"
    ]
  },
  {
    "objectID": "chapter6.html#ライブラリのインストール",
    "href": "chapter6.html#ライブラリのインストール",
    "title": "6  ライブラリ",
    "section": "6.2 ライブラリのインストール",
    "text": "6.2 ライブラリのインストール\n\n6.2.1 CRANからのインストール\n上記のように、ライブラリはまずインストールしないと用いることはできません。Rでライブラリをインストールする時には、install.packages関数を用います。install.packages関数の引数は文字列のライブラリ名です。ですので、ライブラリ名をダブルクオーテーションで囲う必要があります。ライブラリは自動的にダウンロードされ、.libPaths関数で表示されるフォルダにインストールされます。\n\n\n\nライブラリのインストール\n\ninstall.packages(\"tidyverse\") # tidyverseというライブラリをインストールする\ninstall.packages(c(\"tidyverse\", \"pacman\")) # 複数のパッケージ名をベクターで与えることもできる\n\ninstall.packages(tidyverse) # エラーが出る。ライブラリ名は文字列でないとダメ\n\n.libPaths() # ライブラリのインストール先を表示",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ライブラリ</span>"
    ]
  },
  {
    "objectID": "chapter6.html#ライブラリをロードする",
    "href": "chapter6.html#ライブラリをロードする",
    "title": "6  ライブラリ",
    "section": "6.3 ライブラリをロードする",
    "text": "6.3 ライブラリをロードする\nライブラリをロードするときには、library関数を用います。library関数の引数は、文字列ではないライブラリ名です。文字列のライブラリ名でも読み込みはできますが、ダブルクオーテーションで囲う必要はありません。\n同様にrequire関数でもライブラリを読み込むことができます。require関数では、ライブラリの読み込みに成功するとTRUEが、失敗するとFALSEが返り値として返ってくるという特徴があります。\nlibrary関数を引数なしで実行すると、インストールされているライブラリの一覧が表示されます。\n\n\n\nライブラリをロードする\n\nlibrary(tidyverse) # tidyverseパッケージを読み込む\nlibrary(\"pacman\") # pacmanパッケージを読み込む（文字列）\n\nrequire(pacman) # requireによる読み込み（読み込みができたらTRUEが返ってくる）\n\nlibrary() # ライブラリの一覧を表示する\n\n\n\n6.3.1 ライブラリをロードせずに使用する\nライブラリに登録されている関数を用いるには、通常ロードする必要がありますが、ライブラリをロードしなくても個別の機能（関数）を用いることはできます。ライブラリをロードせずにそのライブラリの関数を用いるときには、「ライブラリ名::関数名」という形で関数を呼び出します。\n\n\n\nライブラリをロードせずに関数を用いる\n\n# install.packages(\"lubridate\") であらかじめライブラリのインストールが必要\n\nymd(\"2023-10-10\") # lubridateパッケージの関数はライブラリをロードしないと使えない\n## Error in ymd(\"2023-10-10\"): could not find function \"ymd\"\n\nlubridate::ymd(\"2023-10-10\") # パッケージ名::関数名でロードしなくても関数が使える\n## [1] \"2023-10-10\"\n\n\n\n\n6.3.2 githubからのインストール\n最近では、最新のライブラリはCRANだけでなく、GitHubというプログラム開発プラットフォームからインストールすることもあります。ただし、GitHubのライブラリはCRANによるチェックを受けていないものですので、インストールする際には注意が必要です。GitHubからのライブラリのインストールには、devtools (Wickham et al. 2022)パッケージのinstall_github関数を用います。引数には、ライブラリのリポジトリというものを文字列で取ります。\n例えば、Displayrという会社が開発しているflipPlotsというライブラリをGitHubからインストールする場合には、GitHubの対象のページのアドレス（https://github.com/Displayr/flipPlots）のうち、後ろの2つの項目（Displayr/flipPlots）をリポジトリとして取り扱います。GitHubのページにはリポジトリ名が記載されています。\n\n\n\n図1：GitHubのリポジトリ名\n\n\n\n\n\nGitHubからのライブラリのインストール\n\n# flipPlotsというライブラリをGitHubからインストールする(インストールは自己責任で)\n# devtools::install_github(\"Displayr/flipPlots\") \n\n\n\n\n\n\n\n\nGitとGithub\n\n\n\n\n\nGitHubは、Git（バージョン管理システム）というものと連携して用いる、リモートリポジトリと呼ばれるものです。RstudioからGit及びGitHubを利用することもできます。\n\n\n\n\n\n6.3.3 Bioconductorからのインストール\n生物系の統計手法（DNAのアライメントやシーケンサーデータの処理、系統樹の計算等）のライブラリを専門的に取り扱っているのが、Bioconductorです。Bioconductorに設定されているライブラリはCRANやgithubのものとは取り扱いが少し異なります。\nBioconductorのライブラリを利用するには、BiocManager (Morgan and Ramos 2023)というライブラリをあらかじめインストールする必要があります。BioconductorのライブラリのインストールにはこのBiocManegerパッケージのinstall関数を用います。install関数を引数なしで用いると、Bioconductorのコアライブラリをすべてインストールすることができます。特定のライブラリをインストールするときには、引数に文字列のライブラリ名を入力します。\nインストールしたBioconductorライブラリのロードは通常のライブラリと同様にlibrary関数で行うことができます。\n\n\n\nBioconductorのライブラリをインストール\n\ninstall.packages(\"BiocManager\") # BioManagerパッケージのインストール\nBiocManager::install() # Bioconductorのコアライブラリをインストールする\nBiocManager::install(c(\"GenomicFeatures\", \"AnnotationDbi\"))",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ライブラリ</span>"
    ]
  },
  {
    "objectID": "chapter6.html#ライブラリを簡単に取り扱うpacman",
    "href": "chapter6.html#ライブラリを簡単に取り扱うpacman",
    "title": "6  ライブラリ",
    "section": "6.4 ライブラリを簡単に取り扱う：pacman",
    "text": "6.4 ライブラリを簡単に取り扱う：pacman\nライブラリはインストールしないとロードすることができません。ですので、インストールしていないライブラリをロードしようとするととエラーが出ます。if文を用いると、ライブラリがインストールされていないときにはインストールしてロード、インストールされているときにはロードが実行されるようにすることもできます。\n\n\n\npacman::p_load関数によるライブラリのロード\n\n# climetricsパッケージ（気候変化に関するライブラリ）は\n# インストールされていないので、エラーが出る\nlibrary(climetrics) \n\nrequire(climetrics) # インストールしないと読み込めないので、FALSEが返ってくる\n\n# require関数でFALSEが返ってきたら、パッケージをインストールする\nif(!require(climetrics)) install.packages(\"climetrics\")\n\n\nこのif文とrequire関数を用いる書き方は長い間使用されてきましたが、やや複雑で覚えにくいものです。このようなライブラリの取り扱いを簡単にしてくれるのがpacman (Rinker and Kurkiewicz 2018)パッケージです。近年では、このpacmanパッケージのp_load関数を用いてパッケージをロードすることも増えてきています。p_load関数を用いるには、pacmanパッケージをロードする必要があります。ライブラリのロードのために別途pacmanだけロードするのは面倒ですので、pacman::p_loadという形で、ライブラリをロードすることなく関数だけ用いるのが一般的です。この他に、pak(Csárdi and Hester 2024)と呼ばれるパッケージ管理のライブラリも最近では用いられています。\n\n\n\npacman::p_load関数を用いたライブラリのロード\n\n# ライブラリをロードする（インストールされてなければインストールしてからロードする）\npacman::p_load(tidyverse, lubridate)",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ライブラリ</span>"
    ]
  },
  {
    "objectID": "chapter6.html#tidyverse",
    "href": "chapter6.html#tidyverse",
    "title": "6  ライブラリ",
    "section": "6.5 tidyverse",
    "text": "6.5 tidyverse\n近年のRでは、Posit（旧Rstudio、IDEであるRstudioの開発元）およびPositのチーフサイエンティストであるHadley Wickhamが中心となって作成された複数のライブラリのセットである、tidyverse (Wickham et al. 2019)を用いるのがほぼ常識となっています。tidyverseのライブラリ群を用いなくてもRを使うことはできますが、このライブラリ群を用いることでデータの整理・グラフ作成・文字列の処理等を簡単に行うことができるようになります。tidyverseのライブラリ群は以下のように一度にインストール・ロードすることができます。\n\n\n\ntidyverseのインストールと読み込み\n\npacman::p_load(tidyverse) # tideverseのインストール・ロード(install.packages・library関数でも可)\n\n\ntidyverseに含まれているライブラリを以下に示します。個別の、重要なライブラリに関しては別章で説明します。\n\n\n\n表1：tidyverseに含まれるライブラリ群\n\n\nライブラリ名\nライブラリの主な機能\n\n\n\n\ndpylr\nデータフレームの編集\n\n\ntidyr\nデータフレームの変形（縦・横持ち）\n\n\nggplot2\n現代的なデザインのグラフ作成\n\n\ntibble\n使いやすいデータフレームの提供\n\n\nstringr\n文字列の処理\n\n\npurrr\nリストへの関数の適用\n\n\nreadr\nデータ読み込み\n\n\nforcats\n因子（factor）の処理",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ライブラリ</span>"
    ]
  },
  {
    "objectID": "chapter6.html#その他の便利なライブラリ",
    "href": "chapter6.html#その他の便利なライブラリ",
    "title": "6  ライブラリ",
    "section": "6.6 その他の便利なライブラリ",
    "text": "6.6 その他の便利なライブラリ\ntidyverseの他にも、データ処理を簡単にしたり、インタラクティブなグラフを作成したり、Rで文書を作成したりするためのライブラリをRは備えています。以下によく用いられるライブラリを示します。統計に関するライブラリも無数に存在します。統計に関するライブラリについては、統計手法の説明の際に紹介します。\n\n\n\n表2：Rで用いられている便利なライブラリ\n\n\nライブラリ名\nライブラリの主な機能\n\n\n\n\nmagrittr\nパイプ演算子を提供\n\n\nreadxl\nExcelファイルの読み込み\n\n\ngooglesheet4\nGoogleスプレッドシートの読み込み\n\n\nlubridate\n日時データの処理\n\n\nbroom\n統計結果の変形\n\n\nDT\n美しい表の作成\n\n\nplotly\nインタラクティブなグラフの作成\n\n\nRmarkdown\n文書の作成\n\n\nshiny\nWebアプリケーションの作成\n\n\npacman\nライブラリのインストール・ロード\n\n\n\n\n\n\n\n\n\n\n図1：GitHubのリポジトリ名\n\n\n\nCsárdi, Gábor, and Jim Hester. 2024. Pak: Another Approach to Package Installation. https://CRAN.R-project.org/package=pak.\n\n\nMorgan, Martin, and Marcel Ramos. 2023. BiocManager: Access the Bioconductor Project Package Repository. https://CRAN.R-project.org/package=BiocManager.\n\n\nRinker, Tyler W., and Dason Kurkiewicz. 2018. pacman: Package Management for R. Buffalo, New York. http://github.com/trinker/pacman.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWickham, Hadley, Jim Hester, Winston Chang, and Jennifer Bryan. 2022. Devtools: Tools to Make Developing r Packages Easier. https://CRAN.R-project.org/package=devtools.",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>ライブラリ</span>"
    ]
  },
  {
    "objectID": "chapter7.html",
    "href": "chapter7.html",
    "title": "7  エラー処理（error handler）",
    "section": "",
    "text": "7.1 エラーメッセージの分類\nRではエラーメッセージとして3種類の警告が出る仕組みを持っています。3種類とは、message、warning、errorの3つです。messageはプログラムを実行しても特に問題はないが、特別に伝えたいことがある場合に、warningはプログラムを実行したときに、問題が起こっている可能性が高い場合に、errorは実行できない場合にそれぞれ表示されます。\nこれらのうち、messageはプログラムの実行に影響を与えません。warningはプログラムを実行したときに問題が起こることがあります。errorが起こるとプログラムの実行が止まります。ですので、エラーとして処理が必要となるのは、主にwarningとerrorです。\nmessage, warning, errorの表示\n\n# messageが出る場合\nreadr::read_tsv(\"iris.txt\")\n## Rows: 150 Columns: 5\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \"\\t\"\n## chr (1): Species\n## dbl (4): Sepal.Length, Sepal.Width, Petal.Length, Petal.Width\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n## # A tibble: 150 × 5\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  \n##  1          5.1         3.5          1.4         0.2 setosa \n##  2          4.9         3            1.4         0.2 setosa \n##  3          4.7         3.2          1.3         0.2 setosa \n##  4          4.6         3.1          1.5         0.2 setosa \n##  5          5           3.6          1.4         0.2 setosa \n##  6          5.4         3.9          1.7         0.4 setosa \n##  7          4.6         3.4          1.4         0.3 setosa \n##  8          5           3.4          1.5         0.2 setosa \n##  9          4.4         2.9          1.4         0.2 setosa \n## 10          4.9         3.1          1.5         0.1 setosa \n## # ℹ 140 more rows\n\n# warning（警告）が出る場合\ntibble::as.tibble(iris[1,])\n## Warning: `as.tibble()` was deprecated in tibble 2.0.0.\n## ℹ Please use `as_tibble()` instead.\n## ℹ The signature and semantics have changed, see `?as_tibble`.\n## # A tibble: 1 × 5\n##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n##          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n## 1          5.1         3.5          1.4         0.2 setosa\n\n# error（エラー）が出る場合\n100 + dog\n## Error in eval(expr, envir, enclos): object 'dog' not found",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>エラー処理（error handler）</span>"
    ]
  },
  {
    "objectID": "chapter7.html#エラーメッセージエラーを表示させる",
    "href": "chapter7.html#エラーメッセージエラーを表示させる",
    "title": "7  エラー処理（error handler）",
    "section": "7.2 エラーメッセージ・エラーを表示させる",
    "text": "7.2 エラーメッセージ・エラーを表示させる\n自分が作ったプログラムや関数を他人が使う場合には、計算に問題があるときにはエラーメッセージを出す処理を加える時があります。また、errorやwarningが起きたときには特別な処理を行いたいこともあります。このような場合のために、Rにはエラーを表示させるための関数があります。message、warning、errorを表示させるための関数は、それぞれmessage関数、warning関数、stop関数です。stop関数ではその名の通り、エラーが表示され、プログラムの実行が止まります。エラーはstopifnot関数でも表示させることができます。stopifnot関数は引数に条件式を取り、条件式がFALSEのときにエラーを表示します。\n\n\n\nエラーを表示させる関数\n\nmessage(\"これはメッセージです。実行に問題はありません\")\n## これはメッセージです。実行に問題はありません\n\nwarning(\"これはwarning（警告）です。実行に問題があるかもしれません\")\n## Warning: これはwarning（警告）です。実行に問題があるかもしれません\n\nstop(\"これはerrorです。実行を止めます。\")\n## Error in eval(expr, envir, enclos): これはerrorです。実行を止めます。\n\nstopifnot(FALSE) # 条件がFALSEだとエラーが出る\n## Error: FALSE is not TRUE\n\nstopifnot(\"エラーメッセージはこのように設定する\" = FALSE) # =の後に条件式を書く\n## Error: エラーメッセージはこのように設定する",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>エラー処理（error handler）</span>"
    ]
  },
  {
    "objectID": "chapter7.html#tryとtrycatch",
    "href": "chapter7.html#tryとtrycatch",
    "title": "7  エラー処理（error handler）",
    "section": "7.3 tryとtryCatch",
    "text": "7.3 tryとtryCatch\nRでのエラー処理には、try関数とtryCatch関数の2つが用いられます。try関数はエラーが出る処理を行った場合に、プログラムを止めずにエラーを返す機能を持ちます。tryCatch関数はエラーが出る処理に対応して別の処理を行う際に用います。\ntry関数は第一引数を評価し、エラーならエラーを表示し、続けてプログラムを実行します。下のfor文では、どちらも\"dog\"に数値を足す計算でエラーが出ます。tryがない場合にはエラーが出た時点でプログラムが停止しますが、try関数の引数にエラーが出る処理がある場合にはエラーが出た後にも計算が継続します。tryは返り値として第一引数の演算結果を返しますが、エラーが出た場合にはtry-errorクラスのオブジェクトを返します。\n\n\n\ntry関数とエラー\n\nd &lt;- data.frame(a=1, b=2, c=\"dog\", d=4, e=5)\nd # 1行5列のデータフレーム\n##   a b   c d e\n## 1 1 2 dog 4 5\n\nfor(i in 1:5){ # エラーが出るので、評価が中断する\n  print(d[1,i] + 1)\n}\n## [1] 2\n## [1] 3\n## Error in d[1, i] + 1: non-numeric argument to binary operator\n\nfor(i in 1:5){ # エラーが出ても、評価は継続する\n  try(print(d[1,i] + 1))\n}\n## [1] 2\n## [1] 3\n## Error in d[1, i] + 1 : non-numeric argument to binary operator\n## [1] 5\n## [1] 6\n\nerr_ &lt;- try(1+\"dog\") # エラーが出たとき\n## Error in 1 + \"dog\" : non-numeric argument to binary operator\n\nclass(err_) # エラーのクラス（try-error）を返す\n## [1] \"try-error\"\n\nwarning_ &lt;- try(as.numeric(\"dog\")) # warningが出たとき\n## Warning in doTryCatch(return(expr), name, parentenv, handler): NAs introduced\n## by coercion\n\nwarning_ # 演算はできるので、演算結果（NA）が返ってくる\n## [1] NA\n\nclass(warning_) # クラスはnumeric\n## [1] \"numeric\"\n\n\n\n\n\n\n\n\n返り値のNA\n\n\n\n\n\n（try(as.numeric(\"dog\")) の結果）のクラスがnumericになっています。NAは内部的にはNA_integer_（整数のNA）、NA_real_（実数のNA）、NA_complex_（複素数のNA）、NA_character_（文字列のNA）の4種類として扱われており、上記の場合ではNA_real_、つまり実数タイプのNAが返ってきています。このようにNAには型が複数あるため、ベクター中にNAが埋め込まれていても、ベクター全体の型が変化することはありません。\n\n\n\ntry関数では、エラーが出たときにはtry-errorクラスが返ってくるので、try-errorクラスであることを利用してエラー時に行う処理を設定することができます。また、引数に「silent = TRUE」を取ると、エラーメッセージが表示されなくなります。\n\n\n\ntry-errorクラスを用いたエラー処理\n\n# tryの結果のクラスがtry-errorなら、文字列を返すif文\nif(class(try(1+\"dog\"))==\"try-error\"){\"エラーが起きています。\"}\n## Error in 1 + \"dog\" : non-numeric argument to binary operator\n## [1] \"エラーが起きています。\"\n\ntry(1+\"dog\", silent=T) # 何も表示されない\n\n\ntry関数でもエラー処理はできますが、通常エラー処理で用いられるのはtryCatch関数です。tryCatch関数では、errorが起きたときの処理、warningが起きたときの処理、最終的に行う処理（finally）をそれぞれ設定できます。この時、error、warningの処理は関数で、finallyはそのまま書きます。warningやerrorに用いる関数は別途作成しておくこともできますが、下のようにtryCatch関数内で関数として定義する形でも書くこともできます。\n\n\n\n\n\nerrorCatcher &lt;- function(x){ # 対数計算のエラーを捉える関数\n  tryCatch(\n    log(x), # 対数計算を評価する\n    warning = \\(w){\"警告あり\"}, # warningが出たときの処理\n    error = \\(e){\"エラーあり\"}, # errorが出たときの処理\n    finally = print(\"エラーがあってもなくても表示される\") # エラーの有無に関わらず行う処理\n  )\n}\n\nerrorCatcher(0) # エラーなし\n## [1] \"エラーがあってもなくても表示される\"\n## [1] -Inf\nerrorCatcher(-1) # warning\n## [1] \"エラーがあってもなくても表示される\"\n## [1] \"警告あり\"\nerrorCatcher(\"dog\") # error\n## [1] \"エラーがあってもなくても表示される\"\n## [1] \"エラーあり\"\n\n\n\n\n\n\n\n\n無名関数\n\n\n\n\n\nwarningやerrorで記載している関数（\\(e)や\\(w)）は名前を決めずに用いる関数で、無名関数と呼ばれるものです。用途によってはこのような無名関数を用いて処理を書くことがあります。",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>エラー処理（error handler）</span>"
    ]
  },
  {
    "objectID": "chapter8.html",
    "href": "chapter8.html",
    "title": "8  数値",
    "section": "",
    "text": "8.1 数値を引数とする関数\nまずは、数値を演算するときに用いる関数を紹介します。よく用いられる関数は以下の表1の通りです（x、yは引数）。関数は演算子より優先的に計算されます。引数である数値はベクターで与えることもできます。\n表1：数値の演算に用いる関数\n\n\n関数名\nxに適用される計算手法\n\n\n\n\nsqrt(x)\n平方根\n\n\nexp(x)\ne（ネイピア数、自然対数の底）のx乗\n\n\nlog(x, base=y)\nyを底にした対数\n\n\nlog(x)\n自然対数\n\n\nlog10(x)\n常用対数\n\n\nlog2(x)\n底が2の対数\n\n\nsin(x)\nサイン（xはラジアン）\n\n\ncos(x)\nコサイン\n\n\ntan(x)\nタンジェント\n\n\nacos(x)\nアークサイン（サインの逆関数）\n\n\nasin(x)\nアークコサイン\n\n\natan(x)\nアークタンジェント\n\n\nround(x, digits=y)\n小数点以下y桁で四捨五入\n\n\nceiling(x)\n切り上げ\n\n\nfloor(x)\n切り下げ\n\n\ntrunc(x)\n切り捨て\n\n\nsignif(x, digits=y)\ny桁を残して四捨五入\n\n\nabs(x)\nxの絶対値\n数値演算の関数\n\nsqrt(9) # 平方根\n## [1] 3\n\nexp(1) # 指数変換\n## [1] 2.718282\n\nlog(8, base = 2) # 底が2の対数\n## [1] 3\n\nlog(10) # 底がeの対数\n## [1] 2.302585\n\nlog10(10) # 底が10の対数\n## [1] 1\n\nlog2(10) # 底が2の対数\n## [1] 3.321928\n\nsin(0.5*pi) # サイン\n## [1] 1\n\ncos(pi) # コサイン\n## [1] -1\n\ntan(0.25*pi) # タンジェント\n## [1] 1\n\nasin(0.5) # アークサイン（サインの逆関数）\n## [1] 0.5235988\n\nacos(0.5) # アークコサイン\n## [1] 1.047198\n\natan(0.5) # アークタンジェント\n## [1] 0.4636476\n\nround(pi, digits=2) # 四捨五入\n## [1] 3.14\n\nceiling(pi) # 切り上げ\n## [1] 4\n\nfloor(pi) # 切り下げ\n## [1] 3\n\ntrunc(pi) # 切り捨て\n## [1] 3\n\nsignif(pi*100, digits=2) # 2桁以下を四捨五入\n## [1] 310\n\nabs(-5) # 絶対値\n## [1] 5\n\nlog2(c(2, 4, 8, 16, 32, 64)) # ベクターを引数にする時\n## [1] 1 2 3 4 5 6",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>数値</span>"
    ]
  },
  {
    "objectID": "chapter8.html#数値を引数とする関数",
    "href": "chapter8.html#数値を引数とする関数",
    "title": "8  数値",
    "section": "",
    "text": "Rのroundの仕様\n\n\n\n\n\nRのround関数は概ね四捨五入の結果を返しますが、正確には四捨五入にはなっていない場合があるので、注意が必要です。",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>数値</span>"
    ]
  },
  {
    "objectID": "chapter8.html#組み合わせ階乗順列",
    "href": "chapter8.html#組み合わせ階乗順列",
    "title": "8  数値",
    "section": "8.2 組み合わせ・階乗・順列",
    "text": "8.2 組み合わせ・階乗・順列\n統計と確率には密接な関係があります。高校数学の確率で習ったように、確率の計算では順列・組合せの数が重要となります。Rには組み合わせを計算する関数として、choose関数があります。また、階乗を計算する関数はfactorial関数です。順列を計算する関数はないため、階乗を用いて順列を計算する必要があります。\n\n\n\n組み合わせと階乗\n\nchoose(5, 2) # 5個から2個を選ぶ組み合わせ（5C2）\n## [1] 10\n\nfactorial(3) # 3の階乗（1 * 2 * 3）\n## [1] 6\n\nfactorial(5)/factorial(2) # 5個の要素から3つを並べる順列(5P3)\n## [1] 60",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>数値</span>"
    ]
  },
  {
    "objectID": "chapter8.html#数列の作成",
    "href": "chapter8.html#数列の作成",
    "title": "8  数値",
    "section": "8.3 数列の作成",
    "text": "8.3 数列の作成\nRでは、ベクターはc関数を用いて作成します。しかし、長いベクターをc関数で自作するのは大変ですし、等差数列や等比数列を作るのにfor文を用いるのも面倒です。Rでは、数列を作る関数を用いて、等差数列などを作成することができます。また、繰り返しのあるベクターも、関数により作成することができます。\n等差数列の作成には、for文の説明時に用いた :（コロン）やseq関数を用います。等比数列は、簡単なものであればseq関数と累乗を用いて作成できます。繰り返しのあるベクターはrep関数を用いて作成できます。\n\n\n\n表2：数値のベクター作成・組み合わせなどの関数\n\n\n関数名\nxに適用される計算手法\n\n\n\n\nx:y\nxからyまで連続する整数\n\n\nseq(x, y, by = z)\nxからyまでz間隔での数列\n\n\nrep(x, y)\nxをy回繰り返す\n\n\ncumsum(x)\nxの累積和\n\n\ncumprod(x)\nxの累積積\n\n\nchoose(x, y)\nx個からy個を選ぶ組み合わせ\n\n\nfactorial(x)\nxの階乗\n\n\nprod(x)\nxの総乗\n\n\n\n\n\n\n\n\nseq関数とrep関数\n\n1:10 # 1から10まで公差1の数列\n##  [1]  1  2  3  4  5  6  7  8  9 10\n\nseq(from = 1, to = 10, by=3) # 1から10まで公差3の等差数列\n## [1]  1  4  7 10\n\nseq(1, 10, length.out=3) # 1から10まで等間隔で、3つの長さの数列\n## [1]  1.0  5.5 10.0\n\n3 ^ (0:10) # 公比3の等比数列\n##  [1]     1     3     9    27    81   243   729  2187  6561 19683 59049\n\n3 ^ seq(0, 10, by=2) # 公比9の等比数列\n## [1]     1     9    81   729  6561 59049\n\nrep(1:3, 5) # 1, 2, 3を5回繰り返す\n##  [1] 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3\n\nrep(1:3, c(3, 3, 3)) # 1, 2, 3をそれぞれ3回繰り返す\n## [1] 1 1 1 2 2 2 3 3 3\n\nrep(1:3, c(3, 2, 1)) # 1を3回、2を2回、3を1回繰り返す\n## [1] 1 1 1 2 2 3\n\nrep(1:3, length.out=10) # 1, 2, 3を長さ10まで繰り返す\n##  [1] 1 2 3 1 2 3 1 2 3 1\n\nrep(c(\"apple\", \"orange\", \"banana\"), 2) # どの型でも繰り返しができる\n## [1] \"apple\"  \"orange\" \"banana\" \"apple\"  \"orange\" \"banana\"",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>数値</span>"
    ]
  },
  {
    "objectID": "chapter8.html#総乗累積和累積積",
    "href": "chapter8.html#総乗累積和累積積",
    "title": "8  数値",
    "section": "8.4 総乗・累積和・累積積",
    "text": "8.4 総乗・累積和・累積積\nRで総乗（数列をすべて掛け算したもの）を計算する場合には、prod関数を用います。また、累積和（ベクターの前から順番に足し算したもの）と累積積（前から順番に掛け算したもの）の数列を作る時には、cumsum関数とcumprod関数を用います。等比数列はcumprod関数を利用すれば作成することができます。\n\n\n\n総乗・累積和・累積積・等比数列\n\nprod(1:4) # 総乗\n## [1] 24\n\ncumsum(1:5) # 累積和\n## [1]  1  3  6 10 15\n\ncumprod(1:5) # 累積積\n## [1]   1   2   6  24 120\n\ncumprod(rep(2, 10)) # 初項2、公比2の等比数列\n##  [1]    2    4    8   16   32   64  128  256  512 1024",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>数値</span>"
    ]
  },
  {
    "objectID": "chapter8.html#ベクターの基礎演算と基礎統計量",
    "href": "chapter8.html#ベクターの基礎演算と基礎統計量",
    "title": "8  数値",
    "section": "8.5 ベクターの基礎演算と基礎統計量",
    "text": "8.5 ベクターの基礎演算と基礎統計量\n数値のベクターに対して、平均値や標準偏差などを計算する関数も、Rは備えています。代表的な関数を以下に示します。\n\n\n\n表3：数値ベクターの演算に用いる関数\n\n\n関数名\nx、yに適用される計算手法\n\n\n\n\nsum(x)\n合計値\n\n\nlength(x)\nベクターの長さ\n\n\nmean(x)\n平均値\n\n\nvar(x)\n（不偏）分散\n\n\nsd(x)\n（不偏）標準偏差\n\n\nmedian(x)\n中央値\n\n\nmax(x)\n最大値\n\n\nmin(x)\n最小値\n\n\nquantile(x, probs)\n分位値（probsは分位の位値）\n\n\ncov(x, y)\n共分散\n\n\ncov(data.frame)\n分散・共分散行列\n\n\ncor(x, y)\n相関係数\n\n\ncor(data.frame)\n相関行列\n\n\n\n\n\n\n\n\nベクターの基礎演算と基礎統計量\n\nx &lt;- seq(0, 10, by=0.5); x # 0から10まで公差0.5の数列\n##  [1]  0.0  0.5  1.0  1.5  2.0  2.5  3.0  3.5  4.0  4.5  5.0  5.5  6.0  6.5  7.0\n## [16]  7.5  8.0  8.5  9.0  9.5 10.0\ny &lt;- rnorm(21, 5, 3); y # 長さ21の正規乱数\n##  [1]  8.7888629  4.0212999  8.9893978  8.8172880  6.2439243  0.3801499\n##  [7]  2.2142989  4.1158387  4.9826985 12.2139602  7.2907804  2.6029723\n## [13]  1.5570290  4.1316153  4.1023546  3.7654675  5.7566703  2.3242366\n## [19]  6.3070499  1.2873847  4.3271963\n\nsum(x) # xの合計\n## [1] 105\n\nlength(x) # xの長さ\n## [1] 21\n\nmean(x) # xの平均値\n## [1] 5\n\nvar(x) # xの分散\n## [1] 9.625\n\nsd(x) # xの標準偏差\n## [1] 3.102418\n\nsd(x)/length(x)^0.5 # xの標準誤差\n## [1] 0.6770032\n\nmedian(x) # xの中央値\n## [1] 5\n\nmax(x) # xの最大値\n## [1] 10\n\nmin(x) # xの最小値\n## [1] 0\n\nquantile(x, probs=c(0.25, 0.75)) # xの25%、75%分位値\n## 25% 75% \n## 2.5 7.5\n\ncov(x, y) # xとyの共分散\n## [1] -3.274794\n\ncov(data.frame(x, y)) # xとyの分散・共分散行列\n##           x         y\n## x  9.625000 -3.274794\n## y -3.274794  8.942667\n\ncor(x, y) # xとyの相関係数\n## [1] -0.35298\n\ncor(data.frame(x, y)) # xとyの相関行列\n##          x        y\n## x  1.00000 -0.35298\n## y -0.35298  1.00000\n\n\n\n\n\n\n\n\n基礎統計量の計算\n\n\n\n\n\n以下に、上記の基礎統計量の計算式を示します。\nsum(x)：合計値、x1～xnの和は以下の式で表されます。\n\\[sum(x)=\\sum_{i=1}^{n}x_{i}\\]\nmean(x)：平均値（\\(\\bar{x}\\)）、x1～xnの平均値は以下の式で表されます。\n\\[mean(x)=\\frac{\\sum_{i=1}^{n}x_{i}}{n}\\]\nvar(x)：不偏分散、x1～xnの分散は以下の式で表されます。\n\\[var(x)=\\frac{\\sum_{i=1}^{n}(x_{i}-\\bar{x})^2}{n-1}\\]\nsd(x)：不偏標準偏差、x1～xnの不偏標準偏差は以下の式で表されます。\n\\[sd(x)=\\sqrt{\\frac{\\sum_{i=1}^{n}(x_{i}-\\bar{x})^2}{n-1}}\\]\n標準誤差（standard error）、x1～xnの標準誤差は以下の式で表されます。\n\\[se(x)=\\frac{1}{\\sqrt{n}} \\cdot sd(x)=\\frac{1}{\\sqrt{n}}\\sqrt{\\frac{\\sum_{i=1}^{n}(x_{i}-\\bar{x})^2}{n-1}}\\]\ncov(x, y)：共分散、x1～xnとy1～ynの共分散は平均値（\\(\\bar{x}\\)、\\(\\bar{y}\\)）を用いて以下の式で表されます。\n\\[cov(x, y)=\\frac{1}{n}\\sum_{i=1}^{n}(x_{i}-\\bar{x})(y_{i}-\\bar{y})\\]\ncor(x, y)：相関係数、x1～xnとy1～ynの相関係数は平均値（\\(\\bar{x}\\)、\\(\\bar{y}\\)）を用いて以下の式で表されます。\n\\[cor(x,y)=\\frac{cov(x,y)}{var(x) \\cdot var(y)}=\\frac{\\sum_{i=1}^{n}(x_{i}-\\bar{x})(y_{i}-\\bar{y})}{\\sqrt{\\sum_{i=1}^{n}(x_{i}-\\bar{x})^2 \\cdot \\sum_{i=1}^{n}(y_{i}-\\bar{y})^2}}\\]\n\n\n\n\n8.5.1 度数分布の計算\nRでは数値のベクターからヒストグラムを書くことが多いのですが、別途度数分布表を描きたいという場合もあります。度数分布を調べる時には、cut関数を用います。\ncut関数は第一引数に数値のベクター、第二引数に度数分布の切断点（1~10、11~20などの10と11の境目のこと）を取ります。結果として、数値を「(数値, 数値]」という形の因子（factor）に変換したものが返ってきます。この時、カッコ（“(”）は大なり、四角カッコ（“]”）は小なりイコールを表しています。ですので、例えば「(40,60]」と示されている場合には、その値が40より大きく（\\(x&gt;40\\)）、60以下(\\(x \\leq 60\\))であることを表しています。\n因子型を引数とする関数にはtable関数というものがあります。このcut関数とtable関数を組み合わせることで、度数分布表を簡単に作成することができます。\n\n\n\n度数分布の計算\n\nz &lt;- runif(150, min = 0, max = 100)\n# データの存在する範囲を返す関数（因子が返ってくる）\ncut(z, breaks=c(-1, 20, 40, 60, 80, 101)) \n##   [1] (60,80]  (60,80]  (40,60]  (40,60]  (60,80]  (-1,20]  (40,60]  (60,80] \n##   [9] (60,80]  (40,60]  (80,101] (40,60]  (20,40]  (-1,20]  (-1,20]  (20,40] \n##  [17] (40,60]  (60,80]  (40,60]  (80,101] (20,40]  (40,60]  (20,40]  (60,80] \n##  [25] (20,40]  (40,60]  (60,80]  (-1,20]  (80,101] (20,40]  (80,101] (20,40] \n##  [33] (20,40]  (40,60]  (80,101] (80,101] (20,40]  (60,80]  (80,101] (40,60] \n##  [41] (60,80]  (20,40]  (20,40]  (60,80]  (20,40]  (60,80]  (-1,20]  (20,40] \n##  [49] (-1,20]  (20,40]  (-1,20]  (60,80]  (80,101] (60,80]  (60,80]  (40,60] \n##  [57] (40,60]  (80,101] (60,80]  (60,80]  (20,40]  (20,40]  (80,101] (60,80] \n##  [65] (20,40]  (-1,20]  (40,60]  (80,101] (40,60]  (80,101] (60,80]  (20,40] \n##  [73] (40,60]  (-1,20]  (-1,20]  (60,80]  (-1,20]  (40,60]  (60,80]  (80,101]\n##  [81] (40,60]  (40,60]  (-1,20]  (60,80]  (40,60]  (40,60]  (20,40]  (20,40] \n##  [89] (40,60]  (40,60]  (-1,20]  (-1,20]  (60,80]  (80,101] (40,60]  (40,60] \n##  [97] (40,60]  (80,101] (40,60]  (60,80]  (60,80]  (20,40]  (20,40]  (60,80] \n## [105] (40,60]  (-1,20]  (60,80]  (-1,20]  (80,101] (60,80]  (40,60]  (20,40] \n## [113] (40,60]  (40,60]  (-1,20]  (40,60]  (-1,20]  (20,40]  (20,40]  (20,40] \n## [121] (80,101] (40,60]  (60,80]  (80,101] (40,60]  (-1,20]  (20,40]  (60,80] \n## [129] (20,40]  (60,80]  (80,101] (80,101] (20,40]  (20,40]  (80,101] (60,80] \n## [137] (60,80]  (60,80]  (80,101] (20,40]  (-1,20]  (80,101] (40,60]  (80,101]\n## [145] (-1,20]  (60,80]  (60,80]  (80,101] (40,60]  (60,80] \n## Levels: (-1,20] (20,40] (40,60] (60,80] (80,101]\n\nz_cut &lt;- cut(z, breaks=c(-1, 20, 40, 60, 80, 101)) \ntable(z_cut) # 度数分布表を返すtable関数\n## z_cut\n##  (-1,20]  (20,40]  (40,60]  (60,80] (80,101] \n##       21       31       36       37       25",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>数値</span>"
    ]
  },
  {
    "objectID": "chapter8.html#summary関数",
    "href": "chapter8.html#summary関数",
    "title": "8  数値",
    "section": "8.6 summary関数",
    "text": "8.6 summary関数\nRでは、基礎統計量を計算するときにはsummary関数を用いることができます。summary関数はベクターを引数に取り、ベクターの最小値、25%四分位、中央値、平均値、75%四分位値、最大値を一度に計算してくれる関数です。summary関数の引数にはベクターだけでなく、リストやデータフレームを用いることもできます。summary関数は引数の型・クラスによって演算を変え、データの要約を示してくれます。\n\n\n\nsummary関数\n\nsummary(x) # ベクターを引数にするとき\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##     0.0     2.5     5.0     5.0     7.5    10.0\n\nsummary(list(x, y)) # リストを引数にするとき\n##      Length Class  Mode   \n## [1,] 21     -none- numeric\n## [2,] 21     -none- numeric\n\nsummary(data.frame(x, y)) # データフレームを引数にするとき\n##        x              y          \n##  Min.   : 0.0   Min.   : 0.3801  \n##  1st Qu.: 2.5   1st Qu.: 2.6030  \n##  Median : 5.0   Median : 4.1316  \n##  Mean   : 5.0   Mean   : 4.9629  \n##  3rd Qu.: 7.5   3rd Qu.: 6.3071  \n##  Max.   :10.0   Max.   :12.2140\n\n\n\n\n\n\n\n\nジェネリックな関数（generic function）\n\n\n\n\n\nsummary関数のように、色々な型・クラスを引数にとり、その型・クラスに応じて出力を変える関数のことを、ジェネリック関数（generic function）と呼びます。ジェネリック関数は引数によって呼び出す関数（summary.data.frameやsummary.matrixなど）を変えることで、違う型・クラスの引数に対応しています。ジェネリック関数の詳細を調べる場合には、methods関数を用います。例えば、methods(summary)を実行すると、summary関数に属しているジェネリック関数の一覧を確認することができます。",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>数値</span>"
    ]
  },
  {
    "objectID": "chapter8.html#微分と積分",
    "href": "chapter8.html#微分と積分",
    "title": "8  数値",
    "section": "8.7 微分と積分",
    "text": "8.7 微分と積分\n\n8.7.1 微分：deriv関数\nRで微分を計算する関数がderiv関数です。deriv関数は~の後の引数に変数を用いた計算式、第二引数に微分する変数を文字列で指定する関数です。\nderiv関数の返り値はexpressionという型のオブジェクトです。このオブジェクトには、.valueと.gradという2つの値が含まれており、.valueは関数、.gradは関数を微分したものを示します。\nある値における微分値を計算する場合には、deriv関数で文字列で指定した変数名に数値を代入し、eval関数の引数にderiv関数の返り値を取ります。\nまた、function.arg=TRUEを引数に取ると、deriv関数の返り値が関数型になります。この場合には、第二引数で指定した文字列がそのまま引数のリストとなります。\nもう少し単純に微分の式を求める関数がD関数です。D関数では第一引数にexpressionを取り、第二引数に微分する変数を文字列で指定します。\n\n\n\n微分\n\ndx2x &lt;- deriv(~ x^2, \"x\") # 微分はf'(x) ~ 2xになる\ndx2x # .grad[, \"x\"]が微分の式\n## expression({\n##     .value &lt;- x^2\n##     .grad &lt;- array(0, c(length(.value), 1L), list(NULL, c(\"x\")))\n##     .grad[, \"x\"] &lt;- 2 * x\n##     attr(.value, \"gradient\") &lt;- .grad\n##     .value\n## })\n\nclass(dx2x) # 型・クラスはexpression\n## [1] \"expression\"\n\nx &lt;- 5 # xは変数で後から指定できる\neval(dx2x) # evalで微分値の計算(gradientに表示)\n## [1] 25\n## attr(,\"gradient\")\n##       x\n## [1,] 10\n\nx &lt;- 1:10\neval(dx2x) # 数列でも計算できる\n##  [1]   1   4   9  16  25  36  49  64  81 100\n## attr(,\"gradient\")\n##        x\n##  [1,]  2\n##  [2,]  4\n##  [3,]  6\n##  [4,]  8\n##  [5,] 10\n##  [6,] 12\n##  [7,] 14\n##  [8,] 16\n##  [9,] 18\n## [10,] 20\n\n# 関数として微分を設定する\ndx2x_f &lt;- deriv(y~x^2, c(\"x\", \"y\"), function.arg=TRUE)\nclass(dx2x_f) # 関数になっている\n## [1] \"function\"\n\n# xとyを与えると微分値を計算する\ndx2x_f(10, 10^2)\n## [1] 100\n## attr(,\"gradient\")\n##       x y\n## [1,] 20 0\n\n# D関数：関数を与えると微分の式を表示する\nD(expression(x^2), \"x\")\n## 2 * x\n\n\n\n\n8.7.2 関数の最小値を求める：optim関数\n関数の最小値（微分が0となる値）を求めるための関数がoptim関数です。optim関数は変数の初期値と関数を引数に取り、その関数が最小となる変数の組（最適化問題の解）を返します。\n\n\n\n\n\n\n最小値を求めるRosenbrock関数\n\n\n\n\n\n以下は、optimのヘルプ（?optim）で表示されるoptimの使用例に示されている、Rosenbrock関数（\\(y=a*(x_{2}-x_{1}^2)^2+(1-x_{1})^2\\)）の定義とその関数の形をグラフで示したものです。\n\n\n\nRosenbrock関数\n\n# 関数の式\nfr &lt;- function(x) { \n  x1 &lt;- x[1]\n  x2 &lt;- x[2]\n  100 * (x2 - x1 * x1)^2 + (1 - x1)^2\n}\n\nfr2 &lt;- function(x, y){100 * (y - x * x)^2 + (1 - x)^2}\n\npacman::p_load(plotly, tidyverse)\nd &lt;- expand.grid(\n  x1 = seq(-2, 2, by = 0.05),\n  x2 = seq(-2, 2, by = 0.05)\n  )\n\nd$rb &lt;- mapply(fr2, d$x1, d$x2)\n\nmrb &lt;- matrix(d$rb, nrow=81, ncol=81)\n\nd |&gt; \n  ggplot(aes(x=x1, y=x2, color=log(rb), fill=log(rb)))+\n  geom_bin2d(stat=\"identity\")+\n  labs(x=\"x1\", y=\"y1\", color=\"Rosenbrock関数の値\")\n\n\n\n\n\n\n\n\n\nfr(c(1, 1)) # 0になる\n## [1] 0\n\nplot_ly(z=~mrb) |&gt; add_surface()\n\n\n\n\n\n\n\n\n\n\n\noptim関数\n\nfr &lt;- function(x) { ## Rosenbrock関数\n  x1 &lt;- x[1]\n  x2 &lt;- x[2]\n  100 * (x2 - x1 * x1)^2 + (1 - x1)^2\n}\n\n# x1の初期値は-1.2、x2の初期値は1で最小値を求める\noptim(c(-1.2,1), fr) # 最小となるのはc(1,1)のとき\n## $par\n## [1] 1.000260 1.000506\n## \n## $value\n## [1] 8.825241e-08\n## \n## $counts\n## function gradient \n##      195       NA \n## \n## $convergence\n## [1] 0\n## \n## $message\n## NULL\n\n\n\n\n8.7.3 積分：integrate関数\nRでは、integrate関数を用いて積分値を計算することができます。integrate関数は第一引数に関数を取り、その後に積分する範囲を指定する関数です。Infを用いることで無限大までの範囲の積分を計算することもできます。\n\n\n\n積分\n\nf &lt;- \\(x){x^2}\nintegrate(f, 0, 2) # fを0から2まで積分する\n## 2.666667 with absolute error &lt; 3e-14\n\nintegrate(dnorm, 0, Inf) # 正規分布を0から+無限大まで積分する\n## 0.5 with absolute error &lt; 4.7e-05",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>数値</span>"
    ]
  },
  {
    "objectID": "chapter8.html#多項の方程式の解を求める",
    "href": "chapter8.html#多項の方程式の解を求める",
    "title": "8  数値",
    "section": "8.8 多項の方程式の解を求める",
    "text": "8.8 多項の方程式の解を求める\n多項の方程式（\\(ax^3+bx^2+cx+d=0\\)のような方程式）を解くための関数がpolyroot関数です。polyroot関数は上記のa、b、c、dをベクターで引数に指定し、方程式の解を返します。また、polyroot関数の返り値をMod関数に渡すことで、解に虚数が含まれている場合の解の原点からの距離に変換することができます。\n\n\n\npolyroot関数\n\npolyroot(c(1,1)) # x + 1 = 0の解\n## [1] -1+0i\n\npolyroot(c(1, 2, 1)) # x^2 + 2x + 1 = 0の解\n## [1] -1-1.110223e-16i -1+1.110223e-16i\n\npolyroot(c(1, 3, 3, 1)) # x^3 + 3x^2 + 3x + 1 = 0の解\n## [1] -1+1.942890e-16i -1+1.665335e-16i -1-3.608225e-16i\n\npolyroot(c(1, -3, -3, -1)) # 虚数解があるとき\n## [1]  0.259921+5.492479e-22i -1.629961+1.091124e+00i -1.629961-1.091124e+00i\n\nMod(polyroot(c(1, -3, -3, -1)) ) # 原点からの距離に変換\n## [1] 0.259921 1.961459 1.961459",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>数値</span>"
    ]
  },
  {
    "objectID": "chapter9.html",
    "href": "chapter9.html",
    "title": "9  文字列",
    "section": "",
    "text": "9.1 文字列を取り扱う関数",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>文字列</span>"
    ]
  },
  {
    "objectID": "chapter9.html#文字列を取り扱う関数",
    "href": "chapter9.html#文字列を取り扱う関数",
    "title": "9  文字列",
    "section": "",
    "text": "9.1.1 文字列の結合：pasteとpaste0関数\nRには文字列を取り扱う関数が一通り備わっています。まずはpaste関数について紹介します。paste関数は引数の文字列をつないで、1つの文字列にする関数です。各引数の文字列をつなぐ部分には、sep引数で指定した文字列が入ります。paste関数では、sepのデフォルトがスペースとなっているので、sepを設定しなければスペースが自動的に文字列の間に入ります。paste0関数ではsepが空、つまり文字列のつなぎには何も入力されない形となります。\n\n\n\n文字列をつなぐ\n\npaste(\"A dog\", \"is running\") # 引数同士をスペースを挟んでつなぐ\n## [1] \"A dog is running\"\n\npaste(\"A\", \"dog\", \"is\", \"running\") # 引数は2つ以上でもよい\n## [1] \"A dog is running\"\n\npaste(\"A dog\", \"is running\", sep=\"/\") # sepに指定した文字が引数の間に入る\n## [1] \"A dog/is running\"\n\npaste0(\"A dog\", \"is running\") # sepに何も追加したくない場合\n## [1] \"A dogis running\"\n\n\n\n\n9.1.2 sprintf関数\n他のプログラミング言語と同様に、sprintf関数と呼ばれる、文字列に変数を挿入する関数をRでも用いることができます。sprintf関数は第一引数に文字列を取り、この文字列中の\"%s\"や\"%f\"の部分に第二引数で指定した変数を挿入する関数です。\"%s\"には文字列、\"%f\"には数値が入ります。第二引数以降の変数は挿入する順番に指定する必要があります。\n\n\n\nsprintf関数\n\nsprintf(\"%f\", pi)\n## [1] \"3.141593\"\n\n# .2fで小数点2桁まで表示\nsprintf(\"%sは%.2fです。\", \"円周率\", pi)\n## [1] \"円周率は3.14です。\"\n\n# 文字列の部分に数値、数値の部分に文字列が来るのでエラー\nsprintf(\"%sは%.2fです。\", pi, \"円周率\") \n## Error in sprintf(\"%sは%.2fです。\", pi, \"円周率\"): invalid format '%.2f'; use format %s for character objects\n\n\n\n\n9.1.3 文字数をカウントする：nchar\n文字数をカウントする関数がnchar関数です。nchar関数は引数に取った文字列の文字数を返します。type引数を指定すると、文字列のバイト数や文字幅を求める事もできます。\n\n\n\n文字数を数える\n\nnchar(\"Hello R\") # スペースを含めて7文字\n## [1] 7\n\nx &lt;- c(\"A dog is running\", \"A cat is running\")\nnchar(x) # ベクターの要素それぞれについて計算\n## [1] 16 16\n\nnchar(\"日本語\") # 日本語でも文字列はカウントされる\n## [1] 3\n\nnchar(\"日本語\", type=\"bytes\") # バイト数は3倍\n## [1] 9\n\nnchar(\"日本語\", type=\"width\") # 等角文字は半角文字の2倍幅\n## [1] 6\n\n\n\n\n9.1.4 文字列から一部抜き出す：substr\n文字列の一部を抜き出す関数がsubstr関数です。文字列のうち、startで指定した位置の文字からstopで指定した位置の文字までを返します。位置の指定はインデックスと同じで、1文字目が1、2文字目が2、という形を取ります。substr関数によく似たsubstring関数もほぼ同じ機能を持ちますが、引数名がfirstとlastになっており、lastのデフォルト値がとても大きく(1000000L) なっています。ですので、firstだけを引数として指定し、それ以降の文字列を返す形で利用するものになっています。\n\n\n\n文字列の抜き出し\n\nx\n## [1] \"A dog is running\" \"A cat is running\"\n\nsubstr(x, start = 3, stop = 5) # xの3文字目から5文字目\n## [1] \"dog\" \"cat\"\n\nsubstring(x, 3) # 3文字目以降を取得\n## [1] \"dog is running\" \"cat is running\"\n\n\n\n\n9.1.5 文字列を分割する：strsplit\nstrsplit関数は、文字列をある特定の文字で分割し、リストの要素として返す関数です。文字は1文字でも、複数の文字でも問題ありません。\n\n\n\n文字列の分割\n\nx\n## [1] \"A dog is running\" \"A cat is running\"\n\nstrsplit(x, \" \") # スペースで分離。リストが返ってくる\n## [[1]]\n## [1] \"A\"       \"dog\"     \"is\"      \"running\"\n## \n## [[2]]\n## [1] \"A\"       \"cat\"     \"is\"      \"running\"\n\nstrsplit(x, \"i\") # i で分離\n## [[1]]\n## [1] \"A dog \" \"s runn\" \"ng\"    \n## \n## [[2]]\n## [1] \"A cat \" \"s runn\" \"ng\"\n\n\n\n\n9.1.6 パターンにあう位置を調べる：grepとmatch\n文字列が一定のパターン（例えば英単語など）を含むかどうかを調べるのが、grep関数とmatch関数です。\ngrep関数は文字列のベクターに適用し、パターンを含むインデックスを返します。ベクターの要素がパターンを含まない場合には、長さ0のベクター（integer(0)）が返ってきます。\nmatch関数は、パターンが全部一致する要素のインデックスを返す関数です。一部が一致する場合にはインデックスは返ってきません。どの要素にも全部一致するものがなければ、NAが返ってきます。パターンが部分一致する場合にインデックスを返すのがpmatch関数です。pmatch関数では、パターンが部分一致する要素が複数あるとNAが返ってきます。\n\n\n\nパターンに一致するものを調べる\n\nx\n## [1] \"A dog is running\" \"A cat is running\"\n\ngrep(pattern = \"dog\", x)\n## [1] 1\n\ngrep(pattern = \"cat\", x)\n## [1] 2\n\ngrep(pattern = \"is\", x)\n## [1] 1 2\n\ngrep(pattern = \"rat\", x)\n## integer(0)\n\n\nmatch(\"median\",   c(\"mean\", \"median\", \"mode\")) # 全文マッチするベクターの位置を返す\n## [1] 2\n\nmatch(\"med\",   c(\"mean\", \"median\", \"mode\")) # 一部マッチではNA\n## [1] NA\n\n\npmatch(\"mo\",   c(\"mean\", \"median\", \"mode\")) # 一部マッチするベクターの位置を返す\n## [1] 3\n\npmatch(\"me\",   c(\"mean\", \"median\", \"mode\")) # マッチするものが2つ以上あるとNA\n## [1] NA\n\n\n\n\n9.1.7 文字列の置き換え：subとgsub\n文字列の中で、パターンが一致したものを別のパターンに置き換えるのが、sub関数、gsub関数です。sub関数、gsub関数は引数として、パターン（pattern）、置き換える文字列（replacement）、文字列のベクターを取ります。sub関数が文字列のうち、前からサーチして一番始めのパターンのみを置き換えるのに対して、gsub関数はパターンが一致した部分をすべて置き換えるものとなっています。gsub関数と同じような働きを持つchartr関数というものもあります。\n\n\n\n文字列の置き換え\n\nx\n## [1] \"A dog is running\" \"A cat is running\"\n\nsub(pattern = \"n\", replacement = \"N\", x) # 始めの要素だけ置き換え\n## [1] \"A dog is ruNning\" \"A cat is ruNning\"\n\ngsub(pattern = \"n\", replacement = \"N\", x) # すべて置き換え\n## [1] \"A dog is ruNNiNg\" \"A cat is ruNNiNg\"\n\nchartr(\"n\", \"N\", x) # 上のgsub関数と同じ結果\n## [1] \"A dog is ruNNiNg\" \"A cat is ruNNiNg\"\n\n\n\n\n9.1.8 小文字、大文字に変換：tolower toupper\n文字列を小文字に置き換えるのがtolower関数、大文字に置き換えるのがtoupper関数です。\n\n\n\n小文字・大文字の変換\n\ntolower(\"A CAT IS RUNNING\") # 小文字に変換\n## [1] \"a cat is running\"\n\nx\n## [1] \"A dog is running\" \"A cat is running\"\n\ntoupper(x) # 大文字に変換\n## [1] \"A DOG IS RUNNING\" \"A CAT IS RUNNING\"\n\n\n\n\n\n表1：Rの文字列に関する関数\n\n\n\n\n\n\n関数名\n文字列xに適用される演算\n\n\n\n\npaste(x, y, sep = z)\nxとyをzを挟んで結合\n\n\npaste0(x, y)\nxとyを何も挟まず結合\n\n\nnchar(x)\nxの文字数をカウントする\n\n\nsubstr(x, start, stop)\nxから文字を切り出す\n\n\nsubstring(x, y)\nxのy文字目以降を切り出す\n\n\nstrsplit(x, pattern)\nxをpatternで分割する\n\n\ngrep(pattern, x)\npatternを含むxのインデックスを返す\n\n\nmatch(pattern, x)\npattern全文を含む要素のインデックスを返す\n\n\npmatch(pattern, x)\npatternを一部含む要素のインデックスを返す\n\n\nsub(x, pattern, replacement)\n始めに一致するpatternをreplacementに置き換える\n\n\ngsub(x, pattern, replacement)\npatternをreplacementにすべて置き換える\n\n\nchartr(old, new, x)\noldをnewにすべて置き換える\n\n\ntolower(x)\n大文字を小文字に変換\n\n\ntoupper(x)\n小文字を大文字に変換",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>文字列</span>"
    ]
  },
  {
    "objectID": "chapter9.html#stringr",
    "href": "chapter9.html#stringr",
    "title": "9  文字列",
    "section": "9.2 stringr",
    "text": "9.2 stringr\nRのデフォルトの文字列関連の関数だけでも色々な文字列の操作ができますが、名前に統一感がなく、返ってくるものがリストだったりするものもあり、なかなか覚えにくく、使いにくいところがあります。\nこの使いにくさを解消し、統一感のある関数名を付けたライブラリがstringr(Wickham 2023)です。stringrには文字列を操作する関数が40程度登録されており、ほぼいずれの関数も「str_」から名前が始まります。Rstudioでは、「str_」と入力すると入力候補と入力候補の説明文が示されるため、比較的簡単に関数を検索し、利用することができます。文字列を取り扱う場合にRのデフォルトの関数群を用いても特に問題はありませんが、stringrの関数群を用いると返り値の利便性や速度に利点があります。\nstringrはtidyverseに含まれるライブラリです。stringrのインストール、ロードにはpacman::p_load関数を用います。\n\n\n\nstringrのインストールおよびロード\n\npacman::p_load(tidyverse) # あらかじめpacmanのインストールが必要\n\n\n以下に、stringrの代表的な関数の使い方を示します。\n\n\n\n表2：stringrの関数\n\n\n\n\n\n\n関数名\n文字列xに適用される演算\n\n\n\n\nstr_detect(x, pattern)\npatternがあるとTRUEを返す\n\n\nstr_which(x, pattern)\npatternを含むインデックスを返す\n\n\nstr_locate(x, pattern)\npatternの位置を調べる\n\n\nstr_locate_all(x, pattern)\npatternの位置をすべて調べる\n\n\nstr_count(x, pattern)\npatternが含まれる数を返す\n\n\nstr_length(x)\n文字数を返す\n\n\nstr_trim(x)\nxの前後のスペースを取り除く\n\n\nstr_trunc(x, width)\nxをwidthの長さに省略する\n\n\nstr_sub(x, start, end)\nstartからendの位置までの文字列を取り出す\n\n\nstr_subset(x, pattern)\npatternを含む要素を取り出す\n\n\nstr_extract(x, pattern)\npatternを取り出す\n\n\nstr_extract_all(x, pattern)\npatternをすべて取り出す\n\n\nstr_match(x, pattern)\npatternを行列で取り出す\n\n\nstr_match_all(x, pattern)\npatternを行列ですべて取り出す\n\n\nstr_c(x, y, sep)\nxとyをsepを挟んで結合する\n\n\nstr_flatten(x, y, collapse)\nxとyをcollapseを挟んで結合する\n\n\nstr_split(x, pattern)\nxをpatternで分割する\n\n\nstr_split_fixed(x, pattern, n)\nxをpatternでn個に分割する\n\n\nstr_split_i(x, pattern, i)\nxをpatternで分割し、i番目の要素を返す\n\n\nstr_replace(x, pattern, replacement)\n始めに一致するpatternをreplacementに置き換える\n\n\nstr_replace_all(x, pattern, replacement)\npatternをreplacementにすべて置き換える\n\n\nstr_to_lower(x)\n大文字を小文字に変換する\n\n\nstr_to_upper(x)\n小文字を大文字に変換する\n\n\n\n\n\n\n\n\n\n\n\nstringrとラッパー（wrapper）\n\n\n\n\n\nstringrはstringi(Gagolewski 2022)というライブラリのラッパー（wrapper）です。ラッパーとは既存の関数の名前や引数の順序を統一したり、使用頻度の高い関数を選んだり、部分的に機能を追加することで利用しやすくしたものです。stringiはC言語由来の文字列処理を取り込んでいるため、Rのデフォルトの関数よりも計算が速いという特徴があります。\n\n\n\n\n9.2.1 パターンの検出：str_detect\nstr_detect関数はパターンを検索し、論理型を返す関数です。パターンが含まれる要素にはTRUE、含まれない要素にはFALSEが返ってきます。\n\n\n\nパターンの検出\n\nx\n## [1] \"A dog is running\" \"A cat is running\"\n\nstr_detect(x, \"dog\")\n## [1]  TRUE FALSE\n\n\n\n\n9.2.2 パターンの検出：str_which\nstr_which関数は上記のgrep関数と同じく、パターンに一致するベクターのインデックスを返す関数です。複数の要素が一致する場合には、一致するすべてのインデックスを返します。\n\n\n\nパターンを検出する：str_which関数\n\nx\n## [1] \"A dog is running\" \"A cat is running\"\n\nstr_which(x, \"dog\")\n## [1] 1\n\nstr_which(x, \"cat\")\n## [1] 2\n\nstr_which(x, \"is\")\n## [1] 1 2\n\n\n\n\n9.2.3 パターンの位置を調べる：str_locate\nもっと厳密に、そのパターンが存在する文字列上の位置を特定するための関数がstr_locate関数です。str_locate関数は行列、もしくは行列のリストを返します。行列のstart列がパターンの開始位置、endが終了位置を示します。パターンが複数含まれる場合には、行列のリストが返ってきます。\n\n\n\nパターンの位置を返す：str_locate関数\n\nx\n## [1] \"A dog is running\" \"A cat is running\"\n\nstr_locate(x, \"dog\") # 1つ目の要素のみにパターンが含まれる時\n##      start end\n## [1,]     3   5\n## [2,]    NA  NA\n\nstr_locate_all(x, \"n\") # 2つの要素にパターンが複数含まれる時\n## [[1]]\n##      start end\n## [1,]    12  12\n## [2,]    13  13\n## [3,]    15  15\n## \n## [[2]]\n##      start end\n## [1,]    12  12\n## [2,]    13  13\n## [3,]    15  15\n\n\n\n\n9.2.4 パターンが含まれる数を数える：str_count\nパターンが何回含まれるかを数える関数がstr_count関数です。パターンが含まれていればそのパターンの個数を、含まれていなければ0を返します。\n\n\n\nパターンの個数を数える：str_count関数\n\nx\n## [1] \"A dog is running\" \"A cat is running\"\n\nstr_count(x, \"dog\") # 1つ目の要素に1つだけパターンが含まれる場合\n## [1] 1 0\n\nstr_count(x, \"n\") # 2つの要素に3つずつパターンが含まれる場合\n## [1] 3 3\n\n\n\n\n9.2.5 文字数を数える：str_length\nstr_length関数はnchar関数と同じく、文字数を返す関数です。どちらを使っても結果は同じですが、他の言語では文字数を数える関数に「length」関数を当てることが多いため、str_lengthの方が直感的に使い方がわかりやすい名前になっています。\n\n\n\n文字数をカウントする：str_length関数\n\nx\n## [1] \"A dog is running\" \"A cat is running\"\n\nstr_length(x)\n## [1] 16 16\n\nnchar(x)\n## [1] 16 16\n\n\n\n\n9.2.6 文字列を整える：str_trim、str_trunc\nstr_trim関数は文字列の前と後ろのスペースを取り除く関数です。文字列の演算では、スペースが前後に残って邪魔になることがよくあります。このような場合にはstr_trimでスペースを取り除き、形を整えることができます。\nstr_trunc関数は、文字列の前や後ろを切り取り、「…」で置き換えて省略してくれる関数です。長い文字列をラベル等に用いるときに使用します。\n\n\n\n文字列を整形する：str_trim, str_trunc関数\n\nstr_trim(\" x \") # スペースを取り除く\n## [1] \"x\"\n\nx\n## [1] \"A dog is running\" \"A cat is running\"\n\nstr_trunc(x, 12) # 後ろを切り取って...で省略\n## [1] \"A dog is ...\" \"A cat is ...\"\n\nstr_trunc(x, 12, side=\"left\") # 前を切り取って...で省略\n## [1] \"...s running\" \"...s running\"\n\n\n\n\n9.2.7 文字を切り出す：str_subとstr_subset\nstr_sub関数はsubstr関数とほぼ同じ働きを持つ関数で、startの位置からendの位置までの文字列を抜き出します。\nstr_subset関数はやや異なり、パターンを含むベクターの要素のみを取り出す関数です。\n\n\n\nパターンを含む文字列を取り出す：str_sub、str_subset関数\n\nx\n## [1] \"A dog is running\" \"A cat is running\"\n\nstr_sub(x, start=3, end=5) # 位置を特定して抽出\n## [1] \"dog\" \"cat\"\n\nstr_subset(x, \"cat\") # 文字を含む要素を抽出\n## [1] \"A cat is running\"\n\nstr_subset(x, \"is\")\n## [1] \"A dog is running\" \"A cat is running\"\n\nstr_subset(x, \"rat\")\n## character(0)\n\n\n\n\n9.2.8 文字列を抽出する：str_extract\nstr_extract関数は、パターンがマッチしたときに、そのパターンを返す関数です。パターンに一致する部分がない場合には、NAを返します。str_extract関数はマッチした始めのパターンのみを返し、str_extract_all関数はマッチしたパターンをすべて返します。str_extract_all関数の返り値はリストになります。\n\n\n\nパターンを抽出する：str_extract関数\n\nx\n## [1] \"A dog is running\" \"A cat is running\"\n\nstr_extract(x, \"is\") # 特定の文字列を抽出\n## [1] \"is\" \"is\"\n\nstr_extract(x, \"dog\") # 抽出できないとNAを返す\n## [1] \"dog\" NA\n\nstr_extract_all(x, \"n\") # パターン一致するものをすべて抽出\n## [[1]]\n## [1] \"n\" \"n\" \"n\"\n## \n## [[2]]\n## [1] \"n\" \"n\" \"n\"\n\n\n\n\n9.2.9 パターンマッチング：str_match\nstr_match関数も一致したパターンを返す関数です。str_match関数は始めにマッチしたパターンを行列で返し、str_match_all関数はマッチしたすべてのパターンを行列のリストで返します。\n\n\n\nマッチしたパターンを返す：str_match関数\n\nx\n## [1] \"A dog is running\" \"A cat is running\"\n\nstr_match(x, \"dog\") # パターンがあれば、そのパターンを返す\n##      [,1] \n## [1,] \"dog\"\n## [2,] NA\n\nstr_match_all(x, \"n\") # パターンがあれば、それをすべて返す\n## [[1]]\n##      [,1]\n## [1,] \"n\" \n## [2,] \"n\" \n## [3,] \"n\" \n## \n## [[2]]\n##      [,1]\n## [1,] \"n\" \n## [2,] \"n\" \n## [3,] \"n\"\n\n\n\n\n9.2.10 文字列をつなぐ：str_cとstr_flatten\nstr_c関数とstr_flatten関数はいずれも文字列をつなぐ関数です。ともにpaste関数とpaste0関数とほぼ同じですが、NAの取り扱いが少しだけ異なります。\n\n\n\n文字列をつなぐ：str_c関数\n\nx\n## [1] \"A dog is running\" \"A cat is running\"\n\nstr_c(x[1], x[2]) # paste0と同じ\n## [1] \"A dog is runningA cat is running\"\n\nstr_c(x[1], x[2], sep=\" \") # pasteと同じ\n## [1] \"A dog is running A cat is running\"\n\nstr_flatten(c(\"a\", \"dog\", \"is\", \"running\")) # paste0と同じ\n## [1] \"adogisrunning\"\n\nstr_flatten(c(\"a\", \"dog\", \"is\", \"running\"), collapse= \" \") # pasteと同じ\n## [1] \"a dog is running\"\n\n\n\n\n9.2.11 文字列を分割する：str_split、str_split_fixed、str_split_i\nstr_split関数はパターンで文字列を分割する関数で、strsplit関数とほぼ同じ機能を持ちます。\nstr_split_fixed関数はパターンで分割するときに、分割後の要素の数を指定することができる関数です。\nstr_split_i関数は、パターンで分割した後に、数値で指定したインデックスの要素のみを取り出す関数です。\n\n\n\n文字列を分割する：str_split関数\n\nx\n## [1] \"A dog is running\" \"A cat is running\"\n\nstr_split(x, \" \") # パターンで分割\n## [[1]]\n## [1] \"A\"       \"dog\"     \"is\"      \"running\"\n## \n## [[2]]\n## [1] \"A\"       \"cat\"     \"is\"      \"running\"\n\nstr_split_fixed(x, \" \", 2) # 始めのパターンで2つに分割\n##      [,1] [,2]            \n## [1,] \"A\"  \"dog is running\"\n## [2,] \"A\"  \"cat is running\"\n\nstr_split_i(x, \" \", 2) # パターンで分割し、2つ目の要素を取り出す\n## [1] \"dog\" \"cat\"\n\n\n\n\n9.2.12 文字列を置き換える：str_replace、str_replace_all\nstr_replace関数は文字列のパターンを別の文字列に置き換える関数です。sub関数とほぼ同等の機能を持ちます。str_replace_all関数はgsub関数とほぼ同じで、str_replace関数が始めにマッチしたパターンのみを置き換えるのに対し、str_replace_all関数はマッチしたパターンをすべて置き換えます。\n\n\n\n文字列を置き換える：str_replace関数\n\nx\n## [1] \"A dog is running\" \"A cat is running\"\n\nstr_replace(x, \"running\", \"walking\") # 前のパターンを後ろの文字列に置き換える\n## [1] \"A dog is walking\" \"A cat is walking\"\n\nstr_replace_all(x, \" \", \",\") # 前のパターンをすべて、後ろの文字列に置き換える\n## [1] \"A,dog,is,running\" \"A,cat,is,running\"\n\n\n\n\n9.2.13 大文字・小文字の操作：str_to_lower、str_to_upper\nstr_to_lower関数は大文字を小文字に、str_to_upper関数は小文字を大文字に変換する関数です。どちらもtolower関数、toupper関数とほぼ同等の機能を持ちます。str_to_lower、str_to_upper関数は言語による小文字・大文字の違いによる変換にも対応していますが、日本人がこの機能を使うことはほぼ無いでしょう。\n\n\n\n大文字・小文字の操作：str_to_lower、str_to_upper\n\nstr_to_lower(\"A DOG IS RUNNING\")\n## [1] \"a dog is running\"\n\nx\n## [1] \"A dog is running\" \"A cat is running\"\n\nstr_to_upper(x)\n## [1] \"A DOG IS RUNNING\" \"A CAT IS RUNNING\"",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>文字列</span>"
    ]
  },
  {
    "objectID": "chapter9.html#正規表現",
    "href": "chapter9.html#正規表現",
    "title": "9  文字列",
    "section": "9.3 正規表現",
    "text": "9.3 正規表現\n文字列中に含まれる特定の文字や単語を取り出す・検出する際に、1つの文字や単語だけでなく、条件に適合した複数の文字列を対象としたい場合もあります。また、文字列の特定の並び（\"would\", \"like\", \"to\"が順番に並んでいるなど）のみを特定し、検出したいといった場合もあるでしょう。このような場合に文字列のマッチングに用いられるものが、正規表現です。正規表現では、文字列と記号を合わせて複雑な文字列のパターンを特定し、マッチングを行うことができます。\nRで用いることができる正規表現には、Rを含めて汎用されている規格（POSIX 1003.2 standard）のものと、Perl言語で用いられる正規表現の主に2つがあります。ここでは前者のみについて簡単に説明します。\nRで用いることができる正規表現の例を以下の表3に示します。\n\n\n\n表3：Rの正規表現の一覧\n\n\n正規表現\n意味\n\n\n\n\n\\a\nビープ音（BEL）\n\n\n\\e\nエスケープ（ESC）\n\n\n\\f\nフォームフィード（FF，書式送り）\n\n\n\\n\nラインフィード（LF，改行）\n\n\n\\r\nキャリッジリターン（CR，改行）\n\n\n\\t\nタブ（TAB）\n\n\n\\w\nすべての英数字（アルファベット＋数値）\n\n\n\\W\nすべての英数字を含まない\n\n\n\\&lt;，\\&gt;\n文書の端の空欄（&lt;が始め，&gt;が終わり）\n\n\n\\b\n文書の端の空欄\n\n\n\\B\n文書中の空欄（端を除く）\n\n\n[abc]\na，b，cを含む\n\n\n[^abc]\na，b，cを含まない\n\n\n[0-9]\n0～9の数字\n\n\n[:digit:]⁠\n数字\n\n\n[:xdigit:]⁠\n16進数の数字（19，AF）\n\n\n[A-Z]\nA～Zの大文字アルファベット\n\n\n[a-z]\na～zの小文字アルファベット\n\n\n[:alnum:]⁠\nすべての英数字（アルファベット＋数値）\n\n\n⁠[:alpha:]\nすべてのアルファベット\n\n\n⁠[:lower:]⁠\nすべての小文字アルファベット\n\n\n⁠[:upper:]⁠\nすべての大文字アルファベット\n\n\n[:blank:]⁠\nスペースもしくはタブ\n\n\n[:space:]\nスペース文字（FFやCRを含む）\n\n\n[:graph:]⁠\n表示可能な文字（図形文字）\n\n\n⁠[:print:]⁠\n表示可能な文字（スペース含む）\n\n\n[:punct:]⁠\n句読点など\n\n\n[:cntrl:]⁠\n制御文字\n\n\n?a\naが0～1回マッチする\n\n\n*a\naが0回以上マッチする\n\n\n+a\naが1回以上マッチする\n\n\n{5}a\naaaaaがマッチする\n\n\n{5,}a\naaaaaよりaが続く文字列がマッチする\n\n\n{2,4}a\naa，aaa，aaaaのいずれかがマッチする\n\n\n(abc|def)\nabcかdefのどちらかにマッチする\n\n\n[あ-ん]\nすべてのひらがな\n\n\n[ア-ン]\nすべてのカタカナ\n\n\n\n\n\n\n9.3.1 関数での正規表現の利用\n正規表現はこの章で述べたR言語の文字列を対象とする関数や、stringrの関数でパターンとして指定し、用いることができます。以下はgrep関数のpattern引数に正規表現を指定した場合の例です。正規表現を用いることで、例えばhtmlのアドレスやe-mailのアドレスとして正しい記載であるかなど、複雑な文字列のパターンでも検出し、評価することができます。\n\n\n\n正規表現による文字列の検出\n\nv &lt;- c(\"dog\", \"cat\", \"pig\", \"rat\", \"egg\")\ngrep(\"[abc]\", v, value=TRUE) # abcのいずれかを含む\n## [1] \"cat\" \"rat\"\n\ngrep(\"[^crat]\", v, value=TRUE) # crat以外を含む\n## [1] \"dog\" \"pig\" \"egg\"\n\ngrep(\"^c\", v, value=TRUE) # cから始まる\n## [1] \"cat\"\n\ngrep(\"[(o|g)][(p|g)]\", v, value=TRUE) # op、og、gp、ggのいずれかを含む\n## [1] \"dog\" \"egg\"\n\ngrep(\"g{2}\", v, value=TRUE) # ggを含む\n## [1] \"egg\"\n\n\n\n\n9.3.2 rexパッケージ\nとは言っても、正規表現をまるまる覚えるのは大変ですし、いちいち検索して正規表現でパターンを表現するのも場合によってはかなり大変です。rexパッケージ(Ushey, Hester, and Krzyzanowski 2021)はこのような複雑な正規表現を人にも理解しやすい形で作成できるようにするためのパッケージです。よく用いられる正規表現はshortcutsというオブジェクト（リストと同じように取り扱えます）に含まれていますし、rex関数を用いてより複雑な正規表現を作成することもできます。\n\n\n\nrexパッケージ\n\npacman::p_load(rex)\n\nshortcuts$letter # アルファベット\n## [:alpha:]\n\nshortcuts$non_puncts # 句読点以外\n## [^[:punct:]]+\n\nrex(none_of(\"a\", \"e\", \"i\", \"o\", \"u\")) # aeiou以外\n## [^aeiou]\n\n\n\n\n\n\n\n\nGagolewski, Marek. 2022. “stringi: Fast and Portable Character String Processing in R.” Journal of Statistical Software 103 (2): 1–59. https://doi.org/10.18637/jss.v103.i02.\n\n\nUshey, Kevin, Jim Hester, and Robert Krzyzanowski. 2021. Rex: Friendly Regular Expressions. https://CRAN.R-project.org/package=rex.\n\n\nWickham, Hadley. 2023. Stringr: Simple, Consistent Wrappers for Common String Operations. https://CRAN.R-project.org/package=stringr.",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>文字列</span>"
    ]
  },
  {
    "objectID": "chapter10.html",
    "href": "chapter10.html",
    "title": "10  因子（factor）",
    "section": "",
    "text": "10.1 因子のレベル（Levels）\n因子にはレベル（Levels）というアトリビュートが存在します。レベルは、因子の種類と順番を指すアトリビュートです。文字列を因子に変えた場合には、アルファベット順にレベルが付与され、数値を因子に変えた場合には、数値の小さいものからレベルが付与されます。レベルの順序は、グラフや統計結果の表示の順番に影響を与えます。\n因子のレベルを確認する関数には、nlevels関数とlevels関数の2つが存在します。nlevels関数は因子のレベルの数を返す関数です。levels関数は因子のレベルをそのレベルの順番にそって返します。\n因子のレベルとその順番\n\nnlevels(fx)\n## [1] 4\n\nlevels(fx) # levelsはアルファベット順になる\n## [1] \"cat\"   \"dog\"   \"horse\" \"pig\"\n\nx2 &lt;- c(4, 3, 2, 1)\nfx2 &lt;- factor(x2)\nlevels(fx2) # levelsは数値順になる\n## [1] \"1\" \"2\" \"3\" \"4\"",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>因子（factor）</span>"
    ]
  },
  {
    "objectID": "chapter10.html#因子のクラスと型",
    "href": "chapter10.html#因子のクラスと型",
    "title": "10  因子（factor）",
    "section": "10.2 因子のクラスと型",
    "text": "10.2 因子のクラスと型\n因子のクラスはfactor、型はnumeric（integer）です。つまり、因子は整数にレベルがラベル付けされているクラスとなります。\n\n\n\n因子のクラス・型\n\nclass(fx)\n## [1] \"factor\"\nmode(fx)\n## [1] \"numeric\"\ntypeof(fx)\n## [1] \"integer\"\n\n# 文字列から作った因子もnumericとなる\nfch &lt;- c(\"dog\", \"cat\")\nfch &lt;- factor(fch)\nmode(fch)\n## [1] \"numeric\"\n\n\n因子はそもそも型が数値ですので、as.numeric関数で数値に変換できます。このときの数値はレベルの順番に1、2、3…となります。また、因子をas.character関数を用いて文字列に変換することもできます。文字列に変換した場合には、レベルの名前がそのまま出力されます。\nまた、ベクターには、名前（names）というアトリビュートがあるのですが、因子のレベルはこの名前とは異なります。因子のベクターにも名前は別途つけることができますが、過剰に複雑になるので避けた方が良いでしょう。\n\n\n\n因子から数値・文字列への変換\n\nfx\n##  [1] dog   dog   dog   dog   dog   cat   cat   cat   cat   pig   pig   pig  \n## [13] horse horse\n## Levels: cat dog horse pig\n\nas.numeric(fx) # levelsの順に番号が付く\n##  [1] 2 2 2 2 2 1 1 1 1 4 4 4 3 3\n\nas.character(fx) # 文字列には直接変換できる\n##  [1] \"dog\"   \"dog\"   \"dog\"   \"dog\"   \"dog\"   \"cat\"   \"cat\"   \"cat\"   \"cat\"  \n## [10] \"pig\"   \"pig\"   \"pig\"   \"horse\" \"horse\"\n\n# factorの文字はnamesとしては設定されていない（levelsはnamesではない）\nnames(fx) \n## NULL\n\nfx1 &lt;- fx\nnames(fx1) &lt;- rep(c(\"rat\", \"mouse\", \"sheep\", \"monkey\"), c(2, 3, 4, 5))\nfx1 # 名前付きベクターの因子\n##    rat    rat  mouse  mouse  mouse  sheep  sheep  sheep  sheep monkey monkey \n##    dog    dog    dog    dog    dog    cat    cat    cat    cat    pig    pig \n## monkey monkey monkey \n##    pig  horse  horse \n## Levels: cat dog horse pig\n\n\n因子の各レベルの要素の個数を数える場合には、table関数を用います。table関数を用いると、各レベルと、そのレベルの要素の数が返ってきます。同様に、summary関数でも要素の数を数えることができます。\n\n\n\n因子の個数を数える：table関数\n\ntable(fx)\n## fx\n##   cat   dog horse   pig \n##     4     5     2     3\n\nsummary(fx)\n##   cat   dog horse   pig \n##     4     5     2     3",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>因子（factor）</span>"
    ]
  },
  {
    "objectID": "chapter10.html#レベルの順序を変更する",
    "href": "chapter10.html#レベルの順序を変更する",
    "title": "10  因子（factor）",
    "section": "10.3 レベルの順序を変更する",
    "text": "10.3 レベルの順序を変更する\nレベルの順序は、因子を作成するときにfactor関数の引数にlevelsを指定することで変更できます。levelsには因子の要素のベクターで指定します。このlevelsに指定した順番に、レベルの順序が決まります。\n\n\n\nレベルの順序を変更する\n\nfx\n##  [1] dog   dog   dog   dog   dog   cat   cat   cat   cat   pig   pig   pig  \n## [13] horse horse\n## Levels: cat dog horse pig\nfx2 &lt;- factor(fx, levels = c(\"cat\", \"horse\", \"pig\", \"dog\"))\n\nlevels(fx) # レベル順はcat, dog, horse, pig\n## [1] \"cat\"   \"dog\"   \"horse\" \"pig\"\n\nlevels(fx2) # レベルの順序が上のlevelsの順に変更されている\n## [1] \"cat\"   \"horse\" \"pig\"   \"dog\"\n\nas.numeric(fx) # 元の順序\n##  [1] 2 2 2 2 2 1 1 1 1 4 4 4 3 3\n\nas.numeric(fx2) # 変更後の順序\n##  [1] 4 4 4 4 4 1 1 1 1 3 3 3 2 2\n\n\n\n\n\n表1：因子に関連する関数\n\n\n関数名\n因子xに適用される演算\n\n\n\n\nfactor(x, levels)\n因子を作成する・レベルの順序を変える\n\n\nlevels(x)\nレベルを表示する\n\n\nnlevels(x)\nレベルの数を表示する\n\n\ntable(x)\n各レベルの要素数を表示する",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>因子（factor）</span>"
    ]
  },
  {
    "objectID": "chapter10.html#forcats",
    "href": "chapter10.html#forcats",
    "title": "10  因子（factor）",
    "section": "10.4 forcats",
    "text": "10.4 forcats\nRでは因子のレベル順を変更し、グラフや統計結果の表示順を定める場合があります。特に統計学的検定の計算では、対照群（Control）と処理群（Treatment）が因子の順番によって決まる場合があり、因子の順序が計算上重要となります。\nデフォルトのRの関数群でも因子の順序などを編集することはできますが、因子の演算を行う専門のライブラリであるforcats (Wickham 2023)を用いると、より簡潔に、統一感のある因子の演算を行うことができます。forcatsもtidyverse (Wickham et al. 2019)に含まれるライブラリの一つです。\n\n\n\n表2：forcatsの関数\n\n\n\n\n\n\n関数名\n因子xに適用される演算\n\n\n\n\nfct_count(x)\n各レベルの要素の数を返す\n\n\nfct_match(x, pattern)\npatternのレベルであればTRUEを返す\n\n\nfct_unique(x)\n各レベルから要素を1つずつ返す\n\n\nfct_c(x, y)\n因子を結合する\n\n\nfct_unify(list(x, y))\nリスト内の因子間でレベルを追加する\n\n\nfct_relevel(x, levels)\nレベルを付け直す\n\n\nfct_infreq(x)\nレベルの要素の数順にレベルをつけ直す\n\n\nfct_inorder(x)\n前にある要素ほど前のレベルにする\n\n\nfct_rev(x)\nレベルを逆順にする\n\n\nfct_shift(x)\nレベルの順を1つずらす\n\n\nfct_shuffle(x)\nレベルをランダムに並べ替える\n\n\nfct_recode(x, newlevel=“oldlevel”)\noldlevelのラベルをnewlevelにつけ直す\n\n\nfct_anon(x)\nレベル名を匿名化する\n\n\nfct_collupse(x, newlevel=c(levels))\n2つ以上のレベルを1つにまとめる\n\n\nfct_lump_min(x, min)\nminで指定した数以上のレベルをotherにする\n\n\nfct_other(x, keep)\nkeepで指定したレベル以外の因子をotherにする\n\n\n\n\n\n\n10.4.1 因子の確認\nfct_count関数はtable関数とほぼ同じ関数で、因子の要素数を返しますが、結果をデータフレーム（正確にはtibbleというもの）で返す点がtable関数とは異なります。\nfct_match関数は、パターンとしてレベル名を設定し、そのレベルと一致する要素ではTRUE、一致しない要素にはFALSEを返します。\nfct_unique関数はlevels関数とほぼ同じですが、levels関数の返り値が文字列なのに対して、fct_unique関数は因子を返す点が異なります。\n\n\n\nforcats 因子を確認する\n\n# tidyverseをロードすると、forcatもロードされる\npacman::p_load(tidyverse)\n\nfx\n##  [1] dog   dog   dog   dog   dog   cat   cat   cat   cat   pig   pig   pig  \n## [13] horse horse\n## Levels: cat dog horse pig\n\n# table関数と同じ変換をデータフレーム（正確にはtibble）を出力として行う\nfct_count(fx) \n## # A tibble: 4 × 2\n##   f         n\n##   &lt;fct&gt; &lt;int&gt;\n## 1 cat       4\n## 2 dog       5\n## 3 horse     2\n## 4 pig       3\n\nfct_match(fx, \"dog\") # 因子dogを探す関数\n##  [1]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n## [13] FALSE FALSE\n\nfct_unique(fx) # levelsとほとんど同じ関数(因子を返す、levelsは文字列を返す)\n## [1] cat   dog   horse pig  \n## Levels: cat dog horse pig\n\n\n\n\n10.4.2 因子を結合する\n因子をつなぐときに用いるのが、fct_c関数とfct_unity関数です。fct_c関数はc関数と同じですが、因子のリストを引数に取れるという特徴があります。fact_unify関数は引数にリストを取り、お互いにレベルを追加するところが異なります。\n\n\n\nforcats：因子を結合する\n\nfx3 &lt;- factor(rep(c(\"rat\", \"mouse\", \"sheep\"), c(3, 4, 5)))\n\nc(fx, fx3)\n##  [1] dog   dog   dog   dog   dog   cat   cat   cat   cat   pig   pig   pig  \n## [13] horse horse rat   rat   rat   mouse mouse mouse mouse sheep sheep sheep\n## [25] sheep sheep\n## Levels: cat dog horse pig mouse rat sheep\n\nfct_c(fx, fx3) # レベルが追加される(c関数でつないでもほぼ同じ)\n##  [1] dog   dog   dog   dog   dog   cat   cat   cat   cat   pig   pig   pig  \n## [13] horse horse rat   rat   rat   mouse mouse mouse mouse sheep sheep sheep\n## [25] sheep sheep\n## Levels: cat dog horse pig mouse rat sheep\n\nfct_unify(list(fx, fx3)) # 因子のリストにそれぞれレベルを追加する\n## [[1]]\n##  [1] dog   dog   dog   dog   dog   cat   cat   cat   cat   pig   pig   pig  \n## [13] horse horse\n## Levels: cat dog horse pig mouse rat sheep\n## \n## [[2]]\n##  [1] rat   rat   rat   mouse mouse mouse mouse sheep sheep sheep sheep sheep\n## Levels: cat dog horse pig mouse rat sheep\n\n\n\n\n10.4.3 レベルの操作\n因子のレベルを付け直すのがfct_relevel関数です。factor関数にlevels引数を取るのとほぼ同じことができます。\nfct_infreq関数は因子のレベルを因子の個数順（多いものが前、少ないものが後）に、fct_inorder関数は因子のベクターで前に出てきたものをより前にする形でレベルを変更するものです。\nfct_rev関数はレベルを逆順に、fct_shift関数は一番前のレベルを一番最後にシフトし、fct_shuffle関数はレベルの順序をランダムに入れ替える関数です。\n\n\n\nforcats：レベルを操作する\n\nfct_relevel(fx, c(\"dog\", \"cat\", \"pig\", \"horse\")) # factor(fx, levels=c(\"dog\", \"cat\", \"pig\", \"horse\"))と同じ\n##  [1] dog   dog   dog   dog   dog   cat   cat   cat   cat   pig   pig   pig  \n## [13] horse horse\n## Levels: dog cat pig horse\n\nfct_infreq(fx) # 要素が多いものから順番に並べ替える\n##  [1] dog   dog   dog   dog   dog   cat   cat   cat   cat   pig   pig   pig  \n## [13] horse horse\n## Levels: dog cat pig horse\n\nfct_inorder(fx) # 要素が前にあるものをレベルの前に変更する\n##  [1] dog   dog   dog   dog   dog   cat   cat   cat   cat   pig   pig   pig  \n## [13] horse horse\n## Levels: dog cat pig horse\n\nfct_rev(fx) # レベルを逆順にする\n##  [1] dog   dog   dog   dog   dog   cat   cat   cat   cat   pig   pig   pig  \n## [13] horse horse\n## Levels: pig horse dog cat\n\nfct_shift(fx) # レベルを1つずらす\n##  [1] dog   dog   dog   dog   dog   cat   cat   cat   cat   pig   pig   pig  \n## [13] horse horse\n## Levels: dog horse pig cat\n\nfct_shuffle(fx) # レベルをランダムに並べ替える\n##  [1] dog   dog   dog   dog   dog   cat   cat   cat   cat   pig   pig   pig  \n## [13] horse horse\n## Levels: dog cat horse pig\n\n\n\n\n10.4.4 レベル名の変更\nfct_recode関数は因子名を別名に付け替え、fct_anon関数は因子名を匿名化（anonymize）するものです。fct_collapse関数は因子の複数のレベルを1つにまとめ、fct_lump_min関数はmin引数で指定した数より個数が少ない因子をすべてotherに変えます。fct_other関数はkeep引数で指定したレベル以外をotherに変えます。\nいずれも、データをRに取り込んだ後に、余分な因子を処理したり、匿名化することで個人情報等に対応したりするために用いるものです。\n\n\n\nforcats：レベル名を変更する\n\nfct_recode(fx, mouse=\"dog\", rat=\"cat\", monkey=\"pig\", cow=\"horse\") # ラベルを付け替える\n##  [1] mouse  mouse  mouse  mouse  mouse  rat    rat    rat    rat    monkey\n## [11] monkey monkey cow    cow   \n## Levels: rat mouse cow monkey\n\nfct_anon(fx) # 因子を匿名化（anonymize）する\n##  [1] 1 1 1 1 1 3 3 3 3 2 2 2 4 4\n## Levels: 1 2 3 4\n\nfct_collapse(fx, dogcat = c(\"dog\", \"cat\")) # レベルを結合する\n##  [1] dogcat dogcat dogcat dogcat dogcat dogcat dogcat dogcat dogcat pig   \n## [11] pig    pig    horse  horse \n## Levels: dogcat horse pig\n\nfct_lump_min(fx, min=4) # 2つより少ない個数しかない因子をotherに変える\n##  [1] dog   dog   dog   dog   dog   cat   cat   cat   cat   Other Other Other\n## [13] Other Other\n## Levels: cat dog Other\n\nfct_other(fx, keep=c(\"dog\", \"cat\")) # keep以外のレベルをotherに変える\n##  [1] dog   dog   dog   dog   dog   cat   cat   cat   cat   Other Other Other\n## [13] Other Other\n## Levels: cat dog Other\n\n\n\n\n\n\n\n\nWickham, Hadley. 2023. Forcats: Tools for Working with Categorical Variables (Factors). https://CRAN.R-project.org/package=forcats.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>因子（factor）</span>"
    ]
  },
  {
    "objectID": "chapter11.html",
    "href": "chapter11.html",
    "title": "11  ベクター",
    "section": "",
    "text": "11.1 ベクターの作成と結合：cとappend\n要素が一つのベクターは関数などを特に用いることなく作成することができます。要素が複数のベクターはc関数（cはconbineの略）で作成することができます。c関数はベクター同士をつなぐのにも使えます。\nappend関数もベクター同士を結合するのに使います。append関数では、ベクターを追加する位置をafter引数で指定することができます。\nc関数とappend関数でベクターを作成する\n\n1 # 一つの数値はベクター\n## [1] 1\n\n\"moji\" # 一つの文字列もベクター\n## [1] \"moji\"\n\nx &lt;- c(1, 2, 3) # c関数で複数の要素のベクターを作る\nc(x, 4) # c関数はベクター同士をつなぐのにも使える\n## [1] 1 2 3 4\n\nappend(x, 4) # append関数もベクターをつなぐのに使える\n## [1] 1 2 3 4\n\n# append関数では、ベクターの挿入場所を指定できる\nappend(c(1, 2, 3), \"added\", after=1) \n## [1] \"1\"     \"added\" \"2\"     \"3\"",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ベクター</span>"
    ]
  },
  {
    "objectID": "chapter11.html#連続する数値ベクターを作成するコロンsepseq",
    "href": "chapter11.html#連続する数値ベクターを作成するコロンsepseq",
    "title": "11  ベクター",
    "section": "11.2 連続する数値ベクターを作成する：コロン（:）、sep、seq",
    "text": "11.2 連続する数値ベクターを作成する：コロン（:）、sep、seq\n連続する整数や、一定間隔の数列、繰り返しのあるベクターを作成する場合には、:（コロン）、seq関数、rep関数を用います。\n:（コロン）は連続する数値のベクターを作成する演算子で、コロンの前に置いた数値から、後に置いた数値まで公差1の、連続する数値のベクターを作成します。コロンの前後には、マイナスの数値を設定することもできます（例えば、-1:-3とすると、-1, -2, -3のベクターとなります）。このコロンの演算は、他の演算子より前に実行されます。\nseq関数は、第一引数（from）から第二引数（to）まで、by引数で指定した間隔で連続する数値のベクターを作成する関数です。また、by引数の代わりに、length.out引数を設定すると、fromからtoまで、length.outで指定した長さのベクターを作成することができます。\nrep関数は、第一引数にベクターを取り、第二引数に繰り返しの回数を取る関数です。rep関数の出力は、第一引数のベクターを第二引数の回数だけ繰り返したものになります。第二引数にはベクターを取ることもでき、ベクターで指定した回数だけ、要素を繰り返したベクターを作成することができます。\n\n\n\n連続した数値ベクターを作成する\n\n1:3 # 1から3までの整数のベクター\n## [1] 1 2 3\n\n-5:5 # -5から5までの整数のベクター\n##  [1] -5 -4 -3 -2 -1  0  1  2  3  4  5\n\n-1:-10 # -1から-10までの整数のベクター\n##  [1]  -1  -2  -3  -4  -5  -6  -7  -8  -9 -10\n\n-1:-10 * 5 # コロンの演算は掛け算より先に行われる\n##  [1]  -5 -10 -15 -20 -25 -30 -35 -40 -45 -50\n\nseq(1, 5, by=0.5) # 1から5まで、0.5間隔のベクター\n## [1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0\n\nseq(1, 5, length.out=11) # 1から5まで、等間隔の長さ11のベクター\n##  [1] 1.0 1.4 1.8 2.2 2.6 3.0 3.4 3.8 4.2 4.6 5.0\n\nx # xは1、2、3のベクター\n## [1] 1 2 3\n\nrep(x, 5) # xを5回繰り返す\n##  [1] 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3\n\nrep(x, c(1, 2, 3)) # xの要素を1、2、3回繰り返す\n## [1] 1 2 2 3 3 3",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ベクター</span>"
    ]
  },
  {
    "objectID": "chapter11.html#ベクターの型",
    "href": "chapter11.html#ベクターの型",
    "title": "11  ベクター",
    "section": "11.3 ベクターの型",
    "text": "11.3 ベクターの型\nベクターの型は、ベクターに含まれる要素によって変化します。数値のベクターはnumeric、文字列が含まれるベクターはcharacter、因子であればfactor（factorはクラスで、型はnumeric）、論理型であればlogicalとなります。ベクターは1つの型からなる要素の集合ですので、別の型の要素が付け加えられると、元のベクター、もしくは付け加えられた要素の型が変化します。型の優先順位はcharacter &gt; numeric &gt; logical = factorという順で、型が混じったベクターはより優先される型に自動的に変換されます。\nベクターはatomic vectorと呼ばれることもあります。ベクターであることの確認には、is.atomic関数を用います。この関数は、引数がベクターであればTRUE、ベクター以外であればFALSEを返します。\n\n\n\nベクターの型・クラス\n\nclass(c(x, 4)) # 数値ベクター（numeric）\n## [1] \"numeric\"\n\nclass(c(x, \"added\")) # 文字列ベクター（character）\n## [1] \"character\"\n\nclass(factor(x)) # 因子ベクター（factor）\n## [1] \"factor\"\n\nclass(c(T, F, T)) # 論理型ベクター（logical）\n## [1] \"logical\"\n\nclass(c(T, 1)) # logicalとnumericのベクターはnumeric\n## [1] \"numeric\"\n\nclass(c(factor(\"dog\"), 1)) # factorとnumericのベクターはnumeric\n## [1] \"numeric\"\n\nclass(c(T, factor(\"dog\"))) # logicalとfactorのベクターはnumeric（integer）\n## [1] \"integer\"\n\nclass(c(1, \"dog\")) # numericとcharacterのベクターはcharacter\n## [1] \"character\"\n\n\nmode(c(x, 4)) \n## [1] \"numeric\"\n\nmode(c(x, \"added\"))\n## [1] \"character\"\n\nmode(factor(x)) # 因子はクラスで、型は数値型\n## [1] \"numeric\"\n\nmode(c(T, F, T))\n## [1] \"logical\"\n\nis.atomic(1) # 長さ1のベクター\n## [1] TRUE\n\nis.atomic(c(1, 2)) # 長さ2以上のベクター\n## [1] TRUE\n\nis.atomic(list(1)) # リストはベクターではない\n## [1] FALSE",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ベクター</span>"
    ]
  },
  {
    "objectID": "chapter11.html#演算と反復recycling",
    "href": "chapter11.html#演算と反復recycling",
    "title": "11  ベクター",
    "section": "11.4 演算と反復（recycling）",
    "text": "11.4 演算と反復（recycling）\nRのベクターでは、for文などの繰り返し文を用いることなく、すべての要素に対して演算を行うことができます。\n\n\n\nベクターの演算\n\nx &lt;- c(1, 2, 3)\nx + 1\n## [1] 2 3 4\nx - 1\n## [1] 0 1 2\nx * 3\n## [1] 3 6 9\nx / 2\n## [1] 0.5 1.0 1.5\nx %% 3\n## [1] 1 2 0\n\n\nベクターの演算時には、反復（recycling）のルールが適用されます。長いベクターと短いベクターの演算で、反復のルールを確認してみましょう。\n\n\n\n反復（recycling）\n\ny &lt;- c(2, 3, 4) # 長さ3のベクター\nx # 長さ3のベクター\n## [1] 1 2 3\ny\n## [1] 2 3 4\nx + y \n## [1] 3 5 7\nx - y\n## [1] -1 -1 -1\nx * y\n## [1]  2  6 12\nx / y\n## [1] 0.5000000 0.6666667 0.7500000\nz &lt;- c(2, 2, 2, 2, 2, 2) # 長さ6のベクター\nx\n## [1] 1 2 3\nz\n## [1] 2 2 2 2 2 2\nx + z\n## [1] 3 4 5 3 4 5\nx - z\n## [1] -1  0  1 -1  0  1\nx * z\n## [1] 2 4 6 2 4 6\nx / z\n## [1] 0.5 1.0 1.5 0.5 1.0 1.5\n\n\n長さが同じベクターでは、ベクターのインデックスが一致するもの同士が演算されていることがわかります。例えば、x（c(1, 2, 3)）とy（c(2, 3, 4)）の足し算は、1+2、2+3、3+4の結果となります。\n一方で、長さが違うベクターを演算した場合には、短いベクターが反復（recycling）されます。x（c(1, 2, 3)）とz（c(2, 2, 2, 2, 2, 2)）の足し算では、前の3つのインデックスだけでなく、後ろの3つにもxの要素が足し算された結果が返ってきます（1+2, 2+2, 3+2, 1+2, 2+2, 3+2の結果が出力）。このように、短いベクターを繰り返して、長いベクターと同じ長さとし、結果を返すのが反復（recycling）のルールです。ベクターに数値を足し算するような場合にも、この反復と同じルールが適用されています。数値は長さ1のベクターですので、この長さ1のベクターを反復し、長さをあわせて計算した結果が返ってきていることになります。\n\n\n\n反復の書き下し\n\nc(1, 2, 3) + 1 # このような書き方は\n## [1] 2 3 4\nc(1, 2, 3) + c(1, 1, 1) # 自動的にこのような計算とされる\n## [1] 2 3 4\n\n\nこのルールでは、短いベクターの長さがもう一方のベクターの長さの約数でない場合、中途半端に反復されることになります。下の場合では、c(1, 2)が反復されて、c(1, 2, 1)として取り扱われています。このような場合には、Rは警告（warning）を出します。\n\n\n\n長さが中途半端なベクターの演算\n\nc(1, 2) + c(1, 2, 3)\n## Warning in c(1, 2) + c(1, 2, 3): longer object length is not a multiple of\n## shorter object length\n## [1] 2 4 4",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ベクター</span>"
    ]
  },
  {
    "objectID": "chapter11.html#インデックス",
    "href": "chapter11.html#インデックス",
    "title": "11  ベクター",
    "section": "11.5 インデックス",
    "text": "11.5 インデックス\nベクターの要素はインデックスを用いて取り出すことができます。インデックスはベクターの1つ目の要素が1、2つ目の要素が2、という形で設定されており、[ ]（角カッコ）の中にインデックスを指定することで要素を取り出すことができます。\nインデックスは整数のベクターの形でも指定できます。連続したインデックスを指定する際には、コロン（:）を用いて指定します。\nインデックスをマイナスで指定すると、そのインデックスが指定する要素を削除することができます。インデックスをマイナスのベクターで指定すると、そのマイナスで指定した位置の要素が削除されます。\nインデックスは数値だけでなく、論理型（TRUEとFALSE）で指定することもできます。[ ]の中に、TRUE（T）とFALSE（F）のベクターを与えると、TRUEのインデックスにある要素だけを取り出すことができます。この指定では、反復（recycling）が適用されるので、ベクターの長さより論理型ベクターの長さが短ければ、論理型ベクターが反復されて使用されます。論理型ベクターの方が長い場合には反復は行われず、論理型ベクターが余分に長い分だけNAが返ってきます。\nインデックスを論理型ベクターで指定できるため、比較演算子を用いてベクターの要素を取り出すこともできます。例えば、x[x &gt; 5]という形で比較演算子を用いてインデックスを指定すると、xのベクターのうち、5より大きい要素のみを取り出すことができます。\nベクターの一部を確認したいときには、head関数とtail関数を用います。head関数はベクターの始めから6つ目までを、tail関数はベクターの後ろから6つ目までを表示する関数です。どちらも第二引数に数値を入れると、その長さのベクターを取り出すことができます。\n\n\n\nベクターのインデックス\n\nx &lt;- 2:11\nx\n##  [1]  2  3  4  5  6  7  8  9 10 11\n\nx[3] # 3つ目の要素を取り出す\n## [1] 4\n\nx[12] # 要素が無いとNAが返ってくる\n## [1] NA\n\nx[c(10, 5, 2)] # 10番目、5番目、2番目の要素を取り出す\n## [1] 11  6  3\n\nx[4:6] # 4番目から6番目までの要素を取り出す\n## [1] 5 6 7\n\nx[-4] # 4番目の要素を削除する\n## [1]  2  3  4  6  7  8  9 10 11\n\nx[-(5:8)] # 5番目から8番目までの要素を削除する\n## [1]  2  3  4  5 10 11\n\nx[-5:-8] # 上と同じ\n## [1]  2  3  4  5 10 11\n\nx[c(T, T, T, T, F, T, T, T, T, F)] # インデックスは論理型でもよい\n## [1]  2  3  4  5  7  8  9 10\n\nx[c(T, F)] # 反復（recycling）が適用され、2つ置きに要素を取り出すことになる\n## [1]  2  4  6  8 10\n\nx[c(T, T, T, T, F, T, T, T, T, F, T)] # 論理型の方が長いと、NAが返ってくる\n## [1]  2  3  4  5  7  8  9 10 NA\n\nx == 5 # 論理型を比較演算子で作る\n##  [1] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n\nx[x == 5] # 比較演算子を含む演算もインデックスに取れる\n## [1] 5\n\nx[x &gt; 5]\n## [1]  6  7  8  9 10 11\n\nx[x &gt; 3 & x &lt; 6] # 3より大きく、かつ6より小さいものを選ぶ\n## [1] 4 5\n\nx %in% c(2, 7) # %in%は後ろの要素と一致する場合にTRUEを返す\n##  [1]  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE\n\nx[x %in% c(2, 7)] # 2と7である要素を取り出す\n## [1] 2 7\n\nhead(x) # 始めの6つを表示\n## [1] 2 3 4 5 6 7\n\ntail(x) # 最後の6つを表示\n## [1]  6  7  8  9 10 11",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ベクター</span>"
    ]
  },
  {
    "objectID": "chapter11.html#インデックスの位置を特定する",
    "href": "chapter11.html#インデックスの位置を特定する",
    "title": "11  ベクター",
    "section": "11.6 インデックスの位置を特定する",
    "text": "11.6 インデックスの位置を特定する\nインデックスの位置を特定する場合には、which関数を用います。which関数は引数に論理型（もしくは比較・論理演算子）を取り、TRUEになる位置のインデックスを返す関数です。\n\n\n\nwhich関数\n\nx &lt;- c(\"cat\", \"fat\", \"dog\", \"rat\", \"mat\")\nwhich(x == \"cat\") # catはインデックス1\n## [1] 1\n\nwhich(x == \"rat\") # ratはインデックス4\n## [1] 4",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ベクター</span>"
    ]
  },
  {
    "objectID": "chapter11.html#ベクターの要素に名前を付ける",
    "href": "chapter11.html#ベクターの要素に名前を付ける",
    "title": "11  ベクター",
    "section": "11.7 ベクターの要素に名前を付ける",
    "text": "11.7 ベクターの要素に名前を付ける\nベクターには名前（names）というアトリビュートがあります。namesはベクターの要素に名前をつけるものです。namesの要素が重複していても問題はないのですが、後に述べる呼び出しの際に間違いの原因となるため、あまりオススメはできません。\nベクターの要素は上記の通り、インデックスを用いて呼び出すことができます。しかし、ベクターの要素はその名前からでも呼び出すことができます。呼び出すときには、角カッコ（[ ]）の中に、文字列で名前を示します。インデックスの代わりに名前の文字列を用いることで、名前に対応した要素を取り出すことができます。\nベクターの名前は、c関数を用いてベクターを作成するときに設定することができます。ベクターがすでに変数として準備されている場合には、names関数を用いて名前を設定することができます。このnames関数の引数にベクターを取り、names関数に名前を記載したベクターを代入する形で名前を設定することができます。\nベクターの名前もnames関数で確認することができます。ベクターでは、ドルマーク（$）を用いて名前から要素を取り出すことはできません。\nベクターの複数の要素に同じ名前を付けた場合には、インデックスが最も前の要素だけを名前で呼び出すことができます。同じ名前を付けた2つ目、3つ目の要素を名前を用いて呼び出すことはできません。\n\n\n\nベクターの要素の名前\n\nc(dog = 1, cat = 2, pig = 3) # 名前付きべクターをc関数で作る\n## dog cat pig \n##   1   2   3\n\nx &lt;- c(1, 2, 3)\nnames(x) &lt;- c(\"dog\", \"cat\", \"pig\") # ベクターに名前を設定する\nnames(x) # 名前が返ってくる\n## [1] \"dog\" \"cat\" \"pig\"\n\nx[\"cat\"] # 名前の文字列をインデックスにすることができる\n## cat \n##   2\n\nx$cat # 呼び出せない\n## Error in x$cat: $ operator is invalid for atomic vectors\n\n\n\n\n\n\n\n\n連想配列とベクター\n\n\n\n\n\nプログラミング言語には、連想配列（ハッシュやディクショナリなどとも呼ばれる）というデータ型を持つものがあります。連想配列では、文字列（記号）と値を結びつけておき、文字列をインデックスとして値を呼び出すことができるものです（例えば、banana=1、apple=2としておいて、bananaで呼び出すと1が返ってくる）。Rでは、ベクターにnamesが設定でき、名前を用いて要素を呼び出すことができるため、ベクターが連想配列の役割をこなすことができます。",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ベクター</span>"
    ]
  },
  {
    "objectID": "chapter11.html#ベクターの長さを調べる",
    "href": "chapter11.html#ベクターの長さを調べる",
    "title": "11  ベクター",
    "section": "11.8 ベクターの長さを調べる",
    "text": "11.8 ベクターの長さを調べる\nベクターは、名前以外に、長さ（length）を特性として持っています。ベクターの長さは、そのベクターの要素の数のことです。ベクターの長さはlength関数で調べることができます。ベクターは1次元の構造を持つデータですので、dimension（次元）を持ちません。\n\n\n\nベクターの長さ\n\nlength(x) # 要素が3つなので長さは3\n## [1] 3\n\ndim(x) # ベクターは次元（dimension）を持たない\n## NULL",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ベクター</span>"
    ]
  },
  {
    "objectID": "chapter11.html#ベクターの並べ替え",
    "href": "chapter11.html#ベクターの並べ替え",
    "title": "11  ベクター",
    "section": "11.9 ベクターの並べ替え",
    "text": "11.9 ベクターの並べ替え\nベクターの要素を順番に並べ替える場合には、sort関数を用います。sort関数はベクターを昇順に並べ替える関数ですが、decreasing=TRUEを指定すると降順に並べ替えることができます。ベクターを逆順に並べ替える場合には、rev関数を用います。\n\n\n\nベクターの並べ替え\n\nx &lt;- c(5, 3, 4, 2, 1)\n\n# 昇順に並べ替え\nsort(x)\n## [1] 1 2 3 4 5\n\n# 降順に並べ替え\nsort(x, decreasing=TRUE)\n## [1] 5 4 3 2 1\n\nrev(x) # 逆順\n## [1] 1 2 4 3 5",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ベクター</span>"
    ]
  },
  {
    "objectID": "chapter11.html#重複する要素を取り除く",
    "href": "chapter11.html#重複する要素を取り除く",
    "title": "11  ベクター",
    "section": "11.10 重複する要素を取り除く",
    "text": "11.10 重複する要素を取り除く\nベクター内の重複する要素を取り除く場合には、unique関数を用います。\n\n\n\nunique関数で重複を取り除く\n\nx &lt;- c(\"cat\", \"dog\", \"cat\", \"cat\")\nunique(x)\n## [1] \"cat\" \"dog\"\n\n\n\n11.10.0.1 アトリビュート（attribute）を付ける\nRでは、ベクターに名前以外のアトリビュートをつけることもできます。アトリビュートをつけるとき、アトリビュートを呼び出すときにはattr関数を用います。ただし、names以外のアトリビュートをベクターの要素の呼び出しに用いることはできません。\nベクターのアトリビュートを調べるときには、str関数を用いることもできます。strは「structure」の略で、様々なオブジェクトの構造を調べることができる便利な関数です。\n\n\n\nattributeの確認\n\nattr(x, \"hoge\") &lt;- c(\"rat\", \"hat\", \"mat\")\nx$hoge # 呼び出せない\n## Error in x$hoge: $ operator is invalid for atomic vectors\n\nattr(x, \"hoge\") # 呼び出せる\n## [1] \"rat\" \"hat\" \"mat\"\n\nstr(x) # アトリビュートにhogeがあることを確認\n##  chr [1:4] \"cat\" \"dog\" \"cat\" \"cat\"\n##  - attr(*, \"hoge\")= chr [1:3] \"rat\" \"hat\" \"mat\"\n\n\n\n\n\n\n\n\nアトリビュートの使い道\n\n\n\n\n\nベクターにnames以外のattributeを設定しても特に利点はないため、アトリビュートの設定を行うことはほぼありません。attributeには、namesの他にクラス名などが登録されます。",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ベクター</span>"
    ]
  },
  {
    "objectID": "chapter11.html#ランダムサンプリング",
    "href": "chapter11.html#ランダムサンプリング",
    "title": "11  ベクター",
    "section": "11.11 ランダムサンプリング",
    "text": "11.11 ランダムサンプリング\nRは統計の言語です。統計と確率は密接に関係しているため、統計の取り扱いにおいては、時に確率論的な現象を再現したい、という場合があります。確率論的な現象はランダムなものを取り扱うため、Rではベクターからランダムに要素を取り出す関数、sample関数が備わっています。\nこのsample関数では、第一引数にベクター、第二引数にベクターから要素を取り出す回数を指定します。このランダムな取り出しには、復元抽出（1つの要素を何度も取り出すことができる）と非復元抽出（1つの要素を一度取り出すと、再度取り出されることがない）があります。復元抽出と非復元抽出の指定には、sample関数のreplace引数を用います。replace引数のデフォルトはFALSEで、replaceを指定しない場合には非復元抽出が行われます。復元抽出を行う場合には、replaceにTRUEを指定します。\n\n\n\nsample関数と復元・非復元抽出\n\nsample(1:10, 5) # 1~10の整数から5つをランダムに取り出す\n## [1] 4 5 7 6 8\n\nsample(1:10, 5) # ランダムに取り出すので、上とは異なる結果となる\n## [1]  6  9 10  5  3\n\nsample(1:10, 5, replace=FALSE) # 非復元抽出\n## [1] 6 3 1 2 5\n\nsample(1:10, 15, replace=FALSE) # エラー（1度しか取り出せない）\n## Error in sample.int(length(x), size, replace, prob): cannot take a sample larger than the population when 'replace = FALSE'\n\nsample(1:10, 15, replace=TRUE) # 復元抽出ではエラーとならない\n##  [1]  6  2  6  6  8  5  6 10  6 10  6  7  9  9  6",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ベクター</span>"
    ]
  },
  {
    "objectID": "chapter11.html#ベクターを切り分けるsplit",
    "href": "chapter11.html#ベクターを切り分けるsplit",
    "title": "11  ベクター",
    "section": "11.12 ベクターを切り分ける：split",
    "text": "11.12 ベクターを切り分ける：split\nベクターを同じ長さの因子で切り分けるのが、split関数です。split関数は2つの引数を取り、第一引数にはベクター、第二引数にはベクターと同じ長さの因子を取ります。因子のlevelsに従い、第一引数で指定したベクターを2つ以上のグループに切り分けます。split関数では、グループで切り分けたベクターがリストで返ってきます。\n\n\n\nsplit関数\n\nx &lt;- rep(1:5, 5) # xは1~5を5回繰り返すベクター\ny &lt;- factor(c(rep(1, 10), rep(2, 15))) # xを切り分けるための因子\n\nx\n##  [1] 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5\ny\n##  [1] 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n## Levels: 1 2\n\nsplit(x, y) # リストが返ってくる\n## $`1`\n##  [1] 1 2 3 4 5 1 2 3 4 5\n## \n## $`2`\n##  [1] 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5\n\n\n\n\n\n表1：ベクターに関する関数\n\n\n関数名\nベクターに適用される演算\n\n\n\n\nhead(x)\n始めの6つの要素を返す\n\n\ntail(x)\n最後の6つの要素を返す\n\n\nnames(x)\n名前を表示する\n\n\nnames(x) &lt;- y\nyを名前に設定する\n\n\nlength(x)\n要素の数を返す\n\n\nattr(x, which)\nattribute(which)を返す\n\n\nattr(x, which) &lt;- y\nattribute(which)をyに設定する\n\n\nstr(x)\n詳細な情報（構造、structure）を表示する\n\n\nsample(x, size, replace)\nxからsizeの個数の要素をランダムに取り出す\n\n\nsplit(x, f)\n因子fに従ってベクターを分割する\n\n\nsort(x)\n昇順に並べ替える\n\n\nsort(x, decreasing=TRUE)\n降順に並べ替える\n\n\nrev(x)\n逆順に並べ替える\n\n\nunique(x)\n重複を取り除く",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ベクター</span>"
    ]
  },
  {
    "objectID": "chapter11.html#集合としてのベクター",
    "href": "chapter11.html#集合としてのベクター",
    "title": "11  ベクター",
    "section": "11.13 集合としてのベクター",
    "text": "11.13 集合としてのベクター\n統計では、集合を取り扱う場合があります。集合としてベクターを取り扱い、積集合や和集合を取り扱う関数がRには備わっています。\nベクターの要素のうち、重複したものを取り除く関数がunique関数です。unique関数はベクターを引数に取り、引数に含まれる重複した要素を1つだけ残して取り除きます。\n和集合と積集合を求める関数がunion関数とintersect関数です。union関数もintersect関数も共に2つのベクターを引数に取り、union関数は和集合（ベクターがxとyの時、\\(x \\cup y\\)）、intersect関数は積集合（ベクターがxとyの時、\\(x \\cap y\\)）を返します。\n集合の差を示す関数がsetdiff関数です。setdiff関数も2つのベクターを引数に取り、第一引数にあって第二引数に無い要素を返します。\n集合が同一とみなせるかどうか判断する関数がsetequal関数です。2つのベクターを引数に取り、2つのベクターの要素が同一であればTRUE、異なっていればFALSEを返します。\n最後に、集合に関与する演算子である、%in%について説明します。%in%は前と後ろにベクターを取る演算子で、前のベクターにも後ろのベクターにもある要素（積集合の要素）にはTRUE、前のベクターにはあり、後ろのベクターには無い要素にはFALSEを返す関数です。\n\n\n\n表2：集合に関する関数\n\n\n関数名\n集合に適用する演算\n\n\n\n\nunion(x, y)\nxとyの和集合\n\n\nintersect(x, y)\nxとyの積集合\n\n\nsetdiff(x, y)\nxにあってyに無い集合\n\n\nsetequal(x, y)\nxとyが同一かどうかを評価\n\n\nx %in% y\nxのうち、yにある要素はTRUEを返す\n\n\n\n\n\n\n\n\nベクターと集合の演算\n\nx &lt;- rep(1:5, 5)\n\nx\n##  [1] 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5\n\nunique(x)\n## [1] 1 2 3 4 5\n\nx &lt;- 1:10\ny &lt;- 7:16\n\nunion(x, y) # xとyの和集合\n##  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16\n\nintersect(x, y) # xとyの積集合\n## [1]  7  8  9 10\n\nsetdiff(x, y) # xにあってyに無いもの\n## [1] 1 2 3 4 5 6\n\nsetdiff(y, x) # yにあってxに無いもの\n## [1] 11 12 13 14 15 16\n\nsetequal(x, y) # xとyが同一かどうかを評価\n## [1] FALSE\n\nsetequal(x, 10:1) # 要素が同一なのでTRUE\n## [1] TRUE\n\nx %in% y # xのうち、yにあるものはTRUE\n##  [1] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ベクター</span>"
    ]
  },
  {
    "objectID": "chapter12.html",
    "href": "chapter12.html",
    "title": "12  リスト・データフレーム・行列",
    "section": "",
    "text": "12.1 リスト（list）\nリスト（list）は様々なデータ型・クラスを一つにまとめたものです。リストの要素となるのは、ベクター、リスト、データフレーム、行列などで、どのようなデータ型・クラスであってもリストの要素にすることができます。\nリストの作成には、list関数を用います。list関数の引数がリストの要素となります。\nベクターと同様に、リストの要素には名前（names）をつけることができ、要素を名前から呼び出すことができます。名前からの呼び出しでは、ベクターと同じように四角カッコ（[ ]）内に文字列を記入して呼び出してもよいですし、$（ドルマーク）を用いて呼び出すこともできます。ただし、[ ]と$では、返り値の型が異なります（[ ]ではリスト、$では要素が返ってくる）。\n名前の確認・設定はベクターと同じ方法で行います。リストの名前の確認・変更には、names関数を用います。names関数の引数にリストを取ると、そのリストの名前が返ってきます。names関数の引数にリストを取り、文字列ベクターを代入するとリストの名前を設定できます。\nリストの作成と名前\n\n# リストの作成（=の左がnames、右が要素）\nlst &lt;- list(x = c(1, 2, 3, 4), y = \"dog\", z = c(T, F, T, T, F))\nlst # 名前付きリストを表示する\n## $x\n## [1] 1 2 3 4\n## \n## $y\n## [1] \"dog\"\n## \n## $z\n## [1]  TRUE FALSE  TRUE  TRUE FALSE\n\nnames(lst) # リストの名前を表示する\n## [1] \"x\" \"y\" \"z\"\n\nnames(lst) &lt;- c(\"a\", \"b\", \"c\") # リストの名前を変更する\n\nnames(lst) # 変更後の名前\n## [1] \"a\" \"b\" \"c\"\n\nlst[\"a\"] # 名前での要素の呼び出し（リストが返ってくる）\n## $a\n## [1] 1 2 3 4\n\nlst$a # ドルマーク（$）を用いた呼び出し（要素が返ってくる）\n## [1] 1 2 3 4",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>リスト・データフレーム・行列</span>"
    ]
  },
  {
    "objectID": "chapter12.html#リストlist",
    "href": "chapter12.html#リストlist",
    "title": "12  リスト・データフレーム・行列",
    "section": "",
    "text": "12.1.1 リストのインデックス\nリストのインデックスは、基本的には二重角カッコ（[[ ]]）で指定します。通常の角カッコ（[ ]）で指定すると、リストの要素がリストのまま返ってきます。角カッコ（[ ]）で返ってくるのはリストですので、コロンを用いて複数の要素をリストとして取り出すことができます。\nリストの要素（ベクターや行列）のさらに要素を取り出すには、二重角カッコの後に、ベクターや行列に対応したインデックス指定（[1]や[1, 2]など）をつけることになります。\n\n\n\nリストのインデックス\n\nlst[1] # リストの1番目の要素（リストが返ってくる）\n## $a\n## [1] 1 2 3 4\n\nlst[[1]] # リストの1番目の要素（要素が返ってくる）\n## [1] 1 2 3 4\n\nlst[1:2] # リストの1~2番目の要素（リストが返ってくる）\n## $a\n## [1] 1 2 3 4\n## \n## $b\n## [1] \"dog\"\n\nlst[[1]][2] # リストの1番目の要素（ベクター）の2つ目の要素\n## [1] 2\n\n\n\n\n12.1.2 リストの長さ（length）\nリストは、名前（names）の他に、長さ（length）の特性を持ちます。リストのlengthはリストの要素の数です。リストのlengthもベクターと同じく、length関数で確認することができます。\nリストのアトリビュートはattributes関数で確認することができます。アトリビュートをattr関数で別途追加しない場合には、アトリビュートとしてはnamesだけが表示されます。各要素のデータ型はstr関数やsummary関数を用いて確認することができます。\n\n\n\nリストの長さとデータ型\n\nlength(lst)\n## [1] 3\n\nattributes(lst)\n## $names\n## [1] \"a\" \"b\" \"c\"\n\nstr(lst)\n## List of 3\n##  $ a: num [1:4] 1 2 3 4\n##  $ b: chr \"dog\"\n##  $ c: logi [1:5] TRUE FALSE TRUE TRUE FALSE\n\nsummary(lst)\n##   Length Class  Mode     \n## a 4      -none- numeric  \n## b 1      -none- character\n## c 5      -none- logical\n\n\n\n\n12.1.3 リストへの要素の追加\nc関数を用いることで、リストに要素を追加することができます。また、リストに要素を追加する場合には、ドルマークを用いて設定されていない名前を指定し、代入を行うこともできます。設定されている名前を用いて代入した場合には、その要素が書き換えられます。\n\n\n\nリストへの要素の追加\n\nlst &lt;- c(lst, d = \"added list\") # リストに名前dの要素を追加\nlst\n## $a\n## [1] 1 2 3 4\n## \n## $b\n## [1] \"dog\"\n## \n## $c\n## [1]  TRUE FALSE  TRUE  TRUE FALSE\n## \n## $d\n## [1] \"added list\"\n\n# リストに名前eの要素を追加（データフレームにも使える）\nlst$e &lt;- \"object can be added with named index\" # 名前eの要素を追加\nlst$d &lt;- \"revised list\" # dの要素を変更\nlst # 追加・変更後のリスト\n## $a\n## [1] 1 2 3 4\n## \n## $b\n## [1] \"dog\"\n## \n## $c\n## [1]  TRUE FALSE  TRUE  TRUE FALSE\n## \n## $d\n## [1] \"revised list\"\n## \n## $e\n## [1] \"object can be added with named index\"\n\n\n\n\n12.1.4 リストのベクター化\nリストを全部まとめて1つのベクターにする場合には、unlist関数を用います。unlist関数はリストの要素をすべて1次元のベクターに変更します。ベクターに変更すると、ベクターの型が要素の型によって変更されるので、注意が必要です。unlist関数はリストだけでなく、データフレームの行のデータをベクターにするのにも用いられます。\n\n\n\nリストのベクター化\n\nunlist(lst[1:3]) # 文字列のベクターに変換される\n##      a1      a2      a3      a4       b      c1      c2      c3      c4      c5 \n##     \"1\"     \"2\"     \"3\"     \"4\"   \"dog\"  \"TRUE\" \"FALSE\"  \"TRUE\"  \"TRUE\" \"FALSE\"",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>リスト・データフレーム・行列</span>"
    ]
  },
  {
    "objectID": "chapter12.html#データフレームdata.frame",
    "href": "chapter12.html#データフレームdata.frame",
    "title": "12  リスト・データフレーム・行列",
    "section": "12.2 データフレーム（data.frame）",
    "text": "12.2 データフレーム（data.frame）\nRで最も使用頻度が高いクラスの一つがデータフレーム（data.frame）です。データフレームはExcelの表のような構造を持つクラスで、data.frame関数を用いて作成することができます。data.frame関数の引数は各列のベクターで、各列の名前を引数で設定することができます（リストと同じく、「列名=ベクター」という形で設定）。\nデータフレームは、同じ長さのベクターを列に取ったリストです。ですので、class関数ではデータフレーム、mode関数ではリストが返ってきます。\nデータフレームの作成時に、長さの異なるベクターを用いた場合には、反復（recycling）のルールに従い、短いベクターが長いベクターの長さに合わせて反復されます。\n\n\n\nデータフレームを作成する\n\n# データフレームをdata.frame関数で作成する\nd &lt;- data.frame(x = c(\"dog\", \"cat\", \"pig\", \"horse\"), y = c(1, 2, 3, 4), z = c(T, T, F, T))\nd\n##       x y     z\n## 1   dog 1  TRUE\n## 2   cat 2  TRUE\n## 3   pig 3 FALSE\n## 4 horse 4  TRUE\n\nclass(d) # classはdata.frame\n## [1] \"data.frame\"\n\nmode(d) # modeはlist\n## [1] \"list\"\n\n# 長さが異なるベクターを用いると、反復が適用される\nd2 &lt;- data.frame(x = c(\"dog\", \"cat\"), y = c(1, 2, 3, 4), z = T)\nd2\n##     x y    z\n## 1 dog 1 TRUE\n## 2 cat 2 TRUE\n## 3 dog 3 TRUE\n## 4 cat 4 TRUE\n\n\n\n12.2.1 リストからデータフレームを作成する\nデータフレームはリストと同じですので、長さが同じベクターからなるリストはそのままデータフレームに変換できます。データフレームへの変換にはas.data.frame関数を用います。この変換は、data.frame関数を用いても行うことができます。\n長さが異なるベクターや、ベクター以外の要素を含むリストをデータフレームに変換しようとすると、エラーが出ます。反復は行われません。\n\n\n\nリストをデータフレームに変換\n\n# 長さが同じベクターのリストは、そのままデータフレームに変換できる\nlst &lt;- list(x = c(\"dog\", \"cat\", \"pig\", \"horse\"), y = c(1, 2, 3, 4), z = c(T, T, F, T))\nas.data.frame(lst)\n##       x y     z\n## 1   dog 1  TRUE\n## 2   cat 2  TRUE\n## 3   pig 3 FALSE\n## 4 horse 4  TRUE\n\ndata.frame(lst)\n##       x y     z\n## 1   dog 1  TRUE\n## 2   cat 2  TRUE\n## 3   pig 3 FALSE\n## 4 horse 4  TRUE\n\n# 長さが異なるベクターのリストは、データフレームに変換できない\nlst2 &lt;- list(x = c(1, 2, 3, 4), y = \"dog\", z = c(T, F, T, T, F))\nas.data.frame(lst2) # エラー\n## Error in (function (..., row.names = NULL, check.rows = FALSE, check.names = TRUE, : arguments imply differing number of rows: 4, 1, 5\n\n\n\n\n12.2.2 データフレームのインデックス\nデータフレームはリストではありますが、行（横方向）と列（縦方向）を持つ、表の形で表されます。データフレームは表型のデータですので、行・列の2つの次元（dimension）を持ちます。\nデータフレームの要素をインデックスで指定する場合には、[行, 列]という形を用います。このとき、インデックスの数値は行列共に1行目が1、1列目が1となります。インデックスは数値のベクターで指定することもできます。数値のベクターで指定した場合には、ベクターに記載した順番に行・列を取り出すことになります。\nベクターと同様に、データフレームのインデックスはコロン（:）を用いた連続整数の形でも指定できますし、論理型（TRUEとFALSE）のベクターを用いても指定できます。論理型のベクターの長さが行数・列数に足りない場合には、ベクターが反復されます。マイナスのインデックスを用いた場合には、指定した行・列が削除されます。\nインデックスでデータフレームの列のみを指定した場合には、返り値としてその列のベクターが返ってきます。一方、行のみを指定した場合には、ベクターではなく、その行がデータフレームとして返ってきます。行をベクターに変換するには、unlist関数を用います。\nデータフレームのインデックスの指定時には、コンマで行列を区切らず、1つのインデックスだけで指定することもできます。インデックスを1つだけ指定した場合には、ベクターではなく、データフレームが返ってきます。\n\n\n\nデータフレームのインデックス\n\nd1 &lt;- data.frame(a = 1:6, b = seq(4, 6.5, by = 0.5), c = rep(1, 6))\nd1\n##   a   b c\n## 1 1 4.0 1\n## 2 2 4.5 1\n## 3 3 5.0 1\n## 4 4 5.5 1\n## 5 5 6.0 1\n## 6 6 6.5 1\n\nd1[1, 1] # 1行1列目の要素を取り出す\n## [1] 1\n\nd1[1:3, 1] # 1~3行目、1列目の要素を取り出す（ベクター）\n## [1] 1 2 3\n\nd1[c(5, 2, 1), ] # 5行目、2行目、1行目を取り出す\n##   a   b c\n## 5 5 6.0 1\n## 2 2 4.5 1\n## 1 1 4.0 1\n\nd1[1, ] # 1行目の要素を取り出す（データフレーム）\n##   a b c\n## 1 1 4 1\n\nunlist(d1[1, ]) # 1行目の要素を取り出して、ベクターに変換する\n## a b c \n## 1 4 1\n\nd1[2:3, ] # 2~3行目の要素を取り出す（データフレーム）\n##   a   b c\n## 2 2 4.5 1\n## 3 3 5.0 1\n\nd1[, 2:3] # 2~3列目の要素を取り出す（データフレーム）\n##     b c\n## 1 4.0 1\n## 2 4.5 1\n## 3 5.0 1\n## 4 5.5 1\n## 5 6.0 1\n## 6 6.5 1\n\nd1[c(T, T, F, T, F, F), ] # 論理型もインデックスに使用できる\n##   a   b c\n## 1 1 4.0 1\n## 2 2 4.5 1\n## 4 4 5.5 1\n\nd1[c(T, T, F), ] # 反復\n##   a   b c\n## 1 1 4.0 1\n## 2 2 4.5 1\n## 4 4 5.5 1\n## 5 5 6.0 1\n\nd1[, c(T, T, F)] # 列のインデックスにも論理型を使用できる\n##   a   b\n## 1 1 4.0\n## 2 2 4.5\n## 3 3 5.0\n## 4 4 5.5\n## 5 5 6.0\n## 6 6 6.5\n\nd1[-1:-2, ] # 1~2行目を削除\n##   a   b c\n## 3 3 5.0 1\n## 4 4 5.5 1\n## 5 5 6.0 1\n## 6 6 6.5 1\n\nd1[, -1:-2] # 1~2列目を削除\n## [1] 1 1 1 1 1 1\n\nd1[1] # 1列目を取り出す（データフレーム）\n##   a\n## 1 1\n## 2 2\n## 3 3\n## 4 4\n## 5 5\n## 6 6\n\nclass(d1[1]) # 行列で指定（[,1]）しないと、データフレームが返ってくる\n## [1] \"data.frame\"\n\n\n\n\n12.2.3 データフレームの行数・列数\nデータフレームには、行方向と列方向の長さがあります。この行方向と列方向の長さを返すのが、dim関数、nrow関数、ncol関数です。dim関数は、データフレームを引数に取り、行数,列数の2つの値のベクターを返します。nrow関数はデータフレームの行数を、ncol関数はデータフレームの列数を返す関数です。\n\n\n\nデータフレームの行・列数\n\nd # dは4行3列のデータフレーム\n##       x y     z\n## 1   dog 1  TRUE\n## 2   cat 2  TRUE\n## 3   pig 3 FALSE\n## 4 horse 4  TRUE\n\ndim(d) # 4行3列なので、4と3が返ってくる\n## [1] 4 3\n\nnrow(d) # 行数が返ってくる\n## [1] 4\n\nncol(d) # 列数が返ってくる\n## [1] 3\n\n\n\n\n12.2.4 データフレームの名前\nデータフレームの各行・各列には、それぞれ名前をつけることができます。データフレームの行の名前はrownames関数、列の名前はcolnames関数で求めることができます。\n列名はdata.frame関数でデータフレームを作成するときにつけることができます。また、ベクターと同様に、colnames関数に列名を代入する形でも列名をつけることができます。\n行名をつける場合には、rownames関数に行名を代入します。特に行名を指定していない場合には、行の番号が1, 2, 3,…といった形で行名として設定されます。\n行名・列名のいずれもインデックスとして利用することができます。特に列名は、$（ドルマーク）を用いた形で列の取り出しに用いることができます。\n\n\n\nデータフレームの行名・列名\n\nd\n##       x y     z\n## 1   dog 1  TRUE\n## 2   cat 2  TRUE\n## 3   pig 3 FALSE\n## 4 horse 4  TRUE\n\ncolnames(d) # 列名\n## [1] \"x\" \"y\" \"z\"\n\ncolnames(d) &lt;- c(\"a\", \"b\", \"c\") # 列名を変更する\n\nrownames(d) # 行名\n## [1] \"1\" \"2\" \"3\" \"4\"\n\nrownames(d) &lt;- c(\"x\", \"y\", \"z\", \"aa\") # 行名を変更する\n\nd[\"x\", ] # 行名をインデックスに用いることもできる\n##     a b    c\n## x dog 1 TRUE\n\nd[, \"a\"] # 列名もインデックス指定に使うことができる\n## [1] \"dog\"   \"cat\"   \"pig\"   \"horse\"\n\nd$a # ドルマークを使って列を指定することもできる\n## [1] \"dog\"   \"cat\"   \"pig\"   \"horse\"\n\n\nデータフレームにおいても、インデックスに論理型のベクターを使用することができるため、列名と比較演算子を利用して、行を選択することができます。\nインデックスでの比較演算子の利用と同様に条件によって行を選択する際に用いる関数がsubset関数です。subset関数は第一引数にデータフレーム、第二引数に比較演算子を用いた条件式を記載することで、条件に合った行のみを取り出すことができます。\n行のデータを利用して論理型ベクターを作成し、列を選択する事もできます。\n\nd1\n##   a   b c\n## 1 1 4.0 1\n## 2 2 4.5 1\n## 3 3 5.0 1\n## 4 4 5.5 1\n## 5 5 6.0 1\n## 6 6 6.5 1\n\nd1$b &gt; 5 # b列が5以上ならTRUE\n## [1] FALSE FALSE FALSE  TRUE  TRUE  TRUE\n\nd1[d1$b &gt; 5, ] # b列が5以上の行を選択\n##   a   b c\n## 4 4 5.5 1\n## 5 5 6.0 1\n## 6 6 6.5 1\n\nsubset(d1, d1$b &gt; 5) # 上と同じ行の選択をsubset関数で行う\n##   a   b c\n## 4 4 5.5 1\n## 5 5 6.0 1\n## 6 6 6.5 1\n\nd1[1, ] &gt; 3 # 1行目の値が3以上ならTRUE\n##       a    b     c\n## 1 FALSE TRUE FALSE\n\nd1[, d1[1, ] &gt; 3] # 1行目が3以上になる列（2列目）を選択\n## [1] 4.0 4.5 5.0 5.5 6.0 6.5\n\n\n\n12.2.5 データフレームの並べ替え\nデータフレームの並べ替えには、order関数を用います。order関数はベクターの要素の順番に数値を付け、返すだけの関数です。データフレームのインデックスはベクターを取ることができ、ベクターに記載した数値の順番に行を取得します。ですので、order関数の返り値を行のインデックスとして用いると、order関数の返り値の通りにデータフレームが並べ替えられます。\norder関数にはdecreasing（降順）という引数を設定できます。decreasingのデフォルト値はFALSEで、通常はorder関数を用いた並べかえは昇順（一番小さいものが一番上）になります。decreasingをTRUEに設定すると、order関数の結果が逆順になります。したがって、decreasing=TRUEとした場合には、データフレームを降順（一番大きなものが一番上）に並べ替えることができます。\nrev関数は引数にベクターを取り、ベクターを逆順に変換する関数です。このrev関数を用いても、データフレームを降順に並べ替えることができます。\n\n\n\nデータフレームの並べ替え\n\nd &lt;- data.frame(x = c(\"dog\", \"cat\", \"pig\", \"horse\"), y = c(1, 2, 3, 4), z = c(T, T, F, T))\norder(d$x) # x列の順序を返す(文字列はアルファベット順)\n## [1] 2 1 4 3\n\nd[order(d$x),] # x列を昇順に並べ替え\n##       x y     z\n## 2   cat 2  TRUE\n## 1   dog 1  TRUE\n## 4 horse 4  TRUE\n## 3   pig 3 FALSE\n\norder(d$x, decreasing=TRUE)\n## [1] 3 4 1 2\n\nd[order(d$x, decreasing=TRUE), ] # x列を降順に並べ替え\n##       x y     z\n## 3   pig 3 FALSE\n## 4 horse 4  TRUE\n## 1   dog 1  TRUE\n## 2   cat 2  TRUE\n\nd[rev(order(d$x)), ] # rev関数でもベクターを逆順にできる\n##       x y     z\n## 3   pig 3 FALSE\n## 4 horse 4  TRUE\n## 1   dog 1  TRUE\n## 2   cat 2  TRUE\n\n\n\n\n\n\n\n\nrank関数で並べ替え\n\n\n\n\n\norder関数の代わりにrank関数を用いることもできます。ただし、rank関数はデフォルトではタイデータ（同じ値のデータ）に整数で順位を付けないので（2.5位が2つなど）、order関数の方が使い勝手はよいでしょう。\n\n\n\n\n\n12.2.6 データフレームに行・列を追加する\nデータフレームに列を追加する方法はいくつかあります。\n\n$（ドルマーク）に列名に使われていない名前を指定し、ベクターを代入する\n現在の列数+1のインデックスを指定し、ベクターを代入する\ncbind関数を用いる\n\n$と新しい列名を用いて、ベクターを代入した場合には、最も右側にその列名を持つ列が追加されます。数値のインデックスで指定した場合には、Vにインデックスが付いた列名（V1、V2など）が自動的に設定され、列が追加されます。cbind関数を用いた場合には、1つ目の引数（データフレーム）に2つ目の引数（ベクターもしくはデータフレーム）が右側から追加されます。\nデータフレームに行を追加する方法もほぼ同じです。行を追加する場合には、cbind関数ではなく、rbind関数を用います。\nただし、データフレームに行をベクターで追加する場合には、追加した行に従い各列のデータ型が変化します。データ型の変換を起こさないように行を追加するには、追加する行がデータフレームである必要があります。さらに、追加するデータフレームの列名が元のデータフレームの列名と一致する必要があります。\nデータフレームに行を追加すると予期せぬ型変換が起こり、間違いの原因となりますので、行の追加を行うときには型を逐次確認することをおすすめします。\n\n\n\n列・行の追加\n\nd3 &lt;- d\nd3\n##       x y     z\n## 1   dog 1  TRUE\n## 2   cat 2  TRUE\n## 3   pig 3 FALSE\n## 4 horse 4  TRUE\n\nd3$newCol &lt;- 5:8\nd3[, 5] &lt;- 10:13\nd3[5, ] &lt;- c(\"rat\", 6, T, 9, 14) # 各列の型に沿ったベクターを追加\nsummary(d3) # すべての列が文字列になる\n##       x                  y                  z                newCol         \n##  Length:5           Length:5           Length:5           Length:5          \n##  Class :character   Class :character   Class :character   Class :character  \n##  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n##       V5           \n##  Length:5          \n##  Class :character  \n##  Mode  :character\n\nd\n##       x y     z\n## 1   dog 1  TRUE\n## 2   cat 2  TRUE\n## 3   pig 3 FALSE\n## 4 horse 4  TRUE\n\ncbind(d, 1:4) # 列を追加\n##       x y     z 1:4\n## 1   dog 1  TRUE   1\n## 2   cat 2  TRUE   2\n## 3   pig 3 FALSE   3\n## 4 horse 4  TRUE   4\n\nrbind(d, 1:3) # 行を追加する（列のデータ型が変化する）\n##       x y z\n## 1   dog 1 1\n## 2   cat 2 1\n## 3   pig 3 0\n## 4 horse 4 1\n## 5     1 2 3\n\n# データフレームを追加する場合は、列名が同じである必要がある\nrbind(d, data.frame(x = \"pig\", y = 1, z = TRUE)) \n##       x y     z\n## 1   dog 1  TRUE\n## 2   cat 2  TRUE\n## 3   pig 3 FALSE\n## 4 horse 4  TRUE\n## 5   pig 1  TRUE\n\n\n\n\n12.2.7 データフレームの要約\nデータフレームの各列の要約を調べる場合には、ベクターなどと同様に、summary関数を用います。summary関数はデータフレームを引数に取ると、列が文字列の場合にはデータ型と要素の数、論理型や因子の場合はそのレベルごとの要素の数、数値型であれば平均値や中央値、最大値・最小値などを示してくれます。\nデータフレームの列方向の合計値を求める場合にはcolSums関数を、行方向の合計値を求める場合にはrowSums関数を用います。データフレームに文字列の列がある場合には、colSums関数・rowSums関数はエラーを返します。\n同様の関数に、colMeans関数、rowMeans関数もあります。これらはそれぞれ列方向・行方向の平均値を計算する関数です。\nデータフレームの一部を確認したいときには、ベクターと同様にhead関数とtail関数を用いることができます。head関数はデータフレームの上から6行を、tail関数はデータフレームの下から6行をそれぞれ表示します。\n\nsummary(d) # データフレームの要約\n##       x                   y            z          \n##  Length:4           Min.   :1.00   Mode :logical  \n##  Class :character   1st Qu.:1.75   FALSE:1        \n##  Mode  :character   Median :2.50   TRUE :3        \n##                     Mean   :2.50                  \n##                     3rd Qu.:3.25                  \n##                     Max.   :4.00\n\nd1\n##   a   b c\n## 1 1 4.0 1\n## 2 2 4.5 1\n## 3 3 5.0 1\n## 4 4 5.5 1\n## 5 5 6.0 1\n## 6 6 6.5 1\n\ncolSums(d1) # 列方向に合計した値\n##    a    b    c \n## 21.0 31.5  6.0\n\ncolSums(d) # 数値以外が含まれているとエラーになる\n## Error in colSums(d): 'x' must be numeric\n\nrowSums(d1) # 行方向に合計した値\n## [1]  6.0  7.5  9.0 10.5 12.0 13.5\n\ncolMeans(d1) # 列方向の平均値\n##    a    b    c \n## 3.50 5.25 1.00\n\nrowMeans(d1) # 行方向の平均値\n## [1] 2.0 2.5 3.0 3.5 4.0 4.5\n\nhead(d1) # データフレームの上から6行を表示\n##   a   b c\n## 1 1 4.0 1\n## 2 2 4.5 1\n## 3 3 5.0 1\n## 4 4 5.5 1\n## 5 5 6.0 1\n## 6 6 6.5 1\n\ntail(d1) # データフレームの下から6行を表示\n##   a   b c\n## 1 1 4.0 1\n## 2 2 4.5 1\n## 3 3 5.0 1\n## 4 4 5.5 1\n## 5 5 6.0 1\n## 6 6 6.5 1\n\n\n\n\n表1：データフレームに関する関数\n\n\n\n\n\n\n関数名\nデータフレームに適用する演算\n\n\n\n\ndata.frame(x, y)\nデータフレームを作成する\n\n\ndim(x)\n次元（dimension）を返す\n\n\nncol(x)\n列数を返す\n\n\nnrow(x)\n行数を返す\n\n\ncolnames(x)\n列の名前を返す\n\n\nrownames(x)\n行の名前を返す\n\n\ncolnames(x) &lt;- y\nyを列の名前に設定する\n\n\nrownames(x) &lt;- y\nyを行の名前に設定する\n\n\nsubset(x, 条件)\n条件に適合した行を抽出する\n\n\nx[order(x\\(name), ]      |name列で昇順に並べ替え          |\n|x[rev(order(x\\)name)), ]\nname列で降順に並べ替え\n\n\ncbind(x, y)\n列を追加する\n\n\nrbind(x, y)\n行を追加する\n\n\nsummary(x)\nデータフレームの要約を表示\n\n\ncolSums(x)\n列（縦）方向の和を返す\n\n\nrowSums(x)\n行（横）方向の和を返す\n\n\ncolMeans(x)\n列（縦）方向の平均値を返す\n\n\nrowMeans(x)\n行（横）方向の平均値を返す\n\n\nhead(x)\nデータフレームの上から6行を表示\n\n\ntail(x)\nデータフレームの下から6行を表示\n\n\n\n\n\n\n\n\n\n\n\nデータフレームの要約\n\n\n\n\n\nもっと複雑なデータフレームの要約を行う場合には、apply関数群やdplyrパッケージ (Wickham et al. 2023)、tidyrパッケージ (Wickham, Vaughan, and Girlich 2023)などを用います。apply関数群、dplyr、tidyrに関しては15章、16章でそれぞれ紹介します。\n\n\n\n\n\n12.2.8 組み合わせのデータフレームを作成する\n様々な要素について、すべての組み合わせを含むデータを作りたい、という場合が時にあります。このような場合には、expand.grid関数を用いると簡単に組み合わせのデータフレームを作成することができます。expand.grid関数はdata.frame関数と同じように引数を設定し、引数に設定したベクターのすべての組み合わせを含むデータフレームを作成してくれます。\n\n\n\nexpand.grid関数\n\nexpand.grid(sex=c(\"M\", \"F\"), age=c(20,25), location=c(\"Osaka\", \"Kobe\"))\n##   sex age location\n## 1   M  20    Osaka\n## 2   F  20    Osaka\n## 3   M  25    Osaka\n## 4   F  25    Osaka\n## 5   M  20     Kobe\n## 6   F  20     Kobe\n## 7   M  25     Kobe\n## 8   F  25     Kobe",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>リスト・データフレーム・行列</span>"
    ]
  },
  {
    "objectID": "chapter12.html#行列matrix",
    "href": "chapter12.html#行列matrix",
    "title": "12  リスト・データフレーム・行列",
    "section": "12.3 行列（matrix）",
    "text": "12.3 行列（matrix）\nRは高校数学で学んだ行列、線形代数の行列計算を行うためのクラスである、行列（matrix）を持ちます。行列はベクターと同様に同じ型を持つ要素の集合で、行と列の2つの次元（dimension）を持ちます。\nデータフレームも行列と同様に次元を持ちますが、データフレームが行方向には異なるデータ型を取ることができるのに対して、行列はすべての要素のデータ型が同じです。また、データフレームがリストであるのに対し、行列は縦・横の2つの次元を持つベクターです。\n行列の基本的な取り扱い（インデックス、行・列の追加、行名・列名）はデータフレームとほぼ同じです。上に述べたデータフレームの取り扱いに関する方法は、概ね行列にも適用することができます。\n行列の作成には、matrix関数を用います。matrix関数は第一引数にベクター、nrow引数に行の数、ncol引数に列の数を指定します。matrix関数はベクターの数値を縦方向（列方向）に並べて配置します。数値を横（行方向）に並べて配置する場合には、byrow引数をTRUEに指定します。\n\n\n\n行列の作成とインデックス\n\nmat &lt;- matrix(1:12, nrow = 3, ncol = 4) # 列方向にベクターが配置される\nmat\n##      [,1] [,2] [,3] [,4]\n## [1,]    1    4    7   10\n## [2,]    2    5    8   11\n## [3,]    3    6    9   12\n\nmatrix(1:12, nrow = 3, ncol = 4, byrow = TRUE) # 行方向に配置するとき\n##      [,1] [,2] [,3] [,4]\n## [1,]    1    2    3    4\n## [2,]    5    6    7    8\n## [3,]    9   10   11   12\n\ndim(mat) # 行数・列数を返す\n## [1] 3 4\n\nnrow(mat) # 行数\n## [1] 3\n\nncol(mat) # 列数\n## [1] 4\n\ncolnames(mat) &lt;- c(\"dog\", \"cat\", \"pig\", \"horse\") # 列名の設定\nrownames(mat) &lt;- c(\"first\", \"second\", \"third\") # 行名の設定\nmat\n##        dog cat pig horse\n## first    1   4   7    10\n## second   2   5   8    11\n## third    3   6   9    12\n\ncolnames(mat) # 列名の取得\n## [1] \"dog\"   \"cat\"   \"pig\"   \"horse\"\n\nrownames(mat) # 行名の取得\n## [1] \"first\"  \"second\" \"third\"\n\nmat[1, 1] # 1行1列目の要素\n## [1] 1\n\nmat[1, ] # 1行目の要素\n##   dog   cat   pig horse \n##     1     4     7    10\n\nmat[, 1] # 1列目の要素\n##  first second  third \n##      1      2      3\n\nmat[-1, ] # 1行目を削除\n##        dog cat pig horse\n## second   2   5   8    11\n## third    3   6   9    12\n\nmat[c(T, T, F), ] # 論理型でも指定できる\n##        dog cat pig horse\n## first    1   4   7    10\n## second   2   5   8    11\n\nmat[1:2, ] # 1~2行目の要素\n##        dog cat pig horse\n## first    1   4   7    10\n## second   2   5   8    11\n\nmat[, \"dog\"] # インデックスは列名でも指定できる\n##  first second  third \n##      1      2      3\n\nmat$dog # ドルマークを用いることはできない\n## Error in mat$dog: $ operator is invalid for atomic vectors\n\nmat[\"first\", ] # 行名での指定\n##   dog   cat   pig horse \n##     1     4     7    10\n\ncbind(mat, rat = c(4, 6, 8)) # 列の追加\n##        dog cat pig horse rat\n## first    1   4   7    10   4\n## second   2   5   8    11   6\n## third    3   6   9    12   8\n\nrbind(mat, fourth = c(1, 1, 1, 1)) # 行の追加\n##        dog cat pig horse\n## first    1   4   7    10\n## second   2   5   8    11\n## third    3   6   9    12\n## fourth   1   1   1     1\n\n\n\n\n\n\n\n\n3次元以上のクラス：array\n\n\n\n\n\nRには、次元を3つ以上持つクラスである、arrayも存在しますが、matrixほどには使用頻度は高くありません。\n\n\n\n\n12.3.1 行列の演算\n統計の計算には、線形代数（行列）が用いられます。Rには行列の演算に関する関数が一通り揃っています。\n\n\n\n表2：行列に関する関数\n\n\n関数名\n行列に適用する演算\n\n\n\n\n*\nスカラー積\n\n\n%*%\n行列の積\n\n\n%o%\n外積\n\n\n%x%\nクロネッカー積\n\n\ndiag\n単位行列を作成する\n\n\ndet\n行列式を返す\n\n\nt\n転置を返す\n\n\nupper.tri\n上三角行列にTRUEを返す\n\n\nlower.tri\n下三角行列にTRUEを返す\n\n\nsolve\n逆行列を返す\n\n\nqr\nQR分解\n\n\n\n\n\n\n\n12.3.2 行列の積\nRでは、%*%を演算子として行列の積の計算を行います。単に「*」で計算すると、行列の積ではなく、スカラー積が返ってきます。行列同士を「*」で掛け算した場合には、行列の各要素がそれぞれ掛け算されたもの（アダマール積）が返ってきます。行列の演算子として、他に外積（%o%）やクロネッカー積（%x%）の演算子も設定されています。\n\n\n\n行列の演算子\n\n# 要素が1~16のランダムな行列を作成\nmat &lt;- matrix(sample(1:16, 16), nrow=4) \nmat\n##      [,1] [,2] [,3] [,4]\n## [1,]    9    2   13    6\n## [2,]    4   14    5   15\n## [3,]    7   12   11   16\n## [4,]    1    3   10    8\n\nmat * 3 # スカラー積\n##      [,1] [,2] [,3] [,4]\n## [1,]   27    6   39   18\n## [2,]   12   42   15   45\n## [3,]   21   36   33   48\n## [4,]    3    9   30   24\n\nmat * mat # アダマール積\n##      [,1] [,2] [,3] [,4]\n## [1,]   81    4  169   36\n## [2,]   16  196   25  225\n## [3,]   49  144  121  256\n## [4,]    1    9  100   64\n\nmat %*% mat # 行列の積\n##      [,1] [,2] [,3] [,4]\n## [1,]  186  220  330  340\n## [2,]  142  309  327  434\n## [3,]  204  362  432  526\n## [4,]   99  188  218  275\n\nmat[, 1] %o% mat[, 2] # 外積\n##      [,1] [,2] [,3] [,4]\n## [1,]   18  126  108   27\n## [2,]    8   56   48   12\n## [3,]   14   98   84   21\n## [4,]    2   14   12    3\n\nmat[1:2, 1:2] %x% mat[3:4, 3:4] # クロネッカー積\n##      [,1] [,2] [,3] [,4]\n## [1,]   99  144   22   32\n## [2,]   90   72   20   16\n## [3,]   44   64  154  224\n## [4,]   40   32  140  112\n\n\n\n\n12.3.3 行列式・転置・逆行列の演算\n行列式はdet関数、行列の転置はt関数、逆行列はsolve関数で求めることができます。t関数は行列だけでなく、データフレームを引数に取ることができますが、t関数の返り値は必ず行列になります。データフレームをt関数の引数にして転置する場合にはデータ型が変換されることが多いため、注意が必要です。\n\n\n\n行列式・転置・逆行列\n\ndet(mat) # matの行列式\n## [1] -712\n\nt(mat) # matを転置\n##      [,1] [,2] [,3] [,4]\n## [1,]    9    4    7    1\n## [2,]    2   14   12    3\n## [3,]   13    5   11   10\n## [4,]    6   15   16    8\n\nsolve(mat) # matの逆行列\n##             [,1]       [,2]       [,3]  [,4]\n## [1,] -0.08005618 -0.3455056  0.4789326 -0.25\n## [2,]  0.55758427  1.1432584 -1.4058989  0.25\n## [3,]  0.32724719  0.5702247 -0.7823034  0.25\n## [4,] -0.60814607 -1.0983146  1.4452247 -0.25\n\nmat %*% solve(mat) # 丸め誤差はあるが、単位行列になる\n##               [,1] [,2]         [,3]         [,4]\n## [1,]  1.000000e+00    0 0.000000e+00 4.440892e-16\n## [2,]  0.000000e+00    1 3.552714e-15 4.440892e-16\n## [3,] -1.776357e-15    0 1.000000e+00 0.000000e+00\n## [4,] -8.881784e-16    0 1.776357e-15 1.000000e+00\n\n\n\n\n12.3.4 単位行列・三角行列の作成\ndiag関数は単位行列を作成するための関数です。diag関数は数値を引数に取り、その数値の行数・列数の単位行列を返します。\n三角行列の作成には、upper.tri関数とlower.tri関数を用います。この2つの関数は、行列を引数に取り、行列と同じ行数・列数の論理型の上三角行列（上がTRUE、下三角がFALSEの行列）、下三角行列（下がTRUE、上三角がFALSEの行列）をそれぞれ返します。いずれも対角成分はFALSEとなります。\nただし、upper.tri関数、lower.tri関数の返り値をそのまま行列のインデックスに用いても上三角行列・下三角行列を作ることはできません。上三角行列を作成する場合には、lower.tri関数の返り値をインデックスに取り、このインデックスに0を代入します。\n逆に、下三角行列を作成する場合には、upper.tri関数の返り値をインデックスに取り、このインデックスに0を代入します。このように0を下三角・上三角に代入することで、上三角行列・下三角行列を得ることができます。\n\ndiag(3) # 3行3列の単位行列\n##      [,1] [,2] [,3]\n## [1,]    1    0    0\n## [2,]    0    1    0\n## [3,]    0    0    1\n\nupper.tri(mat) # 上三角行列にTRUEを返す\n##       [,1]  [,2]  [,3]  [,4]\n## [1,] FALSE  TRUE  TRUE  TRUE\n## [2,] FALSE FALSE  TRUE  TRUE\n## [3,] FALSE FALSE FALSE  TRUE\n## [4,] FALSE FALSE FALSE FALSE\n\nlower.tri(mat) # 下三角行列にTRUEを返す\n##       [,1]  [,2]  [,3]  [,4]\n## [1,] FALSE FALSE FALSE FALSE\n## [2,]  TRUE FALSE FALSE FALSE\n## [3,]  TRUE  TRUE FALSE FALSE\n## [4,]  TRUE  TRUE  TRUE FALSE\n\nmat.u &lt;- mat\nmat.l &lt;- mat\n\nmat.u[lower.tri(mat)] &lt;- 0 # 下三角行列のみに0を代入\nmat.l[upper.tri(mat)] &lt;- 0 # 上三角行列のみに0を代入\n\nmat.u # 下三角に0を代入すると上三角行列が得られる\n##      [,1] [,2] [,3] [,4]\n## [1,]    9    2   13    6\n## [2,]    0   14    5   15\n## [3,]    0    0   11   16\n## [4,]    0    0    0    8\n\nmat.l # 上三角に0を代入すると下三角行列が得られる\n##      [,1] [,2] [,3] [,4]\n## [1,]    9    0    0    0\n## [2,]    4   14    0    0\n## [3,]    7   12   11    0\n## [4,]    1    3   10    8\n\n\n\n\n\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Davis Vaughan, and Maximilian Girlich. 2023. Tidyr: Tidy Messy Data. https://CRAN.R-project.org/package=tidyr.",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>リスト・データフレーム・行列</span>"
    ]
  },
  {
    "objectID": "chapter13.html",
    "href": "chapter13.html",
    "title": "13  データの読み込みと書き出し（I/O）",
    "section": "",
    "text": "13.1 ディレクトリの操作\nデータを読み込み、書き出すためには、まず読み込む・書き出すためのフォルダが必要となります。フォルダのことをディレクトリとも呼びます。Rでは、ワーキングディレクトリ（working directory）というものが設定されています。Rからはこのワーキングディレクトリの中のファイルを確認することができます。\nワーキングディレクトリは通常、RStudioを起動した時に、右下のカラムのFilesタブに表示されています。\nこのfilesタブでは、任意のフォルダに移動することができます。上図の右上、…と記載されている部分をクリックするとウインドウが開きます。このウインドウ上で任意のフォルダに移動すれば、filesタブに示されるフォルダが変わります。ただし、表示するフォルダを変えるだけではワーキングディレクトリを変更することはできません。\nfilesタブに表示されたフォルダをワーキングディレクトリに設定するには、filesタブの右上、「More」から「Set As Working Directory」を選択します。\nFileに表示されているディレクトリをワーキングディレクトリに変更する場合には、同じ「More」から「Go To Working Directory」を選択します。\nワーキングディレクトリの変更は、上の「Session」から「Set Working Directory」を選択することでも変更できます。\nデフォルトのワーキングディレクトリ（Rstudioを開いた時に設定されているワーキングディレクトリ）を変更する場合には、「Tools」→「Option」を選択し、「Default working directory」に任意のフォルダを指定します。",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データの読み込みと書き出し（I/O）</span>"
    ]
  },
  {
    "objectID": "chapter13.html#ディレクトリの操作",
    "href": "chapter13.html#ディレクトリの操作",
    "title": "13  データの読み込みと書き出し（I/O）",
    "section": "",
    "text": "図1：ワーキングディレクトリをfilesタブで確認する\n\n\n\n\n\n\n\n図2：MoreのリストからSet As Working Directoryを選ぶ\n\n\n\n\n\n\n\n図3：「Session」からワーキングディレクトリを変更する\n\n\n\n\n\n\n図4：デフォルトのワーキングディレクトリを変更する\n\n\n\n13.1.1 getwd関数とsetwd関数\n上記のように、RStudioの機能を使えばワーキングディレクトリを簡単に変更することができます。ただし、データのフォルダ構造によっては、Rでの演算中にワーキングディレクトリを変更したい、といった場合もあります。\nワーキングディレクトリの確認と設定は、getwd関数とsetwd関数を用いて行うことができます。\ngetwd関数は現在のワーキングディレクトリを確認するための関数です。getwd関数は引数を取らず、実行すると現在のワーキングディレクトリのアドレスを文字列で返します。\nsetwd関数はワーキングディレクトリを変更するための関数です。setwd関数は文字列のディレクトリのアドレスを引数に取ります。setwd関数を実行すると、アドレスで指定したフォルダにワーキングディレクトリが変更されます。\n\n\n\nワーキングディレクトリの確認と設定\n\ngetwd() # ワーキングディレクトリを確認\nsetwd(\"directory/name/as/character\") # ワーキングディレクトリを変更\n\n\n\n\n13.1.2 絶対パスと相対パス\nディレクトリを指定する際には、ディレクトリのアドレスを用います。Windowsでは、フォルダを開き、上のアドレスバーを右クリックすると、アドレスをテキストとしてコピーすることができます。この方法でコピーできるアドレスのことを絶対パスと呼びます。絶対パスには、ルートディレクトリ（大元のフォルダ）からそのフォルダまでのアドレスが全て記載されています。\n\n\n\n図5：ディレクトリのアドレス（Windowsの場合）\n\n\nディレクトリのアドレスには、相対パスと呼ばれるものもあります。相対パスは、現在のディレクトリの上位や下位といった、現在のディレクトリからの位置を相対的に表すものです。\nsetwd関数は、この絶対パス、相対パスのいずれも使用することができます。絶対パスの場合には、ルートからのすべてのアドレスを文字列で指定します。一方、相対パスの場合は、.（ピリオド）を用いて、現在のディレクトリからの位置を以下のように指定します。\n\n「./」は今のディレクトリのアドレスを示す記号\n「../」は今のディレクトリの一つ上位のディレクトリを示す記号\n\n上の記号を用いて、一つ下位にあるディレクトリは以下のように示すことができます。\n“./一つ下のフォルダ名”\nまた、setwd関数は、下位のフォルダであれば、そのフォルダまでのパスを記載するだけでもディレクトリを指定することができます。ただし、Windowsではフォルダのつなぎ文字がバックスラッシュ（\\）になっています。Rでのつなぎ文字はスラッシュ（/）ですので、Windowsではアドレスの記法が異なることに注意が必要です。\n\n\n\n相対パスと絶対パス\n\nsetwd(\"../\") # 一つ上のフォルダにワーキングディレクトリを移動\nsetwd(\"./NameF\") # 一つ下の「NameF」というフォルダにワーキングディレクトリを移動\nsetwd(\"NameF\") # 上と同じ\nsetwd(\"NameF/NameF2\") # NameFフォルダ内のNameF2というフォルダに移動",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データの読み込みと書き出し（I/O）</span>"
    ]
  },
  {
    "objectID": "chapter13.html#ディレクトリ内のファイルの確認",
    "href": "chapter13.html#ディレクトリ内のファイルの確認",
    "title": "13  データの読み込みと書き出し（I/O）",
    "section": "13.2 ディレクトリ内のファイルの確認",
    "text": "13.2 ディレクトリ内のファイルの確認\nワーキングディレクトリ内のファイルやフォルダは、Rで開いたり、確認したりすることができます。dir関数とlist.files関数はワーキングディレクトリ内のファイル・フォルダの一覧を表示するための関数です。いずれもファイル・フォルダ名の一覧を文字列のベクターとして返します。list.dirs関数はワーキングディレクトリ内にあるフォルダのアドレスの一覧を文字列のベクターとして返します。\n\n\n\nディレクトリ内のファイル・フォルダの確認\n\ndir() # ディレクトリ名とファイル名が返ってくる\nlist.files() # dir関数と同じ\nlist.dirs() # ディレクトリ名のみ返ってくる",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データの読み込みと書き出し（I/O）</span>"
    ]
  },
  {
    "objectID": "chapter13.html#フォルダとファイルの作成",
    "href": "chapter13.html#フォルダとファイルの作成",
    "title": "13  データの読み込みと書き出し（I/O）",
    "section": "13.3 フォルダとファイルの作成",
    "text": "13.3 フォルダとファイルの作成\n現在のワーキングディレクトリにフォルダを作成する際には、dir.create関数を用います。dir.create関数は作成するフォルダ名の文字列を引数に取ります。ワーキングディレクトリ内にファイルを作成する関数はいくつもあります。単にファイルを作るのであればfile.create関数を、文字列をテキストで保存する場合にはcat関数を用います。\n\n\n\nディレクトリとファイルの作成\n\ndir.create(\"tmp\") # 現在のワーキングディレクトリに「tmp」というフォルダを作成\nsetwd(\"tmp\") # 作成したフォルダにワーキングディレクトリを移動\nfile.create(\"filename.txt\") # 空のテキストファイルを作成\ncat(\"Hello world\", file=\"helloworld.txt\") # Hello worldと書き込まれたテキストファイルを作成",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データの読み込みと書き出し（I/O）</span>"
    ]
  },
  {
    "objectID": "chapter13.html#ワークスペースイメージ.rdataの保存",
    "href": "chapter13.html#ワークスペースイメージ.rdataの保存",
    "title": "13  データの読み込みと書き出し（I/O）",
    "section": "13.4 ワークスペースイメージ（.Rdata）の保存",
    "text": "13.4 ワークスペースイメージ（.Rdata）の保存\nワークスペースとは、Rを実行している時に取り扱っているオブジェクトなどの環境のことです。RGUIやRStudioを閉じるときには、下の図のようなウインドウが表示され、ワークスペースのイメージを保存するかどうか尋ねられます。ワークスペースを保存すると、現在のワーキングディレクトリに「.RData」というファイルが作成されます。この.RDataがワークスペースのイメージです。\n\n\n\n図6：Rstudio終了時のワークスペース保存\n\n\n.RDataファイルはRStudioを閉じるときだけでなく、RStudioのメニューから「Session → Save Workspace As…」を選ぶことでも保存できます。また、save.image関数を用いても、.RDataファイルを作成することができます。\n現在のワークスペースの情報は、RStudio右上のパネルの「Environment」で確認できます。このパネルでは、現在Rで取り扱っている変数（オブジェクト）の一覧を確認することができます。\n\n\n\n図7：Environmentパネル\n\n\nこのパネルに表示されているのと同じ、オブジェクトのリストをR上で取得する場合には、ls関数を用います。\nRを閉じると、オブジェクトはメモリから削除されます。次にRStudioを起動したときには、デフォルトのワーキングディレクトリに存在する.RDataから自動的にワークスペースのイメージが読み込まれます。別途、.RDataファイルを指定してワークスペースを読み込む場合には、load関数を用います。load関数で.RDataファイルを読み込むことで、.RDataファイルを保存した際に使用していたオブジェクトがメモリ上に展開されます。\nこのように、ワークスペースを保存・読み込むことで、以前のデータ分析環境を読み込み、データ分析の続きを行うことができます。\n\n\n\nワークスペースの保存と読み込み\n\nls() # 現在メモリ上にある全てのオブジェクトを表示\nsave.image() # ワークスペースのイメージを保存する\nload(\".Rdata\") # ワークスペースのイメージを読み込む",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データの読み込みと書き出し（I/O）</span>"
    ]
  },
  {
    "objectID": "chapter13.html#オブジェクトの保存と読み込み",
    "href": "chapter13.html#オブジェクトの保存と読み込み",
    "title": "13  データの読み込みと書き出し（I/O）",
    "section": "13.5 オブジェクトの保存と読み込み",
    "text": "13.5 オブジェクトの保存と読み込み\nワークスペース全体ではなく、個別のオブジェクトも、一時的に保存し、読み込むことができます。オブジェクトの保存と読み込みには、save関数とload関数を用います。\nsave関数はオブジェクトと文字列のファイル名の2つを引数に取り、オブジェクトを引数で指定したファイル名で保存する関数です。ファイル名は何でもよく、ファイルの拡張子にも特に指定はないのですが、「.rda」を拡張子としたファイル名とするのが一般的です。\n保存したオブジェクトを読み込む関数が、load関数です。load関数はファイル名の文字列を引数に取り、save関数で保存した.rdaファイルを読み込みます。load関数で読み込むと、Rのワークスペースには保存したオブジェクトが現れます。\nsave・load関数と同様の関数として、dput関数とdget関数というものもあります。dput関数で保存したファイルはload関数で読み込めず、save関数で保存したファイルはdget関数で読み込めないため、dput関数でオブジェクトを保存した場合には、dget関数で読み込む必要があります。dget関数はオブジェクトを返す関数ですので、ワークスペースにオブジェクトが再現されるわけではありません。\n\n\n\nオブジェクトの保存と読み込み\n\nx &lt;- c(1, 2, 3)\nsave(x, file = \"Robject.rda\") # オブジェクトを保存\nrm(x) # xを削除する\nload(\"Robject.rda\") # オブジェクトの読み込み\nx # xが読み込まれている\n\ndput(x, \"Robject_dput.rda\") # オブジェクトを保存\ndget(\"Robject_dput.rda\") # オブジェクトが返ってくる\n\ndget(\"Robject.rda\") # エラー。saveで保存するとdgetで読み込めない\nload(\"Robject_dput.rda\") # エラー。dputで保存するとloadで読み込めない\n\n\n\n13.5.1 プログラムを呼び出す\n保存したプログラムを他のプログラムで呼び出すときには、source関数を用います。source関数の引数はファイル名の文字列です。2章で説明した通り、Rのプログラムは通常「.R」の拡張子を付けて取り扱いますので、拡張子を含めたファイル名を指定します。現在のワーキングディレクトリに保存されているファイルを呼び出す場合はそのファイル名を、他のディレクトリに保存されているファイルを呼び出す場合はそのファイルのパスを含む文字列をsource関数の引数に取ります。。source関数でプログラムを呼び出すと、プログラムが実行されます。複雑なプログラムでは、関数などを別ファイルで定義しておいて、そのファイルを呼び出して用いることもあります。\n\n\n\nsource関数でプログラムの呼び出し\n\nsource(\"code_hello_world.R\")",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データの読み込みと書き出し（I/O）</span>"
    ]
  },
  {
    "objectID": "chapter13.html#データの読み込み",
    "href": "chapter13.html#データの読み込み",
    "title": "13  データの読み込みと書き出し（I/O）",
    "section": "13.6 データの読み込み",
    "text": "13.6 データの読み込み\n\n13.6.1 Excelからデータを読み込む（古典的な方法）\n統計を行うデータは、通常Excelのような表計算ソフトか、データベースで準備するのが一般的です。このようなデータをRで取り込む際には、一昔前までは「テキストファイルに変換」してから読み込むのが一般的でした。\n最近ではライブラリを使用することでExcelやデータベースのファイルから直接データを読み込むことができますが、ライブラリなしのRではこのような読み込みはできません。ライブラリが使用できないときには、以下のような方法でExcelファイルをテキストで保存し、Rで読み込むことになります。\nまた、Web上に保存されているデータがテキストである場合も少なくありません。このような、Web上のテキストファイルの読み込みにも、以下に示すテキスト読み込みの方法を用いることができます。\n\n13.6.1.1 Excel：csv・タブ切りテキストへの変換\nまずは、Excelでのテキストファイルの変換について説明します。Rで読み込むことができるテキストは、大きく分けると以下の4種類です。\n\nコンマ切りテキスト（comma-separated values, csv）\nタブ切りテキスト（tab-separated values, tsv）\nスペース切りテキスト\n固定幅テキスト\n\nこれらのうち、スペース切りテキストについてはデータにスペースが入っていると読み込みが難しくなるため、通常は避けられます。固定幅テキストはやや取り扱いにくいため、Excelからの変換には用いません。したがって、Excelファイルは主にコンマ切りテキストかタブ切りテキストに変換して、Rで読み込むことになります。\nExcelファイルからコンマ切り・タブ切りテキストへの変換はExcel上で行います。Excelの「ファイル」メニューから「名前を付けて保存」を選択し、ファイル名の下のドロップダウンリストから「CSV UTF-8 (コンマ区切り)(*.csv)」もしくは「テキスト (タブ区切り)(*.txt)」を選択します。拡張子である「.csv」や「.txt」は自動的に付与されます。\n\n\n\n\n\n\nエンコーディング\n\n\n\n\n\nテキストにはエンコーディングというものがあり、日本語テキストはUTF-8、Shift-JIS（CP932）、EUC-JPのいずれかのエンコーディングを持ちます。エンコーディングが異なると文字化けを起こします。RのデフォルトのエンコーディングはUTF-8です。WindowsではShift-JISが用いられている場合があるため、エンコーディングに注意が必要となります。\n\n\n\n\n\n\n図8：Excelでコンマ切り・タブ切りテキストを作成する\n\n\n\n\n\n\n\n\nExcelの空欄データ\n\n\n\n\n\nExcelには「データをセルから消したのに何らかのデータが残る」という謎仕様があります。 空のExcelファイルを作成し（Book1）、G7までを1で埋めます（Book2、下図9）。数値をバックスペースで消して保存すると（Book3）、何故かBook1よりBook3の方がファイルサイズが大きくなります（下図10）。Rからテキスト変換したファイルを読み込むと、この「無いけど残っているデータ」を読み込んでしまうので、エラーが生じることがあります。データをDeleteで削除、もしくは右クリックから削除を選ぶと、この残ったデータを削除することができます。\n長い歴史を持つ、代々受け継がれたExcelファイルではこのような謎データがファイルサイズを大きくし、動作を遅くしている場合もありますので、データ数に比べてファイルサイズが大きいExcelファイルがあれば空欄をDeleteしてみることをおすすめします。\n\n\n\n図9：Excelのセルに1を入力し、バックスペースで削除する\n\n\n\n\n\n図10：バックスペースで削除すると、ファイルサイズが増える\n\n\n\n\n\n\n\n\n13.6.2 scan関数\nまずは、1行のデータを読み込む場合について説明します。1行のデータであれば、scan関数を用いて読み込むことができます。scan関数の第一引数は文字列のファイル名です。ファイル名を指定するときには、必ず拡張子を含めて記載します。scan関数には、「sep」という引数を指定することができます。sepはデータ間の区切り文字を指定するものです。コンマ切りテキスト、CSVであれば「sep = \",\"」、タブ切りテキストであれば「sep = \"\\t\"」を指定します。scan関数の返り値はベクターとなります。\nただし、whatという引数を設定すると、返り値をリストにすることができます。whatは空のリストを指定する引数で、リストの要素の個数に従い、scanで読み取った結果が代入されます。代入の順番は、1つ目がリストの1要素目、2つ目がリストの2要素目…となります。リストの長さより多い要素は再びリストの1要素目に代入されます。\n\n\n\nscan関数でテキストファイルを読み込む\n\nscan(\"./data/scansample.txt\", sep = \",\") # コンマ切りテキストを読み込む\n## [1] 1 2 3 4 5 6 7 8\n\nscan(\"./data/scansample.txt\", sep = \",\", what = list(\"\", \"\")) # 出力をリストにする\n## [[1]]\n## [1] \"1\" \"3\" \"5\" \"7\"\n## \n## [[2]]\n## [1] \"2\" \"4\" \"6\" \"8\"\n\n\n\n\n13.6.3 read.table関数\nExcelから読み込む表は、通常行と列を持つ、テーブルの形をしていますので、データフレームにできると便利です。テキストに変換したExcelの表をデータフレームとして読み込む関数がread.table関数です。read.table関数は第一引数にテキストファイルのファイル名を取ります。scan関数と同様に、ファイル名には拡張子を含める必要があります。\nread.table関数はscan関数と同じく、「sep」引数を取ります。sep引数には、コンマ切りテキスト、CSVであれば「sep = \",\"」、タブ切りテキストであれば「sep = \"\\t\"」を指定します。\nread.table関数はさらに、「header」という引数を取ります。この引数にTRUEを指定すると（「header = T」）、読み込むテキストの1行目を列名として、データを読み込みます。\nread.table関数でよく用いられる引数はファイル名、sep、headerの3つですが、その他たくさんの引数を取ることができます。read.table関数の引数の一覧を以下の表1に示します。\n\n\n\n表1：read.table関数の引数\n\n\n\n\n\n\n\n\n引数\nデータ型\n意味\nデフォルト値\n\n\n\n\nfile\n文字列\nファイル名\nー\n\n\nheader\n論理型\n1行目を列名とするか\nFALSE\n\n\nsep\n文字列\n区切り文字（コンマやタブ)\nー\n\n\nquote\n文字列\n文字列が囲まれている文字（“など）\n“\"’”\n\n\ndec\n文字列\n小数点の文字\n“.”\n\n\nnumerals\n文字列\n文字列を数値に変換するときの正確性\nー\n\n\nrow.names\n文字列ベクター\n行名\nー\n\n\ncol.names\n文字列ベクター\n列名\nー\n\n\nas.is\n文字列\n文字列を因子に変えるときのルール\n!stringAsFactors\n\n\ntryLogical\n論理型\nTRUEなどを論理型に変換するか\nTRUE\n\n\nna.strings\n文字列\nNAとして取り扱う文字列\n“NA”\n\n\ncolClasses\n文字列\n列のクラスを指定\nNA\n\n\nnrows\n数値\n読み込む行数\n-1\n\n\nskip\n数値\n読み込まない行数\n0\n\n\ncheck.names\n論理型\n列名をチェックするか\nTRUE\n\n\nfill\n論理型\n空きになっている要素をスペースで埋めるか\n!blank.lines.skip\n\n\nstrip.white\n論理型\nスペースを取り除くか\nFALSE\n\n\nblank.lines.skip\n論理型\n空行をスキップするか\nTRUE\n\n\ncomment.char\n文字列\nコメントの開始文字\n“#”\n\n\nallowEscapes\n論理型\nエスケープ記号を変換するか\nFALSE\n\n\nflush\n論理型\n1行1データかどうか\nFALSE\n\n\nstringAsFactors\n論理型\n文字列を因子に自動変換するか\nFALSE\n\n\nfileEncoding\n文字列\nエンコーディングの指定\n“”\n\n\nencoding\n文字列\nエンコーディング（変更はしない）\n“unknown”\n\n\ntext\n文字列\nfileから読み込まず，直接データを入力\nー\n\n\nskipNul\n論理型\n空データをスキップするか\nFALSE\n\n\n\n\n\n\n\n13.6.4 read.csv関数、read.delim関数\nread.table関数の仲間として、csvの読み込み用のread.csv関数、タブ切りテキスト読み込み用のread.delim関数、固定幅テキストの読み込み用のread.fwf関数がRには準備されています。read.csv関数はsep引数にコンマ、read.delim関数はsep引数にタブがデフォルト値として設定されており、sep引数を入力することなくデータを読み込むことができます。\n\n\n\nテキストファイルの読み込み\n\nread.table(\"filename.txt\", sep=\"\\t\", header=T)\nread.table(\"filename.txt\", sep=\"\\t\", header=T, stringAsFactors = T)\nread.csv(\"filename.csv\")\nread.csv2(\"filename.csv\") # ヨーロッパ仕様\nread.delim(\"filename.tsv\")\nread.delim2(\"filename.tsv\") # ヨーロッパ仕様\n\nread.fwf(\"filename.txt\") # 固定幅テキスト\n\n\n\n\n\n\n\n\nヨーロッパで準備されたファイルのデータ読み込み\n\n\n\n\n\nヨーロッパではコンマ（,）をセミコロン（;）、小数点（ピリオド .）をコンマ（,）で記載するため、通常のread.csv関数、read.delim関数ではテキストファイルをまともに読み込むことができません。ヨーロッパで生成されるテキストファイルの読み込みには、専用の関数（read.csv2、read.delim2）が設けられています。\n\n\n\n\n13.6.4.1 stringAsFactorsとfileEncoding\nread.table関数の「stringAsFactors」という引数は、昔はTRUEがデフォルトとされており、read.table関数で読み込んだ文字列はすべて因子に変換されていました。Rのバージョン4.0.0よりstringAsFactorsのデフォルト値がFALSEに変更されたため、現在のread.table関数では、文字列は文字列のまま読み込まれます。\nWindowsではテキストファイルのエンコーディングがShift JIS（CP932）になっている場合がありますので、「fileEncoding = \"CP932\"」を引数に指定しないと読み込めないことがあります。エンコーディングがUTF-8であれば、fileEncodingを指定する必要はありません。\n\n\n\n13.6.5 クリップボードからの読み込み\nRでは、コピーしたテキストをクリップボードから読み込むこともできます。Ctrl+Cなどでコピーしたテキストを読み込む場合には、read.table関数の引数に\"clipboard\"を指定します。\n\n\n\nクリップボードの内容を読み込む\n\nread.table(\"clipboard\")",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データの読み込みと書き出し（I/O）</span>"
    ]
  },
  {
    "objectID": "chapter13.html#データの書き出し",
    "href": "chapter13.html#データの書き出し",
    "title": "13  データの読み込みと書き出し（I/O）",
    "section": "13.7 データの書き出し",
    "text": "13.7 データの書き出し\nRからのデータの書き出しでは、通常テキストファイルが書き出されます。Excelファイルに直接書き出すこともできなくは無いのですが（xlsxパッケージ (Dragulescu and Arendt 2020)を利用する）、それほど一般的ではありません。データの書き出しに用いられる関数には、write関数、write.table関数などがあります。\n\n13.7.1 write・cat関数\nベクターや行列などのデータの書き出しには、write関数・cat関数を用います。write関数はcat関数のラッパーで、2つの関数の間には大きな差はありません。cat関数はオブジェクトをコンソールに表示するために用いられますが、ファイルを出力する事もできます。print関数を用いてもコンソールへ表示することはできますが、ファイルを保存することはできません。\ncat関数、write関数は、オブジェクトとファイル名を引数に取ります。共にsep引数で区切り文字を指定することができます。\n\n\n\ncat・write関数でのオブジェクトの表示\n\nvec &lt;- c(1, 2, 3)\ncat(vec) # consoleにvecを表示\n\nwrite(vec, \"\") # cat関数と同じ（第2引数が無いとファイル保存が行われる）\n\nprint(vec) # print関数でも表示できる\n\n\n\n\n\ncat・write関数でのファイルの保存\n\ncat(vec, file=\"cat.txt\")\nwrite(vec, file=\"vector.txt\", sep=\"\\t\")\nprint(vec, \"print.txt\") # エラー\n\n\n\n\n13.7.2 write.table関数\nRでは、データ処理の多くはデータフレームを用いて行います。テキストファイルをデータフレームとして取り込むread.table関数とは逆に、データフレームをテキストファイルとして書き出す関数がwrite.table関数です。\nwrite.table関数はデータフレームとファイル名を引数に取り、データフレームをそのファイル名のテキストファイルとして書き出します。\nwrite.table関数の代表的な引数は、sep、col.names、row.names、quoteの4つです。sepはread.table関数と同じく区切り文字を指定する引数です。col.namesとrow.namesは論理型を取り、TRUEであれば列名・行名を保存し、FALSEであれば列名・行名を省いて保存します。quoteも論理型を取り、文字列・因子をダブルクオーテーションで囲むするかどうかを指定します。\nread.table関数にread.csv関数があったように、write.table関数にはCSV用のwrite.csv関数があります。write.csv関数はsepのデフォルト値にコンマが設定されています。ヨーロッパ仕様のwrite.csv2関数もありますが、日本で使用することはまれです。\n\n\n\nwrite.table関数\n\nwrite.table(df_obj, \"filename.txt\", sep = \"\\t\")\n\n# 列名あり、行名なし、ダブルクオーテーションなしで保存\nwrite.table(df_obj, \"filename.txt\", sep = \"\\t\", col.names = T, row.names = F, quote = F) \n\nwrite.csv(df_obj, \"filename.csv\")\nwrite.csv2(df_obj, \"filename.csv\") #  ヨーロッパ仕様",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データの読み込みと書き出し（I/O）</span>"
    ]
  },
  {
    "objectID": "chapter13.html#readr",
    "href": "chapter13.html#readr",
    "title": "13  データの読み込みと書き出し（I/O）",
    "section": "13.8 readr",
    "text": "13.8 readr\nRのデフォルトのI/Oは上記の通りですが、read.table関数、write.table関数を用いると、指定する引数が多かったり、読み込んだ列のデータ型が思うように設定されなかったりすることがよく起こります。また、デフォルトの関数群ではその実行速度が遅く、大きなデータを取り扱う場合には読み込みにとても時間がかかる、という問題もあります。\nこれらの不都合を解決するI/Oに関するライブラリがreadrパッケージ (Wickham, Hester, and Bryan 2023)です。readrパッケージは、Rのデフォルトの関数名のピリオドをアンダースコア（_）に変換した関数群を備えており、列の型をうまく設定してくれる仕組みを備えています。また、デフォルトの関数よりも実行速度が速いため、大きなデータを取り扱う場合には、readrの関数群を用いたほうが良いでしょう。\nreadrパッケージはtidyverse (Wickham et al. 2019)を構成するライブラリの一つであり、インストール・ロードはtidyverseライブラリのインストール・ロードと同時に行うことができます。\n\n\n\nreadrの読み込み\n\npacman::p_load(tidyverse)\n\n\n\n13.8.1 readr：テキストデータの読み込み\nreadrでのテキストデータの読み込みには、read_table関数を用います。read_table関数の使い方はread.table関数とほぼ同じです。read.table関数と同じく、read_table関数も区切り文字をsep引数で設定します。read_table関数のデフォルトの区切り文字はスペースですので、sepを設定しない場合にはスペース切りテキストの読み込みに対応しています。読み込まれたファイルは、tibbleというデータ型の、データフレームに変換されます。\nコンマ切りテキスト（CSV）の読み込みには、read_csvが、タブ切りテキスト（TSV）の読み込みにはread_tsv関数が準備されています。これらの他に、ヨーロッパ仕様のCSVを読み込むread_csv2関数、区切り文字を指定する必要があるread_delim関数、固定幅テキストの読み込みを行うread_fwf関数などがあります。\nreadrパッケージの読み込み関数は圧縮ファイルの読み込みにも対応しており、gzip（.gz）、bzip2（.bz2）、lzma（.xz）、zip（.zip）などの圧縮ファイルを直接読み込むことができます。また、インターネットからテキストファイルを直接読み込むこともできます。インターネットから直接読み込む場合には、テキストファイルが保存されているwebアドレス（http://, https://, ftp:// など）をファイル名として設定します。\n\n\n\nreadrでテキストファイルを読み込む\n\nread_table(\"filename.txt\") # sep=\" \"（スペース切り）がデフォルト\nread_csv(\"filename.csv\") # コンマ切りテキスト\nread_tsv(\"filename.tsv\") # タブ切りテキスト\nread_delim(\"filename.txt\", delim=\"\\t\") # delim引数に区切りを指定\nread_fwf(\"filename.txt\") # 固定幅テキスト\nread_csv2(\"filename.csv\") # ヨーロッパ仕様\n\nread_delim(clipboard()) # クリップボードの読み込み\n\nread_table(\"filename.zip\") # zipファイルも直接読み込める\n\n\n\n\n13.8.2 tibble\nreadrの読み込み関数は、読み込んだデータをtibbleというデータ型に変換します。このtibbleは概ねデータフレームと同じで、取り扱いもデータフレームと同様に行うことができます。\ntibbleはtibble関数で、データフレームと同じように作成することができます。また、as_tibble関数を用いることで、行列や通常のデータフレームをtibbleに変換することができます。\nreadrに限らず、tidyverseのライブラリ群の関数では返り値をtibbleとするものが多いです。tibbleのデータフレームは、表示した時に列のデータ型を表示する、10行以上の行は省略する、列も省略する等の特徴があります。tibbleについては、16章で詳しく説明します。\n\n\n\ntibble\n\npacman::p_load(tidyverse)\n\ntibble(x = 1:3, y = c(\"a\", \"b\", \"c\"), z = c(T, F, T))\n## # A tibble: 3 × 3\n##       x y     z    \n##   &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;\n## 1     1 a     TRUE \n## 2     2 b     FALSE\n## 3     3 c     TRUE\n\nas_tibble(iris)\n## # A tibble: 150 × 5\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n##  1          5.1         3.5          1.4         0.2 setosa \n##  2          4.9         3            1.4         0.2 setosa \n##  3          4.7         3.2          1.3         0.2 setosa \n##  4          4.6         3.1          1.5         0.2 setosa \n##  5          5           3.6          1.4         0.2 setosa \n##  6          5.4         3.9          1.7         0.4 setosa \n##  7          4.6         3.4          1.4         0.3 setosa \n##  8          5           3.4          1.5         0.2 setosa \n##  9          4.4         2.9          1.4         0.2 setosa \n## 10          4.9         3.1          1.5         0.1 setosa \n## # ℹ 140 more rows\n\n\n\n\n13.8.3 readr：テキストファイルの書き出し\nreadrパッケージはwrite.table関数に当たる、テキスト書き出しの関数を備えています。readrが備えている関数は、データフレームをCSVとして保存するwrite_csv関数、タブ切りテキストとして保存するwrite_tsv関数、スペース切りテキストとして保存するwrite_delim関数があります。\nread_table関数と同様に、write_関数もテキストの圧縮ファイルの保存に対応しています。対応している圧縮ファイルはgzip（.gz）、bzip2（.bz2）、lzma（.xz）です。\n\n\n\nreadrでのファイル書き出し\n\nwrite_csv(x, \"filename.csv\") # コンマ切り\nwrite_tsv(x, \"filename.tsv\") # タブ切り\nwrite_delim(x, \"filename.txt\") # スペース切り\nwrite_csv2(x, \"filename.csv\") # ヨーロッパ仕様\n\nwrite_csv(x, \"filename.gz\") # gzipで圧縮して出力\nwrite_csv(x, \"filename.bz2\") # bzip2で圧縮して出力\nwrite_csv(x, \"filename.xz\") # lzmaで圧縮して出力",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データの読み込みと書き出し（I/O）</span>"
    ]
  },
  {
    "objectID": "chapter13.html#readxl",
    "href": "chapter13.html#readxl",
    "title": "13  データの読み込みと書き出し（I/O）",
    "section": "13.9 readxl",
    "text": "13.9 readxl\n私のようなヘボいR使いは昔から上記のようにExcelをテキストファイルに変換してはRに読み込むというステップを踏み続けてきました。このExcelからテキストへの変換の手間を無くすライブラリがreadxlパッケージ (Wickham and Bryan 2023)です。\nreadxlパッケージもtidyverseと同じく、Posit Softwareが開発しているライブラリですが、tidyverseには含まれていません。tidyverseとは別に、readxlパッケージを独立に読み込む必要があります。\nreadxlパッケージで使用する関数は、ほぼread_excel関数だけです。read_excel関数は、.xlsおよび.xlsxファイルの読み込みに対応しており、ファイル名で指定したExcelファイルからテーブルをtibbleとして読み込みます。read_excel関数ではsheetという引数を設定することができます。read_excel関数はsheetに設定した番号（もしくはシート名）のシートを読み込みます。\nreadxlパッケージはread_excel関数以外に、Excelファイルのメタデータ読み込みのための関数などを備えています。\n\n\n\nreadxlでExcelファイルを読み込む\n\npacman::p_load(readxl)\nread_excel(\"filename.xlsx\", sheet = 1) # read_xlsxが読み込まれる\nread_excel(\"filename.xls\", sheet = 1) # read_xlsが読み込まれる",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データの読み込みと書き出し（I/O）</span>"
    ]
  },
  {
    "objectID": "chapter13.html#excelファイルの種類",
    "href": "chapter13.html#excelファイルの種類",
    "title": "13  データの読み込みと書き出し（I/O）",
    "section": "13.10 Excelファイルの種類",
    "text": "13.10 Excelファイルの種類\nExcelには昔使用されていたファイルである.xlsファイルと、Excel2007から使われている.xlsxファイルがあります。\n.xlsファイルはバイナリファイルで、内部的には1と0でデータが表現されています。\n.xlsxファイルは実際にはzipファイルで、xmlというフォーマットで記載されたデータがzipファイルのフォルダ内に含まれています。.xlsxファイルは拡張子を.zipに書き換えるとzipファイルとして解凍することができ、中身を確認することができます。\n.xlsと.xlsxは全然違うファイルですが、read_excel関数は拡張子によって.xlsを読み込むread_xls関数と.xlsxを読み込むread_xlsx関数を切り替えて呼び出しています。",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データの読み込みと書き出し（I/O）</span>"
    ]
  },
  {
    "objectID": "chapter13.html#data.table",
    "href": "chapter13.html#data.table",
    "title": "13  データの読み込みと書き出し（I/O）",
    "section": "13.11 data.table",
    "text": "13.11 data.table\n近年のデータサイエンスでは、時に数百万～数千億程度のデータを取り扱うこともあります。個人のPCでRを使ってこのような超大規模のデータを取り扱うのは現実的ではありませんが、数万～数十万行ぐらいのデータをPCで取り扱うことは増えてきています。例えば、生物分野ではマイクロアレイや高速シークエンサーのデータは数万～数十万行で、分析を個人が、自分のPCで取り扱うこともあるかと思います。自分でマイクロアレイやシークエンサーを使ってデータを出さなくても、GEO Datasetなどからデータを取得して、解析してみることも一般的に行われています。\nこのような超巨大データを取り扱う場合、R謹製のread.table関数では手に余りますし、read_table関数を用いても、読み込んだ後のデータ処理が重く、取り扱いに苦労します。このような大規模データの読み込みに特化したライブラリが、data.tableパッケージ (Barrett, Dowle, and Srinivasan 2023)です。\ndata.tableパッケージは、大規模データを読み込み、Rで高速に利用できるよう設計されたライブラリです。\ndata.tableパッケージでデータを読み込むときには、fread関数を用います。fread関数はhtmlからの読み込みにも対応しています。読み込んだデータはdata.tableクラスのオブジェクトとなります。\n\n\n\ndata.tableパッケージのfread関数でファイルを読み込む\n\npacman::p_load(data.table)\n\n# flights14（NYのフライトデータ、25万行11列）をinputとする\ninput &lt;- \"https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv\"\n\n# freadで読み込む\nflights &lt;- fread(input) # 219MBのデータ読み込み\nclass(flights)\n\ndim(flights)\n\n\ndata.tableの取り扱いの方法はほぼデータフレームと同じです。data.tableはインデックスからデータの要約ができる機構を備えています。ただし、後の章で説明するtidyr・dplyrの関数も適用できますので、データの要約はtidyr・dplyrで行ってもよいでしょう。\n\n\n\ndata.tableクラスの取り扱い\n\nflights[5, 1] # 通常のインデックスに対応\n\nflights[1:5] # 行列を指定しない場合は、行のインデックスになる\n\nflights[1:5, 2:5] # ベクターでの読み出しにも対応\n\nhead(flights[origin == \"JFK\", ]) # originがJFKの行を選択\n\nhead(flights[, .(month, day)]) # monthとdayの列を選択\n\nhead(flights$origin) # originの列を抽出\n\n\n\n\n\n\n\n\ndata.tableでのデータ取り扱い\n\n\n\n\n\ndata.tableが使われ始めた頃は、data.tableオブジェクトの取り扱い方がデータフレームとは大きく異なっており、かなりとっつきにくかったのですが、現在ではデータフレームとほぼ同じ取り扱いができるようになっています。\n\n\n\n\n\n\n\n\n図1：ワーキングディレクトリをfilesタブで確認する\n図2：MoreのリストからSet As Working Directoryを選ぶ\n図3：「Session」からワーキングディレクトリを変更する\n図4：デフォルトのワーキングディレクトリを変更する\n図5：ディレクトリのアドレス（Windowsの場合）\n図6：Rstudio終了時のワークスペース保存\n図7：Environmentパネル\n図8：Excelでコンマ切り・タブ切りテキストを作成する\n図9：Excelのセルに1を入力し、バックスペースで削除する\n図10：バックスペースで削除すると、ファイルサイズが増える\n\n\n\nBarrett, Tyson, Matt Dowle, and Arun Srinivasan. 2023. Data.table: Extension of ‘Data.frame‘. https://CRAN.R-project.org/package=data.table.\n\n\nBryan, Jennifer. 2023. Googlesheets4: Access Google Sheets Using the Sheets API V4. https://CRAN.R-project.org/package=googlesheets4.\n\n\nDragulescu, Adrian, and Cole Arendt. 2020. Xlsx: Read, Write, Format Excel 2007 and Excel 97/2000/XP/2003 Files. https://CRAN.R-project.org/package=xlsx.\n\n\nOoms, Jeroen. 2014. “The Jsonlite Package: A Practical and Consistent Mapping Between JSON Data and r Objects.” arXiv:1403.2805 [Stat.CO]. https://arxiv.org/abs/1403.2805.\n\n\nR Special Interest Group on Databases (R-SIG-DB), Hadley Wickham, and Kirill Müller. 2024. DBI: R Database Interface. https://CRAN.R-project.org/package=DBI.\n\n\nWickham, Hadley. 2022. Rvest: Easily Harvest (Scrape) Web Pages. https://CRAN.R-project.org/package=rvest.\n\n\n———. 2023. Httr2: Perform HTTP Requests and Process the Responses. https://CRAN.R-project.org/package=httr2.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWickham, Hadley, and Jennifer Bryan. 2023. Readxl: Read Excel Files. https://CRAN.R-project.org/package=readxl.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2023. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWickham, Hadley, Evan Miller, and Danny Smith. 2023. Haven: Import and Export ’SPSS’, ’Stata’ and ’SAS’ Files. https://CRAN.R-project.org/package=haven.",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>データの読み込みと書き出し（I/O）</span>"
    ]
  },
  {
    "objectID": "chapter14.html",
    "href": "chapter14.html",
    "title": "14  データセット",
    "section": "",
    "text": "14.1 代表的なデータセット",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>データセット</span>"
    ]
  },
  {
    "objectID": "chapter14.html#代表的なデータセット",
    "href": "chapter14.html#代表的なデータセット",
    "title": "14  データセット",
    "section": "",
    "text": "14.1.1 iris\nirisは3種のアヤメ（ヒオウギアヤメ（Iris setosa）、blue flag（Iris versicolor）、Virginia blueflag（Iris virginica））の花弁とがく片の長さと幅を記録したデータです。Ronald Fisherがこのデータを利用したことで有名で、Rでは最も見かけることが多いデータセットです。irisは150行のデータフレームで、左の列から、Sepal.Length（がく片の長さ）、Sepal.Width（がく片の幅）、Petal.Length（花弁の長さ）、Petal.Width（花弁の幅）、Species（種小名）の5列が登録されています。irisの初めの6行は以下の通りです。\n\n\n\niris\n\nhead(iris)\n##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 1          5.1         3.5          1.4         0.2  setosa\n## 2          4.9         3.0          1.4         0.2  setosa\n## 3          4.7         3.2          1.3         0.2  setosa\n## 4          4.6         3.1          1.5         0.2  setosa\n## 5          5.0         3.6          1.4         0.2  setosa\n## 6          5.4         3.9          1.7         0.4  setosa\n\n\n\n\n14.1.2 Nile\nNileはナイル川の水量を1871～1970年にかけて、年次で測定したデータです（単位は108 m3）。ナイル川では1902年にアスワン・ダムが、1970年にアスワン・ハイ・ダムが完成しています。このNileのデータセットでは、1898年頃（イギリスによるアスワン・ダムの建設開始時期）から水量が減っていることで有名で、非連続的な時系列データを取り扱うときの参考にされています。Nileは時系列型（ts）のデータセットです。\n\n\n\nNile\n\nNile\n## Time Series:\n## Start = 1871 \n## End = 1970 \n## Frequency = 1 \n##   [1] 1120 1160  963 1210 1160 1160  813 1230 1370 1140  995  935 1110  994 1020\n##  [16]  960 1180  799  958 1140 1100 1210 1150 1250 1260 1220 1030 1100  774  840\n##  [31]  874  694  940  833  701  916  692 1020 1050  969  831  726  456  824  702\n##  [46] 1120 1100  832  764  821  768  845  864  862  698  845  744  796 1040  759\n##  [61]  781  865  845  944  984  897  822 1010  771  676  649  846  812  742  801\n##  [76] 1040  860  874  848  890  744  749  838 1050  918  986  797  923  975  815\n##  [91] 1020  906  901 1170  912  746  919  718  714  740\nplot(Nile)\n\n\n\n\n\n\n\n\n\n\n\n14.1.3 Titanic\nTitanicは、タイタニック号に乗船していた旅客とクルーの性別・船室（一等船室、二等船室、三等船室、クルー）・年齢区分（大人・子供）・生死に関する人数を4次元のarrayとしたものです。RではTitanicを用いることはそれほどありませんが、kaggleという、機械学習の性能コンテストサイトでは機械学習の手習いとしてこのデータを用い、どのような性質の旅客であれば生存率が高いか、といった予測を行うモデルを作成するのによく用いられています。\n\n\n\nTitanic\n\nTitanic\n## , , Age = Child, Survived = No\n## \n##       Sex\n## Class  Male Female\n##   1st     0      0\n##   2nd     0      0\n##   3rd    35     17\n##   Crew    0      0\n## \n## , , Age = Adult, Survived = No\n## \n##       Sex\n## Class  Male Female\n##   1st   118      4\n##   2nd   154     13\n##   3rd   387     89\n##   Crew  670      3\n## \n## , , Age = Child, Survived = Yes\n## \n##       Sex\n## Class  Male Female\n##   1st     5      1\n##   2nd    11     13\n##   3rd    13     14\n##   Crew    0      0\n## \n## , , Age = Adult, Survived = Yes\n## \n##       Sex\n## Class  Male Female\n##   1st    57    140\n##   2nd    14     80\n##   3rd    75     76\n##   Crew  192     20\n\n\n\n\n14.1.4 BostonHousing\nBostonHousingも、Rでというよりは機械学習の分野で、家賃の予測モデル作成の手習いとしてよく用いられています。BostonHousingは、その名の通りボストンの住宅価格と地域周辺の犯罪率・住宅の部屋数・税率・高速道路へのアクセスなどを、1970年のセンサス（国勢調査）から収集してまとめたものです。Rでは、mlbenchパッケージ (Leisch and Dimitriadou 2021; Newman et al. 1998)（機械学習のベンチマークデータセットを集めたもの）に含まれており、使用するためにはmlbenchパッケージをインストール・ロードする必要があります。BostonHousingのデータ型はデータフレームです。\n\n\n\nBostonHousing\n\npacman::p_load(mlbench)\ndata(\"BostonHousing\")\nhead(BostonHousing)\n##      crim zn indus chas   nox    rm  age    dis rad tax ptratio      b lstat\n## 1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98\n## 2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14\n## 3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03\n## 4 0.03237  0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94\n## 5 0.06905  0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33\n## 6 0.02985  0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21\n##   medv\n## 1 24.0\n## 2 21.6\n## 3 34.7\n## 4 33.4\n## 5 36.2\n## 6 28.7\n\n\n\n\n14.1.5 diamonds\ndiamondsはグラフ作成ライブラリである、ggplot2に含まれるデータセットです。ggplot2 (Wickham 2016)を用いたグラフ作成例ではよく用いられています。diamondsはダイヤモンドのカラット数、透明性、カット、価格などをまとめたデータフレームです。\n\n\n\ndiamonds\n\nhead(ggplot2::diamonds)\n## # A tibble: 6 × 10\n##   carat cut       color clarity depth table price     x     y     z\n##   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n## 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n## 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n## 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n## 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n## 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n\n\n\n\n14.1.6 Gapminder\nGapminderは1952～2007年の各国のGDP、一人当たりGDP、寿命、人口をデータフレームとしてまとめたものです。このデータは、Gapminder Foundation（スウェーデンのNPO、所得格差の認知を推進する活動を行っている）が提供しているデータです。このデータも、Rでのグラフ作成の例でよく用いられているものです。Rでは、gapminderパッケージ (Bryan 2023)にデータセットが含まれています。\n\n\n\ngapminder\n\npacman::p_load(gapminder)\nhead(gapminder::gapminder)\n## # A tibble: 6 × 6\n##   country     continent  year lifeExp      pop gdpPercap\n##   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n## 1 Afghanistan Asia       1952    28.8  8425333      779.\n## 2 Afghanistan Asia       1957    30.3  9240934      821.\n## 3 Afghanistan Asia       1962    32.0 10267083      853.\n## 4 Afghanistan Asia       1967    34.0 11537966      836.\n## 5 Afghanistan Asia       1972    36.1 13079460      740.\n## 6 Afghanistan Asia       1977    38.4 14880372      786.\n\n\n\n\n\n\n\n\nBryan, Jennifer. 2023. Gapminder: Data from Gapminder. https://CRAN.R-project.org/package=gapminder.\n\n\nLeisch, Friedrich, and Evgenia Dimitriadou. 2021. Mlbench: Machine Learning Benchmark Problems.\n\n\nNewman, D. J., S. Hettich, C. L. Blake, and C. J. Merz. 1998. “UCI Repository of Machine Learning Databases.” University of California, Irvine, Dept. of Information; Computer Sciences. http://www.ics.uci.edu/~mlearn/MLRepository.html.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.",
    "crumbs": [
      "Rプログラミングの基礎",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>データセット</span>"
    ]
  },
  {
    "objectID": "chapter15.html",
    "href": "chapter15.html",
    "title": "15  apply関数群",
    "section": "",
    "text": "15.1 繰り返し計算\nベクターのような、多数の要素を含むオブジェクトを用いて演算を行う場合、R以外の言語では通常繰り返し計算を用います。繰り返し計算とは5章で説明した通り、for文やwhile文、repeat文などを用いた計算です。プログラミング言語によって繰り返し計算の式は異なりますが、たくさんの要素を持つオブジェクトの演算では、繰り返し計算は有効な計算方法の一つです。",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>apply関数群</span>"
    ]
  },
  {
    "objectID": "chapter15.html#繰り返し計算とベクター",
    "href": "chapter15.html#繰り返し計算とベクター",
    "title": "15  apply関数群",
    "section": "15.2 繰り返し計算とベクター",
    "text": "15.2 繰り返し計算とベクター\nでは、Rでの繰り返し計算を見てみましょう。下の例では、ベクターの要素に演算を行い、結果をベクターで返す繰り返し計算を行っています。\n\n\n\nfor文でベクターの演算を行う\n\nv &lt;- 1:10 # vは1~10の整数ベクター\n\nv_new &lt;- NULL # 計算結果を代入するNULLが入った変数\n\nfor(i in 1:length(v)){ # vの長さ分計算する\n  temp &lt;- v[i] * 3 + 5\n  v_new &lt;- c(v_new, temp) # v_newにv[i]を演算した結果をつなげる\n}\n\nv_new # 演算結果\n##  [1]  8 11 14 17 20 23 26 29 32 35\n\n\nRでfor文を用いてベクターの要素に演算を行う場合には、\n\nNULLを代入しただけの空っぽの変数を作る\n繰り返し回数を演算に用いるベクターの長さで指定する\nベクターの要素をインデックスで取り出し、演算する\n空っぽの変数に、c関数で演算結果を付け足す\n\nといった計算を行うことがあります。\n上の例では、変数vは1～10の連続する長さ10の整数ベクター、v_newはNULL（空）のオブジェクトです。\nfor文では、iに1:length(v)の要素が繰り返し計算ごとに代入されます。つまり1回目の繰り返し計算ではiは1、2回目ではiは2…となり、iにlength(v)、つまり10が代入された計算が終わると、繰り返し計算が終了します。\nさらに、for文中では、v[i]、つまりiをインデックスにしてvの要素を取り出しています。1回目の繰り返し計算ではiが1ですので、v[i]はvの1つ目の要素、2回目の繰り返し計算ではv[i]はvの2つ目の要素となります。v[i]を3倍して5を足した結果を一時的にtempという変数に代入しています。\nfor文の中では、「v_new &lt;- c(v_new, temp)」という形で、空の変数であるv_newに、計算結果をc関数で繋いだものを、v_newに代入する、という変な演算を行っています。この演算では、1週目ではc(NULL, temp)をv_newに代入することで、v_newはtempを1つだけ持つベクターに変化しています。2週目以降は、v_newのベクターの要素の後に新しく計算したtempが付け加えられます。これを繰り返すことで、v_newにはtempの計算結果がベクターとして記録されていきます。\n最終的に、v_newはvの各要素を3倍して5を足したベクターとして演算が終了します。\n上記のようなfor文の演算は、Rでは非常によろしくない、典型的なバッドノウハウであるとされています。そもそもRでのベクターの演算に繰り返し文を使う必要がないので、上記のfor文は下のように書き換えることができます。ベクターの演算の方が、for文を用いた演算よりずっと速いため、Rでベクターの要素を演算に用いる場合には、繰り返し計算ではなく、ベクターの演算を用いることが推奨されています。\n\n\n\n上のfor文と同じ計算をベクターで行う\n\nv * 3 + 5\n##  [1]  8 11 14 17 20 23 26 29 32 35\n\n\n上のfor文にはもう一点問題があります。v_newというベクターに対して、数値を付け足すという演算を繰り返しています。このような場合、v_newの長さが伸びていくため、Rの内部では、要素が付け加えられる度にv_newというベクターを新しく作り直し、古いものは削除するという演算が行われることになります。この「作り直して」「削除する」という演算に時間がかかるため、上記のような書き方では演算速度に問題が生じます。\nこのような「作り直して」「削除する」プロセスを省くためには、インデックスに代入する方法を用いるとよいでしょう。あらかじめ結果と同じ長さのベクターを準備しておき、このベクターの要素に演算結果を代入します。このような形にすると、v_new自体を作り直すプロセスがなくなり、演算速度が速くなるとされています。\nこの、結果と同じ長さのベクターを準備するときには、numeric関数を用います。numeric関数は数値を1つ引数に取り、数値に応じた長さの、要素が0だけのベクターを作成する関数です。このnumeric関数を用いて演算結果と同じ長さのベクターを作成しておくことで、そのベクターにインデックスを指定して演算結果を代入していくことができます。\n\n\n\nnumeric関数を用いてインデックスに代入する\n\nnumeric(5) # 0が5つ入ったベクター\n## [1] 0 0 0 0 0\n\nv_new &lt;- numeric(length(v)) # v_newは0がvと同じ長さだけ並んだベクター\n\nfor(i in 1:length(v)){ # vの長さ分計算する\n  v_new[i] &lt;- v[i] * 3 + 5 # v_new[i]にv[i]を演算した結果を代入\n}\n\nv_new # 演算結果\n##  [1]  8 11 14 17 20 23 26 29 32 35",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>apply関数群</span>"
    ]
  },
  {
    "objectID": "chapter15.html#繰り返し計算とデータフレーム",
    "href": "chapter15.html#繰り返し計算とデータフレーム",
    "title": "15  apply関数群",
    "section": "15.3 繰り返し計算とデータフレーム",
    "text": "15.3 繰り返し計算とデータフレーム\nデータフレームの要素に対して繰り返し計算をする場合にも、上のベクターでの繰り返し計算と同様の手法が使えます。下の計算では、iris_editedという変数にNULLを代入し、この空のiris_editedにベクターをrbind関数で結合したものをiris_editedに代入するという計算をしています。rbind関数は行を追加する関数ですので、計算結果を含むベクターはiris_editedの一番下の行に追加されます。\nこのような繰り返し計算を行うと、iris_editedは自動的にNULLから行列（matrix）に変換されます。また、計算途中でiris$Species（因子）を文字列に変換し、文字列と数値の計算結果をベクターにまとめているため、数値計算結果は自動的に文字列に変換されています。その結果、繰り返し計算後に得られるiris_editedは文字列の行列になっています。\n行列は、as.data.frame関数でデータフレームに変換できます。ただし、文字列の行列の要素は文字列型のまま変換されるため、結果が数値に見えても文字列になっている場合があります。\nこのように、データフレームを直接繰り返し計算に用いると、データ型の変換が頻繁に起こり、計算結果を予測するのが難しくなります。繰り返し計算時には、取り扱っている変数の型がどのように変化しているのか、常に注意が必要です。\n\n\n\nfor文でデータフレームに行を追加する\n\nhead(iris)\n##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 1          5.1         3.5          1.4         0.2  setosa\n## 2          4.9         3.0          1.4         0.2  setosa\n## 3          4.7         3.2          1.3         0.2  setosa\n## 4          4.6         3.1          1.5         0.2  setosa\n## 5          5.0         3.6          1.4         0.2  setosa\n## 6          5.4         3.9          1.7         0.4  setosa\n\niris_edited &lt;- NULL\n\nfor(i in 1:nrow(iris)){\n  # iris$Speciesは因子で、そのままだと数値に変換されるため、文字列に変換しておく\n  species &lt;- as.character(iris$Species[i]) \n  \n  # Sepal.LengthとSepal.Widthの積を計算\n  Sepal_multiple &lt;- iris$Sepal.Length[i] * iris$Sepal.Width[i]\n  \n  # species（文字列）と計算結果をベクターにまとめる（文字列のベクターに変換）\n  temp_vec &lt;- c(species, Sepal_multiple)\n  \n  # ベクターをiris_editedの行として追加（iris_editedは行列になる）\n  iris_edited &lt;- rbind(iris_edited, temp_vec)\n}\n\ndim(iris_edited) # iris_editedは150行2列\n## [1] 150   2\n\nclass(iris_edited) # iris_editedは行列（matrix）\n## [1] \"matrix\" \"array\"\n\nhead(iris_edited) # 文字列の行列になっている\n##          [,1]     [,2]   \n## temp_vec \"setosa\" \"17.85\"\n## temp_vec \"setosa\" \"14.7\" \n## temp_vec \"setosa\" \"15.04\"\n## temp_vec \"setosa\" \"14.26\"\n## temp_vec \"setosa\" \"18\"   \n## temp_vec \"setosa\" \"21.06\"\n\n\nベクターの繰り返し計算で述べたように、変数に要素を追加して、サイズが変化すると、変数を「作り直して」「削除する」プロセスが繰り返され、計算のコストが大きくなります。計算のコストが大きくなると演算に時間がかかるため、上の例のようにNULLに要素を追加するのは避けた方がよいとされています。ですので、上のような計算では、あらかじめ結果と同じサイズの行列を準備し、その行列の要素に計算結果を追加していくのが良いとされています。\n\n\n\nインデックスへの代入で計算結果を保存する\n\nhead(iris)\n##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 1          5.1         3.5          1.4         0.2  setosa\n## 2          4.9         3.0          1.4         0.2  setosa\n## 3          4.7         3.2          1.3         0.2  setosa\n## 4          4.6         3.1          1.5         0.2  setosa\n## 5          5.0         3.6          1.4         0.2  setosa\n## 6          5.4         3.9          1.7         0.4  setosa\n\n# あらかじめ0が埋まっている行列を準備しておく\niris_edited &lt;- matrix(0, nrow=150, ncol=2)\n\nfor(i in 1:nrow(iris)){\n  species &lt;- as.character(iris$Species[i])\n  Sepal_multiple &lt;- iris$Sepal.Length[i] * iris$Sepal.Width[i]\n  temp_vec &lt;- c(species, Sepal_multiple)\n  iris_edited[i, ] &lt;- temp_vec # 行列のインデックスに行の計算結果を追加する\n}\n\ndim(iris_edited) # iris_editedは150行2列\n## [1] 150   2\n\nclass(iris_edited) # iris_editedは行列（matrix）\n## [1] \"matrix\" \"array\"\n\nhead(iris_edited) # 文字列の行列になっている\n##      [,1]     [,2]   \n## [1,] \"setosa\" \"17.85\"\n## [2,] \"setosa\" \"14.7\" \n## [3,] \"setosa\" \"15.04\"\n## [4,] \"setosa\" \"14.26\"\n## [5,] \"setosa\" \"18\"   \n## [6,] \"setosa\" \"21.06\"\n\n\n上記のように、Rでは繰り返し計算で変数の「作り直し」が起きたり、データ型がころころ変わったりするため、繰り返し計算でベクターやデータフレームの要素を取り扱うのは推奨されません。ただし、繰り返し計算は演算の過程が捉えやすく、後から読んで理解しやすい構造をしています。NULLオブジェクトにデータを追加していくと、結果として得られるオブジェクトのサイズがわかっていなくても演算できるという利点があります。\n2000年頃のPCは性能が低く、計算コストに気を払う必要がありましたが、現在では繰り返し計算を回しても大して時間がかからなくなりました。よほど大きいデータフレーム（数万～数十万行）を取り扱う場合を除けば、繰り返し計算が問題となることは少なくなったと感じます。データの取り扱いが一度きり（ad hoc）の場合には以下のapply関数群を使っても、繰り返し計算を使っても大差ないため、好みの、わかりやすい方法を用いればよいでしょう。",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>apply関数群</span>"
    ]
  },
  {
    "objectID": "chapter15.html#apply関数群",
    "href": "chapter15.html#apply関数群",
    "title": "15  apply関数群",
    "section": "15.4 apply関数群",
    "text": "15.4 apply関数群\nRでのデータフレーム演算の「お作法」では、繰り返し計算ではなく、apply関数群を用いるのが望ましいとされています。apply関数群にはapply, mapply, lapply, sapply, tapply, aggregate, byなど、かなりたくさんの関数があり、それぞれ少し癖のある使い方が求められます。以下の表1にapply関数群についてまとめます。\n\n\n\n表1 apply関数群（funは関数、factは因子、marginは方向を指す）\n\n\n\n\n\n\n関数名\n計算の内容\n\n\n\n\napply(x, margin, fun)\nmarginの方向に関数を適用する\n\n\nmapply(fun, 引数1, 引数2…)\n引数に指定した複数の値を関数に代入する\n\n\nlapply(list, fun)\nlistの要素に関数を適用する\n\n\nsapply(list, fun)\nlistの要素に関数を適用する\n\n\nvapply(x, fun, fun.value)\nxに関数を適用し、fun.valueに指定した形で返す\n\n\nreplicate(n, calc)\ncalcで指定した演算をn回繰り返す\n\n\ntapply(x, fact, fun)\nxを因子で切り分け、関数を適用する\n\n\nsweep(x, margin, y)\nmarginの方向にyの要素を引く\n\n\naggregate(x, by, fun)\nbyで指定した要素ごとに関数を適用する\n\n\naggregate(formula, data)\nformulaに従い、要素ごとに関数を適用する\n\n\nby(x, by, fun)\nbyで指定した要素ごとに関数を適用する\n\n\n\n\n\n\n15.4.1 apply関数\napply関数群の中で最も基本的なものが、apply関数です。apply関数は第一引数にデータフレーム（もしくは行列）を取り、第二引数にMARGIN、第三引数に関数を取ります。第二引数のMARGINは1か2を取り、1を取ると行（横）方向、2を取ると列（縦）方向のベクターを計算対象とします。apply関数はデータフレームの要素に、MARGINで指定した方向に、第三引数で指定した関数を適用します。第三引数に指定する関数には、Rに備わっている関数、自作した関数の両方を用いることができます。\napply関数の演算では、（特に行方向、MARGIN = 1の時には）データ型が一致していることが必要となります。apply関数の使い方を以下の図1に示します。\n\n\n\n図1：apply関数の使い方\n\n\n\n\n\napply関数の演算\n\napply(iris[, 1:4], 1, sum) # 行方向に和を求める\n##   [1] 10.2  9.5  9.4  9.4 10.2 11.4  9.7 10.1  8.9  9.6 10.8 10.0  9.3  8.5 11.2\n##  [16] 12.0 11.0 10.3 11.5 10.7 10.7 10.7  9.4 10.6 10.3  9.8 10.4 10.4 10.2  9.7\n##  [31]  9.7 10.7 10.9 11.3  9.7  9.6 10.5 10.0  8.9 10.2 10.1  8.4  9.1 10.7 11.2\n##  [46]  9.5 10.7  9.4 10.7  9.9 16.3 15.6 16.4 13.1 15.4 14.3 15.9 11.6 15.4 13.2\n##  [61] 11.5 14.6 13.2 15.1 13.4 15.6 14.6 13.6 14.4 13.1 15.7 14.2 15.2 14.8 14.9\n##  [76] 15.4 15.8 16.4 14.9 12.8 12.8 12.6 13.6 15.4 14.4 15.5 16.0 14.3 14.0 13.3\n##  [91] 13.7 15.1 13.6 11.6 13.8 14.1 14.1 14.7 11.7 13.9 18.1 15.5 18.1 16.6 17.5\n## [106] 19.3 13.6 18.3 16.8 19.4 16.8 16.3 17.4 15.2 16.1 17.2 16.8 20.4 19.5 14.7\n## [121] 18.1 15.3 19.2 15.7 17.8 18.2 15.6 15.8 16.9 17.6 18.2 20.1 17.0 15.7 15.7\n## [136] 19.1 17.7 16.8 15.6 17.5 17.8 17.4 15.5 18.2 18.2 17.2 15.7 16.7 17.3 15.8\n\napply(iris[, 1:4], 2, sum) # 列方向に和を求める\n## Sepal.Length  Sepal.Width Petal.Length  Petal.Width \n##        876.5        458.6        563.7        179.9\n\n# 自作の関数\nfunc1 &lt;- function(x){sum(sqrt(x) * log(x))}\n\napply(iris[, 1:4], 2, func1)\n## Sepal.Length  Sepal.Width Petal.Length  Petal.Width \n##    638.50578    292.37383    373.96812     32.26917\n\napply(iris[1:5, 1:4], 2, \\(x){sum(sqrt(x) * log(x))}) # 無名関数も利用できる\n## Sepal.Length  Sepal.Width Petal.Length  Petal.Width \n##    17.424140    10.749705     1.990091    -3.598813\n\n\n\n15.4.1.1 3次元以上のarrayにapplyを適用する\napply関数は3次元以上のarrayを引数に取ることもできます。3次元以上のarrayを引数に取る場合には、MARGINの設定がやや複雑になります。MARGINに1つの値を設定した場合には、その次元を残す形で関数を適用します。MARGINに2つの値を設定した場合には、その2つの次元を残して関数を適用します。MARGINに2つ以上の値を指定する場合には、ベクターを用います。\n\n\n\napply関数でarrayを演算する\n\nUCBAdmissions # 3次元アレイ\n## , , Dept = A\n## \n##           Gender\n## Admit      Male Female\n##   Admitted  512     89\n##   Rejected  313     19\n## \n## , , Dept = B\n## \n##           Gender\n## Admit      Male Female\n##   Admitted  353     17\n##   Rejected  207      8\n## \n## , , Dept = C\n## \n##           Gender\n## Admit      Male Female\n##   Admitted  120    202\n##   Rejected  205    391\n## \n## , , Dept = D\n## \n##           Gender\n## Admit      Male Female\n##   Admitted  138    131\n##   Rejected  279    244\n## \n## , , Dept = E\n## \n##           Gender\n## Admit      Male Female\n##   Admitted   53     94\n##   Rejected  138    299\n## \n## , , Dept = F\n## \n##           Gender\n## Admit      Male Female\n##   Admitted   22     24\n##   Rejected  351    317\n\ndimnames(UCBAdmissions) # 次元の順番はAdmit, Gender, Deptの順\n## $Admit\n## [1] \"Admitted\" \"Rejected\"\n## \n## $Gender\n## [1] \"Male\"   \"Female\"\n## \n## $Dept\n## [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\"\n\napply(UCBAdmissions, 1, mean) # 1次元目（Admit）の平均を求める\n## Admitted Rejected \n## 146.2500 230.9167\n\napply(UCBAdmissions, 2, mean) # 2次元目（Gender）の平均を求める\n##     Male   Female \n## 224.2500 152.9167\n\napply(UCBAdmissions, 3, mean) # 3次元目（Dept）の平均を求める\n##      A      B      C      D      E      F \n## 233.25 146.25 229.50 198.00 146.00 178.50\n\n\napply(UCBAdmissions, 1:2, mean) # 3次元目（Dept）方向に平均を求める\n##           Gender\n## Admit          Male    Female\n##   Admitted 199.6667  92.83333\n##   Rejected 248.8333 213.00000\n\napply(UCBAdmissions, c(1, 3), mean) # 2次元目（Gender）方向に平均を求める\n##           Dept\n## Admit          A     B   C     D     E   F\n##   Admitted 300.5 185.0 161 134.5  73.5  23\n##   Rejected 166.0 107.5 298 261.5 218.5 334\n\napply(UCBAdmissions, 2:3, mean) # 1次元目（Admit）方向に平均を求める\n##         Dept\n## Gender       A     B     C     D     E     F\n##   Male   412.5 280.0 162.5 208.5  95.5 186.5\n##   Female  54.0  12.5 296.5 187.5 196.5 170.5\n\n\n\n\n\n15.4.2 mapply関数\nmapply関数は、関数が2種類以上の引数を取る場合に用います。mapply関数はapply関数とは引数の順番が異なり、適用する関数が第一引数になります。続いて適用する関数の引数をベクターで取ります。mapply関数の返り値は適用する関数により異なり、関数の返り値が1つならmapply関数の返り値はベクター、返り値が2つ以上ならmapply関数の返り値はリストになります。\n\n\n\n図2：mapply関数の使い方\n\n\n\n\n\nmapply関数\n\nmapply(mean, 1:4, 2:5)\n## [1] 1 2 3 4\n\nlst &lt;- mapply(rep, times = 1:4, x = 4:1) # 関数の引数を指定して、ベクターで与える 複数の引数を取れる\nlst\n## [[1]]\n## [1] 4\n## \n## [[2]]\n## [1] 3 3\n## \n## [[3]]\n## [1] 2 2 2\n## \n## [[4]]\n## [1] 1 1 1 1\n\n# 無名関数も使える\nmapply(\\(x, y){x / y}, x = 1:5, y = 5:1)\n## [1] 0.2 0.5 1.0 2.0 5.0\n\n\n\n\n15.4.3 lapply関数/sapply関数\nlapply関数はリストを引数に取る関数です。lapply関数は第一引数にリスト、第二引数に関数を取り、リストの各要素に関数を適用します。lapply関数は返り値にリストを取ります。データフレームはリストですので、lapply関数はapply(x, 2, FUN)、つまり列方向に関数を適用するのと同じ計算を行うことができます。\nsapply関数は返り値がベクターになったlapply関数です。関数の返り値が2つ以上の値であれば、sapply関数は行列を返します。\n\n\n\n図3：lapply/sapply関数の使い方\n\n\n\n\n\nlapply関数とsapply関数\n\nlapply(lst, sum) # リストの各要素に関数を適用する（返り値はリスト）\n## [[1]]\n## [1] 4\n## \n## [[2]]\n## [1] 6\n## \n## [[3]]\n## [1] 6\n## \n## [[4]]\n## [1] 4\n\nlapply(iris[, 1:4], sum) # データフレームは列方向のリストなので、適用可能\n## $Sepal.Length\n## [1] 876.5\n## \n## $Sepal.Width\n## [1] 458.6\n## \n## $Petal.Length\n## [1] 563.7\n## \n## $Petal.Width\n## [1] 179.9\n\nlapply(lst, summary)\n## [[1]]\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##       4       4       4       4       4       4 \n## \n## [[2]]\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##       3       3       3       3       3       3 \n## \n## [[3]]\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##       2       2       2       2       2       2 \n## \n## [[4]]\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##       1       1       1       1       1       1\n\n\nsapply(lst, sum) # 返り値がベクターのlapply\n## [1] 4 6 6 4\n\nsapply(iris[, 1:4], sum)\n## Sepal.Length  Sepal.Width Petal.Length  Petal.Width \n##        876.5        458.6        563.7        179.9\n\n\n\n\n15.4.4 vapply関数\nvapply関数は関数が複数の返り値を持つときに用いる関数です。vapply関数の第一引数はベクターやリスト、第二引数は複数の返り値を取る関数です。vapply関数はこの返り値を行列に変換するのですが、この変換時の行名をFUN.VALUEという第三引数で設定します。FUN.VALUEの設定は名前付きベクターで、値は0とします。かなり癖が強いので、使われているところをほとんど見たことがない関数です。\n\n\n\n図3：vapply関数の使い方\n\n\n\n\n\nvapply関数\n\nfivenum(1:10) # データを5つに集約する関数（最小値、第一四分位、中央値、第三四分位、最大値）\n## [1]  1.0  3.0  5.5  8.0 10.0\n\nvapply(iris[, 1:4], fivenum, c(Min. = 0, \"1st Qu\" = 0, Median = 0, \"3rd Qu\" = 0, Max. = 0)) # 集約値をそれぞれ表示\n##        Sepal.Length Sepal.Width Petal.Length Petal.Width\n## Min.            4.3         2.0         1.00         0.1\n## 1st Qu          5.1         2.8         1.60         0.3\n## Median          5.8         3.0         4.35         1.3\n## 3rd Qu          6.4         3.3         5.10         1.8\n## Max.            7.9         4.4         6.90         2.5\n\n\n\n\n15.4.5 replicate関数\nreplicate関数は、第一引数に繰り返し計算の回数、第二引数に関数を取ります。replicate関数は関数の計算を繰り返し計算の回数だけ繰り返し、結果をベクターで返します。指定する関数の引数を変えることはできないので、一見あまり意味がなさそうに見えます。しかし、Rでは乱数（ランダムな数値）を用いた計算を行うことが多く、乱数計算を繰り返すと同じ関数の返り値でも変化することがあります。したがって、replicate関数は乱数を使った計算で利用すると生きる関数となっています。\n\n\n\n図5：replicate関数の使い方\n\n\n\n\n\nreplicate関数\n\nsample(1:6, 10, replace=T) # サイコロを10回ふる\n##  [1] 6 1 4 1 2 5 3 6 2 3\n\nsum(sample(1:6, 10, replace=T)) # サイコロを10回ふり、合計値を求める\n## [1] 36\n\nreplicate(20, sum(sample(1:6, 10, replace=T))) # 上の試行を20回繰り返す\n##  [1] 34 36 31 44 36 41 34 30 35 36 41 33 28 26 30 34 37 34 32 49\n\n\n\n\n15.4.6 tapply関数\ntapply関数はベクターと因子を引数に取り、因子のグループごとに関数をベクターに適用します。ベクターに測定値、因子にカテゴリ（たとえば男性・女性など）を取っておけば、カテゴリごとの集計値を計算するのに使えます。\n\n\n\n図6：tapply関数の使い方\n\n\n\n\n\ntapply関数\n\nv &lt;- 1:10\ncutv &lt;- factor(c(1, 1, 1, 1, 2, 2, 2, 3, 3, 4))\ntapply(v, cutv, sum) # ベクターを因子で切り分け、関数を適用する\n##  1  2  3  4 \n## 10 18 17 10\n\n\n\n\n15.4.7 sweep関数\nsweep関数は、apply関数に似ていますが、第三引数が関数ではなく、ベクターであるところが異なります。MARGINは1が行方向、2が列方向であるのはapply関数と同じですが、第三引数が引き算に使われるのが特徴です。\n\n\n\nsweep関数\n\nmatrix(1:15, nrow=3)\n##      [,1] [,2] [,3] [,4] [,5]\n## [1,]    1    4    7   10   13\n## [2,]    2    5    8   11   14\n## [3,]    3    6    9   12   15\n\nsweep(matrix(1:15, nrow=3), 1, 1:3) # 列方向に1, 2, 3を引く\n##      [,1] [,2] [,3] [,4] [,5]\n## [1,]    0    3    6    9   12\n## [2,]    0    3    6    9   12\n## [3,]    0    3    6    9   12\n\nsweep(matrix(1:15, nrow=3), 2, 1:5) # 行方向に1, 2, 3, 4, 5を引く\n##      [,1] [,2] [,3] [,4] [,5]\n## [1,]    0    2    4    6    8\n## [2,]    1    3    5    7    9\n## [3,]    2    4    6    8   10\n\n\n\n\n15.4.8 aggregate関数\naggregate関数は、dplyrが出てくるまではデータフレームの結果を集計するのによく用いられてきた関数です。aggregate関数の第一引数はデータフレーム、第二引数にはby（因子のリスト）、第三引数に関数を取ります。aggregate関数はbyに指定した因子に従い、各列に関数を適用します。因子にカテゴリ（下の例ではirisの種、Species）を指定することで、因子ごとにデータを集計するのに用いることができます。\naggregate関数は引数にデータフレームだけでなく、formula（式）というものを取ることもできます。このformulaはRでは統計でよく用いられる表現で、~（チルダ）を演算子として用いるものです。~の左側には目的変数、右側には説明変数を足し算・掛け算で記入する形をとるのが最も一般的です。aggregate関数では、左側に関数を適用する列名、右側にbyにあたる因子を指定します。また、formulaでは、~の左側または右側に.（ピリオド）を置くことがあります。このピリオドは、「従属変数または独立変数に使用しなかったすべての列」を表す表現です。このformulaについては、統計の章で詳しく説明します。\nby関数もaggregate関数と類似した関数ですが、byは関数の引数に各列のベクターではなく、因子で区切ったデータフレームを指定します。ですので、データフレームを処理できない関数を用いると、計算ができない場合があります。\n\n\n\n図7：aggregate関数の使い方\n\n\n\n\n\naggregate関数とby関数\n\naggregate(iris[,1:4], by=list(iris$Species), FUN = \"mean\") # byはリスト、Speciesごとの平均値\n##      Group.1 Sepal.Length Sepal.Width Petal.Length Petal.Width\n## 1     setosa        5.006       3.428        1.462       0.246\n## 2 versicolor        5.936       2.770        4.260       1.326\n## 3  virginica        6.588       2.974        5.552       2.026\n\naggregate(iris[,1:4], by=list(iris$Species), FUN = \"min\") # Speciesごとの最小値\n##      Group.1 Sepal.Length Sepal.Width Petal.Length Petal.Width\n## 1     setosa          4.3         2.3          1.0         0.1\n## 2 versicolor          4.9         2.0          3.0         1.0\n## 3  virginica          4.9         2.2          4.5         1.4\n\n# formulaでも演算ができる（.はirisのSpecies以外の列）\naggregate(.~Species, data = iris, max) \n##      Species Sepal.Length Sepal.Width Petal.Length Petal.Width\n## 1     setosa          5.8         4.4          1.9         0.6\n## 2 versicolor          7.0         3.4          5.1         1.8\n## 3  virginica          7.9         3.8          6.9         2.5\n\nhead(ToothGrowth) # ラットの歯の成長のデータ\n##    len supp dose\n## 1  4.2   VC  0.5\n## 2 11.5   VC  0.5\n## 3  7.3   VC  0.5\n## 4  5.8   VC  0.5\n## 5  6.4   VC  0.5\n## 6 10.0   VC  0.5\n\n# 与えるサプリの種類と量ごとの歯の長さの平均値\naggregate(len~., data = ToothGrowth, mean) \n##   supp dose   len\n## 1   OJ  0.5 13.23\n## 2   VC  0.5  7.98\n## 3   OJ  1.0 22.70\n## 4   VC  1.0 16.77\n## 5   OJ  2.0 26.06\n## 6   VC  2.0 26.14\n\nby(iris[, 1], list(iris$Species), mean) # 1列目のSpeciesごとの平均値\n## : setosa\n## [1] 5.006\n## ------------------------------------------------------------ \n## : versicolor\n## [1] 5.936\n## ------------------------------------------------------------ \n## : virginica\n## [1] 6.588\n\nby(iris[, 1:2], list(iris$Species), mean) # meanは2列のデータを処理できない\n## : setosa\n## [1] NA\n## ------------------------------------------------------------ \n## : versicolor\n## [1] NA\n## ------------------------------------------------------------ \n## : virginica\n## [1] NA\n\nby(iris[, 1:4], list(iris$Species), summary) # summaryはデータフレームを引数にできるので、計算できる\n## : setosa\n##   Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n##  Min.   :4.300   Min.   :2.300   Min.   :1.000   Min.   :0.100  \n##  1st Qu.:4.800   1st Qu.:3.200   1st Qu.:1.400   1st Qu.:0.200  \n##  Median :5.000   Median :3.400   Median :1.500   Median :0.200  \n##  Mean   :5.006   Mean   :3.428   Mean   :1.462   Mean   :0.246  \n##  3rd Qu.:5.200   3rd Qu.:3.675   3rd Qu.:1.575   3rd Qu.:0.300  \n##  Max.   :5.800   Max.   :4.400   Max.   :1.900   Max.   :0.600  \n## ------------------------------------------------------------ \n## : versicolor\n##   Sepal.Length    Sepal.Width     Petal.Length   Petal.Width   \n##  Min.   :4.900   Min.   :2.000   Min.   :3.00   Min.   :1.000  \n##  1st Qu.:5.600   1st Qu.:2.525   1st Qu.:4.00   1st Qu.:1.200  \n##  Median :5.900   Median :2.800   Median :4.35   Median :1.300  \n##  Mean   :5.936   Mean   :2.770   Mean   :4.26   Mean   :1.326  \n##  3rd Qu.:6.300   3rd Qu.:3.000   3rd Qu.:4.60   3rd Qu.:1.500  \n##  Max.   :7.000   Max.   :3.400   Max.   :5.10   Max.   :1.800  \n## ------------------------------------------------------------ \n## : virginica\n##   Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n##  Min.   :4.900   Min.   :2.200   Min.   :4.500   Min.   :1.400  \n##  1st Qu.:6.225   1st Qu.:2.800   1st Qu.:5.100   1st Qu.:1.800  \n##  Median :6.500   Median :3.000   Median :5.550   Median :2.000  \n##  Mean   :6.588   Mean   :2.974   Mean   :5.552   Mean   :2.026  \n##  3rd Qu.:6.900   3rd Qu.:3.175   3rd Qu.:5.875   3rd Qu.:2.300  \n##  Max.   :7.900   Max.   :3.800   Max.   :6.900   Max.   :2.500\n\n\n\n\n\n\n\n図1：apply関数の使い方\n図2：mapply関数の使い方\n図3：lapply/sapply関数の使い方\n図3：vapply関数の使い方\n図5：replicate関数の使い方\n図6：tapply関数の使い方\n図7：aggregate関数の使い方\n\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Davis Vaughan, and Maximilian Girlich. 2023. Tidyr: Tidy Messy Data. https://CRAN.R-project.org/package=tidyr.",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>apply関数群</span>"
    ]
  },
  {
    "objectID": "chapter16.html",
    "href": "chapter16.html",
    "title": "16  tidyr・dplyr",
    "section": "",
    "text": "16.1 メソッドチェーン\ntidyr・dplyrについて説明する前に、R以外の言語で用いられている、メソッドチェーンについて簡単に説明します。\nR以外の言語では、オブジェクトに対して演算を行う時、関数以外にメソッドを利用することがあります。メソッドは、オブジェクトの後にピリオドで繋いで、オブジェクトに何らかの演算を行うものです。例えばRubyでは文字列に対して、「.upcase」というメソッドが設定されています。.upcaseは文字列を大文字にするメソッドです。例えば「\"Hello world\".upcase」とすると、\"Hello world\"の小文字が大文字に変換され、\"HELLO WORLD\"が返ってきます。\nメソッドは2つ以上繋げて用いることができます。例えば、.reverseは文字列を逆順にするメソッドですが、「\"Hello world\".reverse.upcase」とすると、\"Hello world\"を逆順にし、続いて大文字に変換することができます。このように、メソッドを繋いで使用することをメソッドチェーンと呼びます。\n以下に、Rubyとjavascriptでのメソッドチェーンの例を示します。\nRubyでのメソッドチェーン\n\nstring = \"dlrow olleH\"\nstring.reverse.upcase # 文字列を逆順にし、大文字に変換する\n#&gt;  \"HELLO WORLD\"\nJavaScriptでのメソッドチェーン\n\nvar firstName = \" Rajat \"; // firstNameは \" Rajat \"\nconsole.log(firstName); \n#&gt; \" Rajat \"\n\nvar modifiedName = \n  firstName \n    .toUpperCase() // 大文字にして\n        .trim(); // 前後のスペースを削除する\n\nconsole.log(modifiedName)\n#&gt; \"RAJAT\"\nメソッドチェーンのよいところは、演算の過程を左から右へ、文章を読むように追いかけることができることです。上記のメソッドチェーンと同じような演算をRで行うと、以下のようになります。\n文字列に2つの処理を行う\n\npacman::p_load(tidyverse) # stringrを使うためtidyverseをロードする\nfirstname &lt;- \" Rajat \"\n\n# 例1\nstr_to_upper(str_trim(firstname)) # スペースを取り除いて大文字にする\n## [1] \"RAJAT\"\n\n# 例2\nfirstname1 &lt;- str_trim(firstname) # スペースを取り除く\nstr_to_upper(firstname1) # 大文字にする\n## [1] \"RAJAT\"\nRではメソッドチェーンは使えないので、複数の演算を行うときには、上の例1のように関数の中に関数を入れる（ネストする）か、例2のように一時的に計算結果を変数に入れておき、その一時的な変数を利用して再度演算（逐次的な演算）をする必要があります。\nどちらも実用上大きな問題はないのですが、プログラムとしては理解しにくく、メソッドチェーンのように簡単に複数の処理を行えるものではありません。\nこのような問題を解決する演算子が、パイプ演算子です。",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>tidyr・dplyr</span>"
    ]
  },
  {
    "objectID": "chapter16.html#パイプ演算子pipe-operator",
    "href": "chapter16.html#パイプ演算子pipe-operator",
    "title": "16  tidyr・dplyr",
    "section": "16.2 パイプ演算子（pipe operator）",
    "text": "16.2 パイプ演算子（pipe operator）\nパイプ演算子とは、「演算子の前のオブジェクトを、演算子の後ろの関数の引数にする」演算子です。Rのパイプ演算子には以下の2種類があります。\n\n|&gt;：Rのデフォルトのパイプ演算子\n%&gt;%：magrittrパッケージ (Bache and Wickham 2022)に登録されているパイプ演算子\n\nパイプ演算子を用いると、以下の演算は同じ意味を持ちます。\n\n\n\nパイプ演算子\n\nvec &lt;- c(1, 2, 3)\nmean(vec) # 通常の演算\n## [1] 2\n\nvec |&gt; mean() # パイプ演算子\n## [1] 2\n\n\nこれだけ見てもパイプ演算子を用いる利点はよくわかりませんが、パイプ演算子を用いることで、上記のメソッドチェーンのような機能をRに与えることができます。\n上のjavascriptでのメソッドチェーンと同じ演算をパイプ演算子を用いて行うと、以下のようになります。パイプ演算子を用いることで、「文字列からスペースを取り除き、大文字にする」という、文章と同じ順序でデータを処理することができます。このように順序が変わることで、一度にたくさんの演算を行っても、理解しやすいプログラムを書くことができます。\n\n\n\nパイプ演算子を用いて文字列を処理する\n\nfirstname &lt;- \" Rajat \"\nfirstname |&gt; str_trim() |&gt; str_to_upper() # スペースを取り除き、大文字にする\n## [1] \"RAJAT\"\n\n\n\n16.2.1 デフォルトとmagrittrパッケージのパイプ演算子\nでは、まず2種類のパイプ演算子について見ていきましょう。Rで先に実装されたのはmagrittrで、2014年にライブラリが公開されています。Rのデフォルトのパイプ演算子はずっと後になって、2021年にR version 4.1.0で実装されました。\nRstudioでは、パイプ演算子を「Ctrl+Shift+M」のショートカットで入力することができます。RStudioはRのデフォルトのパイプ演算子が実装される前から存在するため、デフォルトのパイプ演算子はmagrittrの「%&gt;%」になっています。デフォルトのパイプ演算子をRのデフォルトのもの（|&gt;）に変更する場合には、「Tools→Global Options」から「Code」を選択し、下の図1の赤線で囲った部分にチェックを入れます。\n\n\n\n図2：ショートカットで入力するパイプ演算子を変更する\n\n\n2種類のパイプ演算子は、記号が異なるだけでなく、使い方も少し異なっています。\n\n関数の後の()の必要性（|&gt;は必要、%&gt;%は不要）\n引数の位置を指定する文字の違い（|&gt;は「_」（アンダースコア）、%&gt;%は「.」（ピリオド））\n関数のreturnに使えるかどうか（|&gt;は使えず、%&gt;%は使える）\n\nまた、%&gt;%を用いるにはmagrittrパッケージ（tidyverseに含まれている）をロードする必要があるのに対し、|&gt;はライブラリのロードを必要としません。\n\n\n16.2.2 関数のカッコの有無\n|&gt;では関数名の後にカッコをつけるのが必須で、カッコが無いとエラーが出ます。\n\n\n\nデフォルトのパイプ演算子\n\npacman::p_load(tidyverse) # magrittrはtidyverseに含まれる\n\nfunc1 &lt;- function(x, y = 1){x + y} # xに1を足す関数\n\nfunc1(1) # 2が帰ってくる\n## [1] 2\n\n1 |&gt; func1() # |&gt;ではカッコが必須\n## [1] 2\n\n\n\n\n\nデフォルトのパイプ演算子はカッコ必須\n\n1 |&gt; func1 # カッコが無いとエラー\n## Error: The pipe operator requires a function call as RHS (&lt;text&gt;:1:6)\n\n\n%&gt;%では、カッコがあってもなくても計算をしてくれます。\n\n\n\nmagrittrのパイプ演算子はカッコを必須としない\n\n1 %&gt;% func1() # %&gt;%はカッコがあってもなくても計算できる\n## [1] 2\n\n1 %&gt;% func1\n## [1] 2\n\n\n|&gt;では、パイプ演算子の前の値を代入する位置をアンダースコア（_）で指定できます。%&gt;%では、ピリオド（.）で指定します。指定しない場合には、パイプ演算子の左辺の値が第一引数となります。\n\n\n\n引数の位置の指定\n\nfunc1(1, 2) # 引数を2個取り、足し算する関数\n## [1] 3\n\n1 |&gt; func1(y = 2) # 第一引数に1が入る（第2引数が2）\n## [1] 3\n\n2 |&gt; func1(x = 1, y = _) # 引数を入る位置を「_」で指定\n## [1] 3\n\n1 %&gt;% func1(y = 2) # 第一引数に1が入る\n## [1] 3\n\n2 %&gt;% func1(x = 1, y = .) # 引数を入る位置を「.」で指定\n## [1] 3\n\n\n|&gt;・%&gt;%のどちらでも、ピリオドやアンダースコアにインデックス・列名を付け加えることで、要素を呼び出すことができます。\n\n\n\nパイプ演算子での要素の呼び出し\n\n4:6 |&gt; _[2] # インデックスで呼び出せる\n## [1] 5\n\n4:6 %&gt;% .[2]\n## [1] 5\n\niris |&gt; _$Species |&gt; head() # 列名で呼び出せる\n## [1] setosa setosa setosa setosa setosa setosa\n## Levels: setosa versicolor virginica\n\niris %&gt;% .$Species %&gt;% head\n## [1] setosa setosa setosa setosa setosa setosa\n## Levels: setosa versicolor virginica\n\n\n|&gt;・%&gt;%共に、演算子の後に改行を入れることができます。パイプ演算子を用いるときには、以下のように、パイプ演算子ごとに改行を入れる書き方をするのが一般的です。\n\n\n\nパイプ演算子の後で改行\n\n\"Hello world\" |&gt; # 文字列の\n  str_replace(pattern = \"world\", replacement = \"R\") |&gt; # 一部を置き換え、\n  str_to_upper() # 大文字にする\n## [1] \"HELLO R\"",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>tidyr・dplyr</span>"
    ]
  },
  {
    "objectID": "chapter16.html#tidy-data",
    "href": "chapter16.html#tidy-data",
    "title": "16  tidyr・dplyr",
    "section": "16.3 tidy data",
    "text": "16.3 tidy data\ntidyr・dplyrの説明の前に、データフレームを取り扱う上で重要な概念である、「tidy data（整然としたデータ）」について簡単に説明します。\n「tidy data」はggplot2やtidyr、dplyrを開発しているPOSIT SoftwareのチーフサイエンティストであるHadley Wickhamが2014年に示したデータ構造についての考え方です(Wickham 2014)。データフレームのような表形式のデータを対象としたもので、「データの行は各観察結果、データの列は各列が一つの種類のデータであるように整理し、データの各要素には一つの値しか入力しない」というルールに従い、データは準備されるべきであるとしています。tidyr、dplyrはこの概念を念頭に設計されています。\n\ntidyではないデータは世の中にゴロゴロ転がっています。以下の表1はファイザーのCOVID-19ワクチン（コミナティ筋注）の第3相試験に関するNew England Journal of Medicineの論文の表1の一部を加工したものです(Polack et al. 2020)。\n\n論文の表は人が見やすいように作成されています。ですので、この表を見て、意味が全くわからない、ということはあまりないでしょう。しかし、この表はtidyではありません。\nまず、1つのセル（要素）に人数とその割合（%）の2つのデータが記載されています。また、投薬された治験薬（BNT162b2とPlacebo）は処置（Treatment）という同じカテゴリのデータですので、列名として2つに分けていることで、同じカテゴリのデータを2列に表示していることになっています。\n上の2行は性別に関するデータ、下の3行は人種に関するデータですので、2つの別のデータが同じ表に乗っています。したがって、この表は人にとってはわかりやすくても、tidyなデータではありません。\n上の表をtidyなデータにしたものが、以下の表2です。人数のデータ、割合のデータは各1列に、治験薬はTreatmentとして1列に表記しています。性別と人種ではデータのカテゴリが異なりますので、表を2つに分けています。Ratioはそのまま変換すると足し合わせて200%となるため、2で割って調整しています。\nこれが完全にtidyなデータであるかと言われるとやや難しいところもありますが、少なくとも上の表1よりはRで取り扱いしやすいデータとなっています。\n\nRでは、グラフ作成・統計共に、元の表より下のtidyなデータの方が取り扱いやすいです。多くのデータは人が見やすいように収集・準備されており、tidyではありません。R上でデータをtidyに加工・整形するためのツールが、tidyrとdplyrです。",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>tidyr・dplyr</span>"
    ]
  },
  {
    "objectID": "chapter16.html#tidyr",
    "href": "chapter16.html#tidyr",
    "title": "16  tidyr・dplyr",
    "section": "16.4 tidyr",
    "text": "16.4 tidyr\ntidyrはデータを縦持ち・横持ちに変換するためのライブラリです。この縦持ち・横持ちというのは、以下の図のように、縦長・横長のデータのことを指します。\n\n\n\n縦持ちと横持ちの図\n\n\n人が見る分には、横持ちのデータはわかりやすいと思います。しかし、Rで取り扱う場合には、圧倒的に縦持ちのデータの方が取り扱いが簡単です。ですので、人が作ったデータをRで取り扱うために縦持ちに変換する、Rで生成したデータを人が理解しやすいように横持ちに変換する時に、tidyrの関数を用いることになります。以下の表3にtidyrの関数の一覧を示します。\n\n\n\n表1：tidyrの関数群\n\n\n関数名\n適用する演算\n\n\n\n\npivot_longer\nデータフレームを縦持ちデータにする\n\n\ngather\nデータフレームを縦持ちデータにする（旧版）\n\n\npivot_wider\nデータフレームを横持ちデータにする\n\n\nspread\nデータフレームを横持ちデータにする（旧版）\n\n\ngroup_by\nデータを列でグループ化する\n\n\nnest\nデータをネストする\n\n\nunnest\nネストを解除する\n\n\ndrop_na\nNAを含む行を取り除く（na.omitと同じ）\n\n\nexpand\n各列の組み合わせを作成する\n\n\nfill\nNAに上の要素を埋める\n\n\nreplace_na\nNAに引数で指定した要素を埋める\n\n\n\n\n\n\n16.4.1 pivot_longerとpivot_wider\nデータフレームを縦持ちに変換する関数がpivot_longer関数、横持ちに変換する関数がpivot_wider関数です。共に第一引数がデータフレームで、パイプ演算子を用いて演算を行います。\npivot_longer関数もpivot_wider関数も、Rでのデータ解析ではとても重要となりますが、共に変換がやや複雑で、挙動がわかりにくい関数でもあります。下の例を参考に、どのようにデータが変換されるのか、よく理解した上で用いるのがよいでしょう。\n\n\n16.4.2 縦持ちへの変換：pivot_longer\npivot_longer関数はデータフレームと列番号を引数に取り、列番号で指定した列の名前をnameという列の要素に変換し、列番号で指定した列の要素をvalueという名前の列として、1列のデータに変換します。このような変換により、データは縦長の構造を取ります。\n変換後の列名は引数で指定でき、列の名前に関する列名は「names_to」、列の要素に関する列名は「values_to」引数に指定します。このpivot_longer関数は特に統計・グラフ作成の際によく用います。\ntidyrが開発されるまでは、reshape (Wickham 2007a)やreshape2 (Wickham 2007b)という関数で縦持ち変換を行うのが一般的でした。また、pivot_longer関数はtidyr開発初期にはgatherという名前で、引数の順番も少し異なっていました。今でもreshapeやreshape2、gatherを用いて縦持ちへの変換を行うことはできます。\n\n\n\npivot_longerで縦持ちデータに変換\n\nhead(iris)\n##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 1          5.1         3.5          1.4         0.2  setosa\n## 2          4.9         3.0          1.4         0.2  setosa\n## 3          4.7         3.2          1.3         0.2  setosa\n## 4          4.6         3.1          1.5         0.2  setosa\n## 5          5.0         3.6          1.4         0.2  setosa\n## 6          5.4         3.9          1.7         0.4  setosa\n\n# pivot_longer 縦持ちデータへの変換（返り値はtibble）\niris |&gt; pivot_longer(cols = 1:4) \n## # A tibble: 600 × 3\n##    Species name         value\n##    &lt;fct&gt;   &lt;chr&gt;        &lt;dbl&gt;\n##  1 setosa  Sepal.Length   5.1\n##  2 setosa  Sepal.Width    3.5\n##  3 setosa  Petal.Length   1.4\n##  4 setosa  Petal.Width    0.2\n##  5 setosa  Sepal.Length   4.9\n##  6 setosa  Sepal.Width    3  \n##  7 setosa  Petal.Length   1.4\n##  8 setosa  Petal.Width    0.2\n##  9 setosa  Sepal.Length   4.7\n## 10 setosa  Sepal.Width    3.2\n## # ℹ 590 more rows\n\n# 上と同じ（列名を設定）\niris |&gt; pivot_longer(cols = 1:4, names_to = \"category\", values_to = \"value\") \n## # A tibble: 600 × 3\n##    Species category     value\n##    &lt;fct&gt;   &lt;chr&gt;        &lt;dbl&gt;\n##  1 setosa  Sepal.Length   5.1\n##  2 setosa  Sepal.Width    3.5\n##  3 setosa  Petal.Length   1.4\n##  4 setosa  Petal.Width    0.2\n##  5 setosa  Sepal.Length   4.9\n##  6 setosa  Sepal.Width    3  \n##  7 setosa  Petal.Length   1.4\n##  8 setosa  Petal.Width    0.2\n##  9 setosa  Sepal.Length   4.7\n## 10 setosa  Sepal.Width    3.2\n## # ℹ 590 more rows\n\n# gather（返り値はデータフレーム）\niris |&gt; gather(category, value, 1:4) |&gt; head()\n##   Species     category value\n## 1  setosa Sepal.Length   5.1\n## 2  setosa Sepal.Length   4.9\n## 3  setosa Sepal.Length   4.7\n## 4  setosa Sepal.Length   4.6\n## 5  setosa Sepal.Length   5.0\n## 6  setosa Sepal.Length   5.4\n\n# 上と同じ\niris |&gt; gather(category, value, -Species) |&gt; head() \n##   Species     category value\n## 1  setosa Sepal.Length   5.1\n## 2  setosa Sepal.Length   4.9\n## 3  setosa Sepal.Length   4.7\n## 4  setosa Sepal.Length   4.6\n## 5  setosa Sepal.Length   5.0\n## 6  setosa Sepal.Length   5.4\n\n\n\n\n16.4.3 横持ちへの変換：pivot_wider\npivot_wider関数は、データを横持ちに変換する関数です。pivot_wider関数は列名となる列をnames_from引数に、要素となる列をvalues_from引数に指定します。指定しなかった列はそのまま維持されます。names_fromで指定した列の要素は各列名となり、values_fromで指定した列の要素がnames_fromで新しく作られた列の値となります。この変換により、データは横長の、幅の広い構造を取ることになります。\n横持ちへの変換もreshapeを用いて行うことができます。また、pivot_widerは以前はspreadという名前であったため、このspread関数を用いて横持ちデータへの変換を行うこともできます。\n\n\n\npivot_widerで横持ちデータに変換\n\n# pivot_wider 横持ちデータへの変換\nus_rent_income\n## # A tibble: 104 × 5\n##    GEOID NAME       variable estimate   moe\n##    &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;\n##  1 01    Alabama    income      24476   136\n##  2 01    Alabama    rent          747     3\n##  3 02    Alaska     income      32940   508\n##  4 02    Alaska     rent         1200    13\n##  5 04    Arizona    income      27517   148\n##  6 04    Arizona    rent          972     4\n##  7 05    Arkansas   income      23789   165\n##  8 05    Arkansas   rent          709     5\n##  9 06    California income      29454   109\n## 10 06    California rent         1358     3\n## # ℹ 94 more rows\n\nus_rent_income |&gt; pivot_wider(names_from = variable, values_from = c(estimate, moe)) \n## # A tibble: 52 × 6\n##    GEOID NAME                 estimate_income estimate_rent moe_income moe_rent\n##    &lt;chr&gt; &lt;chr&gt;                          &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n##  1 01    Alabama                        24476           747        136        3\n##  2 02    Alaska                         32940          1200        508       13\n##  3 04    Arizona                        27517           972        148        4\n##  4 05    Arkansas                       23789           709        165        5\n##  5 06    California                     29454          1358        109        3\n##  6 08    Colorado                       32401          1125        109        5\n##  7 09    Connecticut                    35326          1123        195        5\n##  8 10    Delaware                       31560          1076        247       10\n##  9 11    District of Columbia           43198          1424        681       17\n## 10 12    Florida                        25952          1077         70        3\n## # ℹ 42 more rows\n\n# spread（valueは1つしか値を取れない）\nus_rent_income |&gt; spread(variable, estimate)\n## # A tibble: 104 × 5\n##    GEOID NAME         moe income  rent\n##    &lt;chr&gt; &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n##  1 01    Alabama        3     NA   747\n##  2 01    Alabama      136  24476    NA\n##  3 02    Alaska        13     NA  1200\n##  4 02    Alaska       508  32940    NA\n##  5 04    Arizona        4     NA   972\n##  6 04    Arizona      148  27517    NA\n##  7 05    Arkansas       5     NA   709\n##  8 05    Arkansas     165  23789    NA\n##  9 06    California     3     NA  1358\n## 10 06    California   109  29454    NA\n## # ℹ 94 more rows\n\n\n\n\n16.4.4 tidyrのその他の関数\ntidyrには、pivot_longer、pivot_wider以外にも、データの全組み合わせを作成したり、データフレーム上のNAを置き換えるような関数が備わっています。pivot_longer/pivot_widerほどには使用頻度は高くありませんが、覚えておくと役に立つ場面もあるかもしれません。\n\n\n\nその他のtidyrの関数\n\nd &lt;- data.frame(x = c(1, 2, NA, 4), y = c(NA, \"b\", \"c\", \"d\"))\nd\n##    x    y\n## 1  1 &lt;NA&gt;\n## 2  2    b\n## 3 NA    c\n## 4  4    d\n# d |&gt; expand.grid()と同じく、総当たりのデータフレームを作成（tibbleが返ってくる）\nd |&gt; expand(x, y) \n## # A tibble: 16 × 2\n##        x y    \n##    &lt;dbl&gt; &lt;chr&gt;\n##  1     1 b    \n##  2     1 c    \n##  3     1 d    \n##  4     1 &lt;NA&gt; \n##  5     2 b    \n##  6     2 c    \n##  7     2 d    \n##  8     2 &lt;NA&gt; \n##  9     4 b    \n## 10     4 c    \n## 11     4 d    \n## 12     4 &lt;NA&gt; \n## 13    NA b    \n## 14    NA c    \n## 15    NA d    \n## 16    NA &lt;NA&gt;\n\nd |&gt; replace_na(list(x = 1, y = \"nodata\")) # NAの置き換え\n##   x      y\n## 1 1 nodata\n## 2 2      b\n## 3 1      c\n## 4 4      d\n\nd |&gt; fill(x, y) # 一つ上の値でNAを埋める（1番上はNAのまま）\n##   x    y\n## 1 1 &lt;NA&gt;\n## 2 2    b\n## 3 2    c\n## 4 4    d\n\n\nデータのグループ化（group_by）、ネスト（nest）については後ほど説明します。",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>tidyr・dplyr</span>"
    ]
  },
  {
    "objectID": "chapter16.html#dplyr",
    "href": "chapter16.html#dplyr",
    "title": "16  tidyr・dplyr",
    "section": "16.5 dplyr",
    "text": "16.5 dplyr\ntidyrによって縦持ちに変換したデータフレームを加工し、データの抽出・演算・集計等を行うためのライブラリが、dplyrです。dplyrの関数群も、基本的にパイプ演算子を用いて使用することが想定されています。dplyrと同様の加工ができる関数や方法はたくさんあるのですが、パイプ演算子で繋いだ演算の中で加工がすべて完了するのがdplyrの特徴になっています。\ndplyrには非常に沢山の関数が設定されていますが、特に使用頻度が高く、重要な関数は、filter、select、arrange、mutate、summariseの5つです。\n以下の表にdplyrの関数の一覧を示します。\n\n\n\n表2：dplyrの関数群\n\n\n関数名\n適用する演算\n\n\n\n\nfilter\n条件で行を選択する（subsetと類似）\n\n\nselect\n列を選択する\n\n\narrange\n列で並べ替える\n\n\ndesc\n並べ替えを降順にする\n\n\nmutate\n新しい列を追加する\n\n\ngroup_by\nデータを列でグループ化する\n\n\nrowwise\n行ごとに演算できるようにする\n\n\nsummarise\n列ごとに関数を適用する\n\n\ndistinct\n重複した行を削除\n\n\nslice\n一部の行を取り出す\n\n\nrename\n列名を変更する\n\n\ninner_join\nデータフレームを結合する（NAのある行を削除）\n\n\nfull_join\nデータフレームを結合する（すべての行を残す）\n\n\nleft_join\nデータフレームを左から結合する\n\n\nright_join\nデータフレームを右から結合する\n\n\ncase_when\nswitch文と類似した条件分岐\n\n\ncase_match\nswitch文と類似した条件分岐\n\n\nif_else\nifelse文の取り扱いを良くした関数\n\n\n\n\n\n\n16.5.1 filter関数\nfilter関数は、データフレームから条件に従い行を選択するための関数です。Rにはよく似たsubsetという関数がありますが、他のtidyverseの関数と共に用いる場合はfilter関数を用いたほうが良いでしょう。\nfilter関数はデータフレームを第一引数、条件式を第二引数に取る関数です。第二引数に指定した条件に合致した行のみを選択することができます。下の例では、Speciesの列の要素がsetosaである行を選択しています。\n\n\n\nfilter関数で行を選択\n\niris |&gt; tibble() |&gt; filter(Species == \"setosa\")\n## # A tibble: 50 × 5\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n##  1          5.1         3.5          1.4         0.2 setosa \n##  2          4.9         3            1.4         0.2 setosa \n##  3          4.7         3.2          1.3         0.2 setosa \n##  4          4.6         3.1          1.5         0.2 setosa \n##  5          5           3.6          1.4         0.2 setosa \n##  6          5.4         3.9          1.7         0.4 setosa \n##  7          4.6         3.4          1.4         0.3 setosa \n##  8          5           3.4          1.5         0.2 setosa \n##  9          4.4         2.9          1.4         0.2 setosa \n## 10          4.9         3.1          1.5         0.1 setosa \n## # ℹ 40 more rows\n\n\n\n\n16.5.2 select関数\nselect関数は、データフレームから列を選択するための関数です。select関数もデータフレームを第一引数にとり、それ以降に列名を引数に取ります。select関数を用いると、引数で指定した列のみを含むデータフレームが返ってきます。また、マイナスで列名を指定すると、その列を取り除いたデータフレームが返ってきます。\n\n\n\nselect関数で列を選択\n\niris |&gt; tibble() |&gt; select(Sepal.Length, Sepal.Width, Species)\n## # A tibble: 150 × 3\n##    Sepal.Length Sepal.Width Species\n##           &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n##  1          5.1         3.5 setosa \n##  2          4.9         3   setosa \n##  3          4.7         3.2 setosa \n##  4          4.6         3.1 setosa \n##  5          5           3.6 setosa \n##  6          5.4         3.9 setosa \n##  7          4.6         3.4 setosa \n##  8          5           3.4 setosa \n##  9          4.4         2.9 setosa \n## 10          4.9         3.1 setosa \n## # ℹ 140 more rows\n\niris |&gt; tibble() |&gt; select(-Sepal.Length, -Sepal.Width, -Species)\n## # A tibble: 150 × 2\n##    Petal.Length Petal.Width\n##           &lt;dbl&gt;       &lt;dbl&gt;\n##  1          1.4         0.2\n##  2          1.4         0.2\n##  3          1.3         0.2\n##  4          1.5         0.2\n##  5          1.4         0.2\n##  6          1.7         0.4\n##  7          1.4         0.3\n##  8          1.5         0.2\n##  9          1.4         0.2\n## 10          1.5         0.1\n## # ℹ 140 more rows\n\n\nselect関数では、列を選択するための関数を引数に取ることもできます。\n\n\n\n表3：selectに用いる列選択の関数\n\n\n\n\n\n\n関数名\n適用する演算\n\n\n\n\neverything()\nすべての列を選択する\n\n\nlast_col(n)\n後ろからn番目の列を選択する\n\n\ngroup_cols()\nグループ化に用いた列を選択する\n\n\nstarts_with(“文字列”)\n指定した文字列から始まる列名を選択する\n\n\nends_with(“文字列”)\n指定した文字列で終わる列名を選択する\n\n\ncontains(“文字列”)\n指定した文字列を含む列名を選択する\n\n\nmatches(“正規表現”)\n正規表現に従い列名を選択する\n\n\nnum_range(“文字列”, n:m)\n文字列で始まる列名のn～m番目を選択する\n\n\nall_of(“文字列”)\n列名を文字列で選択する（列名がないとエラー）\n\n\nany_of(“文字列”)\n列名を文字列で選択する\n\n\nwhere(関数)\n論理型を返す関数に従い選択する\n\n\n\n\n\n\n\n16.5.3 arrange関数\narrange関数は、データフレームを指定した列に従い、昇順（小さいものが上）に並べ替える関数です。order関数を用いてもデータフレームの並べ替えはできますが、arrange関数を用いるとより簡単に並べ替えを行うことができます。\narrange関数のヘルパーとして、desc関数が設定されています。desc関数はデータフレームを降順（大きいものが上）に並べ替える場合に用います。\n\n\n\narrange関数で並べ替え\n\niris |&gt; tibble() |&gt; arrange(Sepal.Length) # 昇順に並べ替え\n## # A tibble: 150 × 5\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n##  1          4.3         3            1.1         0.1 setosa \n##  2          4.4         2.9          1.4         0.2 setosa \n##  3          4.4         3            1.3         0.2 setosa \n##  4          4.4         3.2          1.3         0.2 setosa \n##  5          4.5         2.3          1.3         0.3 setosa \n##  6          4.6         3.1          1.5         0.2 setosa \n##  7          4.6         3.4          1.4         0.3 setosa \n##  8          4.6         3.6          1           0.2 setosa \n##  9          4.6         3.2          1.4         0.2 setosa \n## 10          4.7         3.2          1.3         0.2 setosa \n## # ℹ 140 more rows\n\niris |&gt; tibble() |&gt; arrange(desc(Sepal.Length)) # 降順に並べ替え\n## # A tibble: 150 × 5\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species  \n##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;    \n##  1          7.9         3.8          6.4         2   virginica\n##  2          7.7         3.8          6.7         2.2 virginica\n##  3          7.7         2.6          6.9         2.3 virginica\n##  4          7.7         2.8          6.7         2   virginica\n##  5          7.7         3            6.1         2.3 virginica\n##  6          7.6         3            6.6         2.1 virginica\n##  7          7.4         2.8          6.1         1.9 virginica\n##  8          7.3         2.9          6.3         1.8 virginica\n##  9          7.2         3.6          6.1         2.5 virginica\n## 10          7.2         3.2          6           1.8 virginica\n## # ℹ 140 more rows\n\n\n\n\n16.5.4 mutate関数\nmutate関数は、データフレームに新しい列を追加する関数です。mutateは第一引数にデータフレーム、第二引数に「新しい列の名前 = 値」という形で、追加したい列の名前と値を指定します。値の計算には、すでにデータフレームに存在する列名を用いることができます。したがって、「列のデータを加工・演算して新しい列を作る」場合にmutate関数を用いることになります。\nデータフレームの列のインデックスに値を代入しても同様の列の追加を行うことができますが、パイプ演算子の途中で代入を行うことはできません。mutate関数を用いれば、パイプ演算子中で列を追加し、以降の演算に用いることができます。\n\n\n\nmutate関数で列を追加\n\niris |&gt; tibble() |&gt; mutate(Sepal.ratio = Sepal.Length / Sepal.Width) # Sepal.ratioを列として追加\n## # A tibble: 150 × 6\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species Sepal.ratio\n##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;         &lt;dbl&gt;\n##  1          5.1         3.5          1.4         0.2 setosa         1.46\n##  2          4.9         3            1.4         0.2 setosa         1.63\n##  3          4.7         3.2          1.3         0.2 setosa         1.47\n##  4          4.6         3.1          1.5         0.2 setosa         1.48\n##  5          5           3.6          1.4         0.2 setosa         1.39\n##  6          5.4         3.9          1.7         0.4 setosa         1.38\n##  7          4.6         3.4          1.4         0.3 setosa         1.35\n##  8          5           3.4          1.5         0.2 setosa         1.47\n##  9          4.4         2.9          1.4         0.2 setosa         1.52\n## 10          4.9         3.1          1.5         0.1 setosa         1.58\n## # ℹ 140 more rows\n\n\n\n\n16.5.5 summarise関数\nsummarise関数（summarizeでも可）は、データフレームの列に演算を適用し、結果をデータフレームとして返す関数です。summarise関数も第一引数にはデータフレームを取り、以降の引数に「計算結果の列名 = 演算」という形で、適用したい演算を記載します。下の例では、Sepal.Lengthの平均値と標準偏差を返しています。\n\n\n\nsummarise関数で列を要約\n\niris |&gt; summarise(m = mean(Sepal.Length), s=sd(Sepal.Length))\n##          m         s\n## 1 5.843333 0.8280661\n\n\nこれだけではapply関数より不便ですし、意味が無いように見えます。summarise関数が本領を発揮するのは、group_by関数により、データをグループ化した後になります。\n\n\n16.5.6 group_by関数\ngroup_by関数は、文字列か因子の列に従い、データフレームの行をグループ化するための関数です。\ntidyr・dplyrでデータフレームを取り扱うと、データフレームは自動的にtibbleに変換されます。group_by関数でデータフレームをグループ化すると、tibbleにgroupというものが追加され、クラスに「grouped_df」というものが追加されます。group_by関数の機能はこれだけです。\nグループ化したtibbleは、ungroup関数でグループ解除できます。\n\n\n\ngroup_by関数でグループ化\n\niris |&gt; group_by(Species) # tibbleの左上にGroups: Species[3]と表示される\n## # A tibble: 150 × 5\n## # Groups:   Species [3]\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n##  1          5.1         3.5          1.4         0.2 setosa \n##  2          4.9         3            1.4         0.2 setosa \n##  3          4.7         3.2          1.3         0.2 setosa \n##  4          4.6         3.1          1.5         0.2 setosa \n##  5          5           3.6          1.4         0.2 setosa \n##  6          5.4         3.9          1.7         0.4 setosa \n##  7          4.6         3.4          1.4         0.3 setosa \n##  8          5           3.4          1.5         0.2 setosa \n##  9          4.4         2.9          1.4         0.2 setosa \n## 10          4.9         3.1          1.5         0.1 setosa \n## # ℹ 140 more rows\n\niris |&gt; group_by(Species) |&gt; class() # クラスにgrouped_dfが追加\n## [1] \"grouped_df\" \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nd &lt;- iris |&gt; group_by(Species)\nungroup(d) # グループの解除\n## # A tibble: 150 × 5\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n##  1          5.1         3.5          1.4         0.2 setosa \n##  2          4.9         3            1.4         0.2 setosa \n##  3          4.7         3.2          1.3         0.2 setosa \n##  4          4.6         3.1          1.5         0.2 setosa \n##  5          5           3.6          1.4         0.2 setosa \n##  6          5.4         3.9          1.7         0.4 setosa \n##  7          4.6         3.4          1.4         0.3 setosa \n##  8          5           3.4          1.5         0.2 setosa \n##  9          4.4         2.9          1.4         0.2 setosa \n## 10          4.9         3.1          1.5         0.1 setosa \n## # ℹ 140 more rows\n\n\n\n\n16.5.7 group_by関数とsummarise関数を同時に用いる\n上記のように、summarise関数もgroup_by関数も、どちらも単独ではいまいちよく分からない関数ですが、組み合わせて使用することで、15章で解説したaggregate関数と同じように、カテゴリごとの集計計算を行うことができます。\nまずはデータフレームをgroup_by関数でグループ化します。このグループ化したデータフレームにsummarise関数で計算を適用すると、計算をグループごとに実行してくれます。下の例では、Speciesでグループ化した後に、Sepal.Lengthの平均をsummarise関数で計算しています。結果として、SpeciesごとにSepal.Lengthの平均値を計算したデータフレームが返ってきます。グループ化した場合は、グループ化に用いた列を結果のデータフレームに残してくれます。\nこのgroup_byとsummariseを用いると、カテゴリごとに平均値や標準偏差などを求め、その結果をデータフレームとしたものを返り値として得ることができます。\nsummariseには.byという引数を指定することができ、この.byにグループ化するための列を設定することもできます。ただし、dplyrでは、group_byで明示的にグループ化した後にsummariseを用いることを推奨しているようです。\ntidyrのpivot_longer関数と組み合わせて用いれば、複数列の要約データを一度に計算することもできます。\n\n\n\ngroup_byとsummariseでデータを要約する\n\niris |&gt; group_by(Species) |&gt; summarise(m = mean(Sepal.Length))\n## # A tibble: 3 × 2\n##   Species        m\n##   &lt;fct&gt;      &lt;dbl&gt;\n## 1 setosa      5.01\n## 2 versicolor  5.94\n## 3 virginica   6.59\n\niris |&gt; summarise(m = mean(Sepal.Length), .by = Species) # 上と同じ\n##      Species     m\n## 1     setosa 5.006\n## 2 versicolor 5.936\n## 3  virginica 6.588\n\n# 複数列の結果に対して、一度に平均値と標準偏差を求める\niris |&gt; \n  pivot_longer(1:4) |&gt; \n  group_by(Species, name) |&gt; \n  summarise(m=mean(value), s=sd(value))\n## `summarise()` has grouped output by 'Species'. You can override using the\n## `.groups` argument.\n## # A tibble: 12 × 4\n## # Groups:   Species [3]\n##    Species    name             m     s\n##    &lt;fct&gt;      &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n##  1 setosa     Petal.Length 1.46  0.174\n##  2 setosa     Petal.Width  0.246 0.105\n##  3 setosa     Sepal.Length 5.01  0.352\n##  4 setosa     Sepal.Width  3.43  0.379\n##  5 versicolor Petal.Length 4.26  0.470\n##  6 versicolor Petal.Width  1.33  0.198\n##  7 versicolor Sepal.Length 5.94  0.516\n##  8 versicolor Sepal.Width  2.77  0.314\n##  9 virginica  Petal.Length 5.55  0.552\n## 10 virginica  Petal.Width  2.03  0.275\n## 11 virginica  Sepal.Length 6.59  0.636\n## 12 virginica  Sepal.Width  2.97  0.322\n\n\n\n\n16.5.8 rowwise関数\nrowwise関数は、mutateやsummariseでの演算を行方向に変更してくれる関数で、apply関数をMARGIN = 1と設定した場合とよく似た計算を行うことができる関数です。group_by関数の行方向版と言えるかもしれません。rowwise関数をデータフレームに適用すると、tibbleに「Rowwise:」の印がつき、クラスに「rowwise_df」が追加されます。rowwise関数もgroup_by関数と同じく、ungroup関数で解除することができます。\nrowwise関数を用いることで、例えばminやmaxのような関数を、列方向ではなく行方向に対して適用することができます。\n\n\n\nrowwise関数で行方向に演算\n\niris |&gt; rowwise() # Rowwiseのラベルが付く\n## # A tibble: 150 × 5\n## # Rowwise: \n##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n##  1          5.1         3.5          1.4         0.2 setosa \n##  2          4.9         3            1.4         0.2 setosa \n##  3          4.7         3.2          1.3         0.2 setosa \n##  4          4.6         3.1          1.5         0.2 setosa \n##  5          5           3.6          1.4         0.2 setosa \n##  6          5.4         3.9          1.7         0.4 setosa \n##  7          4.6         3.4          1.4         0.3 setosa \n##  8          5           3.4          1.5         0.2 setosa \n##  9          4.4         2.9          1.4         0.2 setosa \n## 10          4.9         3.1          1.5         0.1 setosa \n## # ℹ 140 more rows\n\niris |&gt; rowwise() |&gt; ungroup() # ungroupでRowwiseが消える\n## # A tibble: 150 × 5\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n##  1          5.1         3.5          1.4         0.2 setosa \n##  2          4.9         3            1.4         0.2 setosa \n##  3          4.7         3.2          1.3         0.2 setosa \n##  4          4.6         3.1          1.5         0.2 setosa \n##  5          5           3.6          1.4         0.2 setosa \n##  6          5.4         3.9          1.7         0.4 setosa \n##  7          4.6         3.4          1.4         0.3 setosa \n##  8          5           3.4          1.5         0.2 setosa \n##  9          4.4         2.9          1.4         0.2 setosa \n## 10          4.9         3.1          1.5         0.1 setosa \n## # ℹ 140 more rows\n\niris |&gt; rowwise() |&gt; mutate(minr = min(c(Sepal.Length, Sepal.Width))) # 横（行）方向への演算\n## # A tibble: 150 × 6\n## # Rowwise: \n##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species  minr\n##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;   &lt;dbl&gt;\n##  1          5.1         3.5          1.4         0.2 setosa    3.5\n##  2          4.9         3            1.4         0.2 setosa    3  \n##  3          4.7         3.2          1.3         0.2 setosa    3.2\n##  4          4.6         3.1          1.5         0.2 setosa    3.1\n##  5          5           3.6          1.4         0.2 setosa    3.6\n##  6          5.4         3.9          1.7         0.4 setosa    3.9\n##  7          4.6         3.4          1.4         0.3 setosa    3.4\n##  8          5           3.4          1.5         0.2 setosa    3.4\n##  9          4.4         2.9          1.4         0.2 setosa    2.9\n## 10          4.9         3.1          1.5         0.1 setosa    3.1\n## # ℹ 140 more rows\n\niris |&gt; tibble() |&gt; mutate(minr = min(c(Sepal.Length, Sepal.Width))) # 縦の最小値が出てくる\n## # A tibble: 150 × 6\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species  minr\n##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;   &lt;dbl&gt;\n##  1          5.1         3.5          1.4         0.2 setosa      2\n##  2          4.9         3            1.4         0.2 setosa      2\n##  3          4.7         3.2          1.3         0.2 setosa      2\n##  4          4.6         3.1          1.5         0.2 setosa      2\n##  5          5           3.6          1.4         0.2 setosa      2\n##  6          5.4         3.9          1.7         0.4 setosa      2\n##  7          4.6         3.4          1.4         0.3 setosa      2\n##  8          5           3.4          1.5         0.2 setosa      2\n##  9          4.4         2.9          1.4         0.2 setosa      2\n## 10          4.9         3.1          1.5         0.1 setosa      2\n## # ℹ 140 more rows\n\n\n\n\n16.5.9 データフレームの結合\n2つのデータフレームを横に結合する時に用いる関数が、_join関数です。_join関数には複数の種類があり、それぞれ結合の仕方が少しずつ異なります。\n結合する際には、基本的には以下のルールに従います。\n\n列名が同じ要素があれば、1つの列とする\n列名が異なる要素は、新しく付け加える\n行（レコード）に列の要素がなければ、NAで埋める\n\n結合する際に、NAの要素を含む行を取り除くのがinner_join関数、NAの要素を含む行を全て残すのがfull_join関数です。\nleft_join関数とright_join関数は引数の順番により残す行が変わる関数で、left_join関数はパイプ演算子の左のデータフレームの行は全て残し、付け加えたデータフレームの行のうちNAを含むものを取り除く関数です。right_join関数は逆に、付け加えたデータフレームの行をすべて残し、パイプ演算子の左のデータフレームの行のうちNAを含むものを削除します。\nこの他に、2つのデータフレームの要素のすべての組み合わせにデータフレームを作成するcross_join、列を指定して両方のデータフレームにその列の要素があるものを残すsemi_join、逆に片方にのみ存在する要素を残すanti_join、後に説明するnestされたデータフレームを作成するnest_joinなどがあります。\n\n\n\njoin関数でデータフレームを結合する\n\nband_members\n## # A tibble: 3 × 2\n##   name  band   \n##   &lt;chr&gt; &lt;chr&gt;  \n## 1 Mick  Stones \n## 2 John  Beatles\n## 3 Paul  Beatles\n\nband_instruments\n## # A tibble: 3 × 2\n##   name  plays \n##   &lt;chr&gt; &lt;chr&gt; \n## 1 John  guitar\n## 2 Paul  bass  \n## 3 Keith guitar\n\nband_members |&gt; inner_join(band_instruments) # NAのデータがあると取り除かれる\n## Joining with `by = join_by(name)`\n## # A tibble: 2 × 3\n##   name  band    plays \n##   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n## 1 John  Beatles guitar\n## 2 Paul  Beatles bass\n\nband_members |&gt; full_join(band_instruments) # すべてのレコードを残す\n## Joining with `by = join_by(name)`\n## # A tibble: 4 × 3\n##   name  band    plays \n##   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n## 1 Mick  Stones  &lt;NA&gt;  \n## 2 John  Beatles guitar\n## 3 Paul  Beatles bass  \n## 4 Keith &lt;NA&gt;    guitar\n\nband_members |&gt; left_join(band_instruments) # 左の要素を元に、右の要素を付け加える\n## Joining with `by = join_by(name)`\n## # A tibble: 3 × 3\n##   name  band    plays \n##   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n## 1 Mick  Stones  &lt;NA&gt;  \n## 2 John  Beatles guitar\n## 3 Paul  Beatles bass\n\nband_members |&gt; right_join(band_instruments) # 右の要素を元に、左の要素を付け加える\n## Joining with `by = join_by(name)`\n## # A tibble: 3 × 3\n##   name  band    plays \n##   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n## 1 John  Beatles guitar\n## 2 Paul  Beatles bass  \n## 3 Keith &lt;NA&gt;    guitar\n\n\n\n\n16.5.10 その他のdplyrの関数\ndplyrにはfilter、select、arrange、mutate、summarise以外にも、たくさんの関数が登録されています。slice関数は行を一部分選択する関数です。slice関数以外にも、「slice_」という名前を持つ複数の関数がdplyrには登録されています。\n\n\n\nslice関数\n\niris |&gt; slice(5:10)\n##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 1          5.0         3.6          1.4         0.2  setosa\n## 2          5.4         3.9          1.7         0.4  setosa\n## 3          4.6         3.4          1.4         0.3  setosa\n## 4          5.0         3.4          1.5         0.2  setosa\n## 5          4.4         2.9          1.4         0.2  setosa\n## 6          4.9         3.1          1.5         0.1  setosa\n\niris |&gt; _[5:10, ] # 上と同じ\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 5           5.0         3.6          1.4         0.2  setosa\n## 6           5.4         3.9          1.7         0.4  setosa\n## 7           4.6         3.4          1.4         0.3  setosa\n## 8           5.0         3.4          1.5         0.2  setosa\n## 9           4.4         2.9          1.4         0.2  setosa\n## 10          4.9         3.1          1.5         0.1  setosa\n\niris %&gt;% .[5:10, ] # 上と同じ\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 5           5.0         3.6          1.4         0.2  setosa\n## 6           5.4         3.9          1.7         0.4  setosa\n## 7           4.6         3.4          1.4         0.3  setosa\n## 8           5.0         3.4          1.5         0.2  setosa\n## 9           4.4         2.9          1.4         0.2  setosa\n## 10          4.9         3.1          1.5         0.1  setosa\n\niris |&gt; slice_head(n = 5) # head(iris, 5)と同じ\n##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 1          5.1         3.5          1.4         0.2  setosa\n## 2          4.9         3.0          1.4         0.2  setosa\n## 3          4.7         3.2          1.3         0.2  setosa\n## 4          4.6         3.1          1.5         0.2  setosa\n## 5          5.0         3.6          1.4         0.2  setosa\n\niris |&gt; slice_tail(n = 5) # tail(iris, 5)と同じ\n##   Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n## 1          6.7         3.0          5.2         2.3 virginica\n## 2          6.3         2.5          5.0         1.9 virginica\n## 3          6.5         3.0          5.2         2.0 virginica\n## 4          6.2         3.4          5.4         2.3 virginica\n## 5          5.9         3.0          5.1         1.8 virginica\n\niris |&gt; slice_min(Sepal.Length, n = 5) # Sepal.Lengthが小さいものから5行\n##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 1          4.3         3.0          1.1         0.1  setosa\n## 2          4.4         2.9          1.4         0.2  setosa\n## 3          4.4         3.0          1.3         0.2  setosa\n## 4          4.4         3.2          1.3         0.2  setosa\n## 5          4.5         2.3          1.3         0.3  setosa\n\niris |&gt; slice_max(Sepal.Length, n = 5) # Sepal.Lengthが大きいものから5行\n##   Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n## 1          7.9         3.8          6.4         2.0 virginica\n## 2          7.7         3.8          6.7         2.2 virginica\n## 3          7.7         2.6          6.9         2.3 virginica\n## 4          7.7         2.8          6.7         2.0 virginica\n## 5          7.7         3.0          6.1         2.3 virginica\n \niris |&gt; slice_sample(n = 5) # ランダムに5行抽出\n##   Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n## 1          6.1         3.0          4.9         1.8  virginica\n## 2          6.2         2.2          4.5         1.5 versicolor\n## 3          6.4         2.8          5.6         2.1  virginica\n## 4          6.7         3.0          5.0         1.7 versicolor\n## 5          5.1         3.5          1.4         0.2     setosa\n\n\nglimpse関数はstr関数とよく似た機能を持ち、データフレームの構造を表示してくれます。pull関数は列をベクターとして返す関数です。relocate関数は列の順番を並べ替えて返してくれます。rename関数は列名を付け直す関数です。count関数とtally関数はそれぞれ要素の数と行数を返す関数です。\nrelocate関数やrename関数はパイプ演算子に特化した関数で、用いることでパイプ演算の途中で列の順番や名前を変えることができます。\n\n\n\nその他のdplyrの関数\n\niris |&gt; tibble() |&gt; glimpse()\n## Rows: 150\n## Columns: 5\n## $ Sepal.Length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n## $ Sepal.Width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n## $ Petal.Length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n## $ Petal.Width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n## $ Species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…\n\niris |&gt; head() |&gt; tibble() |&gt; pull(Species) # iris$Speciesと同じ\n## [1] setosa setosa setosa setosa setosa setosa\n## Levels: setosa versicolor virginica\n\n# 列の並べ替え\niris |&gt; tibble() |&gt; relocate(Species, Petal.Width, Petal.Length, Sepal.Width, Sepal.Length)\n## # A tibble: 150 × 5\n##    Species Petal.Width Petal.Length Sepal.Width Sepal.Length\n##    &lt;fct&gt;         &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;\n##  1 setosa          0.2          1.4         3.5          5.1\n##  2 setosa          0.2          1.4         3            4.9\n##  3 setosa          0.2          1.3         3.2          4.7\n##  4 setosa          0.2          1.5         3.1          4.6\n##  5 setosa          0.2          1.4         3.6          5  \n##  6 setosa          0.4          1.7         3.9          5.4\n##  7 setosa          0.3          1.4         3.4          4.6\n##  8 setosa          0.2          1.5         3.4          5  \n##  9 setosa          0.2          1.4         2.9          4.4\n## 10 setosa          0.1          1.5         3.1          4.9\n## # ℹ 140 more rows\n\niris |&gt; tibble() |&gt; rename(S = Species) # 列名SpeciesをSに変更\n## # A tibble: 150 × 5\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width S     \n##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt; \n##  1          5.1         3.5          1.4         0.2 setosa\n##  2          4.9         3            1.4         0.2 setosa\n##  3          4.7         3.2          1.3         0.2 setosa\n##  4          4.6         3.1          1.5         0.2 setosa\n##  5          5           3.6          1.4         0.2 setosa\n##  6          5.4         3.9          1.7         0.4 setosa\n##  7          4.6         3.4          1.4         0.3 setosa\n##  8          5           3.4          1.5         0.2 setosa\n##  9          4.4         2.9          1.4         0.2 setosa\n## 10          4.9         3.1          1.5         0.1 setosa\n## # ℹ 140 more rows\n\n\niris |&gt; count(Species) # 因子や文字列の数を数える関数\n##      Species  n\n## 1     setosa 50\n## 2 versicolor 50\n## 3  virginica 50\n\niris |&gt; tally() # 行数を数える関数\n##     n\n## 1 150\n\niris |&gt; group_by(Species) |&gt; tally() # グループごとに行数を数える関数\n## # A tibble: 3 × 2\n##   Species        n\n##   &lt;fct&gt;      &lt;int&gt;\n## 1 setosa        50\n## 2 versicolor    50\n## 3 virginica     50",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>tidyr・dplyr</span>"
    ]
  },
  {
    "objectID": "chapter16.html#tibble",
    "href": "chapter16.html#tibble",
    "title": "16  tidyr・dplyr",
    "section": "16.6 tibble",
    "text": "16.6 tibble\nデータのI/Oの章で説明した通り、tidyverseで取り扱う関数は、データフレームをtibbleというクラスに変換して返り値を返します。tibbleには以下の特徴があります。\n\n表示の際に、データフレームの列・行数、各列のデータ型を表示し、上から10行だけ示す\nクラスにdata.frame、tbl_df、tblを設定する\ngroup_byやrowwiseにより、グループ化ができる（グループ化したクラスが付け加わる）\nネスト（nest）したデータを取り扱える\n\ntibbleはデータフレームの作成と同じように、tibble関数を用いて作成できます。また、as_tibble関数を用いることで、データフレームをtibbleに変換することができます。\n\n\n\ntibble\n\npacman::p_load(tidyverse)\nd &lt;- tibble(x = 1:3, y = c(\"a\", \"b\", \"c\"), z = c(T, F, T)) # tibbleを作成\nd\n## # A tibble: 3 × 3\n##       x y     z    \n##   &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;\n## 1     1 a     TRUE \n## 2     2 b     FALSE\n## 3     3 c     TRUE\n\nclass(d) # クラスはtbl_df、tbl、data.frame\n## [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nas_tibble(iris) # データフレームをtibbleに変換\n## # A tibble: 150 × 5\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n##  1          5.1         3.5          1.4         0.2 setosa \n##  2          4.9         3            1.4         0.2 setosa \n##  3          4.7         3.2          1.3         0.2 setosa \n##  4          4.6         3.1          1.5         0.2 setosa \n##  5          5           3.6          1.4         0.2 setosa \n##  6          5.4         3.9          1.7         0.4 setosa \n##  7          4.6         3.4          1.4         0.3 setosa \n##  8          5           3.4          1.5         0.2 setosa \n##  9          4.4         2.9          1.4         0.2 setosa \n## 10          4.9         3.1          1.5         0.1 setosa \n## # ℹ 140 more rows\n\n\ndata.frame関数でデータフレームを作成する場合、列の要素が他の列より短い場合、recycling（繰り返して採用）されてデータフレームが作成されます。tibbleでは、列の要素が1つだけのときのみrecyclingされ、2つ以上であればエラーとなります。不自然なrecyclingは抑制される仕組みになっています。\n\n\n\ntibbleでのrecycling\n\n# サイズが2個以上だとrecycleしない。data.frame関数はrecyclingする\nd &lt;- tibble(x = rep(1:3, 5), y = rep(c(\"a\", \"b\", \"c\"), rep(5, 3)), z = c(T, F, T)) \n## Error in `tibble()`:\n## ! Tibble columns must have compatible sizes.\n## • Size 15: Existing data.\n## • Size 3: Column `z`.\n## ℹ Only values of size one are recycled.",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>tidyr・dplyr</span>"
    ]
  },
  {
    "objectID": "chapter16.html#ネストnestしたデータ",
    "href": "chapter16.html#ネストnestしたデータ",
    "title": "16  tidyr・dplyr",
    "section": "16.7 ネスト（nest）したデータ",
    "text": "16.7 ネスト（nest）したデータ\ntibbleは、複数のデータを含むものを列の要素とする（nest、ネストする）ことができます。要は、データフレームやリスト、統計結果のオブジェクトなどを、1つのセルに登録できるということです。「ネストしてしまうとtidyじゃないのでは？」と思わなくは無いのですが、データフレームをコンパクトにして見やすくすることはできます。\nこの、「複数のデータを含むもの」を作成する場合には、nest関数を用います。グループ化したtibbleにnest関数を適用すると、グループごとのデータフレームを1つのセルに詰め込むことができます。nestしたデータを元に戻すときには、unnest関数を用います。\n\n\n\nnest関数でネストする\n\niris |&gt; group_by(Species) # データのグループ化（tibbleに変換される）\n## # A tibble: 150 × 5\n## # Groups:   Species [3]\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n##  1          5.1         3.5          1.4         0.2 setosa \n##  2          4.9         3            1.4         0.2 setosa \n##  3          4.7         3.2          1.3         0.2 setosa \n##  4          4.6         3.1          1.5         0.2 setosa \n##  5          5           3.6          1.4         0.2 setosa \n##  6          5.4         3.9          1.7         0.4 setosa \n##  7          4.6         3.4          1.4         0.3 setosa \n##  8          5           3.4          1.5         0.2 setosa \n##  9          4.4         2.9          1.4         0.2 setosa \n## 10          4.9         3.1          1.5         0.1 setosa \n## # ℹ 140 more rows\n\niris_nested &lt;- iris |&gt; as_tibble() |&gt; group_by(Species) |&gt; nest() # ネストしたデータ\n\niris_nested\n## # A tibble: 3 × 2\n## # Groups:   Species [3]\n##   Species    data             \n##   &lt;fct&gt;      &lt;list&gt;           \n## 1 setosa     &lt;tibble [50 × 4]&gt;\n## 2 versicolor &lt;tibble [50 × 4]&gt;\n## 3 virginica  &lt;tibble [50 × 4]&gt;\n\niris_nested[1, 2] |&gt; unnest() # ネストを解除\n## Warning: `cols` is now required when using `unnest()`.\n## ℹ Please use `cols = c(data)`.\n## # A tibble: 50 × 4\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width\n##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n##  1          5.1         3.5          1.4         0.2\n##  2          4.9         3            1.4         0.2\n##  3          4.7         3.2          1.3         0.2\n##  4          4.6         3.1          1.5         0.2\n##  5          5           3.6          1.4         0.2\n##  6          5.4         3.9          1.7         0.4\n##  7          4.6         3.4          1.4         0.3\n##  8          5           3.4          1.5         0.2\n##  9          4.4         2.9          1.4         0.2\n## 10          4.9         3.1          1.5         0.1\n## # ℹ 40 more rows\n\n\nこれだけではnestする意味があまりわかりませんが、このnestと共に、リストに関数を適用するためのライブラリである、purrrパッケージ (Wickham and Henry 2023)を用いると、統計計算の効率を高めることができます。purrrパッケージのmap関数は、リスト（データフレームはリスト）の要素に対して、関数を適用する関数です。これだけだとapply関数群で説明したlapply・sapply関数と同じなのですが、map関数はパイプ演算子の中で、mutate関数の引数として用いることができます。\nグループ化したtibbleに対してmutate関数内でネストした要素に対してmap関数を用いると、統計結果をネストしたtibbleが返ってきます。\n下の例では、irisを種別にあらかじめグループ化・ネストしておき、irisのSepal.LengthとSepal.Widthについて線形回帰を行った結果を、mutate関数でtibbleに追加しています。このような計算を行うと、追加された列には&lt;lm&gt;という要素が登録されます。&lt;lm&gt;は線形回帰の結果のオブジェクトですので、グループごと、つまり種ごとにSepal.LengthとSepal.Widthの線形回帰を行った結果が記録され、保存されていることを示しています。このような形でプログラムを書くことで、3回線形回帰を繰り返すことなく、1行のパイプ演算子の演算により3回の線形回帰結果を得ることができます。\n\n\n\npurrr::mapでネストしたデータを統計解析する\n\niris |&gt; group_by(Species) |&gt; nest() # nestするとdataの行が追加される\n## # A tibble: 3 × 2\n## # Groups:   Species [3]\n##   Species    data             \n##   &lt;fct&gt;      &lt;list&gt;           \n## 1 setosa     &lt;tibble [50 × 4]&gt;\n## 2 versicolor &lt;tibble [50 × 4]&gt;\n## 3 virginica  &lt;tibble [50 × 4]&gt;\n\n# tibbleは統計結果もnestできる\n(d &lt;- \n    iris |&gt; \n    group_by(Species) |&gt; \n    nest() |&gt; \n    mutate(lmcalc = map(data, ~lm(Sepal.Length ~ Sepal.Width, data = .))))\n## # A tibble: 3 × 3\n## # Groups:   Species [3]\n##   Species    data              lmcalc\n##   &lt;fct&gt;      &lt;list&gt;            &lt;list&gt;\n## 1 setosa     &lt;tibble [50 × 4]&gt; &lt;lm&gt;  \n## 2 versicolor &lt;tibble [50 × 4]&gt; &lt;lm&gt;  \n## 3 virginica  &lt;tibble [50 × 4]&gt; &lt;lm&gt;\n\nd$lmcalc[1] # 線形回帰の結果\n## [[1]]\n## \n## Call:\n## lm(formula = Sepal.Length ~ Sepal.Width, data = .)\n## \n## Coefficients:\n## (Intercept)  Sepal.Width  \n##      2.6390       0.6905",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>tidyr・dplyr</span>"
    ]
  },
  {
    "objectID": "chapter16.html#dplyrの条件分岐",
    "href": "chapter16.html#dplyrの条件分岐",
    "title": "16  tidyr・dplyr",
    "section": "16.8 dplyrの条件分岐",
    "text": "16.8 dplyrの条件分岐\n\n16.8.1 if_else関数\ndplyrには、データフレームを取り扱う関数の他に、条件分岐に関する機能を提供しています。\nifelse関数はデフォルトのRで利用できる関数ですが、dplyrには、if_else関数という、ほとんど同じ機能を持つ関数が設定されています。ifelseとif_elseの違いは、\n\n条件式にNAが含まれた時にmissing引数に設定した値を返す\n返り値のデータ型を維持する\nTRUEとFALSEの返り値の型が違うとエラー\n\nの3点です。通常のifelse関数では型変換等のトラブルが起こりやすいため、なるべくif_else関数を利用したほうがよいでしょう。\n\n\n\nif_else関数\n\nv &lt;- c(1, 2, NA, 3)\nifelse(v &gt; 2, \"large\", \"small\")\n## [1] \"small\" \"small\" NA      \"large\"\n\nif_else(v &gt; 2, \"large\", \"small\") # ifelseと同じ\n## [1] \"small\" \"small\" NA      \"large\"\n\nif_else(v &gt; 2, \"large\", \"small\", missing = \"missing\") # NAだと\"missing\"が返ってくる\n## [1] \"small\"   \"small\"   \"missing\" \"large\"\n\n\nifelse(TRUE, as.Date(\"2023-10-10\"), as.Date(\"2023-10-11\")) # 数値が返ってくる\n## [1] 19640\n\nifelse(TRUE, as.Date(\"2023-10-10\"), FALSE) # 型が違っても数値が返ってくる\n## [1] 19640\n\nif_else(TRUE, as.Date(\"2023-10-10\"), as.Date(\"2023-10-11\")) # 日時が返ってくる\n## [1] \"2023-10-10\"\n\nif_else(TRUE, as.Date(\"2023-10-10\"), FALSE) # 型が違うとエラーが返ってくる\n## Error in `if_else()`:\n## ! Can't combine `true` &lt;date&gt; and `false` &lt;logical&gt;.\n\n\n\n\n16.8.2 case_matchとcase_when\ndplyrには、条件分岐を取り扱う文（関数）として、case_matchとcase_whenが設定されています。どちらもチルダ（~）を返り値の設定に用いるもので、else if文やswitch文を用いなくても、比較的簡単に3つ以上の条件分岐を行うことができます。\ncase_matchは第一引数にベクター、それ以降に「評価する値 ~ 返り値」という形で引数を取り、ベクターの要素が「評価する値」と一致する場合に、対応する返り値を返す関数です。「評価する値」はベクターで設定することもできます。\n\n\n\ncase_matchで条件分岐\n\nc(1, 2, 1, 2) |&gt; \n  case_match( # ベクターの要素が1ならone、2ならtwoを返す\n    1 ~ \"one\",\n    2 ~ \"two\"\n  )\n## [1] \"one\" \"two\" \"one\" \"two\"\n\n1:10 |&gt; \n  case_match( # 「評価する値」はベクターでも設定できる\n    c(1, 3, 5, 7, 9) ~ \"odd\",\n    c(2, 4, 6, 8, 10) ~ \"even\"\n  )\n##  [1] \"odd\"  \"even\" \"odd\"  \"even\" \"odd\"  \"even\" \"odd\"  \"even\" \"odd\"  \"even\"\n\n\ncase_whenは、引数に「条件式 ~ 返り値」を取り、条件式がTRUEのときに対応する返り値を返します。case_match、case_whenのいずれもパイプ演算子中で他のdplyrの関数と共に用いることを想定して設計されています。if_else、case_match、case_whenを用いれば、mutate関数内で条件分岐を行うこともできます。また、どの条件にも合わないとき（if文におけるelseに当たるもの）の返り値を設定する場合には、default引数を設定します。\n\n\n\ncase_when関数で条件分岐\n\niris_s &lt;- iris |&gt; slice_sample(n = 5) |&gt; select(Species) |&gt; unlist() |&gt; as.character()\niris_s\n## [1] \"versicolor\" \"setosa\"     \"setosa\"     \"virginica\"  \"virginica\"\n\ncase_when(\n  iris_s == \"setosa\" ~ 1, # 条件がTRUEなら、~の後ろの値を返す\n  iris_s == \"versicolor\" ~ 2,\n  iris_s == \"virginica\" ~ 3\n)\n## [1] 2 1 1 3 3\n\n\n\n\n\n\n\n図2：ショートカットで入力するパイプ演算子を変更する\n縦持ちと横持ちの図\n\n\n\nBache, Stefan Milton, and Hadley Wickham. 2022. Magrittr: A Forward-Pipe Operator for r. https://CRAN.R-project.org/package=magrittr.\n\n\nPolack, Fernando P., Stephen J. Thomas, Nicholas Kitchin, Judith Absalon, Alejandra Gurtman, Stephen Lockhart, John L. Perez, et al. 2020. “Safety and Efficacy of the BNT162b2 mRNA Covid-19 Vaccine.” New England Journal of Medicine 383 (27): 2603–15. https://doi.org/10.1056/NEJMoa2034577.\n\n\nWickham, Hadley. 2007a. “Reshaping Data with the Reshape Package.” Journal of Statistical Software 21 (12). https://www.jstatsoft.org/v21/i12/.\n\n\n———. 2007b. “Reshaping Data with the reshape Package.” Journal of Statistical Software 21 (12): 1–20. http://www.jstatsoft.org/v21/i12/.\n\n\n———. 2011. “The Split-Apply-Combine Strategy for Data Analysis.” Journal of Statistical Software 40 (1): 1–29. https://www.jstatsoft.org/v40/i01/.\n\n\n———. 2014. “Tidy Data.” Journal of Statistical Software 59 (10): 1–23. https://doi.org/10.18637/jss.v059.i10.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, and Lionel Henry. 2023. Purrr: Functional Programming Tools. https://CRAN.R-project.org/package=purrr.\n\n\nWickham, Hadley, Davis Vaughan, and Maximilian Girlich. 2023. Tidyr: Tidy Messy Data. https://CRAN.R-project.org/package=tidyr.",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>tidyr・dplyr</span>"
    ]
  },
  {
    "objectID": "chapter17.html",
    "href": "chapter17.html",
    "title": "17  日時データの取り扱い",
    "section": "",
    "text": "17.1 日時データのクラス：Date・POSIXct・POSIXlt・POSIXt\nRでは、日時データのクラスとして、Date・POSIXct・POSIXlt・POSIXtの4種類が設定されています。これらのうち、Date型は日付のみを取り扱う型、POSIXct・POSIXlt・POSIXt型は日時（日付＋時間）を取り扱う型です。これらの型は、それぞれ取り扱い方が少しずつ異なります。\nRには、表1に示す日時データ取り扱いのための関数が備わっています。以下にそれぞれの関数・データ型の取り扱いについて説明します。\n表1：R標準の日時関連関数群\n\n\n\n\n\n\n関数名\n適用する演算\n\n\n\n\nSys.Date()\n現在の日付を返す(Date)\n\n\nSys.Time()\n現在の日時を返す(POSIXct)\n\n\nSys.timezone()\n現在のタイムゾーンを返す\n\n\nas.POSIXlt(x)\nxをPOSIXltに変換する\n\n\nweekdays(x)\nxの曜日を返す\n\n\nmonths(x)\nxの月名を返す\n\n\nquarters(x)\nxの四半期を返す\n\n\nISOdatetime(y, m, d, h, m, s)\nPOSIXctオブジェクトを作成\n\n\nseq(x, by, length.out)\nxからbyの間隔でlength.outの長さのベクターを作成\n\n\ncut.POSIXt(x, breaks)\nxをbreaksで丸めた因子を作成\n\n\nmin(x)\nxの最小値を返す\n\n\nmax(x)\nxの最大値を返す\n\n\nmean(x)\nxの平均値を返す\n\n\nrange(x)\nxの範囲を返す\n\n\ndifftime(x, y)\nxとyの時間差を返す\n\n\nround(x, unit)\nxをunitにまるめて返す\n\n\nSys.sleep(sec)\n演算をsec秒停止する\n\n\ntic()\n時間計測を開始（tictocパッケージ）\n\n\ntoc()\n時間計測を終了（tictocパッケージ）",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>日時データの取り扱い</span>"
    ]
  },
  {
    "objectID": "chapter17.html#日時データのクラスdateposixctposixltposixt",
    "href": "chapter17.html#日時データのクラスdateposixctposixltposixt",
    "title": "17  日時データの取り扱い",
    "section": "",
    "text": "POSIXtクラス\n\n\n\n\n\nPOSIXtクラスはPOSIXctとPOSIXltの親クラスです。Rの日時に関する関数の多くはPOSIXtクラスを引数に取るよう設定されているため、POSIXctもPOSIXltもほぼ同じように取り扱うことができます。",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>日時データの取り扱い</span>"
    ]
  },
  {
    "objectID": "chapter17.html#現在の日時を取得する",
    "href": "chapter17.html#現在の日時を取得する",
    "title": "17  日時データの取り扱い",
    "section": "17.2 現在の日時を取得する",
    "text": "17.2 現在の日時を取得する\nSys.Date関数とSys.time関数は、現在の日付・日時をそれぞれ取得するための関数です。Sys.Date関数は現在の日付をDateクラスで、Sys.time関数は現在の時刻をPOSIXctクラスで返します。同様の関数としてdate関数もありますが、この関数の返り値は文字列です。\nSys.timezone関数は、Rが演算に用いるタイムゾーンを返す関数です。日本で使用しているPCでは、通常Asia/Tokyo（GMT+9）をタイムゾーンとしています。\n\n\n\nSys.DateとSys.time関数\n\nSys.Date() # 現在の日付（Date）\n## [1] \"2025-03-29\"\n\nSys.time() # 現在の日時（POSIXct）\n## [1] \"2025-03-29 07:47:43 +09\"\n\ndate() # 現在の日時（文字列）\n## [1] \"Sat Mar 29 07:47:43 2025\"\n\nSys.timezone() # システムのタイムゾーン\n## [1] \"Etc/GMT-9\"\n\n\nSys.Date() |&gt; class() # Sys.Dateの返り値はDate\n## [1] \"Date\"\n\nSys.time() |&gt; class() # Sys.timeの返り値はPOSIXct（POSIXt）\n## [1] \"POSIXct\" \"POSIXt\"\n\ndate() |&gt; class() # dateの返り値は文字列（character）\n## [1] \"character\"\n\n\nDateクラスのデータ型は数値で、as.numeric関数で数値に変換すると1970年1月1日からの日数を返します。\n\n\n\nDateクラス\n\nSys.Date() |&gt; mode() # Dateクラスは数値型\n## [1] \"numeric\"\n\nSys.Date() |&gt; as.numeric() # 1970/1/1からの日数\n## [1] 20176\n\n\n同様に、POSIXctもデータ型は数値で、数値変換すると1970年1月1日0時0分0秒からの秒数を返します。\n\n\n\nPOSIXctクラス\n\nSys.time() |&gt; mode() # POSIXctクラスは数値型\n## [1] \"numeric\"\n\nSys.time() |&gt; as.numeric() # 1970/1/1からの時間（秒）\n## [1] 1743202064",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>日時データの取り扱い</span>"
    ]
  },
  {
    "objectID": "chapter17.html#posixctクラスとposixltクラス",
    "href": "chapter17.html#posixctクラスとposixltクラス",
    "title": "17  日時データの取り扱い",
    "section": "17.3 POSIXctクラスとPOSIXltクラス",
    "text": "17.3 POSIXctクラスとPOSIXltクラス\nPOSIXctクラスのオブジェクトは、as.POSIXlt関数でPOSIXltクラスに変換することができます。また、as.POSIXct関数を用いてPOSIXltクラスのオブジェクトをPOSIXctクラスに変換することもできます。\nPOSIXctクラスとPOSIXltクラスの違いは、POSIXctが数値なのに対し、POSIXltにはクラスだけでなく、名前（names）とタイムゾーン（tzone）がアトリビュートとして設定されているリストである点です。POSIXltは名前付きリストですので、設定されている名前（sec、min、hour、mdayなど）を用いて、秒、分、時、日などの日時の部分データを呼び出すことができます。\n\n\n\nPOSIXltクラス\n\nSys.time() |&gt; as.POSIXct() # POSIXctに変換\n## [1] \"2025-03-29 07:47:44 +09\"\n\nSys.time() |&gt; as.POSIXlt() # POSIXltに変換\n## [1] \"2025-03-29 07:47:44 +09\"\n\n\nt &lt;- Sys.time() # tはPOSIXct\nt$year # POSIXctには名前が無いため、エラー\n## Error in t$year: $ operator is invalid for atomic vectors\n\nattributes(t) # class以外は設定されていない\n## $class\n## [1] \"POSIXct\" \"POSIXt\"\n\n\nt1 &lt;- as.POSIXlt(t) # t1はPOSIXlt\nattributes(t1) # 名前とタイムゾーンが設定されている\n## $names\n##  [1] \"sec\"    \"min\"    \"hour\"   \"mday\"   \"mon\"    \"year\"   \"wday\"   \"yday\"  \n##  [9] \"isdst\"  \"zone\"   \"gmtoff\"\n## \n## $class\n## [1] \"POSIXlt\" \"POSIXt\" \n## \n## $tzone\n## [1] \"\"    \"+09\" \"   \"\n## \n## $balanced\n## [1] TRUE\n\nas.numeric(t1) # POSIXltも数値に置き換えできる\n## [1] 1743202064\n\nmode(t1) # POSIXltはリスト\n## [1] \"list\"\n\nt1$mday # POSIXltは$で名前から呼び出し可能\n## [1] 29\n\nt1$hour\n## [1] 7\n\nt1$wday # 曜日は月曜日が1\n## [1] 6\n\nt1$zone # タイムゾーン\n## [1] \"+09\"\n\n\nPOSIXltにはタイムゾーンがアトリビュートとして設定されており、POSIXctには設定されていませんが、いずれもas.POSIXlt、as.POSIXct関数のtz引数を設定することで、タイムゾーンを変更することができます。\n\n\n\nタイムゾーンの設定\n\nas.POSIXct(Sys.time(), tz = \"GMT\") # POSIXct型のSys.time()をUTCに変換\n## [1] \"2025-03-28 22:47:44 GMT\"\n\nas.POSIXct(Sys.time(), tz = \"EST\") # アメリカ東時間に変換\n## [1] \"2025-03-28 17:47:44 EST\"\n\nas.POSIXlt(t1, tz = \"GMT\") # POSIXlt型をUTCに変換\n## [1] \"2025-03-29 07:47:44 +09\"\n\nas.POSIXlt(t1, tz = \"EST\") # アメリカ東時間に変換\n## [1] \"2025-03-29 07:47:44 +09\"\n\n\nPOSIXct、POSIXltクラスのオブジェクトは、共にRの日時データに関する関数の引数として設定し、演算を行うことができます。\n代表的な日時データに関する関数は、weekdays関数やmonths関数、quarters関数などです。いずれも日時データのベクターを引数に取り、曜日・月・四半期などの値を返します。\n\n\n\n日時データに関する関数\n\nweekdays(t)\n## [1] \"土曜日\"\n\nweekdays(t, abbreviate = T) # 省略形\n## [1] \"土\"\n\nweekdays(as.POSIXlt(t, tz=\"EST\")) # US時間に変更しても、日本語で出てくる\n## [1] \"金曜日\"\n\n\nt2 &lt;- c(as.POSIXct(\"2023-10-10 11:11:11\"), as.POSIXct(\"2024-1-11 11:11:11\"))\nweekdays(t2) # ベクターでも処理可能\n## [1] \"火曜日\" \"木曜日\"\n\nmonths(t2) # 月を返す関数\n## [1] \"10月\" \"1月\"\n\nquarters(t2) # 四半期を返す関数\n## [1] \"Q4\" \"Q1\"",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>日時データの取り扱い</span>"
    ]
  },
  {
    "objectID": "chapter17.html#文字列を日時データに変換する",
    "href": "chapter17.html#文字列を日時データに変換する",
    "title": "17  日時データの取り扱い",
    "section": "17.4 文字列を日時データに変換する",
    "text": "17.4 文字列を日時データに変換する\nExcelやテキストファイルなどでは、日時データは文字列や数値で保存されています。Rでは文字列や数値をそのまま日時データとして取り扱うことはできないため、日時データに変換する必要があります。日時データへの変換にも、as.POSIXct関数やas.POSIXlt関数を用います。\n文字列は、日本人が通常使うような日時の表現（\"2022/2/22 11:11:11\"や\"2022-2-22 11:11:11\"など）であれば、その文字列のみを引数に取り、as.POSIXct関数やas.POSIXlt関数で日時クラスに変換できます。\nただし、単に日時の数値を並べた文字列や、年月日等の日本語が混じった文字列では、どのような日時データなのかRが読み解くことができないため、as.POSIXct関数やas.POSIXlt関数で直接日時データに変換することはできません。\nこのように、文字列を日時データに変換する場合には、変換のルールであるフォーマットを指定する必要があります。フォーマットとは、%（パーセント）に特定のアルファベットを付けて、年や月、分などを指定するものです。例えば、年であれば%Yや%y、月であれば%mが対応するフォーマットとなります。フォーマットの一覧を以下の表2に示します。\n\n\n\n表2：日時formatの記載一覧\n\n\n記号\n意味\n\n\n\n\n%a\n省略した曜日名（Mon, Tueなど）\n\n\n%A\n省略しない曜日名（Mondayなど）\n\n\n%b\n省略した月名（Jan，Febなど）\n\n\n%B\n省略しない月名（Januaryなど）\n\n\n%c\n日時（通常表示はこれ，%Y-%m-%d %H:%M:%Sと同じ）\n\n\n%C\n世紀\n\n\n%d\n日（01-30日）\n\n\n%D\n日付（%Y-%m-%dと同じ）\n\n\n%e\n日（1-30日，ゼロがないもの）\n\n\n%F\n%Y-%m-%dと同じ\n\n\n%g\nweek-based-yearの最後2桁（1-99）\n\n\n%G\nweek-based-year（01-99）\n\n\n%h\n%bと同じ\n\n\n%H\n時間（00-23）\n\n\n%I\n時間（00-12）\n\n\n%j\n年基準の日数（001-366）\n\n\n%m\n月（01-12）\n\n\n%M\n分（00-59）\n\n\n%n\n新しい行（出力），スペース（入力）\n\n\n%p\nAM・PMの表記\n\n\n%r\n%I:%M:%S %pと同じ\n\n\n%R\n%H:%Mと同じ\n\n\n%S\n秒（00-61）\n\n\n%t\nタブ切り（出力），スペース（入力）\n\n\n%T\n%H:%M:%Sと同じ\n\n\n%u\n週の日数（1-7，1は月曜）\n\n\n%U\n日曜日を始めとするweek of the year（00-53）\n\n\n%V\nISO8601に従ったweek of the year（01-53）\n\n\n%w\n週の日数（0-6，0は日曜）\n\n\n%W\n月曜日を始めとするweek of the year（00-53）\n\n\n%x\n%y/%m/%dと同じ\n\n\n%X\n%H:%M:%Sと同じ\n\n\n%y\n世紀表現なしの年（00-99）\n\n\n%Y\n正規表現込みの年（2023など）\n\n\n%z\nUTCからの時間差表現（-0800など）\n\n\n%Z\nタイムゾーンの出力\n\n\n\n\n\nフォーマットを利用することで、日本語の混じった文字列や、単に数値だけの文字列であっても、日時データに変換することができます。\n\n\n\nフォーマットを用いた日時データへの変換\n\nas.POSIXlt(\"2022-2-22 11:11:11\")\n## [1] \"2022-02-22 11:11:11 +09\"\n\nas.POSIXlt(\"2022/2/22 11:11:11\")\n## [1] \"2022-02-22 11:11:11 +09\"\n\nas.Date(\"2022/10/22\")\n## [1] \"2022-10-22\"\n\n\nas.POSIXct(\"20221022 111111\") # エラー\n## Error in as.POSIXlt.character(x, tz, ...): character string is not in a standard unambiguous format\n\nas.POSIXct(\"20221022 111111\", format = \"%Y%m%d %H%M%S\") # フォーマットを設定\n## [1] \"2022-10-22 11:11:11 +09\"\n\nas.Date(\"20221022\", format = \"%Y%m%d\")\n## [1] \"2022-10-22\"\n\n # 漢字が混じっていても、フォーマットを設定すると日時データに変換できる\nas.POSIXct(\"2022年10月22日 11時11分11秒\", format = \"%Y年%m月%d日 %H時%M分%S秒\")\n## [1] \"2022-10-22 11:11:11 +09\"",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>日時データの取り扱い</span>"
    ]
  },
  {
    "objectID": "chapter17.html#数値を日時データに変換する",
    "href": "chapter17.html#数値を日時データに変換する",
    "title": "17  日時データの取り扱い",
    "section": "17.5 数値を日時データに変換する",
    "text": "17.5 数値を日時データに変換する\nas.Dateやas.POSIXctの引数に数値を指定すると、1970年1月1日からの日数・秒数に従い日時データに変換されてしまいます。したがって、数値を日時データに変換する場合には、まず文字列に変換しておく必要があります。\n\n\n\n数値から日時データへの変換\n\nas.Date(20221022, format = \"%Y%m%d\") # 数値はうまく変換できない\n## [1] \"57333-04-12\"\n\n20221022 |&gt; as.character() |&gt; as.Date(format = \"%Y%m%d\") # 文字列に変換する\n## [1] \"2022-10-22\"\n\n\n\n17.5.1 ISOdatetime関数で日時データを作成する\nISOdatetime関数を用いて日時データを作成することもできます。ISOdatetime関数は引数に年、月、日、時、分、秒の数値を取り、引数に応じた日時データをPOSIXctクラスで返します。\n\n\n\nISOdatetime関数\n\nISOdatetime(2022, 2, 22, 2, 22, 22) # POSIXct型の2022/2/22 2:22:22を作成\n## [1] \"2022-02-22 02:22:22 +09\"",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>日時データの取り扱い</span>"
    ]
  },
  {
    "objectID": "chapter17.html#連続した日時データの作成",
    "href": "chapter17.html#連続した日時データの作成",
    "title": "17  日時データの取り扱い",
    "section": "17.6 連続した日時データの作成",
    "text": "17.6 連続した日時データの作成\nココまでは、1つの日時データの作成について見てきました。しかし、統計では日時データとして一定間隔で数時間～数年などの連続した時間を取り扱う場合が多いです。このような一定間隔での日時データの作成には、seq関数を用います。\n数値ベクターでのseq関数と同じく、第一引数に始めの日時、第二引数に終わりの日時、by引数に時間間隔を入力すると、始めの日時から終わりの日時まで、by引数で指定した間隔での連続した日時データを作成することができます。\nseq関数の引数にはDateクラスもPOSIXtクラスも利用することができますが、DateクラスとPOSIXtクラスを同時に用いることはできません。\n\n\n\nseq関数で連続する日時データを作成する\n\nday1 &lt;- as.POSIXlt(\"2022-2-22\")\nday2 &lt;- as.POSIXlt(\"2022-2-26\")\n\n# day1からday2まで、1日置きのベクター\nseq(day1, day2, by=\"day\")\n## [1] \"2022-02-22 +09\" \"2022-02-23 +09\" \"2022-02-24 +09\" \"2022-02-25 +09\"\n## [5] \"2022-02-26 +09\"\n\n# 1日間隔で、5日間のベクター\nseq(day1, by=\"day\", length.out=5)\n## [1] \"2022-02-22 +09\" \"2022-02-23 +09\" \"2022-02-24 +09\" \"2022-02-25 +09\"\n## [5] \"2022-02-26 +09\"\n\n# 1週間間隔で、5週間のベクター\nseq(day1, by=\"week\", length.out=5)\n## [1] \"2022-02-22 +09\" \"2022-03-01 +09\" \"2022-03-08 +09\" \"2022-03-15 +09\"\n## [5] \"2022-03-22 +09\"\n\n# 2週間間隔で、10週間のベクター\nseq(day1, by=\"2 week\", length.out=5)\n## [1] \"2022-02-22 +09\" \"2022-03-08 +09\" \"2022-03-22 +09\" \"2022-04-05 +09\"\n## [5] \"2022-04-19 +09\"\n\nday3 &lt;- as.Date(\"2022-2-22\") # Dateクラスでも同じ演算が使える\nseq(day3, by=\"1 week\", length.out=5)\n## [1] \"2022-02-22\" \"2022-03-01\" \"2022-03-08\" \"2022-03-15\" \"2022-03-22\"\n\nseq(day1, day3, by=\"day\") # POSIXtとDateを同時に使うとエラー\n## Error in seq.POSIXt(day1, day3, by = \"day\"): 'to' must be a \"POSIXt\" object\n\n\n\n\n\n\n\n\nseq関数で連続した日時データを作成する\n\n\n\n\n\nseq関数はジェネリック関数の一つで、引数が数値の場合にはseq.default関数、整数の場合にはseq.int関数、引数がPOSIXtの場合にはseq.POSIXt関数、引数がDateの場合はseq.Date関数がそれぞれ実行されます。seq関数の第一引数と第二引数のクラスは同じである必要があります。引数にDateとPOSIXtを指定すると、第一引数に従い用いる関数が変化するため（第一引数がDateならseq.Date、POSIXtならseq.POSIXtが呼び出される）、第一引数と第二引数のデータ型が異なるとエラーとなります。",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>日時データの取り扱い</span>"
    ]
  },
  {
    "objectID": "chapter17.html#cut関数",
    "href": "chapter17.html#cut関数",
    "title": "17  日時データの取り扱い",
    "section": "17.7 cut関数",
    "text": "17.7 cut関数\ncut関数は、第一引数に日時データのベクター、第二引数byに時間間隔（\"weeks\"、\"months\"など）を取り、時間間隔で指定した範囲の日時データを同一の値に変換する関数です。返り値は因子になるため、週や月、年の集計データを収集したい場合などに利用できます。\n\n\n\ncut関数\n\nhdays &lt;- seq(day1, by=\"day\", length.out = 25) # 2022-2-22から25日間のデータ\ncutdays &lt;- cut(hdays, \"weeks\") # hdaysを週ごとに分けて、因子にする\ncutdays[1:14] # 同一週の日時は同じ因子のレベルが振り当てられる\n##  [1] 2022-02-21 2022-02-21 2022-02-21 2022-02-21 2022-02-21 2022-02-21\n##  [7] 2022-02-28 2022-02-28 2022-02-28 2022-02-28 2022-02-28 2022-02-28\n## [13] 2022-02-28 2022-03-07\n## Levels: 2022-02-21 2022-02-28 2022-03-07 2022-03-14\n\nclass(cutdays) # cut関数の返り値は因子\n## [1] \"factor\"\n\nlevels(cutdays) # 週ごとにレベルが設定される\n## [1] \"2022-02-21\" \"2022-02-28\" \"2022-03-07\" \"2022-03-14\"",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>日時データの取り扱い</span>"
    ]
  },
  {
    "objectID": "chapter17.html#日時データを引数に取る関数",
    "href": "chapter17.html#日時データを引数に取る関数",
    "title": "17  日時データの取り扱い",
    "section": "17.8 日時データを引数に取る関数",
    "text": "17.8 日時データを引数に取る関数\n上記のcut関数以外にも、Rには日時データを引数に取る関数が多数設定されています。例えば最初の日時、最後の日時を返すmin・max関数、平均の日時を返すmean関数、最初と最後の日時を返すrange関数などが代表例です。日時の差はdifftime関数で計算することができますが、単に日時データを引き算することでも計算できます。また、特定の単位（年、月、日など）で丸める場合には、round関数を用いることができます。\n\n\n\n日時データの関数演算\n\nmin(hdays)\n## [1] \"2022-02-22 +09\"\n\nmax(hdays)\n## [1] \"2022-03-18 +09\"\n\nmean(hdays)\n## [1] \"2022-03-06 +09\"\n\nrange(hdays)\n## [1] \"2022-02-22 +09\" \"2022-03-18 +09\"\n\ndifftime(max(hdays), min(hdays))\n## Time difference of 24 days\n\nmax(hdays) - min(hdays)\n## Time difference of 24 days\n\nround(t, unit=\"year\")\n## [1] \"2025-01-01 +09\"",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>日時データの取り扱い</span>"
    ]
  },
  {
    "objectID": "chapter17.html#演算を一時停止するsys.sleep関数",
    "href": "chapter17.html#演算を一時停止するsys.sleep関数",
    "title": "17  日時データの取り扱い",
    "section": "17.9 演算を一時停止する：Sys.sleep関数",
    "text": "17.9 演算を一時停止する：Sys.sleep関数\nSys.sleep関数はRの演算の途中で、演算を指定した時間だけ一時停止するための関数です。一時停止する時間（秒）を数値で引数に取ります。\n\n\n\nSys.sleep関数\n\nSys.sleep(5) # 5秒待つ",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>日時データの取り扱い</span>"
    ]
  },
  {
    "objectID": "chapter17.html#演算時間の計測",
    "href": "chapter17.html#演算時間の計測",
    "title": "17  日時データの取り扱い",
    "section": "17.10 演算時間の計測",
    "text": "17.10 演算時間の計測\nSys.time関数を用いると、演算にかかる時間を計測することができます。繰り返し計算などで、とても時間がかかる演算を含む場合には、あらかじめ演算時間を計測しておくと、繰り返し計算全体でどの程度時間がかかるのか把握しやすくなります。\nまず、Sys.time関数の返り値である、現在の時刻を変数tに代入します。その後何らかの演算を行い（下の例ではSys.sleep関数で3秒停止）、その後、演算後の現在時刻からtを引くと、Sys.sleep関数による演算の時間を計測することができます。Sys.sleep関数による3秒の停止以外にも、代入等でわずかに時間がかかるため、3秒よりほんの少し時間がかかっていることが計測できます。\n同様の時間計測は、system.time関数を用いても行うことができます。system.time関数は演算全体を引数に取り、その演算にかかる時間を計測します。\n\n\n\nプログラムの演算時間を計測する\n\nt &lt;- Sys.time() # 現在時刻を記録\nSys.sleep(3) # 3秒スリープ\nSys.time() - t # 現在時刻と記録した時刻の差を計算\n## Time difference of 3.051899 secs\n\n# system.time関数でも演算時間を計測できる\nsystem.time(for(i in 1:1000000){i^2})\n##    user  system elapsed \n##       0       0       0\n\n\n\n17.10.1 tictocパッケージ\nもう少しスマートに演算時間を計測する方法をtictocパッケージ (Izrailev 2023)が提供しています。tictocパッケージにはtic関数とtoc関数が設定されており、tic関数で計測を開始し、toc関数で計測を終了、演算時間を返します。\ntic関数は引数に文字列を取ることができ、toc関数で計測時間が返ってくる時に、このtic関数の引数を同時に返してくれます。tic関数、toc関数による時間計測は、後入れ先出し（Last In, First Out, LIFO）のルールに従い時間を計測します。ですので、後からtic関数で計測をスタートした演算時間は、先のtoc関数で返ってくる仕組みになっています。\n\n\n\ntictocパッケージで演算時間を計測\n\npacman::p_load(tictoc)\ntic()\nSys.sleep(3)\ntoc()\n## 3.06 sec elapsed\n\ntic(\"first\")\ntic(\"second\")\ntic(\"third\")\ntoc() # 後のtic（third）からの時間がまず返ってくる\n## third: 0 sec elapsed\n\ntoc()\n## second: 0.01 sec elapsed\n\ntoc() # 先のtic（first）が最後に返ってくる\n## first: 0.01 sec elapsed",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>日時データの取り扱い</span>"
    ]
  },
  {
    "objectID": "chapter17.html#時系列データtsクラス",
    "href": "chapter17.html#時系列データtsクラス",
    "title": "17  日時データの取り扱い",
    "section": "17.11 時系列データ：tsクラス",
    "text": "17.11 時系列データ：tsクラス\n時系列データ（time series data）は、日時データとセットになった測定値です。例えば、14章で説明したNileのデータセットは時系列データの代表的な例です。Nileは1871年から1970年のナイル川の流量を年ごとに測定したデータです。\n\n\n\nNileデータセット\n\nNile # 時系列データの代表例：ナイル川の流量\n## Time Series:\n## Start = 1871 \n## End = 1970 \n## Frequency = 1 \n##   [1] 1120 1160  963 1210 1160 1160  813 1230 1370 1140  995  935 1110  994 1020\n##  [16]  960 1180  799  958 1140 1100 1210 1150 1250 1260 1220 1030 1100  774  840\n##  [31]  874  694  940  833  701  916  692 1020 1050  969  831  726  456  824  702\n##  [46] 1120 1100  832  764  821  768  845  864  862  698  845  744  796 1040  759\n##  [61]  781  865  845  944  984  897  822 1010  771  676  649  846  812  742  801\n##  [76] 1040  860  874  848  890  744  749  838 1050  918  986  797  923  975  815\n##  [91] 1020  906  901 1170  912  746  919  718  714  740\n\n\nこのような時系列データをRで取り扱うために準備されているクラスが、tsクラスです。tsクラスには計測されたデータと共に、日時に関する情報が付属しています。\n\n\n\ntsクラスのattribute\n\nattributes(Nile) # 日時に関するattribute（tsp）が記録されている\n## $tsp\n## [1] 1871 1970    1\n## \n## $class\n## [1] \"ts\"\n\n\ntsクラスを引数とする関数が、Rには複数備わっています。tsクラスを引数とする関数の一覧を以下の表3に示します。\n\n\n\n表3：tsクラスを引数とする関数群\n\n\n\n\n\n\n関数名\n適用する演算\n\n\n\n\nts(x, frequency, start)\nfrequency周期で，startから始まるtsオブジェクトを作成する\n\n\nas.ts(x)\ntsに変換する\n\n\nis.ts(x)\ntかどうか確認する\n\n\ntsp(x)\ntsオブジェクトを変換する\n\n\ncycle(x)\nfrequencyの周期の位置を返す\n\n\nfrequency(x)\nfrequencyを返す\n\n\ndeltat(x)\nデータの時間間隔を返す\n\n\nwindow(x, start, end)\nstartからendまでのデータを返す\n\n\ntime(x)\n時間に変換する\n\n\nstart(x)\n開始日時を返す\n\n\nend(x)\n終了日時を返す\n\n\n\n\n\n\n\n\ntsクラスの作成と演算\n\nvalue &lt;- rep(1:3, 8) # 時系列の元になる値\n# tsクラスの変数を作成\ntsobj &lt;- ts(value, frequency = 1, start=c(2023)) \ntsobj # 2023年から2046年までのtsクラスのデータ\n## Time Series:\n## Start = 2023 \n## End = 2046 \n## Frequency = 1 \n##  [1] 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3\n\nas.ts(1:12) # tsに変換\n## Time Series:\n## Start = 1 \n## End = 12 \n## Frequency = 1 \n##  [1]  1  2  3  4  5  6  7  8  9 10 11 12\n\ntsobj |&gt; is.ts() # tsオブジェクトであることを確認\n## [1] TRUE\n\nts(value, frequency = 4, start=c(2023)) # 4半期ごとのデータ\n##      Qtr1 Qtr2 Qtr3 Qtr4\n## 2023    1    2    3    1\n## 2024    2    3    1    2\n## 2025    3    1    2    3\n## 2026    1    2    3    1\n## 2027    2    3    1    2\n## 2028    3    1    2    3\n\nts(value, frequency = 12, start=c(2023)) # 月次のデータ\n##      Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n## 2023   1   2   3   1   2   3   1   2   3   1   2   3\n## 2024   1   2   3   1   2   3   1   2   3   1   2   3\n\ntsobj2 &lt;- ts(value, frequency = 4, start=c(2023))\ntsobj2 |&gt; tsp() # 2023年から2028年4Qまで四半期置きのデータ\n## [1] 2023.00 2028.75    4.00\n\ntsobj2 |&gt; cycle() # 四半期（cycle）についてのラベル\n##      Qtr1 Qtr2 Qtr3 Qtr4\n## 2023    1    2    3    4\n## 2024    1    2    3    4\n## 2025    1    2    3    4\n## 2026    1    2    3    4\n## 2027    1    2    3    4\n## 2028    1    2    3    4\n\ntsobj2 |&gt; frequency() # frequencyは4\n## [1] 4\n\ntsobj2 |&gt; deltat() # データの間隔は1/4年\n## [1] 0.25\n\n# 2025年1Qから2026年4Qまでのデータを返す\ntsobj2 |&gt; window(c(2025, 1), c(2026, 4)) \n##      Qtr1 Qtr2 Qtr3 Qtr4\n## 2025    3    1    2    3\n## 2026    1    2    3    1\n\ntsobj2 |&gt; time() # 各データの時点に変換\n##         Qtr1    Qtr2    Qtr3    Qtr4\n## 2023 2023.00 2023.25 2023.50 2023.75\n## 2024 2024.00 2024.25 2024.50 2024.75\n## 2025 2025.00 2025.25 2025.50 2025.75\n## 2026 2026.00 2026.25 2026.50 2026.75\n## 2027 2027.00 2027.25 2027.50 2027.75\n## 2028 2028.00 2028.25 2028.50 2028.75\n\ntsobj2 |&gt; start() # 2023年1Qからのデータ\n## [1] 2023    1\n\ntsobj2 |&gt; end() # 2028年4Qまでのデータ\n## [1] 2028    4\n\n\n\n\n\n\n\n\ntsクラスの利用\n\n\n\n\n\n時系列データを取り扱う場合に、必ずしもtsクラスのオブジェクトを用いないといけない、というわけではありません。日時データと値の2つのベクターを用いても、時系列の解析を行うことはできます。\n時系列データの解析には、Stan (Carpenter et al. 2017)などの外部ツールを用いる場合もあるため、場合によってはtsクラスではないデータの方が取り扱いやすい場合もあります。",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>日時データの取り扱い</span>"
    ]
  },
  {
    "objectID": "chapter17.html#lubridateパッケージ",
    "href": "chapter17.html#lubridateパッケージ",
    "title": "17  日時データの取り扱い",
    "section": "17.12 lubridateパッケージ",
    "text": "17.12 lubridateパッケージ\n上記のように、Rには時間を取り扱うクラスとして、Date、POSIXct、POSIXlt、tsなどを備えています。ただし、フォーマットの設定や関数に見られるように、必ずしもすべてのクラスが時系列データの解析において使いやすい、というわけではありません。\nRでの日時データの取り扱いを簡単にするためのライブラリが、lubridateパッケージ (Grolemund and Wickham 2011)です。lubridateパッケージは日時データを取り扱うための関数のセットを提供しており、様々なフォーマットの文字列を簡単に日時データに変換し、演算に用いることができます。\nlubridateパッケージが提供する関数群を以下の表4に示します。\n\n\n\n表4：lubridateパッケージの関数群\n\n\n\n\n\n\n関数名\n適用する演算\n\n\n\n\nymd(x), mdy(x), dmy(x)\nxを日付に変換\n\n\nymd_hms(x), ymd_hm(x)\nxを日時に変換\n\n\nhms(x)\nxを時間に変換\n\n\nparse_date_time(x, order)\nxをorderに従い日時に変換\n\n\nyear(x)\nxの年を返す\n\n\nyear(x)&lt;-\nxの年を代入値に変換する\n\n\nmonth(x)\nxの月を返す\n\n\nday(x)\nxの日を返す\n\n\nhour(x)\nxの時間を返す\n\n\nminute(x)\nxの分を返す\n\n\nsecond(x)\nxの秒を返す\n\n\ntz(x)\nタイムゾーンを返す\n\n\nnow()\n現在の日時を返す\n\n\ntoday()\n現在の日付を返す\n\n\nstamp(char)(x)\nxをcharの文字列に合わせて返す\n\n\nduration(x, units)\n単位がunits，値がxの時間差（period）オブジェクトを作成\n\n\nyears(n)\nn年のperiodオブジェクトを作成\n\n\nmonths(n)\nn月のperiodオブジェクトを作成\n\n\ndays(n)\nn日のperiodオブジェクトを作成\n\n\nhours(n)\nn時間のperiodオブジェクトを作成\n\n\nminutes(n)\nn分のperiodオブジェクトを作成\n\n\nseconds(n)\nn秒のperiodオブジェクトを作成\n\n\nam(x)\nxが午前中ならTRUEを返す\n\n\npm(x)\nxが午後ならTRUEを返す\n\n\ninterval(x, y)\nxとyのintervalオブジェクトを作成\n\n\nint_length(x)\nxの期間の長さを返す\n\n\nint_overlaps(x, y)\nxとyに時間の重なりがあればTRUEを返す\n\n\n\n\n\n\n17.12.1 日付データへの変換：ymd関数\n文字列を日時データに変換する場合、as.POSIXlt関数やas.Date関数で、フォーマットを指定するのがRのデフォルトの手法です。この手順を簡単に行うことができる関数が、ymd関数を含む関数群です。ymdは、「year, month, day」の略で、この年月日の順で数値が記載された文字列や数値であれば、かなり適当に記載した文字列・数値であっても、正確に日時データに変換してくれます。\n日本では年月日の順で日付を書くのが一般的ですが、アメリカでは月日年、ヨーロッパでは日月年の順で日付を書くことになっています。このように、年月日の順番が異なる場合には、ymd関数ではなく、mdy関数やdmy関数を用いることで、日時データに簡単に変換することができます。\n\n\n\nymd・mdy・dmy関数でDateに変換\n\npacman::p_load(lubridate)\n\n# どんな書き方でも変換してくれる\nymd(\"20231020\")\n## [1] \"2023-10-20\"\n\nymd(\"2023/10/20\")\n## [1] \"2023-10-20\"\n\nymd(\"2023-10-20\")\n## [1] \"2023-10-20\"\n\nymd(\"23 10 20\")\n## [1] \"2023-10-20\"\n\nymd(\"2023年10月20日\") # 漢字が入っていても変換可能\n## [1] \"2023-10-20\"\n\nymd(20231020) # 数値でも変換可能\n## [1] \"2023-10-20\"\n\nymd(231020)\n## [1] \"2023-10-20\"\n\nmdy(\"10/20/2023\") # USでは月/日/年\n## [1] \"2023-10-20\"\n\ndmy(\"20/10/2023\") # ヨーロッパでは日/月/年\n## [1] \"2023-10-20\"\n\nym(\"2023/10\") # yearとmonthだけのデータも対応できる\n## [1] \"2023-10-01\"\n\n\n\n\n17.12.2 日時データの変換：ymd_hms関数\n時間を含むデータの場合には、ymd_hms関数などの関数群を用います。こちらも、かなりいい加減な記載の日時データでも、簡単にPOSIXctクラスに変換してくれます（デフォルトのタイムゾーンはUTC、グリニッジ標準時）。タイムゾーンはtz引数に文字列で指定（TZ identifierで指定）することで変更できます。\n\n\n\nymd_hms関数でPOSIXctに変換\n\nymd_hms(\"2023/10/20 22:22:22\") # POSIXctに変換\n## [1] \"2023-10-20 22:22:22 UTC\"\n\nymd_hms(\"2023年10月20日 22時22分22秒\") # POSIXctに変換\n## [1] \"2023-10-20 22:22:22 UTC\"\n\nymd_hms(231020222222) # 数値も変換できる\n## [1] \"2023-10-20 22:22:22 UTC\"\n\nymd_hms(\"2023年10月20日 22時22分22秒\", tz=\"Asia/Tokyo\") # JSTに変換\n## [1] \"2023-10-20 22:22:22 JST\"\n\n\nymd関数群やymd_hms関数群などの機能を1つの関数に落とし込んだものが、parse_date_time関数です。このparse_date_time関数では、関数名で年月日の順番を指定するのではなく、ordersという引数で年月日、時間の順番を指定します。\n\n\n\nparse_date_timeで日時データに変換\n\nparse_date_time(\"2023/12/21\", \"ymd\")\n## [1] \"2023-12-21 UTC\"\n\nparse_date_time(\"2023/12/21 12:25:30\", \"ymdHMS\")\n## [1] \"2023-12-21 12:25:30 UTC\"\n\n\nlubridateには、日時データから年や月などの一部を取り出す関数群として、year、month、week、day、hour、minute、secondが設定されています。日時データを引数に取り、関数に数値を代入することで、特定の値を変更することもできます。\nまた、日時データのタイムゾーンをtz関数で取得することができ、日時データを引数に取ったtz関数にタイムゾーンを代入することで、タイムゾーンを変更することもできます。\n\n\n\nlubridateの日時データ演算に関する関数\n\nt &lt;- ymd(\"2023/10/20\") # Dateクラスの変数を作成\nyear(t)\n## [1] 2023\n\nyear(t) &lt;- 2024 # 代入で変更できる\nt\n## [1] \"2024-10-20\"\n\ntz(t) # タイムゾーンを返す関数\n## [1] \"UTC\"\n\ntz(t) &lt;- \"Asia/Tokyo\" # 代入でタイムゾーンも変更可能\ntz(t)\n## [1] \"Asia/Tokyo\"\n\n\n\n\n17.12.3 現在時刻の取得：today関数とnow関数\nSys.Date関数やSys.time関数と同じような関数として、lubridateにはtoday関数とnow関数が設定されています。\n\n\n\ntoday・now関数\n\ntoday() # 今日の日付\n## [1] \"2025-03-29\"\n\nnow() # 今の日時\n## [1] \"2025-03-29 07:47:50 +09\"\n\n\n\n\n17.12.4 時刻を整形した文字列に変換：stamp関数\nstamp関数は日時データを整形し、文字列として返すための関数です。stamp関数の引数は日時を表記するための文字列で、日時自体はどのような時間でも問題ありません。stamp関数の後にカッコを付けて、カッコ内に文字列に変換したい日時データを与えます。この関数を実行すると、カッコ内の日時データを、stamp関数の引数の形に従って整形した文字列に変換して返してくれます。\n文字列が日付のみで、日時データがPOSIXctなどの時間を含むデータだと、正しく変更できない場合もあります。\n\n\n\nstamp関数で文字列に変換する\n\nstamp(\"1970/1/1 12:00:00\")(now())\n## Multiple formats matched: \"%Y/%Om/%d %H:%M:%S\"(1), \"%Y/%d/%Om %H:%M:%S\"(1), \"%Y/%m/%d %H:%M:%S\"(1), \"%Y/%d/%m %H:%M:%S\"(1)\n## Using: \"%Y/%Om/%d %H:%M:%S\"\n## [1] \"2025/03/29 07:47:50\"\n\nstamp(\"1970/1/1 12:00:00に作成されたデータ\")(now())\n## Multiple formats matched: \"%Y/%Om/%d %H:%M:%Sに作成されたデータ\"(1), \"%Y/%d/%Om %H:%M:%Sに作成されたデータ\"(1), \"%Y/%m/%d %H:%M:%Sに作成されたデータ\"(1), \"%Y/%d/%m %H:%M:%Sに作成されたデータ\"(1)\n## Using: \"%Y/%Om/%d %H:%M:%Sに作成されたデータ\"\n## [1] \"2025/03/29 07:47:50に作成されたデータ\"\n\n# うまくいかないときもある（月と日を曜日に変換している）。\nstamp_date(\"1970年01月01日\")(now()) \n## Multiple formats matched: \"%Y年%Om%a%d%a\"(1), \"%Y年%d%a%Om%a\"(1), \"%Y年%m%a%d%a\"(1), \"%Y年%d%a%m%a\"(1), \"%Y年%Om月%d日\"(1), \"%Y年%d月%Om日\"(1), \"%Y年%m月%d日\"(1), \"%Y年%d月%m日\"(1)\n## Using: \"%Y年%Om%a%d%a\"\n## [1] \"2025年03土29土\"",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>日時データの取り扱い</span>"
    ]
  },
  {
    "objectID": "chapter17.html#periodクラス",
    "href": "chapter17.html#periodクラス",
    "title": "17  日時データの取り扱い",
    "section": "17.13 periodクラス",
    "text": "17.13 periodクラス\nココまではDateクラス、POSIXct・POSIXlt型に関するlubridateの関数について示してきました。lubridateには、Date・POSIXct・POSIXlt以外に、時間の間隔を取り扱うクラスとして、periodクラスが備わっています。\nDateクラスやPOSIXctクラスは基本的に数値型ですので、足し算や引き算で日時を変更することができます。ただし、例えばPOSIXct型で1年3ヶ月と10日後の、3時間前といった変更をしたい場合には、すべて秒として換算し直して演算を行う必要があります。これはあまり直感的ではありませんし、月ごとに日数が異なっているため、正確に演算することも困難です。\n\n\n\nperiodでの演算\n\ntoday()\n## [1] \"2025-03-29\"\n\ntoday() + 10 # 10日後\n## [1] \"2025-04-08\"\n\nnow()\n## [1] \"2025-03-29 07:47:50 +09\"\n\nnow() + 60 # 1分後\n## [1] \"2025-03-29 07:48:50 +09\"\n\ntoday() + 365 * 1 + 3 * 30 + 10 # 1年3ヶ月と10日後\n## [1] \"2026-07-07\"\n\n\nこのような複雑な日時データの演算に対応するため、lubridateではperiodクラスのオブジェクトを作成し、このオブジェクトを演算に用いることができるようになっています。\nperiodクラスのオブジェクトを作成するには、duration関数を用いる、または、years、months、days、hours、minutes、secondsの、「時間の単位+s」の名前が付いた関数を用います。\nduration関数は引数に数値と時間の単位を取り、引数の時間単位で数値の値を持つオブジェクトを作成する関数です（クラスはDuration）。このオブジェクトはDateクラスやPOSIXctクラスとの演算に用いることができます。\n例えば、Periodクラスのオブジェクトであるmonths(20)を用いて、「now() + months(20)」とすると、現在時刻から20ヶ月後を演算することができます。「1年3ヶ月と10日後の、3時間前」といった複雑な計算も、このperiodクラスを用いれば簡単に行うことができます。\n\n\n\nperiodクラスを作成する関数群\n\nduration(90, \"seconds\") # 90秒のperiod\n## [1] \"90s (~1.5 minutes)\"\n\nnow() + duration(10, \"years\") # 10年後\n## [1] \"2035-03-29 19:47:50 +09\"\n\nnow() + years(10) # 上と同じ\n## [1] \"2035-03-29 07:47:50 +09\"\n\nnow() + months(20) # 20ヶ月後\n## [1] \"2026-11-29 07:47:50 +09\"\n\nnow() + days(30)\n## [1] \"2025-04-28 07:47:50 +09\"\n\nnow() + hours(40)\n## [1] \"2025-03-30 23:47:50 +09\"\n\nnow() + minutes(50)\n## [1] \"2025-03-29 08:37:50 +09\"\n\nnow() + seconds(60)\n## [1] \"2025-03-29 07:48:50 +09\"\n\n\n\n17.13.1 hms関数\n時間に関するperiodクラスのオブジェクトを作成する場合には、ymd関数のように、文字列を自動的にperiodクラスのオブジェクトに変換してくれる関数である、hms関数を用いることができます。hms関数は文字列を時・分・秒を持つperiodクラスのオブジェクトに変換し、返してくれます。ymdとは異なり、hms関数は数値をperiodに変換することはできません。\n\n\n\nhms関数でperiodクラスオブジェクトを作成\n\nhms(\"2:22:22\")\n## [1] \"2H 22M 22S\"\n\nhms(22222) # エラー\n## Warning in .parse_hms(..., order = \"HMS\", quiet = quiet): Some strings failed\n## to parse\n## [1] NA\n\n\n\n\n17.13.2 時間の切り上げ・切り下げ\n日時データを四捨五入する際には、Rのround関数を用いることができます。ただし、切り下げ（floor）や切り上げ（ceiling）の関数は、DateクラスやPOSIXtクラスには対応していません。\n日時の四捨五入・切り下げ・切り上げには、round_date、floor_date、ceiling_date関数を用いることができます。切り上げ等の単位は、unit引数に指定します。\n\n\n\n日時の四捨五入\n\nnow() |&gt; round_date(unit=\"month\") # 月で四捨五入\n## [1] \"2025-04-01 +09\"\n\nnow() |&gt; floor_date(unit=\"hour\") # 時間で切り下げ\n## [1] \"2025-03-29 07:00:00 +09\"\n\nnow() |&gt; ceiling_date(unit=\"hour\") # 時間で切り上げ\n## [1] \"2025-03-29 08:00:00 +09\"\n\n\n\n\n17.13.3 am・pm関数\n日時データが午前か午後かを判別する関数が、am関数とpm関数です。共に論理型（TRUE・FALSE）を返す関数で、引数が午前ならam関数はTRUE、pm関数はFALSEを返します。\n\n\n\nam・pm関数\n\nnow() |&gt; am()\n## [1] TRUE\n\nnow() |&gt; pm()\n## [1] FALSE\n\n\n\n\n17.13.4 interval\nlubridateには、ある期間（interval）を評価するためのクラスとして、Intervalクラスが設定されています。このIntervalクラスのオブジェクトはinterval関数に始めと最後の日時を与えることで作成できます。Intervalの期間の長さはint_length関数で、2つのIntervalクラスオブジェクトに重複があるかどうかはint_overlaps関数を用いて判別できます。\n\n\n\nIntervalの取り扱い\n\nintr1 &lt;-  interval(ymd(\"2023-10-20\"), ymd(\"2023-10-30\"))\nintr2 &lt;-  interval(ymd(\"2023-10-25\"), ymd(\"2023-11-5\"))\n\nintr1 # 始めと最後の日が記録されている\n## [1] 2023-10-20 UTC--2023-10-30 UTC\n\nintr1 |&gt; class() # データ型はInterval\n## [1] \"Interval\"\n## attr(,\"package\")\n## [1] \"lubridate\"\n\nint_length(intr1) # 期間の長さの単位は秒\n## [1] 864000\n\nint_overlaps(intr1, intr2) # 重複があればTRUEが返ってくる\n## [1] TRUE\n\n\n\n\n\n\n\n\nCarpenter, Bob, Andrew Gelman, Matthew D Hoffman, Daniel Lee, Ben Goodrich, Michael Betancourt, Marcus Brubaker, Jiqiang Guo, Peter Li, and Allen Riddell. 2017. “Stan: A Probabilistic Programming Language.” Journal of Statistical Software 76 (1).\n\n\nGrolemund, Garrett, and Hadley Wickham. 2011. “Dates and Times Made Easy with lubridate.” Journal of Statistical Software 40 (3): 1–25. https://www.jstatsoft.org/v40/i03/.\n\n\nIzrailev, Sergei. 2023. Tictoc: Functions for Timing r Scripts, as Well as Implementations of \"Stack\" and \"StackList\" Structures. https://CRAN.R-project.org/package=tictoc.",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>日時データの取り扱い</span>"
    ]
  },
  {
    "objectID": "chapter18.html",
    "href": "chapter18.html",
    "title": "18  オブジェクト指向とクラス",
    "section": "",
    "text": "18.1 クラス\nオブジェクトにはクラスという特性があります。Rでは、数値（numeric）、文字列（character）、論理型（logical）、リスト（list）、行列（matrix、array）、因子（factor）、データフレーム（data.frame）、時系列（ts）などがクラスとして設定されています。クラスはclass関数を用いて確認することができます。\nオブジェクトのクラス\n\n1 |&gt; class()\n## [1] \"numeric\"\n\"a\" |&gt; class()\n## [1] \"character\"\nT |&gt; class()\n## [1] \"logical\"\n\nc(1, 1, 1) |&gt; class() # ベクター自体には特別なクラスはない\n## [1] \"numeric\"\nlist(1, 1, 1) |&gt; class()\n## [1] \"list\"\nmatrix(1:4, nrow = 2) |&gt; class()\n## [1] \"matrix\" \"array\"\n\nfactor(1) |&gt; class()\n## [1] \"factor\"\niris |&gt; class()\n## [1] \"data.frame\"\nNile |&gt; class()\n## [1] \"ts\"\nクラスの役割は、「オブジェクトの型と取扱いの方法」を定めるところにあります。例えばデータフレームであれば、「同じ長さのベクトルのリストで、行と列を持つ表の形をしていて、行と列に名前を登録できるもの」という「型」を持っています。また、plot.data.frame関数のように、データフレームを「取り扱う方法」が準備されています。このように、クラスは「型」と「取り扱い方」をセットにし、データの取り扱いを簡単にする役割を持ちます。\nデータフレームをクラスとするオブジェクトは、この「型」を元にした構造を持ち、値や行・列の数・名前が異なるものになっています。つまり、データフレームという「型」は同じですが、中身が違うものがオブジェクトとして作り出されていることになります。プログラミング言語では、この「型」から作り出されたオブジェクトのことを、インスタンスと呼びます。\nつまり、data.frameはクラスであり、data.frameクラスのオブジェクトであるirisやcarsはインスタンスである、ということになります。",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>オブジェクト指向とクラス</span>"
    ]
  },
  {
    "objectID": "chapter18.html#pythonでのクラスの例",
    "href": "chapter18.html#pythonでのクラスの例",
    "title": "18  オブジェクト指向とクラス",
    "section": "18.2 Pythonでのクラスの例",
    "text": "18.2 Pythonでのクラスの例\nクラスとインスタンスに関しては、他の言語での例を見た方がわかりやすいかと思います。以下はPythonのDocumentationに記載されているDogクラスの定義とインスタンス作成の例です。\nRを含めて、多くのプログラミング言語ではクラスを定義することができます。クラスにはクラス名が必要です（下の例ではDogがクラス名）。クラスを定義するときには、インスタンスの要素（name（名前）とtricks（芸）という2つ）、インスタンスを演算に用いるメソッド、アクセサ（アクセス・メソッド）と呼ばれる、インスタンスの要素を変更する方法（下の例ではadd_trickメソッド、セッター（setter）と呼ばれる）と要素を呼び出す方法（ゲッター（getter））を準備するのが一般的です。\nインスタンスを作成する場合には、クラス名にカッコをつけ、__init__に示した引数（selfはそのオブジェクト自身を指すので、nameが引数）を指定して実行します。下の例ではdog_Fidoとdog_Buddyという2つのインスタンスを作成し、それぞれnameに\"Fido\"、\"Buddy“を設定しています。\n\n# クラスの定義\nclass Dog:\n    # メソッドの定義\n    def __init__(self, name):\n        self.name = name\n        self.tricks = []\n    # アクセサの定義\n    def add_trick(self, trick):\n        self.tricks.append(trick)\n\n# インスタンス（クラスオブジェクト）の作成\ndog_Fido = Dog('Fido')\ndog_Buddy = Dog('Buddy')\n\n\n18.2.1 RとPythonでのクラスの比較\nこれだけではよく分からないと思いますので、もう少し説明を加えます。\nクラスの設定の目的の一つは、データをカプセル化することです。カプセル化というのは、バラバラのデータや取り扱い方法をひとまとめにして、取り扱いやすくすることです。上の例では、犬の名前（name）、芸（trick）と取り扱い方法（メソッド）をひとまとめにしています。こうすることで、その犬の名前と芸をひとまとめ、つまりカプセル化しているわけです。\nRでは、このようなカプセル化を行うのに、リストが用いられています。ですので、非常に単純化すると、カプセル化とはリストみたいなものだと思ってもらうと良いかと思います。\nまた、犬の名前や芸がころころ変わってしまうと、犬の名前とその犬ができる芸の関係を維持するのが難しくなってしまいます。ですので、アクセサを準備して、関数を用いないと名前や芸などの要素を追加・変更できないようにしています。\nRでは、listの要素を変える方法、例えば、リストの要素への代入（セッター）や、リストの要素を呼び出す方法（ゲッター）が、アクセサに当たります。\nオブジェクトを作成すると、そのクラスのオブジェクトとして変数ができます。この変数は、「型」から作られた「もの」、つまりインスタンスになります。下のRの例では、lst_Fiboがリスト（クラス）のオブジェクト（インスタンス）である、ということになります。\n\n# これが__init__に当たる、オブジェクト作成時の方法\nlst_Fibo &lt;- list(name = \"Fibo\", tricks = c(\"ballcatch\", \"zigzag\"))\n\nlst_Fibo$name &lt;- \"Pochi\" # これがアクセサ（セッター）みたいなもの\n\nlst_Fibo$name # これもアクセサ（ゲッター）みたいなもの\n## [1] \"Pochi\"\n\nlst_Fibo # オブジェクトの名前の要素が変わる\n## $name\n## [1] \"Pochi\"\n## \n## $tricks\n## [1] \"ballcatch\" \"zigzag\"\n\nこのように見ると、リストは大体クラスの要件を満たしているように見えます。ただし、リストでは要素の数を自由自在に増やしたり減らしたりすることができます。例えば、登録されている犬の名前（name）を変えたり、tricksを削ってbirthdayを追加する、といったことがリストでは簡単にできてしまいます。このような変換を行うと、Pythonの型（クラス）で定義したものとは違う要素を持つオブジェクトを簡単に作れてしまうことになります。\n他言語のクラスでは、インスタンスごとに取り扱いが変わることがないように、要素の追加や削除は原則できないようになっています。また、クラスの定義を行うときに、要素のデータ型や要素に対する取り扱いの方法（メソッド）を定義しておき、要素の型、取り扱いの方法を厳密に定めておくのが一般的です。このようにクラスの「要素」・「型」・「取り扱い方」を厳密に定めておくことで、そのクラスのインスタンスをいつ用いても同じ方法で取り扱えることを担保しています。\nこのような性質は、「誰が、いつ、どのような形でそのクラスのインスタンスを用いても、同じ方法で取り扱うことができる」ために重要となります。ですので、複数人が関わる大規模な開発や大きなアプリケーション、メンテナンスを常時必要とする長期プロジェクトなどではクラスの厳密な定義が非常に重要となります。\n一方で、Rはその場限りの解析に用いることが多い言語です。もちろん、ライブラリの構築時や、恒常的に組織でメンテナンスし、使い続けるRのプログラムを開発する場合には、クラスの定義と取り扱いは重要となります。ですが、その場限りの解析では、データのカプセル化の役割をリストが十分に果たすことができます。このような理由から、Rでクラスを定義し、用いる方法は（少なくとも簡単な統計解析においては）、あまり重要視されていません。",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>オブジェクト指向とクラス</span>"
    ]
  },
  {
    "objectID": "chapter18.html#rのクラスとアトリビュートattributes",
    "href": "chapter18.html#rのクラスとアトリビュートattributes",
    "title": "18  オブジェクト指向とクラス",
    "section": "18.3 Rのクラスとアトリビュート（attributes）",
    "text": "18.3 Rのクラスとアトリビュート（attributes）\n因子（10章）やデータフレーム（12章）で説明した通り、Rではクラスはアトリビュート（attributes）として設定されています。ただし、クラスは必ずしもアトリビュートとして設定されているわけではありません。クラスにはアトリビュートとして設定されるものと、されていないものがあります。\n数値や文字列、リスト、行列などはアトリビュートとしてクラス名を持たないのに対し、因子やデータフレーム、時系列はアトリビュートとしてクラスが登録されています。\n\n\n\n各クラスに設定されたAttributes\n\n1 |&gt;  attributes()\n## NULL\n\"a\" |&gt; attributes()\n## NULL\nT |&gt; attributes()\n## NULL\n\nc(1, 1, 1) |&gt; attributes()\n## NULL\nlist(1, 1, 1) |&gt; attributes()\n## NULL\nmatrix(1:4, nrow = 2) |&gt; attributes()\n## $dim\n## [1] 2 2\n\nfactor(1) |&gt; attributes()\n## $levels\n## [1] \"1\"\n## \n## $class\n## [1] \"factor\"\niris |&gt; attributes() |&gt; lapply(head)\n## $names\n## [1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\"     \n## \n## $class\n## [1] \"data.frame\"\n## \n## $row.names\n## [1] 1 2 3 4 5 6\nNile |&gt; attributes()\n## $tsp\n## [1] 1871 1970    1\n## \n## $class\n## [1] \"ts\"\n\n\nこのようなアトリビュートの差は、親クラス（superclass、スーパークラス）と呼ばれるものの違いによります。Rを含め、オブジェクト指向の言語では、クラスを定義するときに、他のクラスの定義を流用し、機能や要素等を追加した上で新しいクラスとすることができます。このように、他のクラスの定義を流用することを、継承（inheritance）と呼びます。つまり、数値や文字列、リストなどと、データフレーム、因子、時系列では親クラスが異なるクラスである、ということになります。\nRで親クラスを把握するときに用いる関数として、pryr::otypeがあります(Wickham 2023)。pryr::otypeの引数にオブジェクトを取ると、そのオブジェクトの親クラスを調べることができます。\n\n\n\nplyr::otypeで親クラスを確認する\n\n# 数値、文字列はbaseクラスを親とする\n1 |&gt; pryr::otype()\n## [1] \"base\"\n\"a\" |&gt; pryr::otype()\n## [1] \"base\"\nT |&gt; pryr::otype()\n## [1] \"base\"\n\n# リスト・行列はbaseクラスを親とする\nc(1, 1, 1) |&gt; pryr::otype()\n## [1] \"base\"\nlist(1, 1, 1) |&gt; pryr::otype()\n## [1] \"base\"\nmatrix(1:4, nrow = 2) |&gt; pryr::otype()\n## [1] \"base\"\n\n# 因子・データフレーム・時系列はS3クラスを親とする\nfactor(1) |&gt; pryr::otype()\n## [1] \"S3\"\niris |&gt; pryr::otype()\n## [1] \"S3\"\nNile |&gt; pryr::otype()\n## [1] \"S3\"\n\n\n上のように、数値や文字列、リストなどのアトリビュートにクラスを持たないオブジェクトの親クラスはbase、因子やデータフレーム、時系列などのアトリビュートを持つオブジェクトの親クラスはS3となっています。\nRには、これらの親クラスの他に、S4、R6 (Chang 2021)等の親クラスが存在します。\n\n\n\nS3の例\n\nlm_obj &lt;- lm(iris$Sepal.Length~iris$Sepal.Width)\nlm_obj |&gt; pryr::otype()\n## [1] \"S3\"\n\n\n\n\n\nS4の例\n\npacman::p_load(lme4)\nlme4_obj &lt;- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)\nlme4_obj |&gt; pryr::otype()\n## [1] \"S4\"\n\n\n\n\n\nR6の例\n\npacman::p_load(cmdstanr)\nmod &lt;- \n    file.path(cmdstan_path(), \"examples\", \"bernoulli\", \"bernoulli.stan\") |&gt;\n    cmdstan_model()\nmod |&gt; pryr::otype() # otypeではS3扱い\n## [1] \"S3\"\nmod |&gt; class() # 中身はR6\n## [1] \"CmdStanModel\" \"R6\"\n\n\nRにはこの他にも、reference class（昔はR5として開発されていたものだと思います）、aoos (Warnholz 2017)、S7 (Vaughan et al. 2023)などのオブジェクト指向プログラミングに関するクラスがあります。色々あって混乱しているのは、「S3とS4がイマイチ」と思う人が多かったためでしょう。\nS7を開発しているのがggplot2を開発したHadley Wickhamなので（2023年現在）、いずれはS7が主流になるのかもしれませんが、現状では簡単にRにオブジェクト指向のクラスを持ち込む場合にはS3を、少し複雑なプロジェクトにはS4を用いるのが一般的であるように見えます。特にBioconductorのライブラリではS4のオブジェクトが用いられています。",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>オブジェクト指向とクラス</span>"
    ]
  },
  {
    "objectID": "chapter18.html#rでのs3s4クラスオブジェクトの取り扱い",
    "href": "chapter18.html#rでのs3s4クラスオブジェクトの取り扱い",
    "title": "18  オブジェクト指向とクラス",
    "section": "18.4 RでのS3、S4クラスオブジェクトの取り扱い",
    "text": "18.4 RでのS3、S4クラスオブジェクトの取り扱い\n上に述べたように、Rではライブラリを作成する等の特殊な場合を除いて、クラスを定義することはありません。クラスの定義は入門で学ぶには少し高度な内容となるので、他の文献に説明を譲ります。\nしかし、統計の関数の返り値はS3やS4を親クラスとしたオブジェクトとなっている場合が多いため、オブジェクトの取り扱い方を理解しておくことは統計解析において重要となります。\n典型的なS3の例として線形回帰の結果（lmオブジェクト）、S4の例として線形混合モデルの結果（lmerModオブジェクト、lme4パッケージ (Bates et al. 2015)より）を用いて、オブジェクトの取り扱い方を説明します。\nS3オブジェクトでもS4オブジェクトでも、オブジェクトの内容を確認する場合には、まずstr関数でオブジェクトの構造を理解するところから始めます。\n\n\n\nS3：str関数で構造を確認する\n\nlm_obj |&gt; str(list.len=3) # S3オブジェクト（一部表示）\n## List of 12\n##  $ coefficients : Named num [1:2] 6.526 -0.223\n##   ..- attr(*, \"names\")= chr [1:2] \"(Intercept)\" \"iris$Sepal.Width\"\n##  $ residuals    : Named num [1:150] -0.644 -0.956 -1.111 -1.234 -0.722 ...\n##   ..- attr(*, \"names\")= chr [1:150] \"1\" \"2\" \"3\" \"4\" ...\n##  $ effects      : Named num [1:150] -71.566 -1.188 -1.081 -1.187 -0.759 ...\n##   ..- attr(*, \"names\")= chr [1:150] \"(Intercept)\" \"iris$Sepal.Width\" \"\" \"\" ...\n##   [list output truncated]\n##  - attr(*, \"class\")= chr \"lm\"\n\n\n\n\n\nS4：str関数で構造を確認する\n\nlme4_obj |&gt; str(list.len=3) # S4オブジェクト（一部表示）\n## Formal class 'lmerMod' [package \"lme4\"] with 13 slots\n##   ..@ resp   :Reference class 'lmerResp' [package \"lme4\"] with 9 fields\n##   .. ..$ Ptr    :&lt;externalptr&gt; \n##   .. ..$ mu     : num [1:180] 254 273 293 313 332 ...\n##   .. ..$ offset : num [1:180] 0 0 0 0 0 0 0 0 0 0 ...\n##   .. .. [list output truncated]\n##   .. ..and 28 methods, of which 14 are  possibly relevant:\n##   .. ..  allInfo, copy#envRefClass, initialize, initialize#lmResp,\n##   .. ..  initializePtr, initializePtr#lmResp, objective, ptr, ptr#lmResp,\n##   .. ..  setOffset, setResp, setWeights, updateMu, wrss\n##   ..@ Gp     : int [1:2] 0 36\n##   ..@ call   : language lmer(formula = Reaction ~ Days + (Days | Subject), data = sleepstudy)\n##   .. [list output truncated]\n\n\nどちらもstr関数の引数を指定しない場合にはとても沢山の出力が示されるのですが、特徴としては、\n\n$または@から始まる行がたくさん記載されている\n$・@の後ろに「単語 : データ型」といった表記がある\nS3には$のみ、S4には$と@が記載されている\nところどころにattrという記載がある\nstr関数の引数がS3の時は、1行目に「List of 〇〇」の表記がある\n\nということが分かるかと思います。\n$や@は要素の呼び出しに用いるものです。これらはリストやデータフレームで、名前を用いて要素を呼び出す際の$と同じものです。$・@の後に続き単語はリストやデータフレームの名前に当たるもので、$・@に続けて記載することで要素を呼び出すことができます。S3・S4クラスにはゲッター（getter）の関数が備わっている場合もあり、関数を用いて要素を呼び出せる場合もあります。\n@はS4クラスに特有の呼び出しの記号で、S3クラスでは用いることがありません。attrはattributesの意味で、その要素に付属するattributesを示しています。要素をattributes関数の引数にすることで、そのattributesの内容を取り出すことができます。\n最後に、S3オブジェクトの「List of 〇〇」についてですが、RではS3オブジェクトはデータの登録や関数の適用に特徴のあるリストとして実装されています。データの登録に関しては、S3クラスの定義に従い、型チェック等が組み込まれます。また、アトリビュートにクラスが追加されます。\n関数の適用に関しては、ジェネリック関数を用いて、そのクラスのオブジェクトを引数にした場合の演算が定義されます。このように、関数名は同じだけどオブジェクトのクラスによって出力が異なる性質のことをポリモルフィズムと呼びます。\n以下にS3とS4クラスの値の呼び出しや、関数の適用例を挙げます。\n\n# S3クラス\nlm_obj |&gt; class()\n## [1] \"lm\"\n\n# S3クラス：要素の取り出し\nlm_obj$coefficients\n##      (Intercept) iris$Sepal.Width \n##        6.5262226       -0.2233611\n\n# S3クラス：アトリビュートを読み出す\nlm_obj$coefficients |&gt; attributes()\n## $names\n## [1] \"(Intercept)\"      \"iris$Sepal.Width\"\n\n# S3クラス：関数の引数にする（plot.lmが呼び出されている）\nlm_obj |&gt; plot(which = 1)\n\n\n\n\n\n\n\n\n\n# S4クラス\nlme4_obj |&gt; class()\n## [1] \"lmerMod\"\n## attr(,\"package\")\n## [1] \"lme4\"\n\n# S4クラス：要素の取り出し\nlme4_obj@pp$beta0\n## [1] 0 0\n\n# S4クラス：アトリビュートを読み出す\nlme4_obj@pp$X |&gt; attributes() |&gt; _$dim\n## [1] 180   2\n\n# S4クラス：関数の引数にする（summary.lmerModが呼び出されている）\nsummary(lme4_obj)\n## Linear mixed model fit by REML ['lmerMod']\n## Formula: Reaction ~ Days + (Days | Subject)\n##    Data: sleepstudy\n## \n## REML criterion at convergence: 1743.6\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -3.9536 -0.4634  0.0231  0.4634  5.1793 \n## \n## Random effects:\n##  Groups   Name        Variance Std.Dev. Corr\n##  Subject  (Intercept) 612.10   24.741       \n##           Days         35.07    5.922   0.07\n##  Residual             654.94   25.592       \n## Number of obs: 180, groups:  Subject, 18\n## \n## Fixed effects:\n##             Estimate Std. Error t value\n## (Intercept)  251.405      6.825  36.838\n## Days          10.467      1.546   6.771\n## \n## Correlation of Fixed Effects:\n##      (Intr)\n## Days -0.138\n\n# S4クラス：アクセサ（値を取り出す関数）\ncoef(lme4_obj)\n## $Subject\n##     (Intercept)       Days\n## 308    253.6637 19.6662617\n## 309    211.0064  1.8476053\n## 310    212.4447  5.0184295\n## 330    275.0957  5.6529356\n## 331    273.6654  7.3973743\n## 332    260.4447 10.1951090\n## 333    268.2456 10.2436499\n## 334    244.1725 11.5418676\n## 335    251.0714 -0.2848792\n## 337    286.2956 19.0955511\n## 349    226.1949 11.6407181\n## 350    238.3351 17.0815038\n## 351    255.9830  7.4520239\n## 352    272.2688 14.0032871\n## 369    254.6806 11.3395008\n## 370    225.7921 15.2897709\n## 371    252.2122  9.4791297\n## 372    263.7197 11.7513080\n## \n## attr(,\"class\")\n## [1] \"coef.mer\"\n\n\n\n\n\n\n\nBates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015. “Fitting Linear Mixed-Effects Models Using lme4.” Journal of Statistical Software 67 (1): 1–48. https://doi.org/10.18637/jss.v067.i01.\n\n\nChang, Winston. 2021. R6: Encapsulated Classes with Reference Semantics. https://CRAN.R-project.org/package=R6.\n\n\nVaughan, Davis, Jim Hester, Tomasz Kalinowski, Will Landau, Michael Lawrence, Martin Maechler, Luke Tierney, and Hadley Wickham. 2023. S7: An Object Oriented System Meant to Become a Successor to S3 and S4. https://CRAN.R-project.org/package=S7.\n\n\nWarnholz, Sebastian. 2017. Aoos: Another Object Orientation System. https://CRAN.R-project.org/package=aoos.\n\n\nWickham, Hadley. 2023. Pryr: Tools for Computing on the Language. https://CRAN.R-project.org/package=pryr.",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>オブジェクト指向とクラス</span>"
    ]
  },
  {
    "objectID": "chapter19.html",
    "href": "chapter19.html",
    "title": "19  コーディング規約",
    "section": "",
    "text": "Rに限らず、どのようなプログラミング言語を用いる場合においても、読みやすいコードと読みにくいコードがあります。また、変数や関数の名前はわかりやすくつけておかないと、後々どのような意味の変数・関数であったかを理解しにくくなってしまいます。\nこのような、コードの問題、変数や関数の名前の問題をできるだけ抑えるために、企業などでプログラミングを行う場合には、その組織のコーディング規約（coding style）、つまりコードの書き方のルールを設けるのが一般的です。\nRは大学の研究室などで、教官や学生などが小規模なデータの分析に用いる場合も多いため、コーディング規約は必ずしも重要ではありませんが、コードの可読性を高め、解析の再現性（reproducibility）を担保するためにコーディング規約に基づいたプログラミングを心がけた方が良いでしょう。\nRのコーディング規約では、tidyverseに従ったもの（tidyverse style guide）が主流だと思います。\nRには、styler (Müller and Walthert 2023)やformatR (Xie 2023)という、coding styleを修正してくれるライブラリや、Rstudioのコーディング規約修正（reformat code）のショートカット（Ctrl+Shift+A）などが備わっており、ある程度自動的にフォーマットの修正を行うことができますので、このような機能を用いるのもよいでしょう。\n\n\n\n図1：Rstudioでのフォーマットの修正\n\n\n詳細なRでのコーディング規約の説明は他の文献に譲ります。\n例えば、英語であればtidyverse style guideやGoogle’s R Style Guide、日本語であれば「私たちのR ベストプラクティスの探求」（宋財泫先生、矢内勇生先生）の11章やこのZennのページ、こちらのCoding styleのページなどがコーディング規約の参考になります。\nコーディングスタイル全体については、リーダブルコード (Boswell and Foucher 2012)を読んでみるのが良いでしょう。関数や変数の名前に悩んだ場合には、良い名前を提案してくれるサイト（codic）も役に立ちます。\n\n\n\n\n\n図1：Rstudioでのフォーマットの修正\n\n\n\nBoswell, Dustin, and Trevor Foucher. 2012. リーダブルコード ーより良いコードを書くためのシンプルで実践的なテクニック (Theory in Practice). Translated by 角征典. 単行本（ソフトカバー）. オライリージャパン. https://www.amazon.co.jp/dp/4873115655/.\n\n\nMüller, Kirill, and Lorenz Walthert. 2023. Styler: Non-Invasive Pretty Printing of r Code. https://CRAN.R-project.org/package=styler.\n\n\nXie, Yihui. 2023. formatR: Format r Code Automatically. https://CRAN.R-project.org/package=formatR.",
    "crumbs": [
      "Rでのデータの取り扱い",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>コーディング規約</span>"
    ]
  },
  {
    "objectID": "chapter20.html",
    "href": "chapter20.html",
    "title": "20  グラフ作成：高レベルグラフィック関数",
    "section": "",
    "text": "20.1 高レベルグラフィック関数\nRの高レベルグラフィック関数の一覧を以下の表1に示します。\n表1：高レベルグラフィック関数の一覧\n\n\n関数\nグラフの種類\n\n\n\n\nplot(x, y)\nxとyの散布図\n\n\nplot(tz)\n時系列tzの時系列グラフ\n\n\nplot(factor)\n因子ごとの要素の数の棒グラフ\n\n\nplot(function)\n関数に対応した線グラフ\n\n\nplot(data.frame)\n相関行列の散布図（各列を要素とする）\n\n\ncoplot(x ~ y | z)\nxとyの散布図を因子zで分けて表示\n\n\nhist(x, breaks)\nヒストグラム\n\n\npairs(x, y, z)\n相関行列の散布図\n\n\nboxplot(x ~ y)\n箱ひげ図（yは因子）\n\n\ndotchart(d)\n行列dの散布図\n\n\nimage(x, y, z)\nカラーチャート（ヒートマップ）\n\n\npersp(x, y, z)\n3Dグラフ\n\n\nplot3d(d)\n3Dグラフ（rglパッケージを使用）\n\n\ncontour(x, y, z)\n等高線図",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>グラフ作成：高レベルグラフィック関数</span>"
    ]
  },
  {
    "objectID": "chapter20.html#plot関数",
    "href": "chapter20.html#plot関数",
    "title": "20  グラフ作成：高レベルグラフィック関数",
    "section": "20.2 plot関数",
    "text": "20.2 plot関数\nplot関数は、Rでは最も基本的で、かつ利用範囲の広いグラフ作成関数です。plot関数は典型的なジェネリック関数で、グラフを引数に適した形で表示してくれます。ライブラリを呼び出していない場合、plot関数で呼び出されている関数は以下の30種類です。\n\n\n\nジェネリック関数としてのplot関数\n\nmethods(\"plot\")\n##  [1] plot.acf*           plot.data.frame*    plot.decomposed.ts*\n##  [4] plot.default        plot.dendrogram*    plot.density*      \n##  [7] plot.ecdf           plot.factor*        plot.formula*      \n## [10] plot.function       plot.hclust*        plot.histogram*    \n## [13] plot.HoltWinters*   plot.isoreg*        plot.lm*           \n## [16] plot.medpolish*     plot.mlm*           plot.ppr*          \n## [19] plot.prcomp*        plot.princomp*      plot.profile*      \n## [22] plot.profile.nls*   plot.raster*        plot.spec*         \n## [25] plot.stepfun        plot.stl*           plot.table*        \n## [28] plot.ts             plot.tskernel*      plot.TukeyHSD*     \n## see '?methods' for accessing help and source code\n\n\nライブラリには、そのライブラリで使用するオブジェクトを引数とするのに適した形のplot関数が設定されていることも多く、ライブラリを使用した場合にはこの30種類よりも多くのグラフをplot関数だけで描画することができます。\n\n20.2.1 散布図\nplot関数の引数に、xとyの2つの同じ長さのベクターを数値で取った場合、plot関数は散布図を描画します。xに取った引数が横軸、yに取った引数が縦軸となります。\n\n\n\nplot関数：散布図\n\nx &lt;- 1:10\ny &lt;- 2 * x\nplot(x = x, y = y)\n\n\n\n\n\n\n\n\n\nxとyの関係は、チルダ（~）を用いてformulaの形式で書くこともできます。中学校で習った関数のグラフと同様に、チルダの前が縦軸、チルダの後ろが横軸になります。\n\n\n\nplot関数：formulaで指定\n\nplot(y ~ x)\n\n\n\n\n\n\n\n\n\nplot関数は引数が一つだけでも、グラフを作図してくれます。引数が一つだけの場合、plot関数は値を縦軸に、インデックスを横軸に取ったグラフを作成します。stripchart関数を用いても、同じグラフを作成することができます。\n\n\n\nplot関数：引数が1つの場合\n\nz &lt;- sample(1:10, 10) # 1~10をランダムに並べ替える\nz\n##  [1]  3  2  7  8  5  4 10  1  9  6\n\nplot(z) # 縦軸に値を取るグラフを表示\n\n\n\n\n\n\n\n\n\nplot関数はデータフレーム（もしくは行列）を引数に取ることもできます。2列のデータフレームを引数に取った場合には、1列目をx軸、2列目をy軸とした散布図を描画します。\n\n\n\nplot関数：データフレームを引数に取る\n\ncars |&gt; head() # 車の速度が1列目、停車までの距離が2列目\n##   speed dist\n## 1     4    2\n## 2     4   10\n## 3     7    4\n## 4     7   22\n## 5     8   16\n## 6     9   10\n\nplot(cars) # x軸に速度、y軸に停車までの距離をプロット\n\n\n\n\n\n\n\n\n\n\n\n20.2.2 散布行列図\n2列以上のデータフレーム（もしくは行列）を引数に取った場合には、plot関数は散布行列図（matrix of scatterplots）を表示します。因子は数値に自動的に変換されます。\n\n\n\nplot関数：散布図行列\n\nplot(iris)\n\n\n\n\n\n\n\n\n\n散布行列図には専用の関数である、pairs関数もありますが、plot関数で記述するものと差はありません。\n\n\n\npairs関数で散布図行列\n\npairs(iris)\n\n\n\n\n\n\n\n\n\n\n\n20.2.3 時系列プロット\n時系列（ts）クラスのオブジェクトを引数にした場合、plot関数は横軸に時間、縦軸に値を取った線グラフを表示します。\n\n\n\nplot関数：時系列（ts）を引数に取る\n\nplot(Nile)\n\n\n\n\n\n\n\n\n\ntsクラスに季節性（四半期や12か月）がある場合、単にplot関数の引数に取ると、上記の通り、単に線グラフが返ってきます。\n\n\n\n季節性のあるデータの描画\n\nplot(JohnsonJohnson) # JohnsonJohnsonの4半期ごとの株価\n\n\n\n\n\n\n\n\n\n季節性のある時系列データをdecompose関数の引数に指定すると、時系列データをトレンド、季節性、ランダムな要素に分離してくれます。このdecompose関数の返り値をplot関数の引数に取ると、観察データ、トレンド、季節性、ランダムな要素をそれぞれ線グラフとして表示してくれます。\n\n\n\ndecompose関数と時系列の要素分離\n\nJohnsonJohnson |&gt; decompose() |&gt; plot() # decomposeは時系列のトレンド・季節性・ランダム要素を分ける関数\n\n\n\n\n\n\n\n\n\n\n\n20.2.4 箱ひげ図\nplot関数のxに因子、yに数値を取った場合、plot関数は箱ひげ図を表示します。\n\n\n\nplot関数：箱ひげ図\n\n# x軸が因子、y軸は数値\nplot(x = iris$Species, y = iris$Sepal.Length)\n\n\n\n\n\n\n\n\n\n箱ひげ図の記述する専用の関数として、Rにはboxplot関数が設定されています。boxplot関数を用いた場合、数値ベクターを引数に取り、その数値ベクターに対応した箱ひげ図を記述することができます。plot関数と同様に因子で分割した箱ひげ図を記載することもできますが、分割する場合、boxplot関数では引数をformulaで設定する必要があります。\n\n\n\nboxplot関数で箱ひげ図を描画\n\nboxplot(iris$Sepal.Length) # 数値ベクターを引数に取ることもできる\n\n\n\n\n\n\n\n\nboxplot(iris$Sepal.Length ~ iris$Species) # plot関数とは異なり、formulaを引数に取る\n\n\n\n\n\n\n\n\n\n\n20.2.5 因子と棒グラフ\nplot関数では因子ベクターを一つだけ引数に取ることもできます。因子を引数に取った場合には、各レベルの要素の数（度数）を棒グラフで表示します。\n\n\n\nplot関数：度数を棒グラフで描画\n\nfct &lt;- sample(c(\"dog\", \"cat\", \"pig\"), 50, replace = T) |&gt; factor()\nfct |&gt; summary()\n## cat dog pig \n##  14  16  20\n\nplot(fct)\n\n\n\n\n\n\n\n\n\nplot関数の引数に2つの因子を取ると、モザイク図（mosaic plot）が表示されます。棒グラフの横幅、縦軸ともに各レベルの要素の数を反映しています。\n\n\n\nplot関数：モザイク図\n\n# シロイヌナズナの場所ごとの集団と発芽の方法の関係\nplot(lme4::Arabidopsis$popu, lme4::Arabidopsis$status)\n\n\n\n\n\n\n\n\n\n\n\n20.2.6 確率密度\nRでは、データの分布をカーネル密度に変換し、プロットすることもできます。density関数は数値データをカーネル密度に変換する関数です。density関数の返り値をplot関数の引数に取ると、カーネル密度に変換した数値データの分布が線グラフで表示されます。\n\n\n\ndensity関数と確率密度\n\niris$Sepal.Length |&gt; density() |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\n20.2.7 関数の作図\nplot関数を用いれば、定義した関数をそのままグラフにすることもできます。functionで関数を作成し、この関数をplot関数の引数に取ると、plot関数は作成した関数の引数をx軸に、関数の返り値をy軸に取った線グラフを作成します。\n\n\n\nplot関数：関数の描画\n\nfun1 &lt;- function(x){sin(x)}\nplot(fun1, xlim = c(-pi, pi)) # xlimはx軸の範囲を指定する引数\n\n\n\n\n\n\n\n\nplot(\\(x){cos(x)}, xlim = c(-pi, pi)) # \\で作成した無名関数も使える\n\n\n\n\n\n\n\n\n同様の関数の作図は、curve関数を用いても記述することができます。\n\n\n\ncurve関数で関数を描画\n\ncurve(sin, -pi, pi) # sin関数を-piからpiまで記述\n\n\n\n\n\n\n\n\n\n\n\n20.2.8 ステップ関数（step functions）\nstepfun関数は2つの数値ベクターからステップ関数という、階段状になった値の列を返す関数です。引数xがx軸上の位置、引数yはy軸上の値を示します。このstepfun関数の返り値をplot関数の引数に取ると、ステップ関数が表示されます。\n\n\n\nstepfunでステップ関数を描画する\n\nx &lt;- 1:10\ny &lt;- sample(c(1:3), 11, replace = T)\nstepfun(x, y) # stepfunクラスのオブジェクトを作成\n## Step function\n## Call: stepfun(x, y)\n##  x[1:10] =      1,      2,      3,  ...,      9,     10\n## 11 plateau levels =      1,      3,      1,  ...,      2,      3\n\nstepfun(x, y) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\n20.2.9 plot関数の引数一覧\nplot関数では、x軸・y軸を示す引数以外にも、軸ラベルやグラフの主題、散布図の点の形やグラフの表記のタイプなど、様々なグラフの要素を調整するための引数を指定することができます。引数の一覧を以下の表2に示します。\n\n\n\n表2：plot.default関数の引数一覧\n\n\n\n\n\n\n\n\n引数\n引数のデータ型\n引数の意味\n指定の例\n\n\n\n\ntype\n文字列\nプロットの形式\ntype =“l” や type=“p”など\n\n\ncol\n文字列\nプロットの色\ncol=“red”やcol=“#111111”など\n\n\nbg\n文字列\n背景色\nbg=“red”\n\n\npch\n数値\nプロットの形\npch=2\n\n\ncex\n数値\nプロットの大きさ\ncex=2\n\n\nlty\n数値\n線の種類（実線、点線など）\nlty = 1\n\n\nlwd\n数値\n線の太さ\nlwd=2\n\n\nxlim\n数値ベクター\nx軸の範囲指定\nxlim=c(0, 10)\n\n\nylim\n数値ベクター\ny軸の範囲指定\nylim=c(0, 10)\n\n\nlog\n文字列\n軸の対数変換\n“x”, “y”, “xy”\n\n\nmain\n文字列\nグラフの主題\nmain=“irisのグラフ”\n\n\nsub\n文字列\nグラフの副題\nsub=“Petal.Lengthのグラフ”\n\n\nxlab\n文字列\nx軸の軸ラベル\nxlab=“Petal.Length”\n\n\nylab\n文字列\ny軸の軸ラベル\nylab=“Petal.Width”\n\n\nann\n論理型\nラベルを表記するか\nann = FALSE\n\n\naxes\n論理型\n軸を表記するか\naxis = FALSE\n\n\nframe.plot\n論理型\nグラフの枠を表記するか\nframe.plot = FALSE\n\n\npanel.first\nexpression\nグリッド表示を下から重ねる\npanel.first=grid()\n\n\npanel.last\nexpression\nグリッド表示を上から重ねる\npanel.last=grid()\n\n\nasp\n数値\nxとyのアスペクト比\nasp=5\n\n\nxgap.axis\n数値\nx軸ラベルの記載間隔\nxgap.axis=10\n\n\nygap.axis\n数値\ny軸ラベルの記載間隔\nygap.axis=10\n\n\n\n\n\nplot関数のtype引数には、以下の文字列を設定できます。設定する文字列の一覧を以下の表3に示します。\n\n\n\n表3：type引数の一覧\n\n\ntype引数の指定\n意味\n\n\n\n\n“p”\n点（points）\n\n\n“l”\n線（lines）\n\n\n“b”\n点と線\n\n\n“c”\n線（点の部分は空白になる）\n\n\n“o”\n点と線（点に線が重なる）\n\n\n“s”\nステップ関数\n\n\n“h”\nヒストグラム風の棒グラフ\n\n\n“n”\n何も表示しない\n\n\n\n\n\nplot関数のpch引数には、数値（または文字列）を設定します。数値によって、プロットされる点の形が変化します。指定できる点の形は以下の通りです。",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>グラフ作成：高レベルグラフィック関数</span>"
    ]
  },
  {
    "objectID": "chapter20.html#hist関数ヒストグラム",
    "href": "chapter20.html#hist関数ヒストグラム",
    "title": "20  グラフ作成：高レベルグラフィック関数",
    "section": "20.3 hist関数：ヒストグラム",
    "text": "20.3 hist関数：ヒストグラム\nデータの分布を棒グラフで示すヒストグラムを表示する場合には、hist関数を用います。hist関数は数値のベクターを引数に取り、数値ごとの度数を棒グラフにした形で表示します。このとき、度数は数値の等間隔の範囲ごとに数えます。この等間隔の範囲（棒）の数のことを、binsやbreaksと呼びます。hist関数では、breaks引数でこのbreaks、棒グラフの棒の数を指定します。また、freq引数をFALSEに指定すると、縦軸を確率密度で表示することができます。\n\n\n\nhist関数でヒストグラムを描画\n\nhist(iris$Sepal.Length) # デフォルトではちょうどよい感じで分割してくれる\n\n\n\n\n\n\n\n\nhist(iris$Sepal.Length, freq = FALSE, breaks = 15) # 縦軸は確率密度、15分割したヒストグラム\n\n\n\n\n\n\n\n\nbreaksは数値ベクターで指定することもできます。数値で指定した場合には、数値の間隔が棒グラフの幅となり、数値ベクターの長さ-1が棒の数となります。\n\n\n\nbreaks関数でヒストグラムの幅指定\n\nhist(iris$Sepal.Length, breaks = c(4, 5, 6, 8))",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>グラフ作成：高レベルグラフィック関数</span>"
    ]
  },
  {
    "objectID": "chapter20.html#coplot関数",
    "href": "chapter20.html#coplot関数",
    "title": "20  グラフ作成：高レベルグラフィック関数",
    "section": "20.4 coplot関数",
    "text": "20.4 coplot関数\ncoplot関数は、2数の関係を示すグラフを、因子で分割して表示するための関数です。coplot関数ではformulaでx軸、y軸の数値を指定します（「y軸の値 ~ x軸の値」の形で指定）。グラフを分割するための因子は、formulaの後に、|を挟んで指定します。\n\n\n\ncoplot関数で因子ごとに分けたグラフを作成\n\ncoplot(iris$Sepal.Length ~ iris$Sepal.Width | iris$Species)",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>グラフ作成：高レベルグラフィック関数</span>"
    ]
  },
  {
    "objectID": "chapter20.html#qqプロット",
    "href": "chapter20.html#qqプロット",
    "title": "20  グラフ作成：高レベルグラフィック関数",
    "section": "20.5 qqプロット",
    "text": "20.5 qqプロット\n数値が正規分布しているのか確認するために、正規分布に従った分位点とデータの分位点の関係をプロットするグラフを、qqプロットと呼びます。qqプロットでは、データが正規分布する場合、点が概ね直線上に乗ります。\nRでqqプロットを表示するための関数が、qqnorm関数です。qqnorm関数は数値ベクターを引数に取り、縦軸にデータの分位点、横軸に正規分布を仮定したときの分位点を示します。\n\n\n\nqqnorm関数でqqプロットを作成\n\nqqnorm(iris$Sepal.Length) # 概ね正規分布するときは、直線に乗る\n\n\n\n\n\n\n\n\nqqnorm(runif(1000, 0, 1)) # 一様分布すると、直線に乗らない\n\n\n\n\n\n\n\n\n正規分布ではなく、自分で指定した分布との比較を行いたい場合や、2つの数値の間での分布が一致するかどうか確かめるために用いるのが、qqplot関数です。qqplot関数は引数として数値ベクターを2つ取ります。qqplot関数では、2つの数値ベクターの長さが同じである必要はありません。\n\n\n\nqqplot関数でデータの分布を評価する\n\nqqplot(iris$Sepal.Length, iris$Sepal.Width) # どちらも同じ分布に近いため、直線上に乗る\n\n\n\n\n\n\n\n\nqqplot(iris$Sepal.Length, rchisq(1000, 5)) # Sepal.Lengthはカイ二乗分布とは分布が異なるため、直線に乗らない",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>グラフ作成：高レベルグラフィック関数</span>"
    ]
  },
  {
    "objectID": "chapter20.html#dotchart関数ドットプロット",
    "href": "chapter20.html#dotchart関数ドットプロット",
    "title": "20  グラフ作成：高レベルグラフィック関数",
    "section": "20.6 dotchart関数：ドットプロット",
    "text": "20.6 dotchart関数：ドットプロット\ndotchart関数は、クリーブランドドットプロットと呼ばれるグラフを作成するための関数です。このグラフは、カテゴリごとの値を点で示したもので、カテゴリや因子間で値を比較するときに用いられるものです。\n\n\n\ndotchart関数でクリーブランドドットプロットを作成\n\ndotchart(WorldPhones[, 1:4])",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>グラフ作成：高レベルグラフィック関数</span>"
    ]
  },
  {
    "objectID": "chapter20.html#barplot関数棒グラフ",
    "href": "chapter20.html#barplot関数棒グラフ",
    "title": "20  グラフ作成：高レベルグラフィック関数",
    "section": "20.7 barplot関数：棒グラフ",
    "text": "20.7 barplot関数：棒グラフ\nbarplot関数は棒グラフを表示するための関数です。barplot関数は数値ベクターを引数に取り、ベクターのそれぞれの値を棒グラフで表示します。引数を行列で与えると、積み上げ式棒グラフを作図することもできます。\n\n\n\nbarplot関数で棒グラフを描画\n\nv &lt;- c(first = 1, second = 2, third = 3)\nbarplot(v)\n\n\n\n\n\n\n\n\nv2 &lt;- c(first = 2, second = 4, third = 6)\ncbind(v, v2) # 行列\n##        v v2\n## first  1  2\n## second 2  4\n## third  3  6\n\nbarplot(cbind(v, v2)) # 積み上げ式棒グラフ",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>グラフ作成：高レベルグラフィック関数</span>"
    ]
  },
  {
    "objectID": "chapter20.html#pie関数円グラフ",
    "href": "chapter20.html#pie関数円グラフ",
    "title": "20  グラフ作成：高レベルグラフィック関数",
    "section": "20.8 pie関数：円グラフ",
    "text": "20.8 pie関数：円グラフ\npie関数は円グラフを表示するための関数です。pie関数もbarplot関数と同じく、数値のベクターを引数に取り、数値を反映した円グラフを表示します。ただし、このpie関数のヘルプにも記載されている通り（「Pie charts are a very bad way of displaying information.」）、円グラフは理解しにくく、良いグラフであるとは考えられていません。円グラフで表示せずにドットプロット、棒グラフを用いて示した方がよいでしょう。\n\n\n\npie関数で円グラフを描画\n\n(v &lt;- sample(1:10, 5))\n## [1]  6 10  7  2  4\npar(mar = c(0.5, 0.5, 0.5, 0.5))\npie(v)",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>グラフ作成：高レベルグラフィック関数</span>"
    ]
  },
  {
    "objectID": "chapter20.html#image関数ヒートマップ",
    "href": "chapter20.html#image関数ヒートマップ",
    "title": "20  グラフ作成：高レベルグラフィック関数",
    "section": "20.9 image関数：ヒートマップ",
    "text": "20.9 image関数：ヒートマップ\nimage関数は行列を引数に取り、行列の位置（行・列）とその値の関係を色で示したグラフを表示する関数です。このようなグラフはヒートマップと呼ばれます。\n\n\n\nimage関数でヒートマップ作成\n\nimage(volcano) # 火山の緯度・軽度と標高の関係\n\n\n\n\n\n\n\n\niris[,1:4] |&gt; as.matrix() |&gt; image() # 行列であればヒートマップにできる",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>グラフ作成：高レベルグラフィック関数</span>"
    ]
  },
  {
    "objectID": "chapter20.html#persp関数3次元グラフ",
    "href": "chapter20.html#persp関数3次元グラフ",
    "title": "20  グラフ作成：高レベルグラフィック関数",
    "section": "20.10 persp関数：3次元グラフ",
    "text": "20.10 persp関数：3次元グラフ\npersp関数は3次元グラフを作成するための関数です。x軸、y軸、z軸の値をそれぞれ数値ベクターとして引数に指定し、thetaとphiの2つの引数で、3次元グラフを観察する視点を指定します。ただし、このpersp関数では3次元グラフの視点を動かすのが難しいため、Rではかなり前からrglパッケージ (Murdoch and Adler 2023)を用いて3次元グラフを描画するのが一般的です。\n\n\n\npersp関数で3次元グラフ\n\npar(mar = c(0.5, 0.5, 0.5, 0.5))\npersp(x = 1:nrow(volcano), y = 1:ncol(volcano), z = volcano, theta = 45, phi = 30, expand = 0.5)",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>グラフ作成：高レベルグラフィック関数</span>"
    ]
  },
  {
    "objectID": "chapter20.html#rglパッケージ3次元グラフ",
    "href": "chapter20.html#rglパッケージ3次元グラフ",
    "title": "20  グラフ作成：高レベルグラフィック関数",
    "section": "20.11 rglパッケージ：3次元グラフ",
    "text": "20.11 rglパッケージ：3次元グラフ\nrglパッケージは、OpenGL (Woo et al. 1999)という、C言語の3Dグラフィックスライブラリを使用したRのグラフ作成ライブラリです。rglパッケージの関数群を用いることで、R上でマウスを使って視点をグリグリ動かすことができる3次元グラフを作成することができます。\n\n\n\nrglパッケージで3次元グラフ\n\npacman::p_load(rgl)\np_iris3d &lt;- plot3d(iris$Sepal.Length, iris$Sepal.Width, iris$Petal.Length, col = as.numeric(iris$Species))\n\nrglwidget(elementId = \"plot3drgl\")\n\n\n\n\n\n\n\n\n\n\n\n\n3次元グラフについて\n\n\n\n\n\nRに限らず、3次元グラフを作成できると何か楽しいような気がします。しかし、データ解析においては3次元グラフではデータを理解しにくく、数値を直感的に比較することが困難です。「3次元グラフでなければ表現できない」などの非常に特別な場合を除けば、3次元グラフの利用は避けた方が良いでしょう。",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>グラフ作成：高レベルグラフィック関数</span>"
    ]
  },
  {
    "objectID": "chapter20.html#contour関数等高線グラフ",
    "href": "chapter20.html#contour関数等高線グラフ",
    "title": "20  グラフ作成：高レベルグラフィック関数",
    "section": "20.12 contour関数：等高線グラフ",
    "text": "20.12 contour関数：等高線グラフ\ncontour関数はimage関数と同様に行列を引数に取り、x軸に列、y軸に行、高さとして行列の値を用いた等高線グラフを作成するための関数です。\n\n\n\ncontour関数で等高線グラフを描画\n\ncontour(volcano)\n\n\n\n\n\n\n\n\n\nfilled.contour関数を用いると、等高線に加えて、image関数と同様の色での表現を加えることができます。\n\n\n\nfilled.contour関数で色付き等高線グラフを描画\n\nfilled.contour(volcano)",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>グラフ作成：高レベルグラフィック関数</span>"
    ]
  },
  {
    "objectID": "chapter20.html#デバイス",
    "href": "chapter20.html#デバイス",
    "title": "20  グラフ作成：高レベルグラフィック関数",
    "section": "20.13 デバイス",
    "text": "20.13 デバイス\nRStudioを用いるときにはあまり意識する必要がない概念ですが、R GUIを用いてグラフを作成するときには、デバイスというものを理解することが重要となります。デバイスとは、グラフを描画するときの「キャンパス」に当たるもので、この「キャンパス」にグラフを描画して、「キャンパス」を表示したり、PDFやJEPGのようなファイル形式として出力したりすることができます。デバイスは、絵を描く時に「キャンパス」を複数準備することができるのと同じように、複数準備することができます。また、グラフを描画したデバイス上に、もう一枚グラフを重ね書きすることもできます。\n上記の高レベルグラフィック関数は、呼び出した際に自動的にデバイスを作成し、そのデバイス上にグラフを描画、表示しています。\nデバイスを作成する関数が、dev.new関数です。dev.new関数を引数なしで指定することで、新しいデバイスを作成することができます。この新しく作成したデバイスには何も描画されていません。dev.new関数を呼び出すたびに、新しいデバイスが作成されます。\n\n\n\nデバイスの作成\n\ndev.new() # device 2を作成\ndev.new() # device 3を作成\ndev.cur() # 現在のデバイス（3が返ってくる）\ndev.list() # デバイスのリスト（2と3が返ってくる）\nplot(1:10) # device 3にプロットを描画\n\n\n作成したデバイスを閉じるための関数が、dev.off関数です。dev.off関数では、後に作成したデバイスから閉じていきます。ですので、上の例のように、2枚のデバイス（device 2 とdevice 3）を作成していた場合には、dev.off関数によりまずdevice 3 が閉じられて、次にdev.off関数を呼ぶとdevice 2 が閉じ、すべてのデバイスが閉じられることになります。\n複数のデバイスが存在している時に、すべてのデバイスを閉じる関数が、graphics.off関数です。dev.new関数で複数のデバイスを開いていても、graphics.off関数を呼び出せばすべてのデバイスを一度に閉じることができます。\n\n\n\ndev.off関数とgraphics.off関数\n\ndev.off() # device 3を閉じる\ndev.off() # device 2を閉じる\ngraphics.off() # デバイスをすべて閉じる\n\n\n\n20.13.1 OSごとのデバイス\nRでは、OS（Windows、UNIX、MacOX）ごとのデバイス呼び出し関数が設定されています。Windowsではwindows関数、UNIXではX11関数、MacOXではquartz関数が新しいデバイスを作成する際に用いられます。\n\n\n\n各OSでのデバイス操作\n\nwindows() # windowsでのデバイス作成\ndev.off()\n\nX11() # UNIXでのデバイス作成\ndev.off()\n\nquartz() # Macでのデバイス作成\ndev.off()",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>グラフ作成：高レベルグラフィック関数</span>"
    ]
  },
  {
    "objectID": "chapter20.html#グラフをファイルに保存する",
    "href": "chapter20.html#グラフをファイルに保存する",
    "title": "20  グラフ作成：高レベルグラフィック関数",
    "section": "20.14 グラフをファイルに保存する",
    "text": "20.14 グラフをファイルに保存する\nデバイスには、pdfやtiffのような、画像に関するファイルを作成する機能を持つものもあります。例えばpdf関数は引数にファイル名を取るデバイス作成関数で、そのデバイスを引数で指定したファイル名で保存する関数です。デバイスが開いている間は、そのPDFファイルを開いている状態になっており、Windowsなどからアクセスすることはできません。したがって、PDFファイルが完成するのは、そのデバイスを閉じた時になります。\n\n\n\npdf関数でPDFにグラフを出力する\n\npdf(file = \"filename.pdf\") # PDFファイルをデバイスに設定\nplot(1:10)\ndev.off() # plotが保存されたpdfが作成される\n\n\nRには、pdf関数の他に、postscriptファイルとして保存するためのpostscript関数やtiffファイルとして保存するためのtiff関数など、グラフをファイルとして保存するための複数の関数が設定されています。\n以下の表4に、Rでのデバイス操作に関する関数の一覧を示します。\n\n\n\n表4：デバイス操作に関する関数の一覧\n\n\n関数\n関数の意味\n\n\n\n\ndev.new\nデバイスを作成する\n\n\nwindows\nデバイスを作成する（Windows）\n\n\nX11\nデバイスを作成する（UNIX）\n\n\nquartz\nデバイスを作成する（Mac）\n\n\npdf\nPDFデバイスを作成する\n\n\npostscript\npostscriptデバイスを作成する（.eps）\n\n\nbitmap\nbmpデバイスを作成する\n\n\ntiff\ntiffデバイスを作成する\n\n\ndev.cur\n現在のデバイスを返す\n\n\ndev.list\nデバイスの一覧を返す\n\n\ndev.off\nデバイスを閉じる\n\n\ngraphics.off\nデバイスをすべて閉じる",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>グラフ作成：高レベルグラフィック関数</span>"
    ]
  },
  {
    "objectID": "chapter20.html#グラフの重ね書き",
    "href": "chapter20.html#グラフの重ね書き",
    "title": "20  グラフ作成：高レベルグラフィック関数",
    "section": "20.15 グラフの重ね書き",
    "text": "20.15 グラフの重ね書き\n同じデバイス上に2つのグラフを重ね書きする場合には、「par(new = T)」を2つの高レベルグラフィック関数の間に置きます。この「par(new = T)」は、デバイスは以前にグラフを描画したものと同じものを利用して、グラフを重ね書きすることを指示するための関数です。ただし、この重ね書きでは、プロットの横軸と縦軸のレンジが同じになるよう調整はしてくれないので、高レベルグラフィック関数内で軸のレンジ等をあらかじめ設定する必要があります。\n\n\n\npar(new=T)でグラフを重ね書きする\n\nplot(1:10)\npar(new = T)\nplot(1:10, c(1:5, 1:5), col = \"red\") # 軸がずれたグラフが重ね書きされる\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMurdoch, Duncan, and Daniel Adler. 2023. Rgl: 3D Visualization Using OpenGL. https://CRAN.R-project.org/package=rgl.\n\n\nSarkar, Deepayan. 2008. Lattice: Multivariate Data Visualization with r. New York: Springer. http://lmdvr.r-forge.r-project.org.\n\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with r, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n\nVanderkam, Dan, JJ Allaire, Jonathan Owen, Daniel Gromer, and Benoit Thieurmel. 2018. Dygraphs: Interface to ’Dygraphs’ Interactive Time Series Charting Library. https://CRAN.R-project.org/package=dygraphs.\n\n\nWoo, Mason, Jackie Neider, Tom Davis, and Dave Shreiner. 1999. OpenGL Programming Guide: The Official Guide to Learning OpenGL, Version 1.2. Addison-Wesley Longman Publishing Co., Inc.",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>グラフ作成：高レベルグラフィック関数</span>"
    ]
  },
  {
    "objectID": "chapter21.html",
    "href": "chapter21.html",
    "title": "21  グラフ作成：低レベルグラフィック関数とグラフィックパラメータ",
    "section": "",
    "text": "21.1 points関数\npoints関数は、すでに存在するグラフに点を追加するための関数です。points関数はxとyの2つの引数を取り、そのx、yが示す場所に点を追加します。\npoint関数で点を描画\n\nplot(x = 0, y = 0, type = \"n\", xlab = \"\", ylab = \"\") # 軸だけのプロット\npoints(x = 0, y = 0) # x=0, y=0に点を追加",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>グラフ作成：低レベルグラフィック関数とグラフィックパラメータ</span>"
    ]
  },
  {
    "objectID": "chapter21.html#text関数",
    "href": "chapter21.html#text関数",
    "title": "21  グラフ作成：低レベルグラフィック関数とグラフィックパラメータ",
    "section": "21.2 text関数",
    "text": "21.2 text関数\ntext関数は、グラフに文字を追加するための関数です。text関数はx、yとlabelの3つの引数を取り、そのx、yが示す場所にlabelsで指定した文字列を追加します。\n\n\n\ntext関数でテキスト表示\n\nplot(x = 0, y = 0, type = \"n\", xlab = \"\", ylab = \"\")\ntext(x = 0, y = 0, labels = \"added text\") # x=0, y=0にテキストを追加",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>グラフ作成：低レベルグラフィック関数とグラフィックパラメータ</span>"
    ]
  },
  {
    "objectID": "chapter21.html#abline関数",
    "href": "chapter21.html#abline関数",
    "title": "21  グラフ作成：低レベルグラフィック関数とグラフィックパラメータ",
    "section": "21.3 abline関数",
    "text": "21.3 abline関数\nabline関数はグラフに直線を追加するための関数です。abline関数の引数の指定方法には以下の4種類があります。\n\n切片（引数a）と傾き（引数b）を指定する\n横線のy軸の位置（引数h）を指定する\n縦線のx軸の位置（引数v）を指定する\n線形回帰の結果（引数coef）を指定する\n\n\n\n\nabline関数で直線を引く\n\nplot(x = 0, y = 0, type = \"n\", xlab = \"\", ylab = \"\")\nabline(a = -0.5, b = 2, col = \"red\") # y = 2 x - 0.5 の線を追加\nabline(h = 1, col = \"blue\") # y = 1 の水平線を追加\nabline(v = -1, lty = 2, col = \"darkgreen\") # x = -1 の縦線（点線）を追加",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>グラフ作成：低レベルグラフィック関数とグラフィックパラメータ</span>"
    ]
  },
  {
    "objectID": "chapter21.html#多角形図形矢印を追加",
    "href": "chapter21.html#多角形図形矢印を追加",
    "title": "21  グラフ作成：低レベルグラフィック関数とグラフィックパラメータ",
    "section": "21.4 多角形・図形・矢印を追加",
    "text": "21.4 多角形・図形・矢印を追加\nグラフ上に多角形や長方形、図形、矢印を追加する場合には、それぞれpolygon関数、rect関数、symbols関数、arrows関数を用います。\npolygon関数は、引数xとyに数値のベクターを取り、そのベクターで指定したx、yの点を繋げた多角形を追加する関数です。始点と終点が一致していれば閉じた多角形を、一致していなければ閉じていない多角形を描画します。\nrect関数は長方形を追加するための関数です。rect関数では、引数xleft、xrightで長方形の左端、右端、引数ybottom、ytopで長方形の下端、上端を指定します。\nsymbols関数は引数x、yに指定した位置に図形を追加するための関数です。symbols関数で指定できる図形は、円（circles）、正方形（squares）、長方形（rectangles）、星（stars）、温度計（thirmometers）、箱ひげ図（boxplot）です。図形名を引数に取り、数値で図形の詳細を指定することでそれぞれの図形を描画できます。\narrows関数は矢印を追加するための関数です。arrows関数の始めの2つの引数（x0とy0）には矢印の始点の座標を、3つ目と4つ目の引数（x1とy1）には矢印の終点の座標をそれぞれ指定します。\n\n\n\n様々な図形の描画\n\npar(mai = c(0.1, 0.1, 0.1, 0.1))\nplot(x = 0, y = 0, type = \"n\", xlab = \"\", ylab = \"\", axes = FALSE)\npolygon( # 多角形（星形）を追加\n  x = c(0, 0.2245, 0.9511, 0.3633, 0.5878, 0, -0.5878, -0.3633, -0.9511, -0.2245, 0, 0.2245) * 0.25 - 0.5,\n  y = c(1, 0.309, 0.309, -0.118, -0.809, -0.382, -0.809, -0.118, 0.309, 0.309, 1, 0.309)* 0.25 + 0.5, \n  col = \"#48C9B0\"\n)\n# 長方形を追加\nrect(xleft = 0, xright = 0.5, ybottom = 0.25, ytop = 0.75, col = \"#E74C3C\")\n# 円を追加\nsymbols(x = -0.5, y = -0.5, circles = 0.1, add = TRUE, inches = 0.3, col = \"#5DADE2\")\n# 矢印を追加\narrows(x0 = 0.25, y0 = -0.75, x1 = 0.5, y1 = -0.5, col = \"#A569BD\")",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>グラフ作成：低レベルグラフィック関数とグラフィックパラメータ</span>"
    ]
  },
  {
    "objectID": "chapter21.html#凡例とタイトルの追加",
    "href": "chapter21.html#凡例とタイトルの追加",
    "title": "21  グラフ作成：低レベルグラフィック関数とグラフィックパラメータ",
    "section": "21.5 凡例とタイトルの追加",
    "text": "21.5 凡例とタイトルの追加\nlegend関数は凡例（legend）を追加するための関数です。legend関数はx、y、legendの3つの引数を取り、xとyには凡例の位置を、legendには凡例の説明を示す文字列をそれぞれ引数に取ります。\ntitle関数はグラフのタイトルを追加するための関数です。title関数では、mainとsubの2つの引数にそれぞれメインタイトル、サブタイトルを文字列で指定することで、それぞれのタイトルをグラフに追加することができます。\n\n\n\n凡例（legend）とタイトル（title）の表示\n\nplot(x = 0, y = 0, type = \"n\", xlab = \"\", ylab = \"\")\n# 凡例（legend）を追加\nlegend(x = 0.5, y = -0.5, legend = \"point\", pch = 1)\n# タイトルを追加\ntitle(main = \"メインタイトル\", sub = \"サブタイトル\")",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>グラフ作成：低レベルグラフィック関数とグラフィックパラメータ</span>"
    ]
  },
  {
    "objectID": "chapter21.html#軸とグリッドの操作",
    "href": "chapter21.html#軸とグリッドの操作",
    "title": "21  グラフ作成：低レベルグラフィック関数とグラフィックパラメータ",
    "section": "21.6 軸とグリッドの操作",
    "text": "21.6 軸とグリッドの操作\naxis関数はグラフの縦・横軸を追加するための関数です。axis関数の引数は数値の1～4で、1からそれぞれ下・左・上・右の軸の追加を意味します。\nグリッド線の追加に用いるのがgrid関数です。grid関数を引数無しで指定すれば、すでに記述されている軸ラベルに従いグリッド線を追加してくれます。引数でグリッドの間隔を指定することもできます。\n\n\n\n軸・グリッドの追加\n\n# 軸のないプロットの表示\nplot(x = 0, y = 0, type = \"n\", xlab = \"\", ylab = \"\", axes = FALSE)\naxis(1) # 下に軸を追加\naxis(2) # 左に軸を追加\ngrid() # グリッドを追加",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>グラフ作成：低レベルグラフィック関数とグラフィックパラメータ</span>"
    ]
  },
  {
    "objectID": "chapter21.html#グラフィックパラメータ",
    "href": "chapter21.html#グラフィックパラメータ",
    "title": "21  グラフ作成：低レベルグラフィック関数とグラフィックパラメータ",
    "section": "21.7 グラフィックパラメータ",
    "text": "21.7 グラフィックパラメータ\nRのグラフ作成では、グラフィックパラメータと呼ばれる引数を指定し、点や線、色や軸ラベル等を調整することができます。\nグラフィックパラメータはpar関数の引数として用います。plot関数などの高レベルグラフィック関数では、引数として一部のグラフィックパラメータを使用することもできます。Rのグラフィックパラメータは60以上あり、うまく利用すれば見やすく、理解しやすいグラフを作成することもできます。グラフィックパラメータの一覧を以下の表2に示します。",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>グラフ作成：低レベルグラフィック関数とグラフィックパラメータ</span>"
    ]
  },
  {
    "objectID": "chapter21.html#重ね書きnewt",
    "href": "chapter21.html#重ね書きnewt",
    "title": "21  グラフ作成：低レベルグラフィック関数とグラフィックパラメータ",
    "section": "21.8 重ね書き：new=T",
    "text": "21.8 重ね書き：new=T\n前章で説明した通り、Rではすでに記述しているグラフに、別のグラフを重ね書きすることができます。この重ね書きに用いるのが、new=Tというグラフィックパラメータです。par(new=T)を宣言すると、宣言前に作図したグラフを消去することなく、同じデバイス上に次のグラフが追加されます。\n\n\n\npar(new=T)でグラフの重ね書き\n\nplot(1:10)\npar(new = T) # デバイス上のグラフを消去しない\nplot(10:1, col = \"red\") # 赤のプロットを追加",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>グラフ作成：低レベルグラフィック関数とグラフィックパラメータ</span>"
    ]
  },
  {
    "objectID": "chapter21.html#複数のグラフを1つのデバイスに表示",
    "href": "chapter21.html#複数のグラフを1つのデバイスに表示",
    "title": "21  グラフ作成：低レベルグラフィック関数とグラフィックパラメータ",
    "section": "21.9 複数のグラフを1つのデバイスに表示",
    "text": "21.9 複数のグラフを1つのデバイスに表示\n複数のグラフを1つのデバイス上に描画する場合には、グラフィックパラメータのmfrow引数又はmfcol引数を用います。いずれも引数に2つの数値からなるベクターを取ります。ベクターの1つ目の要素が行方向にデバイスを分割する数、2つ目の要素が列方向にデバイスを分割する数になります。このとき、mfrowとmfcolのいずれを用いても、結果は同じになります。\nグラフィックパラメータとしてpar関数内で引数mfrow又はmfcolを宣言した後、plot関数などの高レベルグラフィック関数を用いてグラフを描画します。plot関数では、引数mfgを用いて、グラフを表示する位置を指定します。位置は引数mfrowで指定した行、列の中で設定します。例えば、mfg=c(2, 3)と指定すると、そのグラフはグラフィックデバイスのうち、2行3列目に描画されます。\n\n\n\n複数のプロットを表示1\n\n# mfcolでもmfrowでも同じ。3行2列にデバイスを分割\npar(mfrow = c(3, 2)) \nplot(1, mfg = c(1, 1)) # 1行1列目のグラフ\nplot(1:10, 1:10, type = \"l\", mfg = c(1, 2)) # 1行2列目のグラフ\nplot(iris$Sepal.Length, iris$Sepal.Width, mfg = c(2, 1)) # 2行1列目のグラフ\nplot(Nile, mfg = c(2, 2))\nhist(iris$Sepal.Length, mfg = c(3, 1))\nboxplot(iris$Petal.Width~iris$Species, mfg = c(3, 2))\n\n\n\n\n\n\n\n\n\n同様のデバイスの分割には、layout関数を用いることもできます。layout関数は行列を引数に取ります。行列の要素は数値で、数値の順にグラフが埋められていきます。\n\n\n\n複数のプロットを表示2\n\nlayout(matrix(c(2, 4, 1, 3), nrow=2)) # 2行2列に分割\nplot(1) # 行列の数値の順番にグラフが描画される\nplot(iris$Sepal.Length, iris$Sepal.Width)\nhist(iris$Sepal.Length)\nboxplot(iris$Sepal.Width~iris$Species)\n\n\n\n\n\n\n\n\n\nグラフの分割には、split.screen関数を用いることもできます。split.screen関数は引数に数値2つのベクターを取ります。1要素目の数値が行数、2要素目の数値が列数を示します。split.screen関数では、screen関数によって描画するグラフの位置を指定します。例えば、screen(n=2)を指定すると、分割したデバイスの2番目の位置に次のグラフが描画されることになります。\n\n\n\nsplit.screen関数でプロットエリアを分割\n\nsplit.screen(c(1, 3)) # 1行3列にデバイスを分割\n\n\n[1] 1 2 3\n\nplot(1) # 1つ目（一番左）に描画\nscreen(n = 2) # 2つ目に描画することを指定\nplot(iris$Sepal.Length, iris$Sepal.Width)\nscreen(n = 3)\nhist(iris$Sepal.Length)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n複数のグラフの表示\n\n\n\n\n\nRのデフォルトの関数群を用いても、上記のように複数のグラフを1つのデバイスにまとめることはできます。ただし、上の図に見られるように、各グラフのラベルやサイズ、タイトルなどをうまく調節するためには、グラフィックパラメータを駆使する必要があります。複数のグラフを一度に表示したい場合には、latticeパッケージやggplot2パッケージを用いることで、デフォルトの関数よりも簡単に複数のグラフをまとめて作成することができます。",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>グラフ作成：低レベルグラフィック関数とグラフィックパラメータ</span>"
    ]
  },
  {
    "objectID": "chapter21.html#マージンの設定",
    "href": "chapter21.html#マージンの設定",
    "title": "21  グラフ作成：低レベルグラフィック関数とグラフィックパラメータ",
    "section": "21.10 マージンの設定",
    "text": "21.10 マージンの設定\nマージン（余白）には、個々のグラフに対するマージンと、デバイスに対するマージンの2つがあります。デバイスにグラフを1つだけ表示する場合には、この2つのマージンは同じ意味を持ちます。\n一方で、上で説明した通り、Rではデバイスを分割して複数のグラフを表示することができます。デバイスを分割する場合には、デバイス全体のマージンとは別に、表示する個々のグラフに対するマージンを設定することができます。\n個々のグラフに対するマージンを設定するグラフィックパラメータはmai、marです。marとmaiの違いは、maiがマージンをインチ単位で設定するのに対し、marは文字の行で設定する点です。いずれも要素が4つの数値ベクターでマージンを設定します。数値ベクターの要素はそれぞれ下、左、上、右のマージンを表したものとなります。\n\n\n\nデフォルトの余白\n\nplot(1)\n\n\n\n\n\n\n\n\n\n\n\n\nmaiで余白の調整\n\npar(mai = c(2, 2, 2, 2))\nplot(1)\n\n\n\n\n\n\n\n\n\nデバイス全体のマージンを設定するグラフィックパラメータがomi、omaです。omiとomaの違いはmai、marと同じで、omiがインチ単位、omaが行単位でマージンを設定する引数です。要素が4つの数値ベクターで設定すること、要素がそれぞれ下、左、上、右のマージンを表すのも、mai、marと同じです。\n\n\n\nデフォルトの余白\n\n# デフォルトの余白\npar(mfcol = c(1, 2))\nplot(1)\nplot(1:10)\n\n\n\n\n\n\n\n\n\n\n\n\nomiで余白の調整\n\n# omiで余白を調整\npar(omi = c(1, 1, 1, 1), mfcol = c(1, 2))\nplot(1)\nplot(1:10)",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>グラフ作成：低レベルグラフィック関数とグラフィックパラメータ</span>"
    ]
  },
  {
    "objectID": "chapter21.html#グラフの色の調整",
    "href": "chapter21.html#グラフの色の調整",
    "title": "21  グラフ作成：低レベルグラフィック関数とグラフィックパラメータ",
    "section": "21.11 グラフの色の調整",
    "text": "21.11 グラフの色の調整\nグラフの色も、グラフィックパラメータを用いることで調整することができます。グラフの色に関わるグラフィックパラメータは、bg、col、col.axis、col.lab、col.main、col.sub、fgです。それぞれ、背景色、点の色、軸の色、軸ラベルの色、メインタイトルの色、サブタイトルの色、枠の色を示します。色の設定を用いると、下のようにグラフの要素の色を変えたグラフを作成することもできます。\n\n\n\nグラフの色の調整\n\npar(bg = \"lightgray\") # 背景色はpar関数で呼び出し\nplot(\n  1:10, \n  cex=3, \n  col = \"red\", # 点の色は赤\n  col.axis = \"blue\", # 軸の数値は青\n  col.lab = \"purple\", #  軸のラベルは紫\n  col.main = \"pink\", # メインタイトルはピンク\n  col.sub = \"orange\", # サブタイトルはオレンジ\n  fg = \"violet\", # 枠の色はバイオレット\n  main = \"メインタイトル\", \n  sub = \"サブタイトル\"\n  )\n\n\n\n\n\n\n\n\n\nRで用いることのできる色については、NCEAS (National Center for Ecological Analysis and Synthesis)が公開しているチートシートに詳しくまとめられています。\n色はベクターで指定することもできます。\n\n\n\nベクターでグラフの色を指定\n\n# Speciesがsetosaなら赤、それ以外は青で表示\nplot(\n  x = iris$Sepal.Length,\n  y = iris$Sepal.Width,\n  col = ifelse(iris$Species == \"setosa\", \"red\", \"blue\")\n  )",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>グラフ作成：低レベルグラフィック関数とグラフィックパラメータ</span>"
    ]
  },
  {
    "objectID": "chapter21.html#インタラクティブグラフィック関数",
    "href": "chapter21.html#インタラクティブグラフィック関数",
    "title": "21  グラフ作成：低レベルグラフィック関数とグラフィックパラメータ",
    "section": "21.12 インタラクティブグラフィック関数",
    "text": "21.12 インタラクティブグラフィック関数\nグラフを描画した後、グラフをクリックすることでその点の値を得る場合には、locator関数を用います。locator関数は引数に数値を取り、その数値の回数だけグラフをクリックし、クリックした位置の値を得ることができます。得た値はxとyのリストで返ってきます。\n\n\n\nlocator関数でクリックした位置の値を取得する\n\nplot(1:10)\nlocator(1) # 1つの点を選ぶ（xとyの値がリストで返ってくる）\n\n\n同様に描画したグラフにテキストなどでラベルを表示するための関数が、identify関数です。identify関数は、x、y、labelsの3つの引数を取ります。x、yにはラベルを表示したい位置、labelsにはそれぞれの点に表示するラベルを文字列で記載します。identify関数はRStudioでは正常に機能せず、RGUIでのみ機能します。\n\n\n\nidentify関数で値を取得する\n\nx &lt;- 1:7\ny &lt;- 1:7\nplot(x, y)\n# 点をクリックすると1~7のラベルが付く（RGUI）\nidentify(x, y, labels = 1:7)",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>グラフ作成：低レベルグラフィック関数とグラフィックパラメータ</span>"
    ]
  },
  {
    "objectID": "chapter22.html",
    "href": "chapter22.html",
    "title": "22  ggplot2",
    "section": "",
    "text": "22.1 aesthetic mapping（aes）\nggplot関数は、引数にaes関数を取ります。このaesはaesthetic（エステティック）mappingの略です。この「エステティック」というのは、美容のエステと同じ言葉で、「美的な」という意味を持ちます。ggplot2では、aes関数内でグラフのx軸、y軸の値などの要素、色や点のサイズ等を指定します。この指定には、ggplot関数の引数であるデータフレームの列名を文字列ではなく、そのまま使用することができます。\n下の例では、データフレームであるirisの列から、Sepal.Lengthをxに、Sepal.Widthをyに設定したものです。aes関数を引数にしてggplot関数を実行すると、点や線などのグラフの要素は表示されませんが、縦と横の軸だけは表示されます。\naesでグラフの要素を指定\n\n# 軸だけが表記される\niris |&gt; ggplot(aes(x = Sepal.Length, y = Sepal.Width))",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter22.html#geom関数",
    "href": "chapter22.html#geom関数",
    "title": "22  ggplot2",
    "section": "22.2 geom関数",
    "text": "22.2 geom関数\nggplot2でグラフを表示するためには、グラフの種類を指定する関数である、geom関数を用いる必要があります。例えば、散布図を描画するためのgeom関数は、geom_point関数です。このgeom関数の中でも、データフレームやaesを設定することができます。ただし、このgeom関数だけでは、グラフを表示することはできません。先程説明した、ggplot関数と組み合わせる必要があります。\n\n\n\ngeom関数\n\n# geom関数だけではグラフを記述できない\ngeom_point(data = iris, aes(x = Sepal.Length, y = Sepal.Width))\n\n\nmapping: x = ~Sepal.Length, y = ~Sepal.Width \ngeom_point: na.rm = FALSE\nstat_identity: na.rm = FALSE\nposition_identity \n\n\ngeom関数は、ggplot関数に+でつなぐ必要があります。まず、データフレームを引数にしたggplot関数を準備し、その関数に足し算でgeom_point関数をつなぎ、ggplot関数内もしくはgeom_point関数内でaesを設定すると、グラフが表示されます。\n\n\n\nggplot関数とgeom関数を+でつなぐ\n\n# geom関数内でaesを設定する\niris |&gt; \n  ggplot() + \n  geom_point(aes(x = Sepal.Length, y = Sepal.Width))\n\n\n\n\n\n\n\n\n\n\n\n\nggplot関数内でaesを指定する\n\n# ggplot関数内でaesを設定する（上と同じ）\niris |&gt; \n  ggplot(aes(x = Sepal.Length, y = Sepal.Width)) + \n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot2の+記号\n\n\n\n\n\nggplot2では、ggplot関数とgeom関数をつなぐために、+の記号を用います。この+はジェネリック関数として設定されており、ggplot2内では足し算とは異なる機能を持ちます。詳しくはggplot2のリファレンスをご一読ください。\n\n\n\n以下の表1に、代表的なgeom関数の一覧を示します。\n\n\n\n表1：代表的なgeom関数\n\n\n\n\n\n\n\ngeom関数\nグラフの種類\naesで必須となる引数\n\n\n\n\ngeom_point\n散布図\nx, y\n\n\ngeom_text\n文字の散布図\nx, y, label\n\n\ngeom_line\n線グラフ（x軸の小さいものからつなぐ）\nx, y\n\n\ngeom_ribbon\nリボン\nxmax, xmin, ymax, ymin（xかyのどちらか）\n\n\ngeom_path\n線グラフ（データフレームの行順につなぐ）\nx, y\n\n\ngeom_step\nステップ関数\nx, y\n\n\ngeom_abline\n直線（傾きと切片で指定）\nintercept, slope\n\n\ngeom_hline\n水平線（横線）\nyintercept\n\n\ngeom_vline\n垂直の線（縦線）\nxintercept\n\n\ngeom_bar\n棒グラフ\nx, y\n\n\ngeom_dotplot\nドットプロット\nx, y（片方のみ）\n\n\ngeom_function\n関数を線形で表記\nfun\n\n\ngeom_boxplot\n箱ひげ図\nx, y（片方でも可）\n\n\ngeom_histogram\nヒストグラム\nx, y（片方のみ）\n\n\ngeom_density\n確率密度\nx, y（片方のみ）\n\n\ngeom_jitter\nジッタープロット\nx, y（片方でも可）\n\n\ngeom_violin\nバイオリンプロット\nx, y（片方でも可）\n\n\ngeom_errorbar\nエラーバー\nxmax, xmin, ymax, ymin\n\n\ngeom_linerange\nエラーバー（横棒無し）\nxmax, xmin, ymax, ymin\n\n\ngeom_pointrange\nフォレストプロット（点と線）\nx, y, xmax, xmin, ymax, ymin\n\n\ngeom_bin_2d\nヒートマップ\nx. y\n\n\ngeom_contour\n等高線\nx, y\n\n\ngeom_map\n地図表記\nmap_id\n\n\ngeom_polygon\n多角形\nx, y",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter22.html#qplot",
    "href": "chapter22.html#qplot",
    "title": "22  ggplot2",
    "section": "22.3 qplot",
    "text": "22.3 qplot\nggplot2には、qplotという関数も準備されています。qplot関数は「Quick plot」の略で、plot関数のように1つの関数だけでグラフの作成が完了します。ただし、このqplot関数で凝ったグラフを作成することは難しいため、現在ではその使用は非推奨とされています。\n\n\n\nqplot関数\n\n# 上と同じグラフをqplotで描画\nqplot(Sepal.Length, Sepal.Width, data = iris, geom=\"point\")\n\n\nWarning: `qplot()` was deprecated in ggplot2 3.4.0.",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter22.html#geom関数群",
    "href": "chapter22.html#geom関数群",
    "title": "22  ggplot2",
    "section": "22.4 geom関数群",
    "text": "22.4 geom関数群\n表1に示した通り、geom関数にはgeom_point以外にもたくさんの関数が設定されています。以下に各geom関数を用いて作成できるグラフを紹介します。\n\n22.4.1 geom_text\ngeom_textは、テキストをグラフ上に表示するための関数です。geom_textはaesにx、y、labelの3つの引数を設定し、そのx、yの位置にlabelで指定した文字列を表示します。\n\n\n\ngeom_text関数\n\niris |&gt; \n  ggplot(aes(x = Sepal.Length, y = Sepal.Width, label = Species)) + \n  geom_text()\n\n\n\n\n\n\n\n\n\n\n\n22.4.2 geom_line\ngeom_lineはaesのx、yに設定した点を結ぶ線、つまり線グラフを描画するための関数です。geom_lineでは、線は必ずxの小さい値から大きい値へと点を繋いでいく形で線が描画されます。\n\n\n\ngeom_line関数\n\neconomics |&gt; \n  ggplot(aes(x = pop, y = pce)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n22.4.3 geom_ribbon\ngeom_ribbonは、幅のあるグラフ（リボン）を描画するための関数です。geom_ribbonはx、ymin、ymaxの3つの引数を取り、xで指定した位置にymin－ymaxの間を幅とするリボンを描画します。引数として、y、xmin、xmaxの3つを取ることもできます。ymin、ymaxを指定した場合にはリボンは横向き、xmin、xmaxを指定した場合にはリボンは縦向きになります。\n\n\n\ngeom_ribbon関数\n\nd &lt;- data.frame(\n  time = time(Nile) |&gt; as.numeric(), \n  Nile100 = Nile |&gt; as.numeric(), \n  Nile90 = Nile |&gt; as.numeric() * 0.9 , \n  Nile110 = Nile |&gt; as.numeric() * 1.1)\n\nd |&gt; \n  ggplot(aes(x = time, ymax = Nile110, ymin = Nile90)) +\n  geom_ribbon()\n\n\n\n\n\n\n\n\n\n\n\n22.4.4 geom_smooth\ngeom_smoothはgeom_point等で表示した点に対して、回帰の式をあてはめ、そのグラフを表示するための関数です。特に引数を指定していない場合、26章で説明するloess回帰をあてはめ、回帰を行った線を表示します。また、95%信頼区間をgeom_ribbonと同様の表記で示します。\n\n\n\ngeom_smooth関数\n\niris |&gt; \n  ggplot(aes(x = Sepal.Length, y = Sepal.Width)) +\n  geom_point(size = 2) +\n  geom_smooth()\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n直線での回帰を行う場合には、引数にmethod=\"lm\"を指定します。また、se引数をFALSEに指定すると、信頼区間の表示を消すことができます。\n\n\n\ngeom_smoothで直線回帰\n\niris |&gt; \n  ggplot(aes(x = Sepal.Length, y = Sepal.Width)) +\n  geom_point(size = 2) +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nデータフレームの因子の列に従ってグラフを分けて回帰したい場合には、aes関数内でgroup引数にその因子を設定します。以下の例ではirisのSpeciesをgroup引数に設定し、アヤメの種ごとに回帰を行っています。\n\n\n\ngroup引数を設定する\n\niris |&gt; \n  ggplot(aes(x = Sepal.Length, y = Sepal.Width, group = Species)) +\n  geom_point(size = 2) +\n  geom_smooth(method = \"lm\")\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\naesにcolorやfillを設定することでも因子ごとに回帰を行うことができます。\n\n\n\ncolor引数やfill引数を設定する\n\niris |&gt; \n  ggplot(aes(x = Sepal.Length, y = Sepal.Width, color = Species, fill = Species)) +\n  geom_point(size = 2) +\n  geom_smooth(method = \"lm\")\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n22.4.5 geom_path\ngeom_pathは、xの大きさに関わらず、データフレームの上の行から線をつなぐ関数です。データフレームを時系列に並べておき、2変数の時間変化を追うような場合に利用します。\ngeom_pathを用いる場合には、一色の線では線のどちらの端が上の行で、どちらが下の行かわからないため、通常は行の順番にそって線の色を変えることになります。色を指定したい場合には、aesの引数にcolorを設定します。colorには、データフレームの列のうち、日時などを設定します。このように設定することで、日時と共に線の色が変わるようなグラフを作成することができます。\n\n\n\ngeom_path関数\n\neconomics |&gt; \n  ggplot(aes(x = uempmed, y = pce, color = date)) +\n  geom_path()\n\n\n\n\n\n\n\n\n\n\n\n22.4.6 geom_step\nRのstep関数を用いた場合と同様のグラフを記述する場合には、geom_step関数を用います。\n\n\n\ngeom_step関数\n\niris |&gt; \n  ggplot(aes(x = 1:150, y = Sepal.Length)) + \n  geom_step()\n\n\n\n\n\n\n\n\n\n\n\n22.4.7 geom_abline、geom_vline、geom_hline\nグラフ上に直線を描く場合には、geom_abline、geom_vline、geom_hlineを用います。geom_ablineは切片（intercept）と傾き（slope）を指定し、その切片・傾きを持つ直線を引くものです。geom_vlineは垂直な線（vertical line）、geom_hlineは水平な線（horizontal line）を描画します。geom_vlineはx軸と交わるため、x軸の切片（xintercept）の設定が必要です。同様にgeom_hlineはy軸と交わるため、y軸の切片（yintercept）を設定します。\n\n\n\ngeom_abline関数など\n\nggplot()+ \n  geom_abline(intercept = 10, slope = -1) +\n  geom_vline(xintercept = 10, color = \"red\") +\n  geom_hline(yintercept = 10, color = \"blue\") +\n  xlim(0, 15) +\n  ylim(0, 15)\n\n\n\n\n\n\n\n\n\n\n\n22.4.8 geom_bar\ngeom_barは、棒グラフを作成するための関数です。geom_barを引数なしで実行すると、ヒストグラムが描画されます。これは、geom_barの引数のうち、stat引数が\"count\"に設定されているためです。このstat引数は、グラフを記述する際に実施する統計的な処理を指定するための引数です。\n\n\n\ngeom_bar関数\n\niris |&gt; \n  ggplot(aes(x = Sepal.Length)) +\n  geom_bar() # ヒストグラムを表示（stat=\"count\"）\n\n\n\n\n\n\n\n\n\n\n\n22.4.9 geom_histogram\nggplot2には、ヒストグラムを描画するための専用の関数である、geom_histogramもあります。ヒストグラムを描くのが目的であれば、こちらのgeom_histogramの方が名前と目的が一致しており、使いやすいかと思います。\n\n\n\ngeom_histogram関数\n\niris |&gt; \n  ggplot(aes(x = Sepal.Length)) +\n  geom_histogram()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\n22.4.10 statの設定\ngeom_bar関数で1つの値に対して1つの棒グラフを描画する、要は通常の棒グラフを描画する場合には、stat=\"identity\"を指定します。棒グラフを描画するときには、まずx軸とy軸の数値・ラベルを含むデータフレームを作成します。\n\n\n\ntidyrd、dplyrでデータフレームの前準備\n\nd &lt;- iris |&gt; \n  group_by(Species) |&gt; \n  summarise(\n    mSepal.Length = mean(Sepal.Length), \n    sSepal.Length = sd(Sepal.Length))\n\nd\n\n\n# A tibble: 3 × 3\n  Species    mSepal.Length sSepal.Length\n  &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;\n1 setosa              5.01         0.352\n2 versicolor          5.94         0.516\n3 virginica           6.59         0.636\n\n\n後は、aesでx軸に配置する値、y軸に配置する値を指定し、geom_bar関数内でstat=\"identity”を指定します。\n\n\n\nstat=\"identity\"を指定\n\nd |&gt; \n  ggplot(aes(x = Species, y = mSepal.Length)) +\n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\n\n\n\n22.4.11 geom_col\nggplot2には、直接棒グラフ（column plot）を描画するための専用の関数である、geom_colもあります。名前から直感的に理解できるなら、こちらを用いてもよいでしょう。\n\n\n\ngeom_col関数\n\nd |&gt; \n  ggplot(aes(x = Species, y = mSepal.Length)) +\n  geom_col()\n\n\n\n\n\n\n\n\n\n\n\n22.4.12 積み上げ式棒グラフ\ngeom_bar関数は積み上げ式棒グラフを作成する際にも用いることができます。積み上げ式棒グラフを描画するときには、特に引数を指定する必要はありませんが、色分けをしないと積み上げたグラフを見分けることができません。積み上げ式グラフを記述するときには、colorとともに、棒の中身の色を設定するfillという引数で、色を指定するのが良いでしょう。\ngeom_barで積み上げ式グラフが記述されるのは、geom_barのposition引数のデフォルトがposition=\"stack\"だからです。position=\"dodge\"を指定すると、横並びにしたグラフが表示されます。\n\n\n\ngeom_bar関数で積み上げ式棒グラフ\n\nd |&gt; \n  ggplot(aes(x = \"1\", y = mSepal.Length, color = Species, fill = Species)) +\n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\n\n\n\n\nposition=\"dodge\"で横並びの棒グラフ\n\nd |&gt; \n  ggplot(aes(x = \"1\", y = mSepal.Length, color = Species, fill = Species)) +\n  geom_bar(stat = \"identity\", position = \"dodge\")\n\n\n\n\n\n\n\n\n\n\n\n22.4.13 geom_dotplot\ngeom_dotplotはドットプロットという、ヒストグラムを点で描いたようなグラフを作成するときに用いる関数です。ドットの数がその値の範囲に存在する値の個数を示します。縦軸の単位がよくわからないものになりますので、通常はヒストグラムの方が使い勝手が良いでしょう。\n\n\n\ngeom_dotplot関数\n\niris |&gt; \n  ggplot(aes(x = Sepal.Length)) +\n  geom_dotplot()\n\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\n\n\n\n\n\n\n22.4.14 geom_density\ngeom_densityはヒストグラムと類似していますが、単に度数を返すのではなく、カーネル密度関数に変換した上で度数分布を示してくれる関数です。geom_densityでは、縦軸の値は確率密度となり、実際のデータが少ない部分にも実際の頻度より高めの確率密度が与えられるため、かなりデータが多い場合以外は正確性に欠くことになります。データが少ない場合にはヒストグラムの方が使い勝手が良いでしょう。\n\n\n\ngeom_density関数\n\niris |&gt; \n  ggplot(aes(x = Sepal.Length)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\n\n22.4.15 geom_freqpoly\nヒストグラムを棒グラフではなく、線で表記するのがgeom_freqpolyです。こちらもヒストグラムほど使い勝手は良くないように思います。\n\n\n\ngeom_freqpoly関数\n\niris |&gt; \n  ggplot(aes(x = Sepal.Length)) +\n  geom_freqpoly()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\n22.4.16 geom_jitter\nデータの分布は単に散布図でも表示できます。ただし、geom_pointで単に表記すると、点が重なってしまって正しいデータ分布を示すことはできません。\n\n\n\ngeom_point関数で点が重なる場合\n\n# geom_pointでは点が重なる\niris |&gt;\n  ggplot(aes(x = Species, y = Sepal.Length, color = Species)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nこのような場合に、点の重なりを抑えるため、データの表示にランダムな幅を持たせるのがgeom_jitterです。xかyのどちらかのみが数値の場合には、数値以外の値には幅を持たせず、両方が数値の場合にはx軸・y軸方向に幅を持たせることになります。ですので、x、yの両方が数値の場合には、点は正確な位置には配置されません。\n\n\n\ngeom_jitter関数で点をバラつかせる\n\niris |&gt; \n  ggplot(aes(x = Species, y = Sepal.Length, color = Species)) +\n  geom_jitter()\n\n\n\n\n\n\n\n\n\n\n\n22.4.17 geom_boxplot\nデータが十分に多い場合には、箱ひげ図を用いてデータの分布を表示することもできます。ggplot2では、geom_boxplotを用いて箱ひげ図を描画することができます。geom_boxplotに数値ベクターを与えれば、自動的に箱ひげ図を描画してくれます。また、lower、upper、middle、 min、maxという引数を与えると、その引数に設定した数値に従い箱ひげ図を描画することもできます。\n\n\n\ngeom_boxplot関数\n\niris |&gt; \n  ggplot(aes(x = Species, y = Sepal.Length)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n22.4.18 geom_violin\n確率密度を90度回転させ、左右対称に配置した形のグラフのことを、バイオリンプロットと呼びます。ggplot2では、このバイオリンプロットをgeom_violinで描画することができます。描画の仕組みはgeom_densityによく似ています。\n\n\n\ngeom_violin関数\n\niris |&gt; \n  ggplot(aes(x = Species, y = Sepal.Length)) +\n  geom_violin()\n\n\n\n\n\n\n\n\n\n\n\n22.4.19 エラーバーの描画：geom_errorbar、geom_linerange、geom_pointrange\nggplot2で結果にエラーバーを付ける時には、geom_errorbarを用います。geom_errorbarでは、aesの引数として、yminとymax、もしくはxminとxmaxを設定します。yminとymaxはy軸方向の、xminとxmaxはx軸方向のエラーバーを設定する際に用います。また、geom_errorbarにはwidthという引数もあり、エラーバーの横棒のサイズを設定することができます。\ngeom_errorbarは通常、geom_pointで描画した点グラフや、geom_barで描画した棒グラフに重ねて表示することで用います。重ね書きする際には、ggplotに+でgeom_pointをつないだ後に、さらに+でgeom_errorbarをつなぐことになります。このように+でつなぐと、ggplot2ではgeom_pointの点グラフの上に、geom_errorbarが重ね描きされます。\n\n\n\nエラーバーを表示する\n\np &lt;- d |&gt; \n  ggplot(\n    aes(\n      x = Species, \n      y = mSepal.Length, \n      ymax = mSepal.Length + sSepal.Length,\n      ymin = mSepal.Length - sSepal.Length))\n\np + geom_point() + geom_errorbar()\n\n\n\n\n\n\n\n\n\ngeom_errorbarではエラーバーに横線が付き、よく見るエラーバーの形となります。ただし、この横線は必ずしも必要なものではありません。横線のないエラーバーを付けたいときには、geom_linerangeを用います。\n\n\n\ngeom_linerange関数でエラーバーをつける\n\np + geom_point() + geom_linerange()\n\n\n\n\n\n\n\n\n\ngeom_errorbarやgeom_linerangeは点が備わっておらず、別途geom_pointで点を書く必要があります。この点と線を同時に描画するのが、geom_pointrangeです。geom_pointrangeを用いると、geom_pointを別途描画しなくても、点とエラーバーが付いたグラフを作成することができます。このような、点と線のみで記述するグラフのことをフォレストプロットと呼び、メタ解析などでよく用いられています。\n\n\n\ngeom_pointrange関数でフォレストプロット\n\np + geom_pointrange()\n\n\n\n\n\n\n\n\n\n棒グラフにもエラーバーを付けることはできます。棒グラフにエラーバーを付ける時には、stat=\"identity\"で指定したgeom_barに、+でgeom_errorbarやgeom_linerangeをつなげます。\n\n\n\n棒グラフにエラーバーをつける\n\np +\n  geom_bar(stat = \"identity\") +\n  geom_linerange()\n\n\n\n\n\n\n\n\n\n\n22.4.19.1 position=“dodge”とエラーバーの位置\n複数のタイプのデータに対して棒グラフを横に並べて描画し、その棒グラフにエラーバーを付けたい、という場合もあります。geom_barのデフォルトはposition=\"stack\"ですので、複数のタイプのデータを表示するときには積み上げ式の棒グラフが描画されます。横に棒グラフを並べる場合には、position=\"dodge\"を指定する必要があります。\nでは、具体的にposition=\"dodge\"の棒グラフにエラーバーを付与する手順を見ていきましょう。まずは、データフレームでデータを準備する必要があります。dplyrやtidyrを用いることで、データの準備を比較的簡単に行うことができます。\n下の例では、irisのSpecies以外のデータ（Sepal.Length、Sepal.Width、Petal.Length、Petal.Width）をpivot_longerを用いて縦持ちに変換し、データ名とSpeciesでグループ化した後、それぞれの平均値と標準偏差を求めています。棒グラフやフォレストプロットの描画の準備では、pivot_longer、group_by、summariseを用いることが多く、データの要約を求める際にも便利な組み合わせです。\n具体的にどのように変換しているのか分かりにくければ、pivot_longerまでと、それ以降を切り離して実行してみると良いでしょう。\n\n\n\n要約したデータの準備\n\nd1 &lt;- \n  iris |&gt; \n  pivot_longer(1:4) |&gt; \n  group_by(name, Species) |&gt; \n  summarise(mvalue = mean(value), svalue = sd(value))\n  \nd1\n\n\n# A tibble: 12 × 4\n# Groups:   name [4]\n   name         Species    mvalue svalue\n   &lt;chr&gt;        &lt;fct&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n 1 Petal.Length setosa      1.46   0.174\n 2 Petal.Length versicolor  4.26   0.470\n 3 Petal.Length virginica   5.55   0.552\n 4 Petal.Width  setosa      0.246  0.105\n 5 Petal.Width  versicolor  1.33   0.198\n 6 Petal.Width  virginica   2.03   0.275\n 7 Sepal.Length setosa      5.01   0.352\n 8 Sepal.Length versicolor  5.94   0.516\n 9 Sepal.Length virginica   6.59   0.636\n10 Sepal.Width  setosa      3.43   0.379\n11 Sepal.Width  versicolor  2.77   0.314\n12 Sepal.Width  virginica   2.97   0.322\n\n\n上で作成したデータフレームを用いて、ggplot2でグラフを描画します。まずはggplot関数でaesを設定していきます。x軸にSpecies、y軸に平均値とエラーバーの要素に平均値±標準偏差（ymin、ymax）、棒の枠の色（color）と棒の中身の色（fill）にデータ名を設定しておきます。\n\n\n\nggplot関数の準備\n\np1 &lt;- d1 |&gt; \n  ggplot(\n    aes(\n      x = Species, \n      y  =mvalue, \n      ymax = mvalue + svalue, \n      ymin = mvalue - svalue,\n      color = name,\n      fill = name\n      )\n    )\n\n\nこのggplot関数に、geom_barとgeom_linerangeを+でつなげると、下の図のように、積み上げ式棒グラフの下の方にエラーバーが重なって表示される、変なグラフが作成されます。これは、geom_barの引数の設定がposition=\"stack\"であるため積み上げ式棒グラフとなる一方で、geom_linerangeなどのエラーバーを指定するgeom関数には積み上げ式の設定がないためです。\n\n\n\npositionを指定しない場合\n\n# positionを指定しないと、積み上げ式棒グラフになる\np1 +\n  geom_bar(stat = \"identity\") +\n  geom_linerange()\n\n\n\n\n\n\n\n\n\npositionに\"dodge\"を指定すると、棒グラフは積み上げ式ではなく、横に並べる形となります。このとき、エラーバーは棒グラフの真ん中に配置されてしまい、どの棒グラフのエラーバーなのかわからなくなります。これは、geom_linerangeのpositionの設定が正しく行われていないためです。\n\n\n\npositionをdodgeに指定した場合\n\np1 +\n  geom_bar(stat = \"identity\", position=\"dodge\") +\n  geom_linerange()\n\n\n\n\n\n\n\n\n\ngeom_linerangeを含む、エラーバーを描画するためのgeom関数のpositionの指定には、position_dodge関数を用います。position=position_dodge(width=0.9)という形でgeom_linerangeのpositionを指定すると、エラーバーが正しい位置（棒グラフの真ん中）に配置されます。やや複雑ですし、width=0.9の意味はよくわからないのですが、この方法はggplot2のReferenceにも記載されています。\n\n\n\nposition_dodge(width=0.9)を指定\n\np1 +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  geom_linerange(position = position_dodge(width = 0.9))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n棒グラフとエラーバー\n\n\n\n\n\n上記のように、棒グラフとエラーバーの色を同じにすると、エラーバーの下側が見えなくなります。このようなグラフ（ダイナマイトっぽい形をしているので、ダイナマイトプロットと呼ばれます）では、エラーバーで示したい範囲が不明瞭となるため、データ表示の方法としては良くないとされています。点と線で表すフォレストプロット（geom_pointrange）を用いたほうが、棒グラフとエラーバーを用いるより、データの表示方法としては優れています。\n\n\n\n\n\n\n22.4.20 geom_bin2d\ngeom_bin2dはx軸、y軸に値を設定し、x・yそれぞれの値のデータを度数分布に変換した上で、度数を2次元グラフ上に色で示すものです。2次元で表示するヒストグラムにあたります。ただし、下の図のようにデータが多く、分布が薄く広がっている場合には度数の差が分かりにくくなってしまいます。\n\n\n\ngeom_bin2dで二次元ヒストグラム\n\ndiamonds |&gt; \n  ggplot(aes(x=carat, y=price)) +\n  geom_bin2d()\n\n\n\n\n\n\n\n\n\nこのようなデータで度数を調べる場合には、geom_pointと透明化を指定する引数であるalphaを用いるのが良いでしょう。alphaを小さい値に指定すると、度数の多いところは濃い色で、度数が小さいところは薄い色で表示されます。下のグラフは上のgeom_bin2dと同じものを表現していますが、こちらの方がデータの分布としては理解しやすいことがわかるかと思います。\n\n\n\nalphaで半透明化\n\ndiamonds |&gt; \n  ggplot(aes(x=carat, y=price)) +\n  geom_point(alpha=0.004)\n\n\n\n\n\n\n\n\n\n棒グラフと同様に、geom_bin2dもstat=\"identity\"と指定することで、数値をそのまま色とするグラフを作成することができます。下の例では、volcanoデータセット（マウンガファウの南北・東西の位置と標高のデータ）を変形し、geom_bin2dで描画したものです。このようにstat=\"identity\"を用いれば、geom_bin2dを用いてヒートマップを作成することもできます。\n\n\n\ngeom_bin2dでヒートマップを描画\n\nvolcano |&gt; \n  as.data.frame() |&gt; \n  cbind(y = 1:nrow(volcano)) |&gt; \n  pivot_longer(1:ncol(volcano), values_to = \"altitude\", names_to = \"x\") |&gt; \n  mutate(x = as.numeric(str_remove_all(x, \"V\"))) |&gt; \n  ggplot(aes(x = as.numeric(x), y = y, color = altitude, fill = altitude)) +\n    geom_bin2d(stat = \"identity\")\n\n\n\n\n\n\n\n\n\n\n\n22.4.21 geom_contour\ngeom_contourはRのcontour関数と同じく、標高線で示された図を表記するのに用いる関数です。geom_bin2dとは異なり、aesには3つの値（x、y、z）を指定する必要があります。\n\n\n\ngeom_contourで等高線グラフを作成\n\nvolcano |&gt; \n  as.data.frame() |&gt; \n  cbind(y = 1:nrow(volcano)) |&gt; \n  pivot_longer(1:ncol(volcano), values_to = \"altitude\", names_to = \"x\") |&gt; \n  mutate(x = as.numeric(str_remove_all(x, \"V\"))) |&gt; \n  ggplot(aes(x = as.numeric(x), y = y, z = altitude)) +\n    geom_contour()\n\n\n\n\n\n\n\n\n\nRデフォルトのfilled.contour関数と同様に、等高線に色を合わせて表示するようなグラフを作成する場合には、geom_contour_filledを用います。geom_contour_filledを用いることで、zの値に従い色分けされたグラフを描画することができます。\n\n\n\ngeom_contour_filledで色付き等高線グラフを作成\n\nvolcano |&gt; \n  as.data.frame() |&gt; \n  cbind(y = 1:nrow(volcano)) |&gt; \n  pivot_longer(1:ncol(volcano), values_to = \"altitude\", names_to = \"x\") |&gt; \n  mutate(x = as.numeric(str_remove_all(x, \"V\"))) |&gt; \n  ggplot(aes(x = as.numeric(x), y = y, z = altitude)) +\n    geom_contour_filled()\n\n\n\n\n\n\n\n\n\n\n\n22.4.22 geom_map\ngeom_mapは地図を表示するための関数です。地図を表記するためには、地図データ、つまり緯度、経度とその場所のIDを記録したもの、を準備する必要があります。\nRで地図データを用いる場合には、mapsパッケージ(Richard A. Becker, Ray Brownrigg. Enhancements by Thomas P Minka, and CRAN team. 2023)を利用するのが比較的簡単です。mapsパッケージには世界地図、アメリカの州の地図、フランスやイタリア、ニュージーランドなどの地図が登録されています。mapsパッケージの地図をggplot2で用いる場合には、ggplot2で使用できるデータフレームに変換してくれるmapsパッケージの関数である、map_dataを用います。\n\n\n\nmapパッケージで地図データの読み込み\n\npacman::p_load(maps)\nstate &lt;- map_data(\"state\") # アメリカの州データをggplot用に変換\nhead(state) # 緯度（lat）、経度（long）などを含むデータフレーム\n\n\n       long      lat group order  region subregion\n1 -87.46201 30.38968     1     1 alabama      &lt;NA&gt;\n2 -87.48493 30.37249     1     2 alabama      &lt;NA&gt;\n3 -87.52503 30.37249     1     3 alabama      &lt;NA&gt;\n4 -87.53076 30.33239     1     4 alabama      &lt;NA&gt;\n5 -87.57087 30.32665     1     5 alabama      &lt;NA&gt;\n6 -87.58806 30.32665     1     6 alabama      &lt;NA&gt;\n\n\nggplot2では、map_dataで変換したデータフレームをggplot関数の引数にするのではなく、map_dataでregionに指定されているラベル（地域）を含むデータフレームを用います。\nUSArrestsはアメリカの州別の10万人あたりの犯罪件数を記録したデータフレームです。このデータフレームの行名が州名になっているので、これをデータフレームの列に追加し、stateと表記を合わせるために小文字に変換します。\naesでは、map_id=stateとし、地図IDを指定します。さらに、fillにはUSArrestsの列名であるMurder（殺人の件数）を指定します。この形で指定することで、Murderの値が色で示されることになります。\ngeom_mapでは、さらにmapという引数に、map_dataの返り値（state）を指定する必要があります。こうすることで、geom_mapはstateを基準に地図を描画し、地図の色にfillで指定したMurderの値を適用します。\n\n\n\ngeom_map関数\n\n# coord_sfを用いるためにsfパッケージをロードする\npacman::p_load(sf)\n\nUSArrests |&gt; \n  mutate(state = tolower(rownames(USArrests))) |&gt; \n  ggplot(aes(map_id = state, fill = Murder)) +\n  geom_map(map = state) +\n  coord_sf(\n      crs = 5070, default_crs = 4326,\n      xlim = c(-125, -70), ylim = c(25, 52)\n    )\n\n\n\n\n\n\n\n\n\n\n\n22.4.23 geom_sf\n上記のようにすれば、地図を表記することはできますが、やや煩雑です。近年のRでは、地図データを扱う際には、地図データ取り扱いの専用クラスであるsf（simple features）を用いるのが一般的になっています。このsfを用いれば、グラフをより簡単に作成することができます。\nsfクラスは、sfパッケージ(Pebesma and Bivand 2023; Pebesma 2018)で定義されているクラスです。sfを使用する際には、まずsfパッケージを読み込みます。\nsfパッケージをインストールすると、sfパッケージ内にある地図データにアクセスできます。下の例では、sfパッケージのフォルダ内にある地図データ（North Carolinaのsfデータ）を読み込んでいます。\n\n\n\nsfパッケージのデータを読み込み\n\n# system.fileはパッケージからフルパスを読み込む関数\nfname &lt;- system.file(\"shape/nc.shp\", package=\"sf\")\nnc &lt;- st_read(fname) # North Carolinaのsfデータ\n\n\nReading layer `nc' from data source \n  `C:\\Program Files\\R\\R-4.4.0\\library\\sf\\shape\\nc.shp' using driver `ESRI Shapefile'\nSimple feature collection with 100 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965\nGeodetic CRS:  NAD27\n\n\nsfは基本的にデータフレームで、geometryという列を持っています。この列は、sfcクラスのデータです。sfcクラスはその行に対応する緯度・経度のセットを専用の表記法で示したものとなります。sfを用いる場合には、このgeometryが地図データを表現する列になります。\n\n\n\nsfのデータ\n\nclass(nc) # sfはデータフレームの一種\n\n\n[1] \"sf\"         \"data.frame\"\n\nnc # geometryという列に地図データが格納されている\n\nSimple feature collection with 100 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965\nGeodetic CRS:  NAD27\nFirst 10 features:\n    AREA PERIMETER CNTY_ CNTY_ID        NAME  FIPS FIPSNO CRESS_ID BIR74 SID74\n1  0.114     1.442  1825    1825        Ashe 37009  37009        5  1091     1\n2  0.061     1.231  1827    1827   Alleghany 37005  37005        3   487     0\n3  0.143     1.630  1828    1828       Surry 37171  37171       86  3188     5\n4  0.070     2.968  1831    1831   Currituck 37053  37053       27   508     1\n5  0.153     2.206  1832    1832 Northampton 37131  37131       66  1421     9\n6  0.097     1.670  1833    1833    Hertford 37091  37091       46  1452     7\n7  0.062     1.547  1834    1834      Camden 37029  37029       15   286     0\n8  0.091     1.284  1835    1835       Gates 37073  37073       37   420     0\n9  0.118     1.421  1836    1836      Warren 37185  37185       93   968     4\n10 0.124     1.428  1837    1837      Stokes 37169  37169       85  1612     1\n   NWBIR74 BIR79 SID79 NWBIR79                       geometry\n1       10  1364     0      19 MULTIPOLYGON (((-81.47276 3...\n2       10   542     3      12 MULTIPOLYGON (((-81.23989 3...\n3      208  3616     6     260 MULTIPOLYGON (((-80.45634 3...\n4      123   830     2     145 MULTIPOLYGON (((-76.00897 3...\n5     1066  1606     3    1197 MULTIPOLYGON (((-77.21767 3...\n6      954  1838     5    1237 MULTIPOLYGON (((-76.74506 3...\n7      115   350     2     139 MULTIPOLYGON (((-76.00897 3...\n8      254   594     2     371 MULTIPOLYGON (((-76.56251 3...\n9      748  1190     2     844 MULTIPOLYGON (((-78.30876 3...\n10     160  2038     5     176 MULTIPOLYGON (((-80.02567 3...\n\n\nggplot2でsfを用いてグラフを描画する場合には、geom_sf関数を用います。geom_sf関数を用いてグラフを作成する場合には、ggplot関数の引数となるデータフレームにsf、aesにsfに含まれる列を指定します。sfを用いれば、このようなシンプルな表記法でgeom_mapよりも簡単に地図を表記することができます。\n\n\n\ngeom_sf関数でsfデータを描画\n\n# sfを用いたグラフの表記\nnc |&gt; \n  ggplot() +\n  geom_sf(aes(fill = AREA))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRでの地図描画ライブラリ\n\n\n\n\n\nsfは2018年に発表された、比較的新しいパッケージです。sfが出てくるまでは、Rで地図データを取り扱う方法は様々で、統一されているという感はありませんでしたが、今後はsfがデフォルトの地図データ取り扱い方法になっていくのではないかと思います。地図データの取扱いに関してはオンラインの英語の教科書（Geocomputation with R）があり、日本語訳（Geocomputation with R (日本語版)）も公開されています。\n地図表示のためのライブラリにはggplot2だけでなく、Leaflet for RというJavascriptの地図ライブラリをRで利用できるようにしたものや、ggplot2風の記法で色々なデザインのグラフを描画できるtmapなどもあります。sf、leaflet、tmapについては32章で説明します。\n\n\n\n\n\n22.4.24 geom_polygon\ngeom_polygonは多角形を描画するための関数です。データフレームには、多角形の各頂点に当たるxとyの座標を指定します。\n\n\n\ngeom_polygon関数\n\n# 頂点のx、y座標を指定する\nd2 &lt;- data.frame(x = c(1, 1.25, 1.75, 2), y = c(1, 2, 2, 1))\nd2\n\n\n     x y\n1 1.00 1\n2 1.25 2\n3 1.75 2\n4 2.00 1\n\n\naesで頂点のx、y座標を指定すると、多角形を描画することができます。低レベルグラフィック関数であるpolygon関数と類似した描画の方法になっています。\n\n\n\ngeom_polygonで多角形を描画\n\nd2 |&gt; \n  ggplot(aes(x = x, y = y)) +\n  geom_polygon()",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter22.html#色の設定",
    "href": "chapter22.html#色の設定",
    "title": "22  ggplot2",
    "section": "22.5 色の設定",
    "text": "22.5 色の設定\n上で説明したように、ggplot2で色を指定するときには、aes中でcolor、fillの引数を指定します。color、fillは数値または因子を指定することができ、点や面を数値・因子に対応した色で表示することができます。\ngeom_pointなどの点を描画する場合では、colorのみを指定します。\n\n\n\ncolorに因子を指定\n\niris |&gt; \n  ggplot(aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\ncolor引数に数値を指定すると、数値に従い色の濃度が変わります。\n\n\n\ncolorに数値を指定\n\niris |&gt; \n  ggplot(aes(x = Sepal.Length, y = Sepal.Width, color = Petal.Length)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\ngeom_barでは、colorだけを指定すると、棒グラフの枠だけに色がつきます。\n\n\n\ngeom_barでcolorだけを指定した場合\n\nd1 |&gt; \n  ggplot(aes(x = Species, y = mvalue, color = name)) +\n  geom_bar(stat = \"identity\", position = \"dodge\")\n\n\n\n\n\n\n\n\n\ngeom_barで、棒グラフの中身の色を変えたい時には、fill引数を指定する必要があります。\n\n\n\ngeom_barでfillを指定した場合\n\nd1 |&gt; \n  ggplot(aes(x = Species, y = mvalue, color = name, fill = name)) +\n  geom_bar(stat = \"identity\", position = \"dodge\")\n\n\n\n\n\n\n\n\n\n\n22.5.1 color brewer\nggplot2では、colorやfillに引数を指定すれば、特に色の指定をしなくても、いい感じの色でグラフを作成してくれます。ただし、デフォルトの色では見にくい時や、デザイン的に別の色を用いたい場合もあります。色を別途指定したい場合には、ColorBrewerを用いた色の設定を行います。\nggplot2でColorBrewerに従った色を用いる場合には、scale_color_brewerを用います。通常のgeom関数と同様に、scale_color_brewerも+で繋いで用います。同様に、fillに指定した色の配色を変えたい場合には、scale_fill_brewerを用います。\n色の指定にはpalette引数を用います。palette引数には、カラーパレットを指定する文字列を指定します。カラーパレットの種類はヘルプ（?scale_color_brewer）から確認できます。\n\n\n\nscale_color_brewerで色を変更\n\niris |&gt; \n  ggplot(aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +\n  geom_point() +\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\n\n\ncolorに数値を指定した場合には、scale_color_distillerで色を指定します。fillに数値を指定する場合には、scale_fill_distillerを用います。\n\n\n\nscale_color_distillerで色を変更\n\niris |&gt; \n  ggplot(aes(x = Sepal.Length, y = Sepal.Width, color = Petal.Length)) +\n  geom_point() +\n  scale_color_distiller(palette = \"RdYlBu\")",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter22.html#点のサイズ",
    "href": "chapter22.html#点のサイズ",
    "title": "22  ggplot2",
    "section": "22.6 点のサイズ",
    "text": "22.6 点のサイズ\ngeom_pointなどで点のサイズを変更する場合には、size引数を指定します。\n\n\n\nsizeで点のサイズを指定\n\niris |&gt; \n  ggplot(aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +\n  geom_point(size = 10)\n\n\n\n\n\n\n\n\n\nsize引数はaes内で、数値の列名を取る形でも宣言できます。aes内で数値で指定した場合には、その数値に応じた点のサイズで表示されます。このように点のサイズを列名で指定することで、3つの要素（x、y、size）を3次元グラフを用いることなく表現することができます。このようなグラフのことをバブルチャートと呼びます。\n\n\n\nsizeに数値を指定する\n\niris |&gt; \n  ggplot(aes(x = Sepal.Length, y = Sepal.Width, color = Species, size = Petal.Length)) +\n  geom_point()",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter22.html#点の透明化",
    "href": "chapter22.html#点の透明化",
    "title": "22  ggplot2",
    "section": "22.7 点の透明化",
    "text": "22.7 点の透明化\n点が大きくなると、重なった点は見えなくなります。重なった点を表示する方法には、ジッタープロット（geom_jitter）などがありますが、x軸もy軸も数値の場合には、位置がランダムに変化することで正確な値を示さなくなります。\n重なった点を適切に表示する場合、透明化が有効となる場合があります。上で説明した通り、透明化を指定する引数はalphaです。alphaには0～1までの値を指定することができ、0では完全に透明、1では完全に不透明の点を表示することになります。\n\n\n\ngeom_point中でalphaを指定\n\niris |&gt; \n  ggplot(aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +\n  geom_point(size = 10, alpha = 0.2)",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter22.html#線の太さとタイプ",
    "href": "chapter22.html#線の太さとタイプ",
    "title": "22  ggplot2",
    "section": "22.8 線の太さとタイプ",
    "text": "22.8 線の太さとタイプ\ngeom_line等の線グラフで線の太さを指定する場合にはlinewidth引数を、線のタイプを指定する場合には、linetype引数を用います。linewidth引数には太さを数値で指定します。linetypeには、\"solid\"、\"dashed\"、\"dotted\"、\"dotdash\"、\"longdash\"、\"twodash\"の各タイプがあり、それぞれ文字列で指定します。線タイプの詳細については、vignette(\"ggplot2-specs\")を実行することで確認できます。\n\n\n\n線の太さとタイプの指定\n\niris |&gt; \n  ggplot(aes(x = Sepal.Length, y = Sepal.Width)) +\n  geom_line(linewidth = 1, linetype = \"dotted\")",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter22.html#グラフの重ね書き",
    "href": "chapter22.html#グラフの重ね書き",
    "title": "22  ggplot2",
    "section": "22.9 グラフの重ね書き",
    "text": "22.9 グラフの重ね書き\nグラフの重ね書きを行う場合には、複数のgeom関数を+で繋ぎます。後に指定したgeom関数が重ね書きの上層（上のレイヤー）に表示されることになります。重ね書きしたグラフの色が下層のグラフの色と同一だと見えなくなってしまうため、通常は色を変えて表示します。\n重ね書きするグラフの間でデータが異なる場合には、ggplot関数でデータフレーム・aesを設定せず、geom関数内でそれぞれdata・aesを指定します。dataにはデータフレームを指定します。geom関数内で別のdataを指定することで、それぞれのgeom関数のグラフに別のデータフレームからのデータを用いることもできます。\n\n\n\nboxplotとjitterplotを重ね書き\n\niris |&gt; \n  ggplot(aes(x = Species, y = Sepal.Length)) +\n  geom_boxplot() +\n  geom_jitter(aes(color = Species), width = 0.2)",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter22.html#複数のグラフの表示facetting",
    "href": "chapter22.html#複数のグラフの表示facetting",
    "title": "22  ggplot2",
    "section": "22.10 複数のグラフの表示：facetting",
    "text": "22.10 複数のグラフの表示：facetting\nデータフレームに異なる要素（因子）のデータが保存されており、要素ごとに別々にグラフにしたい場合には、facetting（facet：宝石のカットの面のこと）を用います。facettingには、facet_wrapとfacet_gridの2つの関数ががあります。facet_wrapはデータフレームの要素で分けたグラフを単に並べたもの、facet_gridはx、y方向に要素がそろったグラフ群を作成する関数です。\n\n22.10.1 facet_wrap\n以下はfacet_wrapの例です。グラフを分ける要素は、facet_wrap内でチルダ（~）を用いて指定します。チルダの左側、右側のどちらに要素をおいても問題ありませんが、右側の要素を入力しない場合には、ピリオド（.）を入力しておきます。グラフはよい感じに縦・横に並べられ、表示されます。並べる順番は要素の因子（factor）のレベル順となります。\n\n\n\nfacet_wrap関数\n\nd1 |&gt; \n  ggplot(aes(x = Species, y = mvalue)) +\n  geom_bar(stat = \"identity\") +\n  facet_wrap(~ name)\n\n\n\n\n\n\n\n\n\n\n22.10.1.1 scalesの指定\nfacet_wrapを用いたときに、表示するグラフごとに縦軸のスケールを調整する場合には、scales引数を指定します。scales引数はfacet_wrap関数内で指定し、scales=\"free_y\"ならy方向のスケールが、scales=\"free_x\"ならx方向のスケールが、scales=\"free\"ならx、y両方のスケールが自動的に調整されます。\n\n\n\nfacet_wrapでscalesを指定\n\n# scalesを指定すると、y軸のスケールがグラフごとに自動調整される\nd1 |&gt; \n  ggplot(aes(x = Species, y = mvalue)) +\n  geom_bar(stat = \"identity\") +\n  facet_wrap(~ name, scales = \"free_y\")\n\n\n\n\n\n\n\n\n\n\n\n\n22.10.2 facet_grid\nfacet_gridでは、チルダの左と右の要素でそれぞれy軸方向、x軸方向を指定することになります。縦－横方向の軸の値もそろえられます。\n\n\n\nfacet_grid関数\n\nd1 |&gt; \n  ggplot(aes(x = Species, y = mvalue)) +\n  geom_bar(stat = \"identity\") +\n  facet_grid(Species ~ name)",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter22.html#軸のラベルの調整labs",
    "href": "chapter22.html#軸のラベルの調整labs",
    "title": "22  ggplot2",
    "section": "22.11 軸のラベルの調整：labs",
    "text": "22.11 軸のラベルの調整：labs\n軸のラベルやタイトル等を設定する場合には、labs関数を用います。labs関数も+で繋いで用います。x、y、title、subtitle、caption引数を指定することでそれぞれx軸ラベル、y軸ラベル、メインタイトル、サブタイトル、キャプション（注釈）をグラフに追加することができます。\n\n\n\nlabsでラベルの編集\n\niris |&gt; \n  ggplot(aes(x = Sepal.Length)) +\n  geom_histogram(bins = 30) +\n  labs(\n    x = \"length\", \n    y = \"count\", \n    title = \"main title\", \n    subtitle = \"sub title\", \n    caption = \"caption\")",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter22.html#軸スケールの変換対数化など",
    "href": "chapter22.html#軸スケールの変換対数化など",
    "title": "22  ggplot2",
    "section": "22.12 軸スケールの変換（対数化など）",
    "text": "22.12 軸スケールの変換（対数化など）\nx軸、y軸の数値を対数変換する場合には、scale_x_log10、scale_y_log10を用います。他のggplot2の関数と同様に、scale_x_log10、scale_y_log10も+で繋ぐことで、x軸、y軸が対数変換されます。\n\n\n\n軸スケールの変換\n\ndiamonds |&gt; \n  ggplot(aes(x = price)) +\n  geom_histogram(bins = 50) +\n  scale_x_log10()\n\n\n\n\n\n\n\n\n\n同様の軸の変換の関数には、scale_x_reverse、scale_x_sqrtなどがあります。それぞれ軸を正負反転、平方根に変換するのに用います。",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter22.html#グラフの並び順の変更",
    "href": "chapter22.html#グラフの並び順の変更",
    "title": "22  ggplot2",
    "section": "22.13 グラフの並び順の変更",
    "text": "22.13 グラフの並び順の変更\nx軸に因子を指定した場合の棒グラフなどの並び順は、その因子のレベルの順番で決まります。ですので、forcatパッケージのfct_reorderを用いて並べ替えることができます。\n\n\n\nfct_reorderで順番を変更する\n\nd |&gt; \n  ggplot(aes(x = forcats::fct_reorder(Species, c(\"virginica\", \"setosa\", \"versicolor\")), y = mSepal.Length)) +\n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\n\nfct_reorder関数は他の数値を参照して、その数値の順番で並べ替えることもできます。\n\n\n\nfct_reorderで数値に従い並べ替え\n\nd |&gt; \n  ggplot(aes(x = forcats::fct_reorder(Species, mSepal.Length, .desc=TRUE), y = mSepal.Length)) +\n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\n\n同様の数値による順番の変更は、reorder関数を用いても行うことができます。\n\n\n\nreorder関数で並べ替え\n\nd |&gt; \n  ggplot(aes(x = reorder(Species, mSepal.Length, decreasing = TRUE), y = mSepal.Length)) +\n  geom_bar(stat = \"identity\")",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter22.html#円グラフの作成",
    "href": "chapter22.html#円グラフの作成",
    "title": "22  ggplot2",
    "section": "22.14 円グラフの作成",
    "text": "22.14 円グラフの作成\nggplot2で円グラフを作成する場合には、coord_polarを用います。coord_polarは軸を円形に配置する関数で、棒グラフを描画し、coord_polarの引数にtheta=\"y\"を指定すると、円グラフが描画されます。\n\n\n\ncoord_polarで円グラフの指定\n\nd |&gt; \n  ggplot(aes(x = \"1\", y = mSepal.Length, color = Species, fill=Species)) +\n  geom_bar(stat = \"identity\") +\n  coord_polar(theta = \"y\")\n\n\n\n\n\n\n\n\n\n棒を複数描画するような場合には、中心からいくつかの層に分かれて円グラフが描画されます。position=\"fill\"を指定すると、棒グラフの高さがそろい、値は割合に変化するため、異なる要素間での比較を示すことができます。ただし、pie関数のhelpに記載されている通り、円グラフではデータの比較が難しくなります。基本的に円グラフを用いない方が良いでしょう。\n\n\n\ncoord_polarでは見にくい場合\n\np1 +\n  geom_bar(stat = \"identity\", position=\"fill\") +\n  coord_polar(theta = \"y\")",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter22.html#theme",
    "href": "chapter22.html#theme",
    "title": "22  ggplot2",
    "section": "22.15 theme",
    "text": "22.15 theme\nthemeは、グラフのもっと細かな要素を調整するための関数です。themeには非常に多くの引数が設定されており、themeを用いることで軸ラベルなどのフォントサイズや色、回転、凡例の位置等を調整することができます。代表的な例として、theme関数のlegend.position引数を用いて、凡例をグラフの下に表示した場合を下に示します。凡例を消す場合には、legend.position=\"none\"を指定します。themeの引数には関数を取るものあり、設定はやや複雑ですが、うまく指定すれば様々なグラフの要素を調整することができます。\n\n\n\nthemeの指定\n\niris |&gt; \n  ggplot(aes(x = Sepal.Length, y = Sepal.Width, color = Species)) + \n  geom_point() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\nthemeには、グラフのデザインを丸ごと変えることができる関数が別途用意されています。例えば、theme_bwででは背景が白いグラフ、theme_lightででは明るめ、theme_darkでは暗めの背景を用いたグラフを作成できます。\n\n\n\ntheme_bw関数で背景を白にする\n\niris |&gt; \n  ggplot(aes(x = Sepal.Length, y = Sepal.Width)) + \n  geom_point() +\n  theme_bw()",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter22.html#グラフの保存ggsave",
    "href": "chapter22.html#グラフの保存ggsave",
    "title": "22  ggplot2",
    "section": "22.16 グラフの保存：ggsave",
    "text": "22.16 グラフの保存：ggsave\nggplot2のグラフを保存する時には、ggsave関数を用います。ggsave関数は第一引数にファイル名、第二引数にggplot2のプロットのオブジェクトを取ります。ファイルの形式はファイル名の拡張子に従い決定します。例えば、ファイル名が「.pdf」で終わっていればPDF、「.jpg」で終わっていればJPEGでグラフが保存されます。\nグラフのサイズはwidth、height引数で、解像度はdpiで指定します。limitsize=FALSEと指定することで、縦横が50インチ以上の非常に大きいグラフを保存することもできます。\n\n\n\nggsave関数\n\n# プロットのオブジェクトをpに代入\np &lt;- \n  iris |&gt; \n  ggplot(aes(x = Sepal.Length, y = Sepal.Width)) +\n  geom_point()\n\n# pをpdfで保存\nggsave(\"plot_iris_Sepal.pdf\", p)",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter22.html#extensions",
    "href": "chapter22.html#extensions",
    "title": "22  ggplot2",
    "section": "22.17 Extensions",
    "text": "22.17 Extensions\nggplot2には、ggplot2に機能を追加するExtensionsというライブラリがたくさん存在します。代表的なExtensionsを以下に紹介します。\n\n22.17.1 patchwork\nまずは、複数のグラフを1つのデバイスにまとめて表示するpatchwork(Pedersen 2023)です。patchworkを用いれば、位置・幅等を簡単に調整しながら、2つ以上のグラフをまとめることができます。\npatchworkを用いる時には、まずggplot2のオブジェクトを変数に代入しておくとよいでしょう。\n\n\n\nggplot2オブジェクトを変数に代入\n\npacman::p_load(patchwork)\np1 &lt;- iris |&gt; ggplot(aes(x = Sepal.Length, y = Sepal.Width)) + geom_point()\np2 &lt;- iris |&gt; ggplot(aes(x = Species, y = Petal.Length)) + geom_boxplot()\np3 &lt;- iris |&gt; ggplot(aes(x = Petal.Width)) + geom_histogram()\np4 &lt;- iris |&gt; ggplot(aes(x = Petal.Length, color = Species, fill = Species)) + geom_histogram(binwidth = 0.5)\n\n\nグラフを横に並べて表示するときには、+でオブジェクトを繋ぎます。\n\n\n\nグラフを横に並べる\n\np1 + p2\n\n\n\n\n\n\n\n\n\n同様にカッコで囲えば表示を一部まとめておくことができます。また、|は横並び、/は縦並びにグラフを配置する場合に用います。\n\n\n\nグラフを縦横に配置する\n\n(p1 | p2) / p3\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nカッコ、|、/を組み合わせれば、グラフを様々な配置に並べて表示することができます。\n\n\n\nカッコを用いて配置する\n\n(p1 | p2) / (p3 | p4)\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\n22.17.2 gganimate\ngganimate(Pedersen and Robinson 2022)はアニメーションを利用したグラフを作成するためのライブラリです。下の例では、gamminder（各国の年別のGDPと寿命、人口のデータ）をバブルチャートとし、年毎にアニメーションとしたものです。transition_timeという部分でアニメーションのフレームとなる変数を設定し、ease_aesという部分でフレームの間隔を表現します。\nアニメーションをgifで保存する場合には、anim_save関数を用います。anim_save関数の引数の指定はggsaveと類似していますが、グラフオブジェクトをanimate関数の引数とした上で、rendererという引数を設定する必要があります。rendererには保存するファイル形式を指定します。gifアニメーションを作成するときにはrenderer=gifski_renderer()を指定します。このgifski_rendererを用いるためには、gifskiパッケージ(Ooms, Kornel Lesi?ski, and Authors of the dependency Rust crates 2023)を呼び出しておく必要があります。gif以外にもmpegなどのファイルにも保存できますが、別途ライブラリの呼び出しが必要です。\n\n\n\ngganimate関数でgifを作成\n\npacman::p_load(gganimate, gifski, gapminder)\n\np &lt;- ggplot(gapminder, aes(gdpPercap, lifeExp, size = pop, colour = country)) +\n  geom_point(alpha = 0.7, show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  scale_x_log10() +\n  facet_wrap(~ continent) +\n  labs(title = 'Year: {frame_time}', x = 'GDP per capita', y = 'life expectancy') + # frame_timeで描画を指定\n  transition_time(year) + # yearの列をフレームとする\n  ease_aes('linear') # yearごとのフレーム間隔は一定\n\nanim_save(\"p.gif\", animate(p, renderer = gifski_renderer())) # 描画の方法を指定\n\n\n\n\n\n22.17.3 GGally\nGGally(Schloerke et al. 2023)はggplot2を使って、相関行列を描画するためのExtensionです。各列のデータの型に従い、表示するグラフの形を変えてくれたり、相関係数を表示してくれたりします。pairs関数を用いてグラフを書くよりもデータの特徴をとらえやすい相関行列の図を簡単に作成することができます。\n\n\n\nGGally::ggpairs関数\n\npacman::p_load(GGally)\nggpairs(iris, mapping=aes(color=Species))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n他言語のグラフ作成との比較\n\n\n\n\n\nR以外の言語にも、グラフ作成のライブラリが備わっています。例えばPythonでは、matplotlibやseaborn、plotlyなどがあります。JuliaではJulia Plotsがデフォルトのグラフ作成ライブラリです。いずれもどちらかと言えばRのデフォルトに近い関数を用いてグラフを作成するようです。\nggplot2では、データ、aes、グラフの形をそれぞれggplot、aes、geom関数で表現し、ジェネリック関数として設定された+で繋ぐ点が特徴です。特徴が他のライブラリとは異なるため、記法に慣れるまでは他のライブラリよりグラフを作成するのが難しく感じるかもしれません。しかし、ggplot2の経験を積み、慣れてしまえば表現したいグラフを他のライブラリよりスムーズに作成することができます。\n\n\n\n\n\n\n\n\n\nOoms, Jeroen, Kornel Lesi?ski, and Authors of the dependency Rust crates. 2023. Gifski: Highest Quality GIF Encoder. https://CRAN.R-project.org/package=gifski.\n\n\nPebesma, Edzer. 2018. “Simple Features for R: Standardized Support for Spatial Vector Data.” The R Journal 10 (1): 439–46. https://doi.org/10.32614/RJ-2018-009.\n\n\nPebesma, Edzer, and Roger Bivand. 2023. Spatial Data Science: With applications in R. Chapman and Hall/CRC. https://doi.org/10.1201/9780429459016.\n\n\nPedersen, Thomas Lin. 2023. Patchwork: The Composer of Plots. https://CRAN.R-project.org/package=patchwork.\n\n\nPedersen, Thomas Lin, and David Robinson. 2022. Gganimate: A Grammar of Animated Graphics. https://CRAN.R-project.org/package=gganimate.\n\n\nRichard A. Becker, Original S code by, Allan R. Wilks. R version by Ray Brownrigg. Enhancements by Thomas P Minka, and Alex Deckmyn. Fixes by the CRAN team. 2023. Maps: Draw Geographical Maps. https://CRAN.R-project.org/package=maps.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz Marbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2023. GGally: Extension to ’Ggplot2’. https://CRAN.R-project.org/package=GGally.",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>ggplot2</span>"
    ]
  },
  {
    "objectID": "chapter23.html",
    "href": "chapter23.html",
    "title": "23  plotly",
    "section": "",
    "text": "23.1 インタラクティブなグラフ\nRでインタラクティブなグラフを作成したい場合には、rglパッケージ(Murdoch and Adler 2023)や、Javascriptのインタラクティブグラフィックライブラリであるd3.jsを使用したライブラリであるr2d3 (Strayer, Luraschi, and Allaire 2022)を用いるなど、様々な方法があります。\nこのようなインタラクティブなグラフ作成パッケージの中では、plotly (Sievert 2020)が機能が多彩かつ記述の方法もシンプルで非常に分かりやすい優れたライブラリです。\nplotlyライブラリのロード\n\npacman::p_load(plotly)",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>plotly</span>"
    ]
  },
  {
    "objectID": "chapter23.html#インタラクティブなグラフ",
    "href": "chapter23.html#インタラクティブなグラフ",
    "title": "23  plotly",
    "section": "",
    "text": "インタラクティブなグラフとR\n\n\n\n\n\n以前はRでインタラクティブなグラフを作成しても、Rが実行されているPC上でのみ確認ができただけで、他の人とグラフを共有するすべがほとんどありませんでした。しかし、ここ10年で、Rを用いてHTMLの文書を作成するライブラリ（RMarkdown (Allaire et al. 2023; Xie, Allaire, and Grolemund 2018; Xie, Dervieux, and Riederer 2020)、Quarto）や、Webアプリケーションを作成するためのライブラリ（Shiny）(Chang et al. 2024)が公開され、インタラクティブなグラフを共有するしくみが構築されました。\nWeb上でのインタラクティブなグラフの多くはd3.jsで構築されていると思います。しかし、d3.jsの記法はやや特殊で、Rユーザーが使いこなすのはやや難しいです。plotlyは主にPythonのライブラリとして開発されていますが、Rやほかの言語での開発も行われています。記法もggplot2やRのデフォルトのグラフィック関数に近く、Rユーザーにも使いやすいものとなっています。\nインタラクティブなグラフの使いどころは難しいですが、有効に用いれば、データを確認しやすく、見る人の興味を引くグラフを作成することができます。",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>plotly</span>"
    ]
  },
  {
    "objectID": "chapter23.html#散布図",
    "href": "chapter23.html#散布図",
    "title": "23  plotly",
    "section": "23.2 散布図",
    "text": "23.2 散布図\nplotlyでは、グラフはplot_ly関数で描画します。plot_ly関数の引数としてグラフのタイプ（type）を指定しない場合には、xやy軸に指定した値に対応したグラフを描画してくれます。xにもyにも数値を指定すれば、散布図が自動的に選択されて、描画されます。xやyなどの、ggplot2でのaesにあたる要素の指定では、データフレームの列名にチルダ（~）を付けます。チルダがないと、列名をうまく読み込むことはできません。\n\n\n\nplot_ly関数で散布図\n\nplot_ly(data = iris, x = ~Sepal.Length, y = ~Sepal.Width, color = ~Species)\n\n\n\n\n\n\nggplot2と同様に、colorやsizeなどの引数に数値を取ることで、バブルチャートなどのグラフを作成することもできます。\n\n\n\nplot_ly関数でバブルチャート\n\niris |&gt; \n  plot_ly(x = ~Sepal.Length, y = ~Sepal.Width, color = ~Petal.Length, size = ~Petal.Width)\n\n\n\n\n\n\nggplot2でのscale_color_brewerのように、Color Brewerを用いた色の指定も行うことができます。配色の指定にはcolorsという引数を用います。\n\n\n\nColorBrewerの色指定\n\ndiamonds[sample(1:nrow(diamonds), 500),] |&gt; \n  plot_ly(data = _, x = ~carat, y = ~price, color = ~carat, colors = \"RdYlGn\")",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>plotly</span>"
    ]
  },
  {
    "objectID": "chapter23.html#棒グラフ",
    "href": "chapter23.html#棒グラフ",
    "title": "23  plotly",
    "section": "23.3 棒グラフ",
    "text": "23.3 棒グラフ\nxに因子、yに数値を与えると、plot_ly関数は自動的に棒グラフを描画します。逆にxに数値、yに因子を与えると、棒グラフが横向きになります。\n\n\n\n棒グラフの描画\n\niris |&gt; \n  group_by(Species) |&gt;\n  summarise(mSepal.Length = mean(Sepal.Length)) |&gt; \n  plot_ly(x = ~Species, y = ~mSepal.Length, color = ~Species)",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>plotly</span>"
    ]
  },
  {
    "objectID": "chapter23.html#線グラフ",
    "href": "chapter23.html#線グラフ",
    "title": "23  plotly",
    "section": "23.4 線グラフ",
    "text": "23.4 線グラフ\n線グラフを描画する場合のx、yの指定は散布図と同じです。線を加える場合には、mode=\"lines\"もしくはmode=\"lines+markers\"と指定します。\"lines\"で指定した場合には線のみ、\"lines+markers\"は点と線を描画する形になります。\n\n\n\nmode=\"lines\"で線グラフを描画\n\npacman::p_load(gapminder)\ncolor_4 &lt;- c(\"red\", \"blue\", \"green\", \"black\") # 色をベクターで指定\n\ngapminder::gapminder |&gt; \n  filter(country == \"Japan\" | country == \"China\" | country == \"United States\" | country == \"Australia\") |&gt; \n  plot_ly(x = ~year, y = ~gdpPercap, type = \"scatter\", mode = \"lines+markers\", color = ~country, colors = color_4)",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>plotly</span>"
    ]
  },
  {
    "objectID": "chapter23.html#次元グラフ",
    "href": "chapter23.html#次元グラフ",
    "title": "23  plotly",
    "section": "23.5 3次元グラフ",
    "text": "23.5 3次元グラフ\n3次元のグラフはrglで描画できますが、plotlyでも簡単に3次元グラフを作成することができます。plotlyで三次元グラフを作成する場合には、x、yに加えて、z軸に相当する値を指定します。ただし、rglと同じように、3次元グラフはデータを認識しにくいため、3dグラフを用いるのではなく他のグラフ、例えばバブルチャートなどを選択する方がよいでしょう。\n\n\n\nplotlyで3次元グラフ\n\niris |&gt; \n  plot_ly(x = ~Sepal.Length, y = ~Sepal.Width, z = ~Petal.Length, color = ~Species, size = 0.1)",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>plotly</span>"
    ]
  },
  {
    "objectID": "chapter23.html#時系列プロット",
    "href": "chapter23.html#時系列プロット",
    "title": "23  plotly",
    "section": "23.6 時系列プロット",
    "text": "23.6 時系列プロット\nx軸に日時データを指定すれば、簡単に時系列グラフを描画することができます。時系列プロットや線グラフを作成する場合には、plot_ly関数の返り値をadd_trace関数の引数にする形でも指定できます。\n\n\n\nadd_trace関数\n\ndata.frame(year = time(Nile), value = Nile) |&gt; \n  plot_ly(type = \"scatter\", mode = \"lines\") |&gt; \n  add_trace(x = ~year, y = ~value)",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>plotly</span>"
    ]
  },
  {
    "objectID": "chapter23.html#ウォーターフォールプロット",
    "href": "chapter23.html#ウォーターフォールプロット",
    "title": "23  plotly",
    "section": "23.7 ウォーターフォールプロット",
    "text": "23.7 ウォーターフォールプロット\n企業の財務状態などを表記する場合には、ウォーターフォールプロットが便利です。ウォーターフォールプロットでは、収益と支出の色を変え、収益はプラス方向、支出はマイナス方向の方向性を持った形で棒グラフで表現します。ウォーターフォールプロットを作図する場合には、type=\"waterfall\"と指定します。\nplotlyでは、ウォーターフォールプロットのほかにも、ろうそくチャートやオープン-ハイ-ロー-クローズチャートなど、ビジネスや株価に関連したグラフを簡単に作成することができます。\n\n\n\nwaterfallプロット\n\nx= c(\"Sales\", \"Consulting\", \"Net revenue\", \"Purchases\", \"Other expenses\", \"Profit before tax\")\nmeasure= c(\"relative\", \"relative\", \"total\", \"relative\", \"relative\", \"total\")\ntext= c(\"+60\", \"+80\", \"\", \"-40\", \"-20\", \"Total\")\ny= c(60, 80, 0, -40, -20, 0)\n\ndata = data.frame(x = factor(x, levels = x), measure, text, y)\n\nfig &lt;- plot_ly(\n  data, name = \"20\", type = \"waterfall\", measure = ~measure,\n  x = ~x, textposition = \"outside\", y= ~y, text = ~text,\n  connector = list(line = list(color = \"rgb(63, 63, 63)\"))) \n\nfig &lt;- fig %&gt;%\n  layout(title = \"Profit and loss statement 2018\",\n        xaxis = list(title = \"\"),\n        yaxis = list(title = \"\"),\n        autosize = TRUE,\n        showlegend = TRUE)\n\nfig",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>plotly</span>"
    ]
  },
  {
    "objectID": "chapter23.html#ggplotly",
    "href": "chapter23.html#ggplotly",
    "title": "23  plotly",
    "section": "23.8 ggplotly",
    "text": "23.8 ggplotly\nplotlyでは、ggplot2で準備したグラフをインタラクティブなグラフに簡単に変換することができます。ggplot2のグラフオブジェクトを変数に保存し、その変数をggplotly関数の引数にするだけで、ggplot2のグラフがインタラクティブなものに変換されます。\n\n\n\nggplotlyでインタラクティブなggplot2グラフ\n\np &lt;- iris |&gt; \n  ggplot(aes(x = Sepal.Length, y = Sepal.Width, size = Petal.Length, color = Species))+\n  geom_point() \n\nggplotly(p)\n\n\n\n\n\n\n\n\n\n\n\n\nAllaire, JJ, Yihui Xie, Christophe Dervieux, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, et al. 2023. Rmarkdown: Dynamic Documents for r. https://github.com/rstudio/rmarkdown.\n\n\nChang, Winston, Joe Cheng, JJ Allaire, Carson Sievert, Barret Schloerke, Yihui Xie, Jeff Allen, Jonathan McPherson, Alan Dipert, and Barbara Borges. 2024. Shiny: Web Application Framework for r. https://CRAN.R-project.org/package=shiny.\n\n\nMurdoch, Duncan, and Daniel Adler. 2023. Rgl: 3D Visualization Using OpenGL. https://CRAN.R-project.org/package=rgl.\n\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with r, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n\nStrayer, Nick, Javier Luraschi, and JJ Allaire. 2022. R2d3: Interface to ’D3’ Visualizations. https://CRAN.R-project.org/package=r2d3.\n\n\nXie, Yihui, J. J. Allaire, and Garrett Grolemund. 2018. R Markdown: The Definitive Guide. Boca Raton, Florida: Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown.\n\n\nXie, Yihui, Christophe Dervieux, and Emily Riederer. 2020. R Markdown Cookbook. Boca Raton, Florida: Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown-cookbook.",
    "crumbs": [
      "Rでのグラフ作成",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>plotly</span>"
    ]
  },
  {
    "objectID": "chapter24.html",
    "href": "chapter24.html",
    "title": "24  確率分布と乱数",
    "section": "",
    "text": "24.1 乱数と種（seed）\nプログラミングでは、ランダムに生成された数値、乱数を使った処理を行うことがあります。例えばゲームなどで偶然性を表現する場合には、整数の乱数が用いられています。Rで整数の乱数を得る時には、sample関数を用います。sample関数は数列のベクターから引数で指定した数だけランダムに取り出し、ベクターとして返します。\n1～100の整数からランダムに20個取り出す\n\nsample(1:100, 20, replace=TRUE)\n##  [1]  22  79  89  50  63  68  98   4  49  99  40  74 100  19 100  83  89  31  96\n## [20]  72\n乱数は完全にランダムな数値というわけではなく、ランダムに見える繰り返し計算から生成されています（疑似乱数）。この疑似乱数を生成するアルゴリズムにはいろいろな種類があるのですが、Rではデフォルトの乱数生成アルゴリズムとして、メルセンヌ・ツイスター法（mersenne twister） (Matsumoto and Nishimura 1998) が用いられています。メルセンヌ・ツイスターは乱数生成アルゴリズムの中でも偏りのない乱数を得られるもので、現在ではExcelでも用いられています。\nRでの乱数生成アルゴリズムを確認、設定する場合には、RNGkind関数を用います。RNGkind関数を用いれば、乱数生成アルゴリズムを変更することもできますが、メルセンヌ・ツイスターから変更する必要は特にないでしょう。\n乱数生成アルゴリズムの確認\n\n# ?RNGkindで利用可能な乱数生成アルゴリズムの一覧を確認できる\nRNGkind()\n## [1] \"Mersenne-Twister\" \"Inversion\"        \"Rejection\"\n乱数生成アルゴリズムは繰り返し計算で乱数を生成するため、乱数を生成するときに乱数の初期値が必要となります。この乱数の初期値のことを乱数の種（seed）と呼びます。Rでは乱数の種をset.seed関数で指定することができます。乱数の種をある値に設定しておくと、乱数を何度生成しても同じ結果を得ることができます。乱数を用いた計算で統計を行う場合には、計算の再現性を保つためにseedを設定しておく方がよいでしょう。\nset.seed関数で乱数のシードを設定\n\nset.seed(0)\nsample(1:100, 20, replace=TRUE) # seedが0のときの乱数\n##  [1] 14 68 39  1 34 87 43 14 82 59 51 97 85 21 54 74  7 73 79 85\n\nset.seed(0)\nsample(1:100, 20, replace=TRUE) # seedを0にしているので、値が上と同じ\n##  [1] 14 68 39  1 34 87 43 14 82 59 51 97 85 21 54 74  7 73 79 85",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter24.html#復元抽出と非復元抽出",
    "href": "chapter24.html#復元抽出と非復元抽出",
    "title": "24  確率分布と乱数",
    "section": "24.2 復元抽出と非復元抽出",
    "text": "24.2 復元抽出と非復元抽出\nsample関数では、第1引数として設定したベクターから選択された場合、その値がもう一度選択することができる場合（復元抽出）と、できない場合（非復元抽出）の設定をreplace引数で設定することができます。replace=TRUEの場合は復元抽出、replace=FALSEの場合は非復元抽出となります。非復元抽出の場合には、第1引数の長さ以上の数の値を呼び出すことはできません。replace引数のデフォルトはFALSEですので、replece引数を指定しない場合には非復元抽出が行われます。\n\n\n\n復元抽出と非復元抽出\n\n# 復元抽出\nsample(1:3, 5, replace = TRUE)\n## [1] 1 1 1 2 1\n\n# 非復元抽出\nsample(1:3, 3, replace = FALSE)\n## [1] 1 2 3\n\n# 非復元抽出で取り出す値の数がベクターより長いと、エラーとなる\nsample(1:3, 5, replace = FALSE)\n## Error in sample.int(length(x), size, replace, prob): cannot take a sample larger than the population when 'replace = FALSE'\n\n\nまた、統計では乱数を使った計算（モンテカルロ法）を用いることがあります。特に確率分布に従った乱数を用いた計算が統計では有用です。このような確率分布に従った乱数計算を行う場合には、sample関数ではなく、確率分布に関連した一連の関数を用いるのが一般的です。\n確率分布とは、ランダムに起こる事象（例えばコイントスや身長・体重の大きさなど）がそれぞれの値を取る確率を関数の形で表現したものです。もっとも一般的に用いられている確率分布は、正規分布（Normal distribution）です。正規分布は平均値と標準偏差をパラメータとした確率分布で、平均値を取る確率が最も高く、平均値から離れるほど確率が低くなっていく、釣鐘型の形を取る分布です。\nRでは、この正規分布の確率密度、累積分布、分位点での値、乱数をそれぞれdnorm、pnorm、qnorm、rnorm関数を用いて計算することができます。",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter24.html#確率密度",
    "href": "chapter24.html#確率密度",
    "title": "24  確率分布と乱数",
    "section": "24.3 確率密度",
    "text": "24.3 確率密度\n確率密度は上で述べた通り、ランダムに起こる事象がそれぞれの値を取る確率を示したものです。この確率密度は確率密度関数（離散的な分布では確率質量関数）という関数で表現されます。この確率密度関数を返すのが、「d + 分布の名前」で示される関数です。正規分布の確率密度関数は、dnorm関数で計算することができます。このdnorm関数は、mean引数で指定した平均値、sd引数で指定した標準編差の正規分布において、第一引数で指定した値（x）における確率密度を返す関数です。ただし、確率密度はその値が確率なのではなく、確率密度の積分が確率となりますので、このdnormの返り値が確率ではありません（ただし、確率質量分布、つまり離散的な分布では確率質量分布の返り値が確率となります）。\n確率密度には連続的なものと離散的なものがあり、確率分布ごとに値を取りうる範囲があります。例えば正規分布は\\(+\\infty\\)から\\(-\\infty\\)の範囲の有理数すべてを取ることができる連続的な分布です。別の分布、ポアソン分布は正の整数のみを取ることができる、離散的な分布となります。\n\n\n\n正規分布の確率密度\n\ndnorm(x = 1, mean = 0, sd = 1) # 正規分布の確率密度\n## [1] 0.2419707\n\n\n\n\n\n\n\n\n確率分布の平均と分散\n\n\n\n\n\n確率分布f(x)はその積分が確率となる関数で表されます。確率は合計すると必ず1となるため、確率分布をその分布の範囲で積分すると1になります。また、積分すると1となることが確率分布であることの条件にもなります。\n\\[\\int_{-\\infty}^{\\infty}f(x)dx=1\\]\n確率分布の平均値（\\(E[f(x)]\\)）と分散（\\(V[f(x)]\\)）は以下の積分で計算できます。\n\\[E[f(x)]=\\int_{-\\infty}^{\\infty}x \\cdot f(x)dx\\]\n\\[V[f(x)]=\\int_{-\\infty}^{\\infty}(x-\\mu)^2 \\cdot f(x)dx\\]",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter24.html#累積分布",
    "href": "chapter24.html#累積分布",
    "title": "24  確率分布と乱数",
    "section": "24.4 累積分布",
    "text": "24.4 累積分布\n確率密度をx軸方向に積分して得られる関数のことを、累積分布関数と呼びます。上に述べた通り、確率密度を積分したものが確率となりますので、累積分布関数を用いると、正規分布する値がある一定の範囲を取る確率を計算することができます。Rで累積分布関数を返すのが、「p + 分布の名前」で示される関数です。\n正規分布の累積分布関数は、pnorm関数で計算することができます。正規分布の累積分布関数では、正規分布する値が\\(-\\infty\\)からその値までの範囲を取る確率が計算されるため、正規分布する値が第一引数qで指定した値以下となる確率を計算することになります。平均値をmean引数、標準偏差をsd引数で指定するのはすべてのnorm関数で共通しています。\n\n\n\n正規分布の累積分布関数\n\npnorm(q = 1, mean = 0, sd = 1) # 正規分布の累積分布関数（q（1）以下となる確率）\n## [1] 0.8413447\n\n# 平均0、標準偏差1の正規分布での標準偏差の区間（-1 ~ 1）の値が得られる確率\npnorm(1, mean = 0, sd = 1) - pnorm(-1, mean = 0, sd = 1) \n## [1] 0.6826895\n\n# 平均0、標準偏差1の正規分布で、-1.96~1.96の値が得られる確率（95％区間）\npnorm(1.96, mean = 0, sd = 1) - pnorm(-1.96, mean = 0, sd = 1) \n## [1] 0.9500042\n\n# 累積分布関数の形（正規分布）\nplot(seq(-3, 3, by = 0.1), pnorm(seq(-3, 3, by = 0.1)), type = \"l\")",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter24.html#分位点",
    "href": "chapter24.html#分位点",
    "title": "24  確率分布と乱数",
    "section": "24.5 分位点",
    "text": "24.5 分位点\n逆に、累積分布関数で求まる確率から、その確率となる値を求める関数が、「q + 分布の名前」で示される関数です。第一引数であるpには確率（0～1）を指定し、その確率が得られる累積分布関数でのx軸上の値を得ることができます。正規分布では、qnorm関数でこの計算を行うことができます。pnorm関数とqnorm関数では、第一引数と返り値の関係がちょうど逆になります。\n引数pに対して、qnorm関数で得られる値のことを、「100*p%分位点」と呼ぶのが一般的です。p=0.25なら25％分位点、p=0.75なら75％分位点が得られることになります。\n\n\n\n正規分布の分位点\n\nqnorm(p = 0.975, mean = 0, sd = 1) # 正規分布の97.5%分位点における値\n## [1] 1.959964\n\n# qnormの形はpnorm（累積分布関数）のx、yが入れ替わったものとなる\nplot(seq(0, 1, by = 0.01), qnorm(seq(0, 1, by = 0.01)), type = \"l\")\n\n\n\n\n\n\n\n\n\n確率密度（dnorm）、累積分布（pnorm）、分位点（qnorm）の関係を図で示すと、以下のような関係になっています。\n\n\n\n確率密度、累積分布、分位点の関係",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter24.html#確率分布に従った乱数",
    "href": "chapter24.html#確率分布に従った乱数",
    "title": "24  確率分布と乱数",
    "section": "24.6 確率分布に従った乱数",
    "text": "24.6 確率分布に従った乱数\n確率分布に従った乱数を得ることができれば、その確率分布に従う現象をシミュレートすることができます。Rで確率分布に従った乱数を求める関数が、「r + 分布の名前」で示される関数です。正規分布では、rnorm関数で乱数（正規乱数）を得ることができます。第一引数（n）で、乱数の個数を指定します。\n\n\n\n正規分布の確率密度\n\nrnorm(n = 10, mean = 0, sd = 1) # 正規分布の乱数\n##  [1]  0.25222345 -0.89192113  0.43568330 -1.23753842 -0.22426789  0.37739565\n##  [7]  0.13333636  0.80418951 -0.05710677  0.50360797\n\n# 乱数をたくさん生成し、ヒストグラムを描画する\nrnorm(10000, mean = 0, sd = 1) |&gt; hist() \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n確率分布に従う乱数を得る\n\n\n\n\n\n通常、確率分布に従う形の乱数を得る場合には、累積分布関数の逆関数というものを用います。逆関数はy=f(x)の関数をx=g(y)という形に、xについて解いたものを指します。確率密度関数の逆関数に一様乱数を入れると、確率分布に従った乱数を得ることができます。rnormなどの乱数生成アルゴリズムはC言語で記載されていて、逆関数を用いているのかはわかりませんが、メルセンヌ・ツイスターで生成されるのは一様乱数ですので、内部的には同様の変換が行われているのだと思います。",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter24.html#rで用いることのできる確率分布の一覧",
    "href": "chapter24.html#rで用いることのできる確率分布の一覧",
    "title": "24  確率分布と乱数",
    "section": "24.7 Rで用いることのできる確率分布の一覧",
    "text": "24.7 Rで用いることのできる確率分布の一覧\nRでは、norm（正規分布）の他に、以下の表1で示す確率分布に関する関数が登録されています。各確率分布の「記号」の前にdを付けると確率密度関数、pを付けると累積分布関数、qを付けると分位点、rを付けると乱数を得る関数となります。\n\n\n\n\n\n記号\n分布\n英語での分布名\nパラメータ\n\n\n\n\nbinom\n二項分布\nbinomial\nsize, prob\n\n\ngeom\n幾何分布\ngeometric\nprob\n\n\nhyper\n超幾何分布\nhypergeometric\nm, n, k\n\n\nnbinom\n負の二項分布\nnegative binomial\nsize, prob\n\n\npois\nポアソン分布\nPoisson\nlambda\n\n\nnorm\n正規分布\nnormal\nmean, sd\n\n\nt\nStudentのt分布\nStudent’s t\ndf\n\n\ncauchy\nコーシー分布\nCauchy\nlocation, scale\n\n\nlogis\nロジスティック分布\nlogistic\nlocation, scale\n\n\nlnorm\n対数正規分布\nlog-normal\nmeanlog, sdlog\n\n\nbeta\nベータ分布\nbeta\nshape1, shape2\n\n\nchisq\nカイ二乗分布\nchi-squared\ndf\n\n\nf\nF分布\nF\ndf1, df2\n\n\ngamma\nガンマ分布\ngamma\nshape, scale\n\n\nexp\n指数分布\nexponential\nrate\n\n\nweibull\nワイブル分布\nWeibull\nshape, scale\n\n\nunif\n一様分布\nuniform\nmin, max\n\n\nmultinom\n多項分布\nmultinomial\nsize, prob\n\n\n\n\n\n\n\n\n\n\n\nその他の確率分布\n\n\n\n\n\n上記の表1に示した以外にも、Rではライブラリを用いることで様々な確率分布の関数を用いることができます。ライブラリの一覧に関しては、CRAN Task ViewのProbability Distributionsが参考になります。また、それぞれの確率分布の関係については、Univariate Distribution Relationshipsに詳しく記載されているので、興味のある方は一読するとよいでしょう。日本語では、こちらの三中先生の解説ページに書かれています。また、確率分布を表示するWebアプリを触ってみるのも良いでしょう。\n\n\n\n以下に、各確率分布の簡単な説明と、各関数を用いたグラフを示します。",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter24.html#二項分布",
    "href": "chapter24.html#二項分布",
    "title": "24  確率分布と乱数",
    "section": "24.8 二項分布",
    "text": "24.8 二項分布\n二項分布はベルヌーイ試行（コイントスのように、1と0だけが確率的に結果として得られる試行）の試行回数（size）と成功確率（prob）から、成功回数xが得られる確率を示したものです。二項分布の確率質量関数は以下の式で表されます。\n\\[Binom(x,n,p)=_{n}C_{x} \\cdot p^{x} \\cdot (1-p)^{n-x}\\]\nnが試行回数、pが成功確率、xが成功回数を表しています。Rでは、nをsize引数、pをprob引数で指定します。コイントスですので、整数でない成功回数（4.21回成功など）が起こることはありませんし、マイナスの試行数も取りません。ですので、二項分布は成功回数xが正の整数のみの離散的な確率分布になります。分布の範囲は0～試行回数です。\n\n確率質量累積分布関数分位点の値二項乱数\n\n\n\n\n\n二項分布の確率密度をプロット\n\nx &lt;- 0:20\nd &lt;- tibble(\n  x,\n  s20p01 = dbinom(x, size = 20, prob = 0.1), # サイズ20、確率0.1\n  s20p05 = dbinom(x, size = 20, prob = 0.5), # サイズ20、確率0.5\n  s20p08 = dbinom(x, size = 20, prob = 0.8) # サイズ20、確率0.8\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n二項分布の累積分布関数をプロット\n\nd &lt;- tibble(\n  x,\n  s20p01 = pbinom(x, size = 20, prob = 0.1), # サイズ20、確率0.1\n  s20p05 = pbinom(x, size = 20, prob = 0.5), # サイズ20、確率0.5\n  s20p08 = pbinom(x, size = 20, prob = 0.8) # サイズ20、確率0.8\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n累積分布関数の分位点と値の関係をqbinomでプロット\n\nx &lt;- seq(0, 1, by = 0.01)\nd &lt;- tibble(\n  x,\n  s20p01 = qbinom(x, size = 20, prob = 0.1), # サイズ20、確率0.1\n  s20p05 = qbinom(x, size = 20, prob = 0.5), # サイズ20、確率0.5\n  s20p08 = qbinom(x, size = 20, prob = 0.8) # サイズ20、確率0.8\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n乱数のヒストグラムをプロット\n\nd &lt;- tibble(\n  s20p01 = rbinom(1000, size = 20, prob = 0.1), # サイズ20、確率0.1\n  s20p05 = rbinom(1000, size = 20, prob = 0.5), # サイズ20、確率0.5\n  s20p08 = rbinom(1000, size = 20, prob = 0.8) # サイズ20、確率0.8\n)\n\nd |&gt; \n  pivot_longer(1:3) |&gt; \n  ggplot(aes(x = value, color = name, fill = name, alpha = 0.5)) +\n  geom_histogram(binwidth = 1, position = \"identity\")",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter24.html#幾何分布",
    "href": "chapter24.html#幾何分布",
    "title": "24  確率分布と乱数",
    "section": "24.9 幾何分布",
    "text": "24.9 幾何分布\n幾何分布は、ベルヌーイ試行を始めて成功させたときの試行数がxとなる確率を指します。2項分布との違いは、成功回数が必ず1回であるところになります。x以外には、成功確率（prob）のみをパラメータとして設定します。分布の範囲は0～\\(+\\infty\\)です。幾何分布の確率質量関数は以下の式で表されます。\n\\[Geom(x,p)=p  \\cdot (1-p)^{x-1}\\]\nRでは、pをprob引数で設定します。\n1回成功するまでに失敗した回数も同じく幾何分布で表現することができます。失敗した回数とする場合には、上の式のx-1をxとするだけです。Rのgeom関数で計算されるのは上の式の結果です。\n\\[Geom(x,p)=p \\cdot (1-p)^{x}\\]\n試行数xは必ず整数となるため、幾何分布も二項分布と同じく、離散的な分布で、xは正の整数を取ります。\n\n確率質量累積分布関数分位点の値幾何乱数\n\n\n\n\n\n幾何分布の確率密度をプロット\n\nx &lt;- 1:50\nd &lt;- tibble(\n  x,\n  r01 = dgeom(x, prob = 0.1), # 確率0.1\n  r05 = dgeom(x, prob = 0.5), # 確率0.5\n  r08 = dgeom(x, prob = 0.8) # 確率0.8\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n幾何分布の累積分布関数をプロット\n\nd &lt;- tibble(\n  x,\n  r01 = pgeom(x, prob = 0.1), # 確率0.1\n  r05 = pgeom(x, prob = 0.5), # 確率0.5\n  r08 = pgeom(x, prob = 0.8) # 確率0.8\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n累積分布関数の分位点と値の関係をqfでプロット\n\nx &lt;- seq(0, 1, by = 0.01)\nd &lt;- tibble(\n  x,\n  r01 = qgeom(x, prob = 0.1), # 確率0.1\n  r05 = qgeom(x, prob = 0.5), # 確率0.5\n  r08 = qgeom(x, prob = 0.8) # 確率0.8\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n乱数の確率密度をプロット\n\nd &lt;- tibble(\n  r01 = rgeom(1000, prob = 0.1), # 確率0.1\n  r05 = rgeom(1000, prob = 0.5), # 確率0.5\n  r08 = rgeom(1000, prob = 0.8) # 確率0.8\n)\n\nd |&gt; \n  pivot_longer(1:3) |&gt; \n  ggplot(aes(x = value, color = name, fill = name, alpha = 0.5)) +\n  geom_histogram(binwidth = 5, position = \"identity\")",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter24.html#超幾何分布",
    "href": "chapter24.html#超幾何分布",
    "title": "24  確率分布と乱数",
    "section": "24.10 超幾何分布",
    "text": "24.10 超幾何分布\n超幾何分布は、ツボの中に白と黒のボールが入っていて、このツボからボールを取り出す試行（非復元抽出）を表現した確率分布です。超幾何分布の確率質量関数は以下の式で表されます。\n\\[ Hyper(x,m,n,k)= \\frac{_{m}C_{k} \\cdot _{n}C_{x-k}}{_{m+n}C_{x}}\\]\nRのhyper関数では、白ボールm個、黒ボールn個が入ったツボからk個ボールを取ったとき、x個の白ボールが取れる確率を計算します。dhyper関数の引数はm、n、kで、xは整数のみを取る離散的な分布です。分布の範囲は0～kとなります。\n\n確率質量累積分布関数分位点の値超幾何乱数\n\n\n\n\n\n超幾何分布の確率密度をプロット\n\nx &lt;- 1:6\nd &lt;- tibble(\n  x,\n  m5n5k5 = dhyper(x, m = 5, n = 5, k = 5), # 白 5, 黒 5, 取るボールの数 5\n  m10n5k5 = dhyper(x, m = 10, n = 5, k = 5), # 白 10, 黒 5, 取るボールの数 5\n  m5n20k10 = dhyper(x, m = 5, n = 20, k = 10) # 白 5, 黒 20, 取るボールの数 10\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n超幾何分布の累積分布関数をプロット\n\nd &lt;- tibble(\n  x,\n  m5n5k5 = phyper(x, m = 5, n = 5, k = 5), # 白 5, 赤 5, 取るボールの数 5\n  m10n5k5 = phyper(x, m = 10, n = 5, k = 5), # 白 10, 赤 5, 取るボールの数 5\n  m5n20k10 = phyper(x, m = 5, n = 20, k = 10) # 白 5, 赤 20, 取るボールの数 10\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n累積分布関数の分位点と値の関係をqfでプロット\n\nx &lt;- seq(0, 1, by = 0.01)\nd &lt;- tibble(\n  x,\n  m5n5k5 = qhyper(x, m = 5, n = 5, k = 5), # 白 5, 赤 5, 取るボールの数 5\n  m10n5k5 = qhyper(x, m = 10, n = 5, k = 5), # 白 10, 赤 5, 取るボールの数 5\n  m5n20k10 = qhyper(x, m = 5, n = 20, k = 10) # 白 5, 赤 20, 取るボールの数 10\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n乱数の確率密度をプロット\n\nd &lt;- tibble(\n  m5n5k5 = rhyper(1000, m = 5, n = 5, k = 5), # 白 5, 赤 5, 取るボールの数 5\n  m10n5k5 = rhyper(1000, m = 10, n = 5, k = 5), # 白 10, 赤 5, 取るボールの数 5\n  m5n20k10 = rhyper(1000, m = 5, n = 20, k = 10) # 白 5, 赤 20, 取るボールの数 10\n)\n\nd |&gt; \n  pivot_longer(1:3) |&gt; \n  ggplot(aes(x = value, color = name, fill = name, alpha = 0.5)) +\n  geom_histogram(binwidth = 0.1, position = \"identity\")",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter24.html#負の二項分布",
    "href": "chapter24.html#負の二項分布",
    "title": "24  確率分布と乱数",
    "section": "24.11 負の二項分布",
    "text": "24.11 負の二項分布\n負の二項分布は、ベルヌーイ試行を行ったとき、n回成功する間にx回失敗する確率を反映した確率分布です。成功の回数がn、失敗回数をx、成功確率をpとしたとき、負の二項分布の確率質量関数は以下の式で表されます。\n\\[Nbinom(x,n,p)=_{x+n+1}C_{x} \\cdot p^x(1-p)^n\\]\nRでの負の二項分布の確率質量関数はdnbinom関数で計算することができます。成功の回数nはsize引数、成功確率pはprob引数で設定します。負の二項分布は正の整数のみを取る離散的な分布で、その範囲は0～\\(\\infty\\)となります。\n\n確率質量累積分布関数分位点の値負の二項乱数\n\n\n\n\n\n負の二項分布の確率密度をプロット\n\nx &lt;- 0:100\nd &lt;- tibble(\n  x,\n  p01 = dnbinom(x, size = 5, prob = 0.1), # サイズ5、確率0.1\n  p05 = dnbinom(x, size = 5, prob = 0.5), # サイズ5、確率0.5\n  p08 = dnbinom(x, size = 5, prob = 0.8) # サイズ5、確率0.8\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n負の二項分布の累積分布関数をプロット\n\nd &lt;- tibble(\n  x,\n  p01 = pnbinom(x, size = 5, prob = 0.1), # サイズ5、確率0.1\n  p05 = pnbinom(x, size = 5, prob = 0.5), # サイズ5、確率0.5\n  p08 = pnbinom(x, size = 5, prob = 0.8) # サイズ5、確率0.8\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n累積分布関数の分位点と値の関係をqfでプロット\n\nx &lt;- seq(0, 1, by = 0.01)\nd &lt;- tibble(\n  x,\n  p01 = qnbinom(x, size = 5, prob = 0.1), # サイズ5、確率0.1\n  p05 = qnbinom(x, size = 5, prob = 0.5), # サイズ5、確率0.5\n  p08 = qnbinom(x, size = 5, prob = 0.8) # サイズ5、確率0.8\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n乱数の確率密度をプロット\n\nd &lt;- tibble(\n  p01 = rnbinom(1000, size = 5, prob = 0.1), # サイズ5、確率0.1\n  p05 = rnbinom(1000, size = 5, prob = 0.5), # サイズ5、確率0.5\n  p08 = rnbinom(1000, size = 5, prob = 0.8) # サイズ5、確率0.8\n)\n\nd |&gt; \n  pivot_longer(1:3) |&gt; \n  ggplot(aes(x = value, color = name, fill = name, alpha = 0.5)) +\n  geom_histogram(binwidth = 10, position = \"identity\")",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter24.html#ポアソン分布",
    "href": "chapter24.html#ポアソン分布",
    "title": "24  確率分布と乱数",
    "section": "24.12 ポアソン分布",
    "text": "24.12 ポアソン分布\nポアソン分布は、起こる確率が非常に低い現象が、ある一定の時間に何回起こるかを確率として表した確率分布です。ポアソン分布の確率質量関数は二項分布の確率を0に、試行回数を\\(\\infty\\)に近づけた極限として計算されます。ポアソン分布のパラメータはλのみで、ポアソン分布は平均値も標準偏差もλとなる特徴があります。ポアソン分布の確率質量関数は以下の式で表されます。分布が取りうる範囲は0～\\(\\infty\\)となります。\n\\[Poisson(x, \\lambda)=\\frac{\\lambda^x \\cdot \\exp(-\\lambda)}{x!}\\]\nRではポアソン分布の確率質量関数はdpois関数で計算することができます。dpois関数のλは引数lambdaで設定します。\n\n確率質量累積分布関数分位点の値ポアソン乱数\n\n\n\n\n\nポアソン分布の確率密度をプロット\n\nx &lt;- 0:25\nd &lt;- tibble(\n  x,\n  l3 = dpois(x, lambda = 3), # ラムダ3\n  l8 = dpois(x, lambda = 8), # ラムダ8\n  l11 = dpois(x, lambda = 11) # ラムダ11\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nポアソン分布の累積分布関数をプロット\n\nd &lt;- tibble(\n  x,\n  l3 = ppois(x, lambda = 3), # ラムダ3\n  l8 = ppois(x, lambda = 8), # ラムダ8\n  l11 = ppois(x, lambda = 11) # ラムダ11\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n累積分布関数の分位点と値の関係をqfでプロット\n\nx &lt;- seq(0, 1, by = 0.01)\nd &lt;- tibble(\n  x,\n  l3 = qpois(x, lambda = 3), # ラムダ3\n  l8 = qpois(x, lambda = 8), # ラムダ8\n  l11 = qpois(x, lambda = 11) # ラムダ11\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n乱数の確率密度をプロット\n\nd &lt;- tibble(\n  l3 = rpois(1000, lambda = 3), # ラムダ3\n  l8 = rpois(1000, lambda = 8), # ラムダ8\n  l11 = rpois(1000, lambda = 11) # ラムダ11\n)\n\nd |&gt; \n  pivot_longer(1:3) |&gt; \n  ggplot(aes(x = value, color = name, fill = name, alpha = 0.5)) +\n  geom_histogram(binwidth = 1, position = \"identity\")",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter24.html#正規分布",
    "href": "chapter24.html#正規分布",
    "title": "24  確率分布と乱数",
    "section": "24.13 正規分布",
    "text": "24.13 正規分布\n正規分布は、様々な分布での値の平均値の分布を反映したもので（中心極限定理）、統計では最も一般的に用いられているものです。正規分布のパラメータは平均値（μ）と標準偏差（σ）です。正規分布の確率密度関数は以下の式で表されます。\n\\[ Norm(x, \\mu, \\sigma)=\\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\cdot \\exp \\left( \\frac{(x-\\mu)^2}{2\\sigma^2} \\right) \\]\nRでは、正規分布の確率密度関数はdnorm関数で計算することができます。dnorm関数では、平均値はmean引数、標準偏差はsd引数で設定します。\n\n確率密度累積分布関数分位点の値正規乱数\n\n\n\n\n\n正規分布の確率密度をプロット\n\nx &lt;- seq(-5, 5, by = 0.01)\nd &lt;- tibble(\n  x,\n  m0s1 = dnorm(x, mean = 0, sd = 1), # 平均0、標準偏差1\n  m1s2 = dnorm(x, mean = 1, sd = 2), # 平均1、標準偏差2\n  m2s05 = dnorm(x, mean = 2, sd = 0.5) # 平均2、標準偏差0.5\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n正規分布の累積分布関数をプロット\n\nd &lt;- tibble(\n  x,\n  m0s1 = pnorm(x, mean = 0, sd = 1), # 平均0、標準偏差1\n  m1s2 = pnorm(x, mean = 1, sd = 2), # 平均1、標準偏差2\n  m2s05 = pnorm(x, mean = 2, sd = 0.5) # 平均2、標準偏差0.5\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n累積分布関数の分位点と値の関係をqnormでプロット\n\nx &lt;- seq(0, 1, by = 0.01)\nd &lt;- tibble(\n  x,\n  m0s1 = qnorm(x, mean = 0, sd = 1), # 平均0、標準偏差1\n  m1s2 = qnorm(x, mean = 1, sd = 2), # 平均1、標準偏差2\n  m2s05 = qnorm(x, mean = 2, sd = 0.5) # 平均2、標準偏差0.5\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n乱数の確率密度をプロット\n\nd &lt;- tibble(\n  m0s1 = rnorm(1000, mean = 0, sd = 1), # 平均0、標準偏差1\n  m1s2 = rnorm(1000, mean = 1, sd = 2), # 平均1、標準偏差2\n  m2s05 = rnorm(1000, mean = 2, sd = 0.5) # 平均2、標準偏差0.5\n)\n\nd |&gt; \n  pivot_longer(1:3) |&gt; \n  ggplot(aes(x = value, color = name, fill = name, alpha = 0.5)) +\n  geom_histogram(binwidth = 1, position = \"identity\")",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter24.html#t分布",
    "href": "chapter24.html#t分布",
    "title": "24  確率分布と乱数",
    "section": "24.14 t分布",
    "text": "24.14 t分布\nt分布は標本サイズが小さいときの母平均と標本平均の差の分布を反映した確率分布です。t分布はt統計量と呼ばれるものの分布を示します。t統計量は以下の式で計算できます。\n\\[t=\\frac{x-\\mu}{s \\sqrt n}\\]\nこの式で、xはサンプルの平均値、μは母平均値、sは標準偏差、nはサンプルの数を指します。t分布は主にt検定（平均値の差の検定）に用いられます。t分布の確率密度関数は以下の式で表されます。\n\\[t(x, \\nu)=\\frac{\\Gamma(\\nu+1)/2}{\\sqrt{\\nu \\pi} \\cdot \\Gamma(\\nu/2)} \\cdot (1+x^2/\\nu)^{-(\\nu+1)/2}\\]\n上の式のνは自由度で、サンプル数から1を引いたものとなります。Rでは、dt関数でt分布の確率密度関数を計算することができます。dt関数の引数には、自由度dfを設定します。t分布は\\(-\\infty\\)～\\(\\infty\\)の範囲を持つ連続値を取り、平均値は0です。t分布は正規分布とよく似た釣鐘型の分布ですが、正規分布と比較して裾が重い、0から遠い値の確率が大きくなる性質を持ちます。自由度dfが\\(-\\infty\\)に近づくと、t分布の形は正規分布と一致します。\nまた、t分布には検出力の計算等に用いられる非心パラメータと呼ばれるものがあり、ncpという引数で非心パラメータを指定することもできます。非心パラメータを0よりも大きく設定すると、t分布は左にゆがみ、平均値が0よりも大きくなります。\n\n確率密度累積分布関数分位点の値t分布の乱数\n\n\n\n\n\nt分布の確率密度をプロット\n\nx &lt;- seq(-5, 15, by = 0.01)\nd &lt;- tibble(\n  x,\n  d3n0 = dt(x, df = 3, ncp = 0), # 自由度3、非心パラメータ0\n  d8n0 = dt(x, df = 8, ncp = 0), # 自由度8、非心パラメータ0\n  d3n3 = dt(x, df = 3, ncp = 3) # 自由度3、非心パラメータ3\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nt分布の累積分布関数をプロット\n\nd &lt;- tibble(\n  x,\n  d3n0 = pt(x, df = 3, ncp = 0), # 自由度3、非心パラメータ0\n  d8n0 = pt(x, df = 8, ncp = 0), # 自由度8、非心パラメータ0\n  d3n3 = pt(x, df = 3, ncp = 3) # 自由度3、非心パラメータ3\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n累積分布関数の分位点と値の関係をqfでプロット\n\nx &lt;- seq(0, 1, by = 0.01)\nd &lt;- tibble(\n  x,\n  d3n0 = qt(x, df = 3, ncp = 0), # 自由度3、非心パラメータ0\n  d8n0 = qt(x, df = 8, ncp = 0), # 自由度8、非心パラメータ0\n  d3n3 = qt(x, df = 3, ncp = 3) # 自由度3、非心パラメータ3\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n乱数の確率密度をプロット\n\nd &lt;- tibble(\n  d3n0 = rt(1000, df = 3, ncp = 0), # 自由度3、非心パラメータ0\n  d8n0 = rt(1000, df = 8, ncp = 0), # 自由度8、非心パラメータ0\n  d3n3 = rt(1000, df = 3, ncp = 3) # 自由度3、非心パラメータ3\n)\n\nd |&gt; \n  pivot_longer(1:3) |&gt; \n  ggplot(aes(x = value, color = name, fill = name, alpha = 0.5)) +\n  geom_histogram(binwidth = 1, position = \"identity\")",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter24.html#コーシー分布",
    "href": "chapter24.html#コーシー分布",
    "title": "24  確率分布と乱数",
    "section": "24.15 コーシー分布",
    "text": "24.15 コーシー分布\nコーシー分布はt分布で自由度が1のときの分布です。コーシー分布はt分布よりもさらに裾が重く、平均値も標準偏差も定義できない分布です。コーシー分布のパラメータは中央値であるtとスケールパラメータであるsの2つです。コーシー分布の確率密度関数は以下の式で表されます。\n\\[Cauchy(x, t, s)=\\frac{1}{s \\cdot \\pi (1+((x-t)/s)^2)} \\]\nRでは、コーシー分布の確率密度関数はdcauchy関数で計算することができます。dcauchy関数の引数は中央値tであるlocationとスケールパラメータsであるscaleの2つです。コーシー分布も正規分布やt分布と同じく、\\(-\\infty\\)～\\(\\infty\\)の範囲を持つ連続値を取ります。\n\n確率密度累積分布関数分位点の値コーシー乱数\n\n\n\n\n\nコーシー分布の確率密度をプロット\n\nx &lt;- seq(-5, 5, by = 0.01)\nd &lt;- tibble(\n  x,\n  l0s1 = dcauchy(x, location = 0, scale = 1), # 中央値0、スケール1\n  lm2s05 = dcauchy(x, location = -2, scale = 0.5), # 中央値-2、スケール0.5\n  l2s2 = dcauchy(x, location = 2, scale = 2) # 中央値2、スケール2\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nコーシー分布の累積分布関数をプロット\n\nd &lt;- tibble(\n  x,\n  l0s1 = pcauchy(x, location = 0, scale = 1), # 中央値20、スケール0.1\n  lm2s05 = pcauchy(x, location = -2, scale = 0.5), # 中央値20、スケール0.5\n  l2s2 = pcauchy(x, location = 2, scale = 2) # 中央値20、スケール0.8\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()+\n  expand_limits(y=0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n累積分布関数の分位点と値の関係をqcauchyでプロット\n\nx &lt;- seq(0, 1, by = 0.01)\nd &lt;- tibble(\n  x,\n  l0s1 = qcauchy(x, location = 0, scale = 1), # 中央値20、スケール0.1\n  lm2s05 = qcauchy(x, location = -2, scale = 0.5), # 中央値20、スケール0.5\n  l2s2 = qcauchy(x, location = 2, scale = 2) # 中央値20、スケール0.8\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n乱数のヒストグラムをプロット\n\nset.seed(0)\nd &lt;- tibble(\n  l0s1 = rcauchy(1000, location = 0, scale = 1), # 中央値20、スケール0.1\n  lm2s05 = rcauchy(1000, location = -2, scale = 0.5), # 中央値20、スケール0.5\n  l2s2 = rcauchy(1000, location = 2, scale = 2) # 中央値20、スケール0.8\n)\n\nd |&gt; \n  pivot_longer(1:3) |&gt; \n  ggplot(aes(x = value, color = name, fill = name, alpha = 0.2)) +\n  geom_histogram(binwidth = 50, position = \"identity\")",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter24.html#ロジスティック分布",
    "href": "chapter24.html#ロジスティック分布",
    "title": "24  確率分布と乱数",
    "section": "24.16 ロジスティック分布",
    "text": "24.16 ロジスティック分布\nロジスティック分布はロジスティック関数を微分したものを分布としたもの、つまり、ロジスティック分布の積分である累積分布関数がロジスティック関数を取る分布のことを指します。ロジスティック関数は線形回帰で用いられる関数で、以下の式で表されます。\n\\[logis(x)=\\frac{1}{(1+\\exp(-(ax+b))}\\]\nロジスティック関数は個体群モデルの数式化と関連のある関数です。統計では、逆関数であるロジット関数から導出されます。ロジット関数は以下の式で表されます。\n\\[log(\\frac{p}{1-p})=ax+b\\]\nロジット関数のpはベルヌーイ試行の成功確率p、ax+bは線形回帰の式です。\\(p/1-p\\)はオッズ比と呼ばれるもので、成功確率と失敗確率の比を指します。\nロジスティック分布は以下の式で表されます。\n\\[Logistic(x, \\mu, s)=\\frac{\\exp(-x)}{s(1+\\exp(-(x-\\mu)/s)^2)}\\]\n上の式のμは中央値、sはスケールパラメータです。Rでは、ロジスティック分布の確率密度関数はdlogis関数で計算することができます。dlogis関数の引数には、中央値μであるlocationとスケールパラメータsであるscaleを指定します。ロジスティック分布は\\(-\\infty\\)～\\(\\infty\\)の範囲を持つ連続値を取ります。\n\n確率密度累積分布関数分位点の値ロジスティック乱数\n\n\n\n\n\nロジスティック分布の確率密度をプロット\n\nx &lt;- seq(-5, 5, by = 0.01)\nd &lt;- tibble(\n  x,\n  l0s1 = dlogis(x, location = 0, scale = 1), # location 0、scale1\n  l1s2 = dlogis(x, location = 1, scale = 2), # location 1、scale2\n  l2s05 = dlogis(x, location = 2, scale = 0.5) # location 2、scale0.5\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nロジスティック分布の累積分布関数をプロット\n\nd &lt;- tibble(\n  x,\n  l0s1 = plogis(x, location = 0, scale = 1), # location 0、scale1\n  l1s2 = plogis(x, location = 1, scale = 2), # location 1、scale2\n  l2s05 = plogis(x, location = 2, scale = 0.5) # location 2、scale0.5\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n累積分布関数の分位点と値の関係をqlogisでプロット\n\nx &lt;- seq(0, 1, by = 0.01)\nd &lt;- tibble(\n  x,\n  l0s1 = qlogis(x, location = 0, scale = 1), # location 0、scale1\n  l1s2 = qlogis(x, location = 1, scale = 2), # location 1、scale2\n  l2s05 = qlogis(x, location = 2, scale = 0.5) # location 2、scale0.5\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n乱数の確率密度をプロット\n\nd &lt;- tibble(\n  l0s1 = rlogis(1000, location = 0, scale = 1), # location 0、scale1\n  l1s2 = rlogis(1000, location = 1, scale = 2), # location 1、scale2\n  l2s05 = rlogis(1000, location = 2, scale = 0.5) # location 2、scale0.5\n)\n\nd |&gt; \n  pivot_longer(1:3) |&gt; \n  ggplot(aes(x = value, color = name, fill = name, alpha = 0.5)) +\n  geom_histogram(binwidth = 1, position = \"identity\")",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter24.html#対数正規分布",
    "href": "chapter24.html#対数正規分布",
    "title": "24  確率分布と乱数",
    "section": "24.17 対数正規分布",
    "text": "24.17 対数正規分布\n対数正規分布は正規分布を指数変換した分布です。年収がこの分布に従うことで有名です。パラメータは正規分布と同じくμとσですが、μとσは分布の平均値・標準偏差ではありません。対数正規分布の確率密度関数は以下の式で表されます。\n\\[Lognorm(x, \\mu, \\sigma)=\\frac{1}{x\\sigma\\sqrt{2\\pi}} \\cdot \\exp(-\\frac{(\\ln x-\\mu)^2}{2\\sigma^2})\\]\nRで対数正規分布の確率密度関数を計算するには、dlnorm関数を用います。dlnorm関数の引数には、μとしてmeanlog、σとしてsdlogを指定します。対数正規分布は左に歪み、右側の裾が長い分布を示し、0～\\(\\infty\\)の範囲を持つ連続値を取ります。\n\n確率密度累積分布関数分位点の値対数正規乱数\n\n\n\n\n\n対数正規分布の確率密度をプロット\n\nx &lt;- seq(0, 5, by = 0.01)\nd &lt;- tibble(\n  x,\n  m0s1 = dlnorm(x, meanlog = 0, sdlog = 1), # 平均（対数）0、標準偏差（対数）1\n  m2s2 = dlnorm(x, meanlog = 2, sdlog = 2), # 平均（対数）2、標準偏差（対数）2\n  mm2s05 = dlnorm(x, meanlog = -2, sdlog = 0.5) # 平均（対数）-2、標準偏差（対数）0.5\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n対数正規分布の累積分布関数をプロット\n\nd &lt;- tibble(\n  x,\n  m0s1 = plnorm(x, meanlog = 0, sdlog = 1), # 平均（対数）0、標準偏差（対数）1\n  m2s2 = plnorm(x, meanlog = 2, sdlog = 2), # 平均（対数）2、標準偏差（対数）2\n  mm2s05 = plnorm(x, meanlog = -2, sdlog = 0.5) # 平均（対数）-2、標準偏差（対数）0.5\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n累積分布関数の分位点と値の関係をqfでプロット\n\nx &lt;- seq(0, 1, by = 0.01)\nd &lt;- tibble(\n  x,\n  m0s1 = qlnorm(x, meanlog = 0, sdlog = 1), # 平均（対数）0、標準偏差（対数）1\n  m2s2 = qlnorm(x, meanlog = 2, sdlog = 2), # 平均（対数）2、標準偏差（対数）2\n  mm2s05 = qlnorm(x, meanlog = -2, sdlog = 0.5) # 平均（対数）-2、標準偏差（対数）0.5\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n乱数の確率密度をプロット\n\nd &lt;- tibble(\n  m0s1 = rlnorm(1000, meanlog = 0, sdlog = 1), # 平均（対数）0、標準偏差（対数）1\n  m2s2 = rlnorm(1000, meanlog = 2, sdlog = 2), # 平均（対数）2、標準偏差（対数）2\n  mm2s05 = rlnorm(1000, meanlog = -2, sdlog = 0.5) # 平均（対数）-2、標準偏差（対数）0.5\n)\n\nd |&gt; \n  pivot_longer(1:3) |&gt; \n  ggplot(aes(x = value, color = name, fill = name, alpha = 0.5)) +\n  geom_histogram(binwidth = 100, position = \"identity\")",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter24.html#ベータ分布",
    "href": "chapter24.html#ベータ分布",
    "title": "24  確率分布と乱数",
    "section": "24.18 ベータ分布",
    "text": "24.18 ベータ分布\nベータ分布は、ベルヌーイ試行などの成功確率をモデル化する際に用いられる分布です。ベータ分布の確率密度関数には2つのパラメータがあり、それぞれα、βと呼ばれます。どちらも形状パラメータを意味しています。ベータ分布の確率密度関数は以下の式で表されます。\n\\[Beta(x, \\alpha, \\beta)=\\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\cdot x^{\\alpha-1} \\cdot (1-x)^{\\beta-1}\\]\nRでは、ベータ分布の確率密度関数はdbeta関数で計算することができます。dbeta分布の引数として、αをshape1、βをshape2として指定します。ベータ分布は0～1までの連続値を取ります。\n\n確率密度累積分布関数分位点の値ベータ分布乱数\n\n\n\n\n\nベータ分布の確率密度をプロット\n\nx &lt;- seq(0, 1, by = 0.01)\nd &lt;- tibble(\n  x,\n  s05s075 = dbeta(x, shape1 = 0.5, shape2 = 0.75), # shape1が0.5、shape2が0.75\n  s1s1  = dbeta(x, shape1 = 1, shape2 = 1), # shape1が1、shape2が1\n  s3s2 = dbeta(x, shape1 = 3, shape2 = 2) # shape1が3、shape2が2\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nベータ分布の累積分布関数をプロット\n\nx &lt;- seq(0, 1, by = 0.01)\nd &lt;- tibble(\n  x,\n  s05s075 = pbeta(x, shape1 = 0.5, shape2 = 0.75), # shape1が0.5、shape2が0.75\n  s1s1  = pbeta(x, shape1 = 1, shape2 = 1), # shape1が1、shape2が1\n  s3s2 = pbeta(x, shape1 = 3, shape2 = 2) # shape1が3、shape2が2\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n累積分布関数の分位点と値の関係をqbetaでプロット\n\nx &lt;- seq(0, 1, by = 0.01)\nd &lt;- tibble(\n  x,\n  s05s075 = qbeta(x, shape1 = 0.5, shape2 = 0.75), # shape1が0.5、shape2が0.75\n  s1s1  = qbeta(x, shape1 = 1, shape2 = 1), # shape1が1、shape2が1\n  s3s2 = qbeta(x, shape1 = 3, shape2 = 2) # shape1が3、shape2が2\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n乱数のヒストグラムをプロット\n\nd &lt;- tibble(\n  s05s075 = rbeta(1000, shape1 = 0.5, shape2 = 0.75), # shape1が0.5、shape2が0.75\n  s1s1  = rbeta(1000, shape1 = 1, shape2 = 1), # shape1が1、shape2が1\n  s3s2 = rbeta(1000, shape1 = 3, shape2 = 2) # shape1が3、shape2が2\n)\n\nd |&gt; \n  pivot_longer(1:3) |&gt; \n  ggplot(aes(x = value, color = name, fill = name, alpha = 0.5)) +\n  geom_histogram(binwidth = 0.1, position = \"identity\")",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter24.html#カイ二乗分布",
    "href": "chapter24.html#カイ二乗分布",
    "title": "24  確率分布と乱数",
    "section": "24.19 カイ二乗分布",
    "text": "24.19 カイ二乗分布\nカイ二乗分布は正規分布に従う確率変数の二乗和の確率分布です。カイ二乗分布は度数の検定に用いられる分布で、そのパラメータは自由度νのみです。カイ二乗分布の確率密度関数は以下の式で表されます。\n\\[Chisq(x, \\nu)=\\frac{\\exp(-x/2) \\cdot \\exp(\\nu/2-1)}{2^{\\nu/2} \\cdot \\Gamma(\\nu/2)}\\]\nRでは、カイ二乗分布はdchisq関数で計算することができます。dchisq関数の引数として、自由度νをdfとして指定します。カイ二乗分布は右側の裾が長い分布を示し、0～\\(\\infty\\)の範囲を持つ連続値を取ります。\n\n確率密度累積分布関数分位点の値カイ二乗乱数\n\n\n\n\n\nカイ二乗分布の確率密度をプロット\n\nx &lt;- seq(0, 30, by = 0.01)\nd &lt;- tibble(\n  x,\n  d3n0 = dchisq(x, df = 3, ncp = 0), # 自由度3、非心パラメータ0\n  d5n05 = dchisq(x, df = 5, ncp = 0.5), # 自由度5、非心パラメータ0.5\n  d10n2 = dchisq(x, df = 10, ncp = 2) # 自由度10、非心パラメータ2\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nカイ二乗分布の累積分布関数をプロット\n\nd &lt;- tibble(\n  x,\n  d3n0 = pchisq(x, df = 3, ncp = 0), # 自由度3、非心パラメータ0\n  d5n05 = pchisq(x, df = 5, ncp = 0.5), # 自由度5、非心パラメータ0.5\n  d10n2 = pchisq(x, df = 10, ncp = 2) # 自由度10、非心パラメータ2\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n累積分布関数の分位点と値の関係をqchisqでプロット\n\nx &lt;- seq(0, 1, by = 0.01)\nd &lt;- tibble(\n  x,\n  d3n0 = qchisq(x, df = 3, ncp = 0), # 自由度3、非心パラメータ0\n  d5n05 = qchisq(x, df = 5, ncp = 0.5), # 自由度5、非心パラメータ0.5\n  d10n2 = qchisq(x, df = 10, ncp = 2) # 自由度10、非心パラメータ2\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n乱数のヒストグラムをプロット\n\nd &lt;- tibble(\n  d3n0 = rchisq(1000, df = 3, ncp = 0), # 自由度3、非心パラメータ0\n  d5n05 = rchisq(1000, df = 5, ncp = 0.5), # 自由度5、非心パラメータ0.5\n  d10n2 = rchisq(1000, df = 10, ncp = 2) # 自由度10、非心パラメータ2\n)\n\nd |&gt; \n  pivot_longer(1:3) |&gt; \n  ggplot(aes(x = value, color = name, fill = name, alpha = 0.5)) +\n  geom_histogram(binwidth = 1, position = \"identity\")",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter24.html#f分布",
    "href": "chapter24.html#f分布",
    "title": "24  確率分布と乱数",
    "section": "24.20 F分布",
    "text": "24.20 F分布\nF分布はカイ二乗に従う2つの独立な変数の比の分布です。F分布は分散分析で用いられる分布です。F分布のパラメータは独立の2変数それぞれの自由度（ν1とν2）です。F分布の確率密度関数は以下の式で表されます。\n\\[F(x, \\nu_{1}, \\nu_{2})=\n\\frac{\\Gamma(\\frac{\\nu_{1}+\\nu_{2}}{2}) \\cdot (\\frac{\\nu_{1}}{\\nu_{2}})^{\\nu_{1}/2 \\cdot x^{\\nu_{1}/2-1}}}\n{\\Gamma(\\frac{\\nu_{1}}{2}) \\cdot \\Gamma(\\frac{\\nu_{2}}{2}) \\cdot (1+\\frac{\\nu_{1}x}{\\nu_{2}})^{\\frac{\\nu_{1}+\\nu_{2}}{2}}}\\]\nRではF分布の確率密度関数をdf関数で計算することができます。df関数では自由度2つをそれぞれdf1、df2引数として指定します。F分布も右側の裾が長い分布を示し、0～\\(\\infty\\)の範囲を持つ連続値を取ります。\n\n確率密度累積分布関数分位点の値F乱数\n\n\n\n\n\nF分布の確率密度をプロット\n\nx &lt;- seq(0, 10, by = 0.01)\nd &lt;- tibble(\n  x,\n  df5df5 = df(x, df1 = 5, df2 = 5), # 自由度1 5、自由度2 5\n  df10df15 = df(x, df1 = 10, df2 = 15), # 自由度1 10、自由度2 15\n  df15df20 = df(x, df1 = 20, df2 = 15) # 自由度1 20、自由度2 15\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nF分布の累積分布関数をプロット\n\nd &lt;- tibble(\n  x,\n  df5df5 = pf(x, df1 = 5, df2 = 5), # 自由度1 5、自由度2 5\n  df10df15 = pf(x, df1 = 10, df2 = 15), # 自由度1 10、自由度2 15\n  df15df20 = pf(x, df1 = 20, df2 = 15) # 自由度1 20、自由度2 15\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n累積分布関数の分位点と値の関係をqfでプロット\n\nx &lt;- seq(0, 1, by = 0.01)\nd &lt;- tibble(\n  x,\n  df5df5 = qf(x, df1 = 5, df2 = 5), # 自由度1 5、自由度2 5\n  df10df15 = qf(x, df1 = 10, df2 = 15), # 自由度1 10、自由度2 15\n  df15df20 = qf(x, df1 = 20, df2 = 15) # 自由度1 20、自由度2 15\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n乱数の確率密度をプロット\n\nd &lt;- tibble(\n  df5df5 = rf(1000, df1 = 5, df2 = 5), # 自由度1 5、自由度2 5\n  df10df15 = rf(1000, df1 = 10, df2 = 15), # 自由度1 10、自由度2 15\n  df15df20 = rf(1000, df1 = 20, df2 = 15) # 自由度1 20、自由度2 15\n)\n\nd |&gt; \n  pivot_longer(1:3) |&gt; \n  ggplot(aes(x = value, color = name, fill = name, alpha = 0.5)) +\n  geom_histogram(binwidth = 1, position = \"identity\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nデータフレームの変数名\n\n\n\n\n\nRでデータフレームを変数に代入する場合、data.frameから変数名をdfとする場合があるのですが、このdfにデータフレームを代入してしまうと、F関数の確率密度関数であるdf関数を上書きしてしまいます。正直df関数を使う機会はほとんどないのですが、データフレームの変数名にはdの一文字を用いたり、きちんと意味のある名前を用いた方がよいでしょう。",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter24.html#ガンマ分布",
    "href": "chapter24.html#ガンマ分布",
    "title": "24  確率分布と乱数",
    "section": "24.21 ガンマ分布",
    "text": "24.21 ガンマ分布\nガンマ分布は機械の信頼性や降雨量などの説明に用いられる分布です。ガンマ分布のパラメータは形状パラメータγとスケールパラメータβの2つです。ガンマ分布の確率密度関数は以下の式で表されます。\n\\[Gamma(x, \\gamma, \\beta)=\\frac{(\\frac{x}{\\beta})^{\\gamma-1} \\cdot \\exp(-\\frac{x}{\\beta})}{\\beta \\cdot \\Gamma(\\gamma)}\\]\nRでのガンマ分布の確率密度関数はdgamma関数で計算することができます。ガンマ分布のパラメータである形状パラメータはshape引数、スケールパラメータはscale引数で指定します。ガンマ分布は右側の裾が長い分布で、最頻値が0以上となる形状を示し、0～\\(\\infty\\)の範囲を持つ連続値を取ります。\n\n確率密度累積分布関数分位点の値ガンマ乱数\n\n\n\n\n\nガンマ分布の確率密度をプロット\n\nx &lt;- seq(0, 100, by = 0.1)\nd &lt;- tibble(\n  x,\n  df5df5 = dgamma(x, shape = 5, scale = 2), # shape 5 scale 2\n  df10df15 = dgamma(x, shape = 10, scale = 4), # shape 10 scale 4\n  df15df20 = dgamma(x, shape = 1, scale = 6) # shape 1 scale 6\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nガンマ分布の累積分布関数をプロット\n\nd &lt;- tibble(\n  x,\n  df5df5 = pgamma(x, shape = 5, scale = 2), # shape 5 scale 2\n  df10df15 = pgamma(x, shape = 10, scale = 4), # shape 10 scale 4\n  df15df20 = pgamma(x, shape = 1, scale = 6) # shape 1 scale 6\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n累積分布関数の分位点と値の関係をqfでプロット\n\nx &lt;- seq(0, 1, by = 0.01)\nd &lt;- tibble(\n  x,\n  df5df5 = qgamma(x, shape = 5, scale = 2), # shape 5 scale 2\n  df10df15 = qgamma(x, shape = 10, scale = 4), # shape 10 scale 4\n  df15df20 = qgamma(x, shape = 1, scale = 6) # shape 1 scale 6\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n乱数の確率密度をプロット\n\nd &lt;- tibble(\n  df5df5 = rgamma(1000, shape = 5, scale = 2), # shape 5 scale 2\n  df10df15 = rgamma(1000, shape = 10, scale = 4), # shape 10 scale 4\n  df15df20 = rgamma(1000, shape = 1, scale = 6) # shape 1 scale 6\n)\n\nd |&gt; \n  pivot_longer(1:3) |&gt; \n  ggplot(aes(x = value, color = name, fill = name, alpha = 0.5)) +\n  geom_histogram(binwidth = 5, position = \"identity\")",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter24.html#指数分布",
    "href": "chapter24.html#指数分布",
    "title": "24  確率分布と乱数",
    "section": "24.22 指数分布",
    "text": "24.22 指数分布\n指数分布はポアソン分布する事象（まれに起こる事象）が起こる時間間隔の分布を示す確率分布です。指数分布は生存時間解析などの、イベントの発生数と時間の関係を解析するのに用いられています。指数分布のパラメータはλのみで、λは正の値を取ります。指数分布の確率密度関数は以下の式で表されます。\n\\[Exp(x, \\lambda)=\\lambda \\cdot \\exp(-\\lambda x)\\]\nRでは指数分布の確率密度関数はdexp関数で計算することができます。dexp関数では、λをrate引数で指定します。指数分布は単調減少で、0～\\(\\infty\\)の範囲を持つ連続値を取ります。\n\n確率密度累積分布関数分位点の値指数乱数\n\n\n\n\n\n指数分布の確率密度をプロット\n\nx &lt;- seq(0, 10, by = 0.01)\nd &lt;- tibble(\n  x,\n  r1 = dexp(x, rate = 1), # ラムダ1\n  r3 = dexp(x, rate = 3), # ラムダ3\n  r5 = dexp(x, rate = 5) # ラムダ5\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n指数分布の累積分布関数をプロット\n\nd &lt;- tibble(\n  x,\n  r1 = pexp(x, rate = 1), # ラムダ1\n  r3 = pexp(x, rate = 3), # ラムダ3\n  r5 = pexp(x, rate = 5) # ラムダ5\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n累積分布関数の分位点と値の関係をqexpでプロット\n\nx &lt;- seq(0, 1, by = 0.01)\nd &lt;- tibble(\n  x,\n  r1 = qexp(x, rate = 1), # ラムダ1\n  r3 = qexp(x, rate = 3), # ラムダ3\n  r5 = qexp(x, rate = 5) # ラムダ5\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n乱数の確率密度をプロット\n\nd &lt;- tibble(\n  r1 = rexp(1000, rate = 1), # ラムダ1\n  r3 = rexp(1000, rate = 3), # ラムダ3\n  r5 = rexp(1000, rate = 5) # ラムダ5\n)\n\nd |&gt; \n  pivot_longer(1:3) |&gt; \n  ggplot(aes(x = value, color = name, fill = name, alpha = 0.5)) +\n  geom_histogram(binwidth = 0.1, position = \"identity\")",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter24.html#ワイブル分布",
    "href": "chapter24.html#ワイブル分布",
    "title": "24  確率分布と乱数",
    "section": "24.23 ワイブル分布",
    "text": "24.23 ワイブル分布\nワイブル分布は指数分布を拡張したような確率分布です。指数分布では、ポアソン分布する事象（イベント）が起きる確率は常に一定であることを仮定していますが、ワイブル分布を用いると単調増加・単調減少でイベントが起きる確率が変化する場合を表現することができます。ワイブル分布のパラメータは形状パラメータのλとスケールパラメータのkの2つです。ワイブル分布の確率密度関数は以下の式で表されます。\n\\[Weibull(x, \\lambda, k)=\\frac{k}{\\lambda}(\\frac{x}{\\lambda})^{k-1} \\cdot \\exp(-\\frac{x}{\\lambda})^k\\]\nRでは、ワイブル分布の確率密度関数をdweibull関数で計算することができます。dweibull関数の引数は形状パラメータλであるshapeと、スケールパラメータkであるscaleの2つです。ワイブル分布はガンマ分布と同じく、右側の裾が長い分布で、最頻値が0以上となる形状を示し、0～\\(\\infty\\)の範囲を持つ連続値を取ります。\n\n確率密度累積分布関数分位点の値ワイブル乱数\n\n\n\n\n\nワイブル分布の確率密度をプロット\n\nx &lt;- seq(0, 5, by = 0.01)\nd &lt;- tibble(\n  x,\n  s1s1 = dweibull(x, shape = 1, scale = 1), # shape 1、scale 1\n  s2s2 = dweibull(x, shape = 2, scale = 2), # shape 2、scale 2\n  s05s05 = dweibull(x, shape = 0.5, scale = 0.5) # shape 0.5、scale 0.5\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nワイブル分布の累積分布関数をプロット\n\nd &lt;- tibble(\n  x,\n  s1s1 = pweibull(x, shape = 1, scale = 1), # shape 1、scale 1\n  s2s2 = pweibull(x, shape = 2, scale = 2), # shape 2、scale 2\n  s05s05 = pweibull(x, shape = 0.5, scale = 0.5) # shape 0.5、scale 0.5\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n累積分布関数の分位点と値の関係をqfでプロット\n\nx &lt;- seq(0, 1, by = 0.01)\nd &lt;- tibble(\n  x,\n  s1s1 = qweibull(x, shape = 1, scale = 1), # shape 1、scale 1\n  s2s2 = qweibull(x, shape = 2, scale = 2), # shape 2、scale 2\n  s05s05 = qweibull(x, shape = 0.5, scale = 0.5) # shape 0.5、scale 0.5\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n乱数の確率密度をプロット\n\nd &lt;- tibble(\n  s1s1 = rweibull(1000, shape = 1, scale = 1), # shape 1、scale 1\n  s2s2 = rweibull(1000, shape = 2, scale = 2), # shape 2、scale 2\n  s05s05 = rweibull(1000, shape = 0.5, scale = 0.5) # shape 0.5、scale 0.5\n)\n\nd |&gt; \n  pivot_longer(1:3) |&gt; \n  ggplot(aes(x = value, color = name, fill = name, alpha = 0.5)) +\n  geom_histogram(binwidth = 0.2, position = \"identity\")",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter24.html#一様分布",
    "href": "chapter24.html#一様分布",
    "title": "24  確率分布と乱数",
    "section": "24.24 一様分布",
    "text": "24.24 一様分布\n一様分布は、最小値（a）から最大値（b）まで、一定の確率で現れる現象を示す分布です。この章の始めに示したsample関数の乱数やサイコロなどが一様分布の典型的な例です。一様分布のパラメータは最小値aと最大値bの2つです。一様分布の確率密度関数は以下の式で表されます。\n\\[Unif(x, a, b)=\\frac{1}{b-a}\\]\nRでは、一様分布の確率密度関数をdunif関数で計算することができます。dunif関数では最小値aとしてmin、最大値bとしてmaxの2つのパラメータを引数に指定します。一様分布はその名の通り確率密度が一定で、a～bの範囲を持つ連続値を取ります。\n\n確率密度累積分布関数分位点の値一様乱数\n\n\n\n\n\n一様分布の確率密度をプロット\n\nx &lt;- seq(-1.5, 4.5, by = 0.01)\nd &lt;- tibble(\n  x,\n  m0m1 = dunif(x, min = 0, max = 1), # 最小0、最大1\n  mm1m1 = dunif(x, min = -1, max = 1), # 最小-1、最大1\n  m2m4 = dunif(x, min = 2, max = 4) # 最小2、最大4\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n一様分布の累積分布関数をプロット\n\nd &lt;- tibble(\n  x,\n  m0m1 = punif(x, min = 0, max = 1), # 最小0、最大1\n  mm1m1 = punif(x, min = -1, max = 1), # 最小-1、最大1\n  m2m4 = punif(x, min = 2, max = 4) # 最小2、最大4\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n累積分布関数の分位点と値の関係をqfでプロット\n\nx &lt;- seq(0, 1, by = 0.01)\nd &lt;- tibble(\n  x,\n  m0m1 = qunif(x, min = 0, max = 1), # 最小0、最大1\n  mm1m1 = qunif(x, min = -1, max = 1), # 最小-1、最大1\n  m2m4 = qunif(x, min = 2, max = 4) # 最小2、最大4\n)\n\nd |&gt; \n  pivot_longer(2:4) |&gt; \n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n乱数の確率密度をプロット\n\nd &lt;- tibble(\n  m0m1 = runif(1000, min = 0, max = 1), # 最小0、最大1\n  mm1m1 = runif(1000, min = -1, max = 1), # 最小-1、最大1\n  m2m4 = runif(1000, min = 2, max = 4) # 最小2、最大4\n)\n\nd |&gt; \n  pivot_longer(1:3) |&gt; \n  ggplot(aes(x = value, color = name, fill = name, alpha = 0.5)) +\n  geom_histogram(binwidth = 1, position=\"identity\")",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter24.html#多項分布",
    "href": "chapter24.html#多項分布",
    "title": "24  確率分布と乱数",
    "section": "24.25 多項分布",
    "text": "24.25 多項分布\n多項分布はここまでに示した確率分布とは異なり、Rには累積分布関数や分位点の関数が設定されていない確率分布です。多項分布は、複数の事象、例えばツボに白・赤・黒のボールを違う数で入れておき、取り出しては戻すような試行（復元抽出）を行うとき、それぞれの色のボールを特定の数だけ取り出す確率を計算するときに用います。各色のボールを取り出す確率はそれぞれ異なりますが、足し合わせれば確率が1となるような状況で多項分布は用いられます。\n多項分布の確率質量関数のパラメータはボールの色がk色の時、ボールを取り出す回数n、各色のボールを取り出す数x1～xk、各色のボールを取り出す確率p1pkの4種類となります。nはx1～xkの和となります。\n\\[Multinomial(n, x_{1}, x_{2}, \\cdots x_{k}, p_{1}, p_{2}, \\cdots p_{k})=\\frac{n!}{x_{1}! \\cdot x_{2}! \\cdot \\cdots \\cdot x_{k}!} \\cdot p_{1}^{x_{1}} \\cdot p_{2}^{x_{2}} \\cdot \\cdots p_{k}^{x_{k}}\\]\nRでは、dmultinom関数で多項分布の確率質量関数を計算することができます。dmultinom関数の引数はボールを取り出す回数nを表すsize、各色のボールを取り出す数のx1～xkをベクターで表したx、各色のボールを取り出す確率であるp1pkを同じくベクターで表したprobの3つとなります。\nまた、多項分布の乱数を得る関数であるrmultinom関数も他の確率分布を示す乱数の関数とはやや使い方が異なります。sizeとprobの2つの引数を指定するのは上と同じですが、返り値は合計がsizeで指定した数値となるボールの数k個の乱数です。probで確率を指定したそれぞれに対する値（ボールの数のようなもの）が第一引数（n）で示した数だけ、列として並ぶ行列が返ってきます。\n\n\n\n多項分布の関数\n\n# 0.1、0.3、0.6の確率で起こる事象がそれぞれ1、2、4回同時に起こる確率\ndmultinom(x = c(1, 2, 4), size = 7, prob = c(0.1, 0.3, 0.6))\n## [1] 0.122472\n\n# 足し合わせると20になるものが10個、列として返ってくる。\n# 行の上から、0.1、0.3、0.6の確率で現れている\nrmultinom(10, size=20, prob = c(0.1, 0.3, 0.6))\n##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n## [1,]    3    2    1    3    4    2    1    0    2     0\n## [2,]    4    6    2    4    6    5    5    9    3     8\n## [3,]   13   12   17   13   10   13   14   11   15    12\n\n\n\n\n\n多項分布の乱数をグラフで示す\n\nrmnom &lt;- rmultinom(1000, size=20, prob = c(0.1, 0.3, 0.6))\nrmnom |&gt; \n  t() |&gt; \n  as_tibble() |&gt; \n  pivot_longer(1:3) |&gt; \n  ggplot(aes(x = value, color = name, fill = name, alpha = 0.5))+\n  geom_histogram(binwidth = 1, position = \"identity\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n確率密度、累積分布、分位点の関係\n\n\n\nMatsumoto, Makoto, and Takuji Nishimura. 1998. “Mersenne Twister: A 623-Dimensionally Equidistributed Uniform Pseudo-Random Number Generator.” ACM Trans. Model. Comput. Simul. 8 (1): 3–30. https://doi.org/10.1145/272991.272995.",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>確率分布と乱数</span>"
    ]
  },
  {
    "objectID": "chapter25.html",
    "href": "chapter25.html",
    "title": "25  検定",
    "section": "",
    "text": "25.1 検定の全体図\nまず、検定の対象となるデータの形と分布、対応する検定手法についての図を示します。概ねこの図に沿って説明していきます。",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>検定</span>"
    ]
  },
  {
    "objectID": "chapter25.html#検定の全体図",
    "href": "chapter25.html#検定の全体図",
    "title": "25  検定",
    "section": "",
    "text": "図1：データと対応する検定手法",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>検定</span>"
    ]
  },
  {
    "objectID": "chapter25.html#パラメトリック検定",
    "href": "chapter25.html#パラメトリック検定",
    "title": "25  検定",
    "section": "25.2 パラメトリック検定",
    "text": "25.2 パラメトリック検定\n統計で用いられる検定には、データの確率分布に仮定を置く（例えば、データが正規分布しているとして計算する）方法と、データの確率分布に仮定を置かない方法の2つがあります。これらのうち、確率分布に仮定を置く方法のことをパラメトリック検定、仮定を置かない方法のことをノンパラメトリック検定と呼びます。\nパラメトリック検定はデータの分布が仮定した確率分布に従っている場合に、正確に検定統計量を計算できる方法です。データの分布が仮定した確率分布に従わない場合には正しく検定を行うことができないとされています。データの確率分布が定まらない場合にはノンパラメトリック検定を用いたほうがよいとされていましたが、ノンパラメトリック検定は検出力（差がある時に差があるとできる割合）が低くなる性質があります。検定を行う際にはデータの分布を調べ、そのデータに適した検定を用いるのがよいでしょう。",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>検定</span>"
    ]
  },
  {
    "objectID": "chapter25.html#t検定",
    "href": "chapter25.html#t検定",
    "title": "25  検定",
    "section": "25.3 t検定",
    "text": "25.3 t検定\nt検定は、正規分布する1群のデータの平均値と「ある値」との差、または2群のデータの平均値の差を検定する方法です。t検定の帰無仮説は1群の場合には「平均値が「ある値」」、2群の場合には「平均値が一致する」とします。「ある値」というのが抽象的でわかりにくいですが、例えば、あるクラスの男子生徒20人の身長が170 cmより高いかどうか検定したい場合には、この170 cmというのが「ある値」となります。\n1群のt検定（Studentのt検定）の場合には、24章で説明した以下のt検定統計量を計算し、データの数から計算した自由度でのt分布とt検定統計量からp値を計算します。μは帰無仮説の下での平均値、つまり「ある値」とします。\n\\[t=\\frac{x-\\mu}{S \\sqrt n}\\]\n2群の場合には、Rではt検定の拡張であるWelchのt検定が用いられます。1群・2群のどちらにおいても、t検定統計量とp値が計算され、p値が0.05より小さければ、平均値に有意な差があると結論付けます。\nRでは、t.test関数でt検定の計算を行います。t.test関数は第一引数に数値ベクターのx、第二引数に数値ベクターのyを取ります。第一引数xのみを設定した場合には1群のt検定を、xとyを設定した場合には2群のt検定を計算します。\n1群のt検定の場合、比較する値にはmuを設定します。muのデフォルト値は0なので、muを設定しない場合には、0との差を検定することになります。\n\n\n\nt.test関数でt検定\n\nx &lt;- rnorm(10, mean = 0.25, sd = 1)\ny &lt;- rnorm(10, mean = 1, sd = 0.5)\n\n# 1群のt検定（平均値が0と有意に異なるかを検定する）\nt.test(x)\n## \n##  One Sample t-test\n## \n## data:  x\n## t = 1.5976, df = 9, p-value = 0.1446\n## alternative hypothesis: true mean is not equal to 0\n## 95 percent confidence interval:\n##  -0.2533217  1.4711697\n## sample estimates:\n## mean of x \n##  0.608924\n\n# 1群のt検定（平均値が4と有意に異なるかを検定する）\nt.test(x, mu = 4)\n## \n##  One Sample t-test\n## \n## data:  x\n## t = -8.8967, df = 9, p-value = 9.383e-06\n## alternative hypothesis: true mean is not equal to 4\n## 95 percent confidence interval:\n##  -0.2533217  1.4711697\n## sample estimates:\n## mean of x \n##  0.608924\n\n# 2群のt検定（Welchのt検定、等分散性の仮定がなくても計算できる）\nt.test(x, y)\n## \n##  Welch Two Sample t-test\n## \n## data:  x and y\n## t = -0.52991, df = 10.419, p-value = 0.6073\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -1.0873669  0.6676961\n## sample estimates:\n## mean of x mean of y \n## 0.6089240 0.8187593\n\n\n\n\n\n\n\n\n検定とp値\n\n\n\n\n\n検定では、通常p値が0.05未満（p &lt; 0.05）であれば有意な差がある、0.01や0.001未満（p &lt; 0.01、p &lt; 0.001）ならよりはっきりとした有意差があるとします。この0.05、0.01、0.001という値には特に意味はありませんが、習慣上この3つの値を用いることが多いです。\n\n\n\n\n25.3.1 t検定の結果\nt検定の結果として、t検定統計量、自由度（df）、p値（p-value）、差の95%信頼区間（95 percent confidence interval）、平均値（estimate）が返ってきます。それぞれの要素は$を用いて以下のように呼び出すことができます。\n\n\n\nt検定の結果を呼び出す\n\nresult_t &lt;- t.test(x)\nresult_t # t検定の結果\n## \n##  One Sample t-test\n## \n## data:  x\n## t = 1.5976, df = 9, p-value = 0.1446\n## alternative hypothesis: true mean is not equal to 0\n## 95 percent confidence interval:\n##  -0.2533217  1.4711697\n## sample estimates:\n## mean of x \n##  0.608924\n\nresult_t$statistic # t統計量\n##        t \n## 1.597551\n\nresult_t$p.value # p値\n## [1] 0.1446073\n\nresult_t$estimate # 平均値\n## mean of x \n##  0.608924\n\nresult_t$conf.int # 差の95%信頼区間（0との差なので、xの95%信頼区間）\n## [1] -0.2533217  1.4711697\n## attr(,\"conf.level\")\n## [1] 0.95\n\n\n\n\n\n\n\n\np値を図示する\n\n\n\n\n\n上のresult_tの結果では、t統計量は1.5975513、p値は0.1446073となっています。このp値は自由度9のt分布から計算することができます。下の図は自由度9のt分布で、縦線はx=1.5975513、つまりt統計量の値です。t統計量より値が大きい確率、つまり下図の青で示した面積の2倍がp値となります。この面積はt分布の積分から計算することができ、0.0723037となります。2倍となるのは、次に説明する両側検定となっているためです。\nt検定では、そのデータでのt統計量が得られるよりも稀な事象が起こる確率を下図の青の面積（p値の0.5倍）として求めます。この確率が非常に小さければ、帰無仮説の下でこのデータが取れることは稀である、つまり帰無仮説が成立しているのは矛盾しているとして、帰無仮説を棄却します。\n\n# p値の計算（t分布で1.5975513となる場合の累積分布関数から計算する）\n(1 - pt(1.5975513, df = 9)) * 2\n## [1] 0.1446073\n\nt_temp &lt;- data.frame(x = seq(-5, 5, by=0.01), tvalue = dt(seq(-5, 5, by = 0.01), df = 9)) # 自由度9のt分布\n\nt_temp &lt;- t_temp |&gt; mutate(col_t = if_else(x &gt; result_t$statistic, tvalue, NA))\nt_temp |&gt; \n  ggplot() +\n  geom_area(aes(x = x, y = tvalue), color = NA, fill = \"#00BFC4\", data = t_temp) +\n  geom_area(aes(x = x, y = tvalue), color = NA, fill = \"#F8766D\", data = t_temp |&gt; filter(is.na(col_t)))+\n  geom_vline(xintercept = result_t$statistic)\n\n\n\n\n\n\n\n\n\n\n\n\n\n25.3.2 両側検定と片側検定\nt検定では通常両側検定という、t分布の両側の確率を用いる検定を行います。例えばp&lt;0.05なら、t検定統計量がt分布の左側2.5%以下、右側97.5%以上にあるかどうかを検定します。これは、2つのデータ群のどちらが大きく、どちらが小さいかをあらかじめ定められない場合に用います。\n一方で、t分布の左側5%以下、右側95%以上の片方のみを検定に用いる場合もあります。この片側のみを用いる検定のことを片側検定と呼びます。片側検定には、下側のみを用いるものと上側のみを用いるものがそれぞれあります。いずれの場合においても、検定に用いる確率を片側に割り振ることになり、有意差が出やすくなる特徴があります。片側検定は基礎研究ではまず使われませんが、治験などではよく用いられています（優越性・非劣性試験）。\n\n両側検定片側検定（下側）片側検定（上側）\n\n\n\nt_temp &lt;- data.frame(x=seq(-5, 5, by = 0.01), tvalue = dt(seq(-5, 5, by = 0.01), df = 5)) # 自由度5のt分布\n# 両側5％（片側2.5%）\nt_temp &lt;- t_temp |&gt; mutate(col_95 = if_else(x &lt; qt(0.025, df = 5) | x &gt; qt(0.975, df = 5), tvalue, NA))\nt_temp |&gt; \n  ggplot() +\n  geom_area(aes(x = x, y = tvalue), color = NA, fill = \"#00BFC4\", data = t_temp) +\n  geom_area(aes(x = x, y = tvalue), color = NA, fill = \"#F8766D\", data = t_temp |&gt; filter(is.na(col_95)))\n\n\n\n\n\n\n\n\n\n\n\nt_temp &lt;- data.frame(x=seq(-5, 5, by=0.01), tvalue = dt(seq(-5, 5, by=0.01), df = 5)) # 自由度5のt分布\n# 下側5％\nt_temp &lt;- t_temp |&gt; mutate(col_95 = if_else(x &lt; qt(0.05, df = 5), tvalue, NA))\nt_temp |&gt; \n  ggplot() +\n  geom_area(aes(x=x, y=tvalue), color=NA, fill=\"#00BFC4\", data=t_temp) +\n  geom_area(aes(x=x, y=tvalue), color=NA, fill=\"#F8766D\", data=t_temp |&gt; filter(is.na(col_95)))\n\n\n\n\n\n\n\n\n\n\n\nt_temp &lt;- data.frame(x=seq(-5, 5, by=0.01), tvalue = dt(seq(-5, 5, by=0.01), df = 5)) # 自由度5のt分布\n# 上側5％\nt_temp &lt;- t_temp |&gt; mutate(col_95 = if_else(x &gt; qt(0.95, df = 5), tvalue, NA))\nt_temp |&gt; \n  ggplot() +\n  geom_area(aes(x=x, y=tvalue), color=NA, fill=\"#00BFC4\", data=t_temp) +\n  geom_area(aes(x=x, y=tvalue), color=NA, fill=\"#F8766D\", data=t_temp |&gt; filter(is.na(col_95)))\n\n\n\n\n\n\n\n\n\n\n\nRで片側検定を行う場合には、t.test関数にalternative引数を指定します。alternative引数のデフォルト値は\"two.sided\"、つまり両側検定です。片側検定を行う場合には、alternative=\"less\"（下側検定）もしくはalternative=\"greater\"（上側検定）を指定します。\n\n\n\n片側のt検定\n\n# 下側検定\nt.test(x, alternative = \"less\")\n## \n##  One Sample t-test\n## \n## data:  x\n## t = 1.5976, df = 9, p-value = 0.9277\n## alternative hypothesis: true mean is less than 0\n## 95 percent confidence interval:\n##      -Inf 1.307635\n## sample estimates:\n## mean of x \n##  0.608924\n\n# 上側検定\nt.test(x, alternative = \"greater\")\n## \n##  One Sample t-test\n## \n## data:  x\n## t = 1.5976, df = 9, p-value = 0.0723\n## alternative hypothesis: true mean is greater than 0\n## 95 percent confidence interval:\n##  -0.08978688         Inf\n## sample estimates:\n## mean of x \n##  0.608924\n\n\n\n\n25.3.3 対応のあるt検定\n2群のデータ、xとyに対応がある場合があります。「対応がある」というのは、xとyの同じインデックスのデータに関連性があること、例えば同じ人から取った2つの時期の結果である場合など、を指します。典型的な例としては、ある群に何か処理をして（例えば投薬をする）、処理前と処理後のデータを同じ個体から取るような場合が「対応がある」状況に当てはまります。このような場合、xとyの値は独立ではないため、対応のあるt検定の手法を用いる必要があります。対応があるデータに対してt検定を行う場合には、引数にpaired=TRUEを指定します。\n\n\n\n対応のあるt検定\n\n# 各行に対応があるとする\n# （同じ行のxとyの値に関連がある、例えばxが投薬前、yが投薬後の同じ人の値とする）\ndata.frame(x, y)\n##              x         y\n## 1   1.51295428 1.3817967\n## 2  -0.07623336 0.6004954\n## 3   1.57979926 0.4261715\n## 4   1.52242932 0.8552692\n## 5   0.66464143 0.8503924\n## 6  -1.28995004 0.7942446\n## 7  -0.67856703 1.1261117\n## 8  -0.04472045 0.5540394\n## 9   0.24423283 1.2178416\n## 10  2.65465339 0.3812308\n\nt.test(x, y, paired = TRUE)\n## \n##  Paired t-test\n## \n## data:  x and y\n## t = -0.4989, df = 9, p-value = 0.6298\n## alternative hypothesis: true mean difference is not equal to 0\n## 95 percent confidence interval:\n##  -1.1612848  0.7416141\n## sample estimates:\n## mean difference \n##      -0.2098354\n\n\n\n\n25.3.4 信頼区間\nXX%信頼区間とは、（概ね）平均値がXX%の確率で存在する区間を指します。一般的には95%信頼区間が最もよく用いられています。t.test関数では、このXXに当たる値をconf.level引数で設定することができます。conf.levelのデフォルト値は0.95で、t.testでは通常95％信頼区間が計算されます。t.test関数にxとyの2群データを与えた場合には、差の信頼区間が計算されます。\n\n\n\n信頼区間の計算\n\n# xの90%信頼区間を計算する\nt.test(x, conf.level = 0.9) |&gt; _$conf.int\n## [1] -0.08978688  1.30763480\n## attr(,\"conf.level\")\n## [1] 0.9\n\n# 差の90％信頼区間を計算する\nt.test(x, y, conf.level = 0.9) |&gt; _$conf.int\n## [1] -0.9246307  0.5049599\n## attr(,\"conf.level\")\n## [1] 0.9\n\n\n\n\n\n\n\n\n信頼区間の意味\n\n\n\n\n\n95％信頼区間とは、「同じ試行を無限回繰り返した場合、95％の試行でその区間に平均値が含まれる区間」という、定義上はよくわからない区間です。95％信用区間という別のものを用いると「平均値が95%の確率で存在する区間」というわかりやすい定義を利用できるのですが、この信用区間は計算方法が複雑です。信頼区間の方が計算が簡単なので、よく用いられています。\nこの95％信頼区間が0を含んでいるかどうかが、p&lt;0.05で有意な差があるかどうかと概ね関連しています。\n\n\n\n\n\n25.3.5 formulaを用いたt検定\nt.test関数では、2群を指定する際に、数値ベクターと因子ベクターを用いることもできます。数値ベクターと因子ベクターを用いる場合には、群は因子ベクターで指定します。t.test関数で因子を用いて群を指定する場合には、formulaを用います。formulaは目的変数~説明変数という形で、目的変数を~（チルダ）の左、説明変数を~の右に指定することで、統計に用いるモデルを表現するものです。t検定の場合には値が目的変数、群が説明変数となるので、数値~因子の形で目的変数と説明変数を指定します。\nt.testを含め、統計に用いる関数では、データをデータフレームで指定することができます。データフレームを指定する場合には、data引数に該当するデータフレームを指定します。data引数でデータフレームを指定した場合、formulaに用いる変数に（文字列ではない）列名をそのまま用いることができるようになります。\n\n\n\nformulaを引数にしたt検定\n\nf &lt;- rep(c(\"a\", \"b\"), c(5, 5)) |&gt; factor() # fはaとbからなる因子\nd &lt;- data.frame(x, f)\nd # 数値と因子のデータフレーム（aとbの2群）\n##              x f\n## 1   1.51295428 a\n## 2  -0.07623336 a\n## 3   1.57979926 a\n## 4   1.52242932 a\n## 5   0.66464143 a\n## 6  -1.28995004 b\n## 7  -0.67856703 b\n## 8  -0.04472045 b\n## 9   0.24423283 b\n## 10  2.65465339 b\n\n# データフレームdのx列を目的変数、fを説明変数としてt検定\nt.test(x ~ f, data = d)\n## \n##  Welch Two Sample t-test\n## \n## data:  x by f\n## t = 1.1534, df = 5.7829, p-value = 0.2942\n## alternative hypothesis: true difference in means between group a and group b is not equal to 0\n## 95 percent confidence interval:\n##  -0.985218  2.712395\n## sample estimates:\n## mean in group a mean in group b \n##       1.0407182       0.1771297\n\n\nformulaは文字列から作成することもできます。文字列からformulaに変換する場合には、formula関数を用います。\n\n\n\n文字列をformulaに変換する\n\nformula(\"x ~ f\")\n## x ~ f\n\n\n\n\n25.3.6 検出力と例数\nt検定では、p値という確率を求めます。このp値は「帰無仮説が成り立つと仮定したとき、その検定統計量が得られるより稀なことが起こる確率」という少し分かりにくいものです。この確率が低いことを根拠に帰無仮説を棄却するのが検定の仕組みになっています。\nしかし、p値が0になることはないため、p値の確率で、帰無仮説が成立する状況であってもその検定統計量より稀な事象が起こります。つまり、帰無仮説を棄却した場合においても、p値の確率で帰無仮説を棄却したことが間違いで、帰無仮説が正しいこともあり得ます。この、「差がないという帰無仮説を棄却したけど実際には差がなかった」場合のことを、統計では「第一の過誤」と呼びます。また、第一の過誤の確率のことをαと呼びます。p値の判定基準が0.05であるというのは、αを0.05に調整しているということになります。\n同様に、p値が大きくて帰無仮説を棄却しなかった場合においても、実際には差がある場合もあります。この「帰無仮説を棄却しなかったが、実際には差があった」という場合のことを、統計では「第二の過誤」と呼びます。また、第二の過誤の確率のことをβと呼びます。\n第一の過誤も第二の過誤も0にすることはできません。しかし、第一の過誤も第二の過誤も検定の間違いとなりますので、できれば両方をうまく調整し、あまり間違いがない検定を行えた方が望ましいです。この、あまり間違いがない検定のための方法の一つが検出力の調整です。\n検出力とは、第二の過誤の確率βを1から引いたもの、つまり、「帰無仮説を棄却せず、実際に差がない」確率です。検出力が高いと、有意な差がない場合に、差がないという仮説を受容しやすくなります。要は差がある場合には差がある、無い場合にはないという結論を導きやすくなるわけです。\n\n\n\n図1：第一の過誤と第二の過誤\n\n\n統計では、通常この検出力を0.8に調整するとよいとされています。この0.8がよいということには何も根拠がないのですが、通例として用いられています。\n検出力（1-β）は、データの数（例数）、第一の過誤の確率（α）、群間の差、標準偏差の4つのパラメータから計算できます。また、例数は、検出力、α、群間の差、標準偏差の4つから計算できます。この5つのパラメータの関係を利用して、検出力0.8、α=0.05のときの例数を計算することを、例数設計と呼びます。\n基礎研究の分野でガチガチに例数設計を行うことは（群間の差も標準偏差もわからないので）まずないのですが、治験では例数設計は非常に重要な概念であるとされています。\nRでt検定の例数設計や検出力の計算を行う関数が、power.t.testです。power.t.testの引数は、例数（n）、群間の差（delta）、標準偏差（sd）、第一の過誤の確率α（sig.level）、検出力（power）の5つです。power.t.testを用いる時には、これらの5つのうち、4つを設定します。4つを設定してpower.t.testで計算を行うと、残り1つの引数に当たる値を求めることができます。\nですので、n、delta、sd、sig.levelを設定すれば検出力（power）が、delta、sd、sig.level、powerを設定すれば例数（n）が計算できます。\n\n\n\nt検定の検出力の計算\n\npower.t.test(n = 10, delta = 4, sd = 5, sig.level = 0.05) # powerを計算\n## \n##      Two-sample t test power calculation \n## \n##               n = 10\n##           delta = 4\n##              sd = 5\n##       sig.level = 0.05\n##           power = 0.3949428\n##     alternative = two.sided\n## \n## NOTE: n is number in *each* group\n\npower.t.test(power = 0.8, delta = 4, sd = 5, sig.level = 0.05) # 例数を計算\n## \n##      Two-sample t test power calculation \n## \n##               n = 25.52463\n##           delta = 4\n##              sd = 5\n##       sig.level = 0.05\n##           power = 0.8\n##     alternative = two.sided\n## \n## NOTE: n is number in *each* group\n\n\n\n\n\n\n\n\nαとβを図示する\n\n\n\n\n\nαとβは、帰無仮説における分布（H0）とデータの分布（H1）から、以下の図のように示すことができます。この図において、左の平均値0の分布がH0の分布、右がH1の分布となります。縦線はα=0.05とする線で、H0のこの線より右側がαとなります。H1の分布におけるこの縦線より左側がβとなります。ですので、H1の分布から青色の部分βを引いた部分（1-β）が検出力となります。\n\nt_temp &lt;- \n  data.frame(\n    x=seq(-7, 7, by = 0.01), \n    tvalue_h0 = dt(seq(-7, 7, by = 0.01), df = 15),\n    tvalue_h1 = c(rep(0, 400), dt(seq(-5, 5, by = 0.01), df = 15))\n    ) \n\n# alphaとbetaの場所を指定\nt_temp &lt;- \n  t_temp |&gt; \n  mutate(\n    alpha = if_else(x &lt; 1.75305, tvalue_h0, NA),\n    beta = if_else(x &gt; 1.75305, tvalue_h1, NA))\n\nt_temp |&gt; \n  ggplot() +\n  geom_line(aes(x = x, y = tvalue_h0), data = t_temp) +\n  geom_line(aes(x = x, y = tvalue_h1), data = t_temp) +\n  geom_area(aes(x = x, y = tvalue_h0), color = NA, fill = \"#F8766D\", alpha = 0.5, data = t_temp |&gt; filter(is.na(alpha)))+\n  geom_area(aes(x = x, y = tvalue_h1), color = NA, fill = \"#00BFC4\", alpha = 0.3, data = t_temp |&gt; filter(is.na(beta)))+\n  geom_vline(xintercept = 1.75305)+\n  labs(caption = \"左の分布が帰無仮説での分布、右の分布がデータの分布、赤がα、青がβ\")",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>検定</span>"
    ]
  },
  {
    "objectID": "chapter25.html#カテゴリカルデータの検定",
    "href": "chapter25.html#カテゴリカルデータの検定",
    "title": "25  検定",
    "section": "25.4 カテゴリカルデータの検定",
    "text": "25.4 カテゴリカルデータの検定\nカテゴリカルデータとは、男性や女性、出身地の都道府県のような、連続値で示すことができない値のことです。統計では、例えば男性と女性の比、出身地ごとの人口など、カテゴリカルデータを取り扱うことがあります。Rではカテゴリカルデータ用のデータ型として、因子（factor）が準備されています。\nカテゴリカルデータ、例えば動物園Aにいるカピバラのオス・メスの比率が1:1と異なるかどうかを検定するような場合に用いるのが、フィッシャーの正確検定やカイ二乗検定です。\n\n25.4.1 フィッシャーの正確検定\nフィッシャーの正確検定（Fisher’s exact test）は比較するカテゴリカルデータの数が小さいときに用いられる、カテゴリカルデータの比率の差の検定の方法です。フィッシャーの正確検定では、カテゴリカルデータの比率の得られる確率を直接計算してp値を計算します。確率を直接計算するため、結果は正確になるのですが、計算量が多いためデータが多いと計算に時間がかかります。\n\n\n25.4.2 カイ二乗検定\nカイ二乗検定もフィッシャーの正確検定と同じように、カテゴリカルデータの比率の差を検定するために用いられる方法です。フィッシャーの正確検定との違いは、データが多くなっても計算量がそれほど多くならず、計算が簡易である反面、データ数が少ないときには結果が不正確となる傾向を持ちます。カテゴリカルデータの比率の差の検定では、正確検定よりもカイ二乗検定を紹介している教科書が多いように思います。\nカイ二乗検定はその名の通り、カイ二乗分布を\\(\\chi^2\\)検定統計量の棄却域の計算に用いる方法です。\\(\\chi^2\\)検定統計量は以下の計算式で求めます。\n\\[\\chi^2=\\sum_{i=1}^{n} \\frac{(O_{i}-E_{i})^2}{E_{i}}\\]\nOiは観察された数（observed、上のカピバラの例であればオスの数）、Eiは予想される数（expected、上の例であればオス＋メスの半分）です。\\(\\chi^2\\)検定統計量をカイ二乗分布の上側（片側）と比較し、p値を計算します。上側のみを用いるため、カイ二乗検定は必ず片側検定になります。\n\n25.4.2.1 適合性の検定と独立性の検定\nカイ二乗検定には適合性の検定と独立性の検定の2つがあります。適合性の検定と独立性の検定が用いられる場面は、以下のような場合です。\n\n適合性：動物園Aにいるカピバラのオス・メスの比率が1:1と異なるかどうかを検定\n独立性：動物園Aと動物園Bにいるカピバラのオス・メスの比率が異なるかどうかを検定\n\n要は、1群を予想される比率と比較するものを適合性、2群の比率を比較する場合を独立性と呼ぶこととされています。\n\n\n\n25.4.3 Rでのフィッシャーの正確検定・カイ二乗検定\nRでフィッシャーの正確検定を行う場合には、fisher.test関数、カイ二乗検定を行う場合にはchisq.testを用います。データは基本的に行列で与えます。行列は、行方向にカテゴリ、列方向に観察された数（observed）、予想される数（expected）を配置します。行列の各セルには、そのカテゴリの度数を入力します。\n独立性の検定として用いる場合には、予想される数（expected）に別群のデータ、例えば動物園Bにいるカピバラのオス・メスの数など、を入力します。\n\n\n\nカイ二乗検定：データの準備\n\n# データは行列で与える\nx &lt;- matrix(c(4, 12, 8, 8), nrow = 2)\ncolnames(x) &lt;- c(\"observed\", \"expected\")\nrownames(x) &lt;- c(\"male\", \"female\")\nx\n##        observed expected\n## male          4        8\n## female       12        8\n\n\nfisher.testもchisq.testも、この行列を引数に取ることで計算を行うことができます。フィッシャーの正確検定では、オッズ比（2項確率の成功確率/失敗確率、p/(1-p)）の信頼区間も同時に得られます。\n\n\n\nフィッシャーの正確検定・カイ二乗検定\n\n# フィッシャーの正確検定\nfisher.test(x)\n## \n##  Fisher's Exact Test for Count Data\n## \n## data:  x\n## p-value = 0.2734\n## alternative hypothesis: true odds ratio is not equal to 1\n## 95 percent confidence interval:\n##  0.05547062 1.83715141\n## sample estimates:\n## odds ratio \n##  0.3454445\n\n# カイ二乗検定\nchisq.test(x)\n## \n##  Pearson's Chi-squared test with Yates' continuity correction\n## \n## data:  x\n## X-squared = 1.2, df = 1, p-value = 0.2733\n\n\nfisher.testもchisq.testも、カテゴリが2つ以上の場合（例えば血液型など）でも、検定を行うことができます。\n\n\n\nカテゴリが2つ以上の場合の検定\n\nmat &lt;- matrix(c(9, 6, 3, 2, 5, 5, 5, 5), nrow = 4)\ncolnames(mat) &lt;- c(\"observed\", \"expected\")\nrownames(mat) &lt;- c(\"A\", \"B\", \"O\", \"AB\")\nmat\n##    observed expected\n## A         9        5\n## B         6        5\n## O         3        5\n## AB        2        5\n\nfisher.test(mat)\n## \n##  Fisher's Exact Test for Count Data\n## \n## data:  mat\n## p-value = 0.4123\n## alternative hypothesis: two.sided\n\nchisq.test(mat)\n## Warning in chisq.test(mat): Chi-squared approximation may be incorrect\n## \n##  Pearson's Chi-squared test\n## \n## data:  mat\n## X-squared = 3.0195, df = 3, p-value = 0.3886\n\n\nfisher.testもchisq.testも、度数に変換した行列だけでなく、因子のベクターを引数に取ることができます。因子のベクターは2つ必要で、2つのベクターのデータフレームをtable関数の引数にしたものを検定の対象とするものです。\n\n\n\n因子ベクターを用いた検定の計算\n\nset.seed(0)\n# 因子のデータフレームを作成\nd &lt;- data.frame(\n  x = rep(c(\"A\", \"B\"), c(20, 60)) |&gt; factor() |&gt; sample(size = 25),\n  y = rep(c(\"C\", \"D\"), c(40, 40)) |&gt; factor() |&gt; sample(size = 25)\n)\nhead(d)\n##   x y\n## 1 A C\n## 2 B C\n## 3 B D\n## 4 A D\n## 5 B D\n## 6 B C\n\ntable(d) # これが検定の対象となる\n##    y\n## x    C  D\n##   A  4  3\n##   B 10  8\n\n# 2x2の行列以外の場合には、オッズ比が計算できないので信頼区間は計算されない\nfisher.test(x = d$x, y = d$y)\n## \n##  Fisher's Exact Test for Count Data\n## \n## data:  d$x and d$y\n## p-value = 1\n## alternative hypothesis: true odds ratio is not equal to 1\n## 95 percent confidence interval:\n##  0.1333234 9.4910727\n## sample estimates:\n## odds ratio \n##    1.06395\n\nchisq.test(x = d$x, y = d$y)\n## Warning in chisq.test(x = d$x, y = d$y): Chi-squared approximation may be\n## incorrect\n## \n##  Pearson's Chi-squared test with Yates' continuity correction\n## \n## data:  d$x and d$y\n## X-squared = 0, df = 1, p-value = 1",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>検定</span>"
    ]
  },
  {
    "objectID": "chapter25.html#分散分析",
    "href": "chapter25.html#分散分析",
    "title": "25  検定",
    "section": "25.5 分散分析",
    "text": "25.5 分散分析\n正規分布する2群の平均値の差を評価する場合には、t検定を用います。t検定は2群の差を調べる際には用いることができますが、3群以上の平均値の差を検定することはできません。このような、3群以上の平均値の差を検定したい場合には、分散分析（Analysis of variance、ANOVA）を用います。\n\n\n\n\n\n\n分散と平均値の差\n\n\n\n\n\n分散（variance）は個々の値と平均値の差の二乗和で、以下の式で表されます。xiは個々の値、μは平均値、nはデータの数です。\n\\[var=\\frac{\\sum_{i=1}^{n} (x_{i}-\\mu)^2}{n}\\]\n上の式からわかる通り、分散はばらつきの指標の一つです。分散分析はその名の通り、分散を分析する検定方法ですが、検定する対象となるのは平均値の差で、直感的には少しわかりづらいかと思います。\n分散を分析して平均値の差がわかるのは、群内の分散と全体の分散を分けて評価するからです。下図左のように、平均値の差が小さい場合には、群内のばらつき（オレンジの矢印）と比較して、全体のばらつき（青色の矢印）が比較的小さくなります。一方で、下図右のように、平均値の差が大きい場合には、群内のばらつきに比べて全体のばらつきが大きくなります。したがってオレンジと青色を比較することで、平均値の差の大きさを評価することができます。ただし、この群内・全体のばらつきを比較しているだけでは、どの群とどの群の間に差があるかを評価することはできません。各群の間の差を評価するには、後ほど説明する多重比較の方法を用いる必要があります。\n\n\n\n\n\n25.5.1 一元分散分析\n分散分析のうち最もシンプルな、3群以上の平均値の差を検定するものが一元分散分析です。一元分散分析では、群内の分散、全体の分散からF検定統計量を計算します。F検定統計量をF分布と比較し、p値を計算します。この計算では、カイ二乗検定と同様に、F分布の上側（片側）のみを比較します。ですので、カイ二乗検定と同様に、分散分析も片側検定となります。\n\n25.5.1.1 oneway.test関数\nRでの一元分散分析の計算方法は複数あります。まずはoneway.test関数を用いた方法を示します。oneway.test関数では、t検定と同様に数値~因子のformulaの形でデータを渡します。数値や因子にはベクターを指定します。また、data引数にデータフレームを指定することもできます。\n\n\n\noneway.test関数で一元分散分析\n\noneway.test(iris$Sepal.Length ~ iris$Species)\n## \n##  One-way analysis of means (not assuming equal variances)\n## \n## data:  iris$Sepal.Length and iris$Species\n## F = 138.91, num df = 2.000, denom df = 92.211, p-value &lt; 2.2e-16\n# oneway.test(Sepal.Length ~ Species, data = iris) # 上と同じ\n\n\noneway.test関数は一元分散分析以外に利用できないこと、分散分析表と呼ばれる表が表示されないことから、Rではそれほど用いられません。Rでよく用いられる分散分析の関数は、次のaov関数とanova関数です。\n\n\n25.5.1.2 aov関数\naov関数は分散分析を行う関数の一つで、この後に出てくるanova関数と共に、1元分散分析だけでなく、2元分散分析、共分散分析等の分散分析にも対応した関数です。aov関数の引数はoneway.test関数と同じで、数値~因子のformulaの形でデータを渡します。data引数にデータフレームを指定できるところもoneway.test関数と同様です。\naov関数の返り値は、平方和（Sum of Squares）、自由度（Deg. of Freedom）、残差の標準誤差（Residual standard error）の3つで、F検定統計量もp値も表示されません。検定統計量やp値を表示させるためには、aov関数の返り値をsummary関数の引数に取る必要があります。aov関数の返り値をsummary関数の引数に取って実行すると、分散分析表（自由度、平方和、F検定統計量、p値を示した表）が表示されます。分散分析表のうち、F valueがF検定統計量、Pr(&gt;F)がF分布で検定統計量が表の値以上の値を取る確率、つまりp値となります。\n\n\n\naov関数で一元分散分析\n\naov_iris &lt;- aov(Sepal.Length ~ Species, data = iris)\naov_iris # 単に返り値を表示しても、p値は表示されない\n## Call:\n##    aov(formula = Sepal.Length ~ Species, data = iris)\n## \n## Terms:\n##                  Species Residuals\n## Sum of Squares  63.21213  38.95620\n## Deg. of Freedom        2       147\n## \n## Residual standard error: 0.5147894\n## Estimated effects may be unbalanced\n\n# summary関数の引数に取ると、p値が表示される\nsummary(aov_iris)\n##              Df Sum Sq Mean Sq F value Pr(&gt;F)    \n## Species       2  63.21  31.606   119.3 &lt;2e-16 ***\n## Residuals   147  38.96   0.265                   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n25.5.1.3 anova関数\nRにはanova関数という、oneway.test関数やaov関数とは別の、分散分析のための関数が準備されています。このanova関数は、引数に線形回帰の結果を取るという点がoneway.test関数やaov関数とは大きく異なっているところです。\n詳しくは次の章で紹介しますが、Rで線形回帰を行う場合には、lm関数を用います。lm関数も上にあげたoneway.test関数やaov関数と同じく、formulaを引数に取る関数です。lm関数では、目的変数~説明変数の形でformulaを指定することで、線形回帰を行うことができます。\nanova関数で分散分析を行う場合には、lm関数の引数であるformulaにおいて、目的変数に数値ベクター、説明変数に因子のベクターを設定します。そして、このlm関数の返り値をanovaの引数にします。anova関数を実行すると、aov関数とほぼ同じ、分散分析表を得ることができます。\n\n\n\nanova関数で一元分散分析\n\nlm_iris &lt;- lm(iris$Sepal.Length ~ iris$Species) # 線形回帰の計算\nanova(lm_iris) # 回帰の計算結果を引数に取る\n## Analysis of Variance Table\n## \n## Response: iris$Sepal.Length\n##               Df Sum Sq Mean Sq F value    Pr(&gt;F)    \n## iris$Species   2 63.212  31.606  119.26 &lt; 2.2e-16 ***\n## Residuals    147 38.956   0.265                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n25.5.2 二元分散分析\n二元分散分析は、群に当たるものが2つ以上、例えば、身長に対して性別・居住地など、が存在する場合に、その群ごとの平均値に差があるかどうかを評価するための方法です。\n\n\n\n二元分散分析に用いるデータの例\n\nd &lt;- data.frame(\n  height = c(175, 169, 168, 153, 153, 151, 181, 180, 174, 158, 155, 169), # 身長\n  sex = rep(c(\"M\", \"F\", \"M\", \"F\"), c(3, 3, 3, 3)), # 性別\n  residence = rep(c(\"Osaka\", \"Kobe\")) # 居住地\n)\n\nd\n##    height sex residence\n## 1     175   M     Osaka\n## 2     169   M      Kobe\n## 3     168   M     Osaka\n## 4     153   F      Kobe\n## 5     153   F     Osaka\n## 6     151   F      Kobe\n## 7     181   M     Osaka\n## 8     180   M      Kobe\n## 9     174   M     Osaka\n## 10    158   F      Kobe\n## 11    155   F     Osaka\n## 12    169   F      Kobe\n\n\n二元分散分析も、基本的には一元分散分析と同じく、aov関数やanova関数を用いて計算します。二元分散分析を行う場合には、formulaの右辺に、群を指定する要素を足し算でつなぎます。上記のデータフレームの例であれば、heightが目的変数なのでformulaの左辺へ、sexとresidenceが群（説明変数）なので、右辺にsex+residenceを置くことになります。\n\n\n\naov関数で二元分散分析\n\naov_d &lt;- aov(height ~ sex + residence, data = d)\n\nsummary(aov_d)\n##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    \n## sex          1  972.0   972.0   24.88 0.000751 ***\n## residence    1    9.4     9.4    0.24 0.635956    \n## Residuals    9  351.6    39.1                     \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nanova関数で二元分散分析\n\nanova(lm(height ~ sex + residence, data = d))\n## Analysis of Variance Table\n## \n## Response: height\n##           Df Sum Sq Mean Sq F value    Pr(&gt;F)    \n## sex        1 972.00  972.00  24.879 0.0007513 ***\n## residence  1   9.37    9.37   0.240 0.6359557    \n## Residuals  9 351.63   39.07                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n上の例では、sex（性別）間の差はp=0.00075で統計的に有意であり、residence（居住地）間の差ではp=0.636で差があるとは言えない、という結果になります。\n\n25.5.2.1 交互作用\n一元分散分析にはない二元分散分析の要素として、交互作用があります。交互作用とは、群1が変化すると、群2の効果が変化することを指します。ただ、これではよくわからないので、下の図1で交互作用について説明します。\n交互作用がない場合には、群1がどのような値においても、群2における値の順番が変わらない、グラフにすると平行な関係にあるような状態にあります。一方で、交互作用がある場合には、群1の値が変わると、群2による値の結果が逆転する、グラフにするとどこかで交わるような関係にあるような状態です。交互作用があると、下の図で青の線が赤の線よりも上にある、とは必ずしも言い切れなくなります。したがって、交互作用がある場合には、群1や群2に差がある結果が得られたとしても、結論を保留する場合があります。\n\n\n\n図1：交互作用の有無\n\n\nRで二元分散分析の交互作用を評価するためには、群を指定する要素を掛け算でつなぎます。上の例であれば、sex * residenceとすることで、性別と居住地の交互作用を評価する二元分散分析を行うことができます。\n\n\n\n交互作用ありの二元分散分析\n\naov_d &lt;- aov(height ~ sex * residence, data = d)\n\nsummary(aov_d)\n##               Df Sum Sq Mean Sq F value  Pr(&gt;F)   \n## sex            1  972.0   972.0  22.720 0.00141 **\n## residence      1    9.4     9.4   0.219 0.65219   \n## sex:residence  1    9.4     9.4   0.219 0.65219   \n## Residuals      8  342.3    42.8                   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n上の例では、交互作用（sex:residence）のp値が0.652なので、「交互作用がないという仮説を棄却しない」という結果になります。交互作用があるとは言えないため、性別（sex）の有意差は信頼できると言えます。\n\n\n\n25.5.3 共分散分析\n共分散分析は、多元の分散分析のうち、1つの要素が数値になっているものを指します。2元の分散分析ではカテゴリカルデータを群1、群2とするところを、共分散分析では群1と数値という形で設定することになります。この形のデータは、以下のToothGrowthデータのグラフに示すように、複数の線形回帰を比較するようなものになります。\n\n\n\n共分散分析に用いるデータの例\n\nToothGrowth |&gt; \n  ggplot(aes(x = dose, y = len, color = supp)) +\n  geom_point(size = 2) +\n  geom_abline(intercept = 11.55, slope = 7.811, color = \"red\") +\n  geom_abline(intercept = 3.295, slope = 11.716, color = \"blue\") +\n  labs(\n    title = \"共分散分析のデータ例：ToothGrowthデータをグラフで表示\", \n    x = \"投与したビタミンCの量\",\n    y = \"モルモットの歯の長さ\", \n    color = \"投与方法\",\n    caption = \"OJ：オレンジジュースに加える、VC：ビタミンCそのまま\")\n\n\n\n\n\n\n\n\n\nRでの共分散分析には、2元分散分析と同じように、aov関数やanova関数を用います。引数の指定はformulaで、因子 * 数値のような形で、因子同士を掛け算でつなぎます。formulaは交互作用ありの二元分散分析と同じ形です。\n\n\n\naov関数で共分散分析\n\naov_ToothGrowth &lt;- aov(len ~ supp * dose, data = ToothGrowth) # suppは因子、doseは数値\n\nsummary(aov_ToothGrowth)\n##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    \n## supp         1  205.4   205.4  12.317 0.000894 ***\n## dose         1 2224.3  2224.3 133.415  &lt; 2e-16 ***\n## supp:dose    1   88.9    88.9   5.333 0.024631 *  \n## Residuals   56  933.6    16.7                     \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n共分散分析の結果として、因子に対するp値（上の例ではsupp）、数値に対するp値（上の例ではdose）、交互作用に関するp値（上の例ではsupp:dose）が得られます。\nこのうち、交互作用に関するp値は、2つの直線（supp：OJとVC）の傾きの差の有無に関する検定の結果となります。この交互作用のp値が小さければ、「2つの直線の傾きが一致する」という帰無仮説を棄却する、つまり傾きに差があると結論します。この検定結果のことを、「共分散分析による平行性の検定」と呼ぶ場合があります。\n次に、因子（supp）についてのp値は、因子間での目的変数（y軸である歯の長さ）の差に関する検定の結果を示します。このp値が小さければ、「2つの因子（OJとVC）の間で歯の長さに差がない」という仮説を棄却する、つまりOJとVCの間で歯の長さに有意な差がある、と結論します。ただし、二元分散分析における交互作用と同様に、平行性の検定で傾きに差がある場合、この因子間の差の結論は保留する場合もあります。\n最後に、数値（dose）についてのp値は、傾きの有意性の検定の結果となります。このp値が小さければ、「doseに対する目的変数（歯の長さ）の直線関係の傾きは0である」という仮説を棄却し、doseと歯の長さの直線関係において、傾きが0ではない、と結論します。\nしたがって共分散分析では、因子間の傾きの差の検定（交互作用）、因子間の差の検定、数値同士の直線関係における傾きの検定の3つを同時に評価することになります。",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>検定</span>"
    ]
  },
  {
    "objectID": "chapter25.html#多重比較",
    "href": "chapter25.html#多重比較",
    "title": "25  検定",
    "section": "25.6 多重比較",
    "text": "25.6 多重比較\n分散分析では、3群以上の平均値の差の検定を行います。ただし、分散分析でわかるのは、3群に差があるのかどうかであって、どの群の間に差があるのかはよくわかりません。\nどの群とどの群の間に差があるかを知りたい場合、もっとも単純に考えると2群ずつのt検定を繰り返せばよいように思います。しかし、 検出力と例数（ Section 25.3.6 ）で説明した通り、検定には第一の過誤という、「差があると結論しても実際には差がなかった」ということが起こります。この第一の過誤の確率はp値となります。ですので、例えばp=0.05のt検定を2回行えば、どちらか一方の検定が間違いである確率は、\\(1-(1-0.05)^2=0.0975\\)となり、0.05より大きい確率で間違いを含んでしまいます。\nこの検定を繰り返すと検定に間違いが含まれる確率が0.05より大きくなる問題のことを多重性の問題と呼びます。この多重性の問題を解決するために、第一の過誤の確率を調整するのが多重比較の方法です。多重比較の方法には様々なものがあります。Rで利用可能な多重比較の方法を以下に示していきます。\n\n25.6.1 Scheffeの方法\nScheffeの方法は、昔は教科書等にも書かれていた多重比較の方法なのですが、最近はあまり紹介されているところを見ないものです。RでScheffeの方法を用いるためには、DescToolsパッケージ (Signorell 2023)のScheffeTest関数を利用する必要があります。ScheffeTest関数はaov関数の返り値を引数に取り、多重比較による各群の総当たりの調整済みp値を計算してくれます。\n\n\n\nScheffeの方法による多重比較\n\npacman::p_load(DescTools)\nScheffeTest(aov(iris$Sepal.Length ~ iris$Species))\n## \n##   Posthoc multiple comparisons of means: Scheffe Test \n##     95% family-wise confidence level\n## \n## $`iris$Species`\n##                       diff    lwr.ci    upr.ci    pval    \n## versicolor-setosa    0.930 0.6753953 1.1846047 8.1e-15 ***\n## virginica-setosa     1.582 1.3273953 1.8366047 &lt; 2e-16 ***\n## virginica-versicolor 0.652 0.3973953 0.9066047 2.0e-08 ***\n## \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n25.6.2 Tukeyの方法\n上で示したScheffeの方法と同様に、総当たりの多重比較を行うのがTukeyの方法です。多重比較の方法として最もよく紹介されているのはこのTukeyの方法だと思います。RでTukeyの方法を利用する場合には、TukeyHSD関数を用います。TukeyHSD関数もaov関数の返り値を引数に取り、多重比較による各群の総当たりの調整済みp値を計算してくれます。\n\n\n\nTukeyの方法による多重比較\n\nTukeyHSD(aov(iris$Sepal.Length ~ iris$Species))\n##   Tukey multiple comparisons of means\n##     95% family-wise confidence level\n## \n## Fit: aov(formula = iris$Sepal.Length ~ iris$Species)\n## \n## $`iris$Species`\n##                       diff       lwr       upr p adj\n## versicolor-setosa    0.930 0.6862273 1.1737727     0\n## virginica-setosa     1.582 1.3382273 1.8257727     0\n## virginica-versicolor 0.652 0.4082273 0.8957727     0\n\n\n\n\n25.6.3 Dunnettの方法\nDunnettの方法は、Tukeyの方法のような総当たりの比較手法ではなく、1つの対照群（control）に対して、その他の群との差を評価するための多重比較の方法です。Dunnettの方法は対照群との差を評価することを目的としているため、対照群以外の群間の差は評価しません。この、対照群以外の群間の差を評価しないことで、第一の過誤が起こる可能性を減らし、第一の過誤の確率の調整量を小さめにする、要は差を出やすくすることができます。\nRでDunnettの方法を行う場合には、DescToolsパッケージのDunnettTest関数を用います。DunnettTest関数は引数にformulaを取ります。また、control引数に因子のレベルを指定すると、そのレベルを対照群として計算を行うこともできます。\n\n\n\nDunnettの方法による多重比較\n\npacman::p_load(DescTools)\n\n# Speciesの一番初めのレベル（Setosa）を対照群とする\nDunnettTest(Sepal.Length ~ Species, data = iris)\n## \n##   Dunnett's test for comparing several treatments with a control :  \n##     95% family-wise confidence level\n## \n## $setosa\n##                    diff   lwr.ci   upr.ci    pval    \n## versicolor-setosa 0.930 0.700032 1.159968 2.0e-15 ***\n## virginica-setosa  1.582 1.352032 1.811968 4.4e-16 ***\n## \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# virginicaを対照群とする\nDunnettTest(Sepal.Length ~ Species, data = iris, control = \"virginica\")\n## \n##   Dunnett's test for comparing several treatments with a control :  \n##     95% family-wise confidence level\n## \n## $virginica\n##                        diff    lwr.ci    upr.ci    pval    \n## setosa-virginica     -1.582 -1.811968 -1.352032 4.4e-16 ***\n## versicolor-virginica -0.652 -0.881968 -0.422032 5.5e-09 ***\n## \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n25.6.4 p値を調整する方法\n多重比較の方法には、上で示した3つ以外に、t検定などで計算したp値自体を用いてp値を直接調整するタイプの方法がたくさんあります。p値を直接調整する手法としては、holmの方法、hochbergの方法、bonferroniの方法、Benjamini & Hochbergの方法、Benjamini & Yekutieliの方法などがあります。\nこれらの方法によるp値の調整はRのp.adjust関数を用いて計算することができます。p.adjust関数の第一引数にはp値のベクターを指定し、method引数に多重比較の方法の指定します。\n\n\n\np.adjust関数でp値を調整する\n\n# p値をベクターで準備\np_vec &lt;- seq(0.005, 0.06, by = 0.005)\np_vec\n##  [1] 0.005 0.010 0.015 0.020 0.025 0.030 0.035 0.040 0.045 0.050 0.055 0.060\n\n# holmの方法でp値を調整\np.adjust(p_vec, method = \"holm\")\n##  [1] 0.06 0.11 0.15 0.18 0.20 0.21 0.21 0.21 0.21 0.21 0.21 0.21\n\n\nまた、総当たりのt検定を行い、p値を上記の手法で補正する関数として、pairwise.t.test関数が設定されています。pairwise.t.test関数は数値ベクターと因子ベクターを引数に取り、p.adjust.method引数にp値の調整方法を指定して用います。\n\n\n\npairwise.t.test関数でp値調整済み総当たりt検定を行う\n\n# formulaは使えない\npairwise.t.test(iris$Sepal.Length, iris$Species, p.adjust.method = \"holm\")\n## \n##  Pairwise comparisons using t tests with pooled SD \n## \n## data:  iris$Sepal.Length and iris$Species \n## \n##            setosa  versicolor\n## versicolor 1.8e-15 -         \n## virginica  &lt; 2e-16 2.8e-09   \n## \n## P value adjustment method: holm\n\n\np値調整の手法ごとのp値の値を比較したグラフを以下に示します。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngatekeeping法\n\n\n\n\n\n多重比較の方法には、この他にgatekeeping法と呼ばれるものもあります。gatekeeping法は研究デザインとの関連性が高い手法で、基礎研究ではまずお目にかからないものです。近年の第III相治験のような、ガチガチに研究デザインを固めてから行う大規模研究以外ではまず使うことはないでしょう。Rにはこのgatekeeping法の計算に関連したライブラリとしてMedianaパッケージ (Paux and Dmitrienko. 2019)や gMCPパッケージ (Bretz et al. 2011)があります。",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>検定</span>"
    ]
  },
  {
    "objectID": "chapter25.html#ノンパラメトリック検定",
    "href": "chapter25.html#ノンパラメトリック検定",
    "title": "25  検定",
    "section": "25.7 ノンパラメトリック検定",
    "text": "25.7 ノンパラメトリック検定\nパラメトリック検定は、検定手法の前提として、データの分布があらかじめわかっていることを仮定しています。例えばt検定や分散分析は目的変数が正規分布することを仮定していますし、フィッシャーの正確検定やカイ二乗検定では、目的変数が二項分布や超幾何分布することを仮定しています。しかし、データによってはこの仮定に当てはまらない、つまり正規分布も二項分布も取らないものもあります。このように、正規分布や二項分布せず、t検定や分散分析、カイ二乗検定の対象とならないデータを用いて検定を行いたい場合には、以前はノンパラメトリック検定を用いるのが良いとされていました。\nノンパラメトリック検定のいいところは、計算が簡単で、手計算でも例数が少なければ計算可能なことです。ただし、この計算の過程で、データの損失が起きるため、検出力が低めになるのが特徴です。最近では、データの分布がある程度特定できれば、データの分布を仮定したパラメトリックな統計手法（一般化線形モデル）を利用することができます。データの分布によってはあらかじめ対数変換し、正規分布を仮定する等の対応方法もあります。\n以下にノンパラメトリック検定の手法を説明しますが、特に理由があってノンパラメトリック検定を用いる場合以外には、データの分布を調べて、次の章で説明する一般化線形モデルなどを用いる方がよいでしょう。\n\n25.7.1 Wilcoxonの順位和検定\nWilcoxonの順位和検定は、正規分布しないデータを取得した場合に、データを大きいものから小さいものまで、データの順序に並べ替え、このデータの順序を利用して順序の差を検定するものです。この「順序に変換する」という過程において、データの損失が生じます。Wilcoxonの順位和検定では、t検定と同様に、2群のデータの比較を行います。\nRでは、wilcox.test関数でWilcoxonの順位和検定を行うことができます。wilcox.test関数は数値ベクター2つ、もしくはformulaを引数に取ります。引数はt.test関数とほぼ同じです。\n\n\n\nノンパラメトリック検定：Wilcoxonの順位和検定\n\nx &lt;- rlnorm(10, meanlog = 0, sdlog = 1)\ny &lt;- rlnorm(10, meanlog = 1, sdlog = 0.5)\nf &lt;- rep(c(\"a\", \"b\"), c(5, 5)) |&gt; factor()\n\n# 2つのベクターを引数に取る\nwilcox.test(x, y)\n## \n##  Wilcoxon rank sum exact test\n## \n## data:  x and y\n## W = 23, p-value = 0.04326\n## alternative hypothesis: true location shift is not equal to 0\n\n# ベクターと因子を引数に取る\nwilcox.test(x ~ f)\n## \n##  Wilcoxon rank sum exact test\n## \n## data:  x by f\n## W = 22, p-value = 0.05556\n## alternative hypothesis: true location shift is not equal to 0\n\n\n\n\n25.7.2 Friedmanのランク和検定\nFriedmanのランク和検定は、3群以上のデータでの差を検定する、ノンパラメトリック検定版の分散分析のような検定です。\nRではFriedmanのランク和検定をfriedman.test関数で計算することができます。friedman.testの引数は行列で、各列が群となります。下の例では、3列の行列をirisから作成し、friedman.testの引数にしています。\n\n\n\nノンパラメトリック検定：Friedmanのランク和検定\n\niris_temp &lt;- iris[1:10, 1:3] |&gt; as.matrix()\niris_temp # 3列の行列\n##    Sepal.Length Sepal.Width Petal.Length\n## 1           5.1         3.5          1.4\n## 2           4.9         3.0          1.4\n## 3           4.7         3.2          1.3\n## 4           4.6         3.1          1.5\n## 5           5.0         3.6          1.4\n## 6           5.4         3.9          1.7\n## 7           4.6         3.4          1.4\n## 8           5.0         3.4          1.5\n## 9           4.4         2.9          1.4\n## 10          4.9         3.1          1.5\n\nfriedman.test(iris_temp)\n## \n##  Friedman rank sum test\n## \n## data:  iris_temp\n## Friedman chi-squared = 20, df = 2, p-value = 4.54e-05\n\n\n同様に、friedman.test関数は繰り返しのない、同じ群のデータが1つしかないような場合の2因子ブロックデザインにも対応しています。この場合、群分けに当たる変数が2つ必要です。引数にはformulaを用いるのですが、formulaの設定方法が他の検定の関数とはやや異なります。formulaでは、群間差を検討する因子を~の後に置き、検討しない方のもう一因子を|を挟んで右側に置きます。ですので、formulaの形は目的変数 ~ 因子1 | 因子2という形で設定します。\n\n\n\n引数がformulaの時のfriedman.test\n\nwb &lt;- warpbreaks |&gt; group_by(wool, tension) |&gt; summarise(breaks = mean(breaks))\n## `summarise()` has grouped output by 'wool'. You can override using the\n## `.groups` argument.\n\nwb # 因子が2つあるデータフレーム\n## # A tibble: 6 × 3\n## # Groups:   wool [2]\n##   wool  tension breaks\n##   &lt;fct&gt; &lt;fct&gt;    &lt;dbl&gt;\n## 1 A     L         44.6\n## 2 A     M         24  \n## 3 A     H         24.6\n## 4 B     L         28.2\n## 5 B     M         28.8\n## 6 B     H         18.8\n\nwb |&gt; pivot_wider(names_from = wool, values_from = \"breaks\") # 2因子のブロックデザインデータ\n## # A tibble: 3 × 3\n##   tension     A     B\n##   &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt;\n## 1 L        44.6  28.2\n## 2 M        24    28.8\n## 3 H        24.6  18.8\n\nfriedman.test(breaks ~ wool | tension, data = wb) # woolの群間差\n## \n##  Friedman rank sum test\n## \n## data:  breaks and wool and tension\n## Friedman chi-squared = 0.33333, df = 1, p-value = 0.5637\n\nfriedman.test(breaks ~ tension | wool, data = wb) # tensionの群間差\n## \n##  Friedman rank sum test\n## \n## data:  breaks and tension and wool\n## Friedman chi-squared = 1, df = 2, p-value = 0.6065\n\n\n\n\n25.7.3 Kruskal-Wallisのランク和検定\nKruskal-Wallisのランク和検定も、ノンパラメトリック版の一元分散分析のようなものになります。RでKruskal-Wallisのランク和検定を計算する場合には、kruskal.test関数を用います。kruskal.test関数はoneway.test関数と同様に、目的変数~説明変数というformulaを引数とします。\n\n\n\nノンパラメトリック検定：Kruskal-Wallisのランク和検定\n\nkruskal.test(iris$Sepal.Length ~ iris$Species)\n## \n##  Kruskal-Wallis rank sum test\n## \n## data:  iris$Sepal.Length by iris$Species\n## Kruskal-Wallis chi-squared = 96.937, df = 2, p-value &lt; 2.2e-16",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>検定</span>"
    ]
  },
  {
    "objectID": "chapter25.html#その他の検定",
    "href": "chapter25.html#その他の検定",
    "title": "25  検定",
    "section": "25.8 その他の検定",
    "text": "25.8 その他の検定\n上記の検定が群間の平均値の差を調べる場合に用いられる主な検定となります。これらの他にも非常にたくさんの検定手法があります。ここでは、その例として正規性の検定、分散の均一性の検定、外れ値の検定の3つの検定を紹介します。\n\n25.8.1 正規性の検定：Shapiro-Wilk検定\n正規性の検定（Shapiro-Wilk検定）は、データが正規分布しているかどうかを検定で判別するための検定手法です。「データが正規分布している」が帰無仮説ですので、正規分布していないデータが与えられたときにp値が小さくなり、帰無仮説が棄却されます。\nただし、この検定よりは、qqプロットのような正規性を図から調べるような方法や、ヒストグラムでの左右対称性の確認、データが連続的であるかどうかなどを指標にして判別する方がよいように思います。\n\n\n\n正規性の検定\n\nrnorm(100) |&gt; shapiro.test() # 正規乱数は正規分布しているので棄却されない\n## \n##  Shapiro-Wilk normality test\n## \n## data:  rnorm(100)\n## W = 0.97824, p-value = 0.09687\n\nrunif(100) |&gt; shapiro.test() # 一様乱数は正規分布していないので棄却される\n## \n##  Shapiro-Wilk normality test\n## \n## data:  runif(100)\n## W = 0.94017, p-value = 0.0001973\n\n\n\n\n25.8.2 分散の均一性の検定\n分散の均一性の検定は、2つの群で分散が同じであるかどうかを検定するための検定手法です。Studentのt検定では、等分散性が正確な検定の条件として設けられているため、2群間で分散が均一であるかどうかは、t検定の信頼性評価に重要な要素でした。ただし、Rのt.test関数では等分散性の仮定から外れても、補正して正確に結果を表示してくれるWelchのt検定が用いられているため、t検定においては等分散性は昔ほど重要ではありません。\n\n\n\n分散の均一性の検定\n\n# 正規分布同士の分散の均一性の検定（異なっていれば帰無仮説を棄却）\nvar.test(rnorm(10), rnorm(10))\n## \n##  F test to compare two variances\n## \n## data:  rnorm(10) and rnorm(10)\n## F = 0.69878, num df = 9, denom df = 9, p-value = 0.602\n## alternative hypothesis: true ratio of variances is not equal to 1\n## 95 percent confidence interval:\n##  0.1735671 2.8132844\n## sample estimates:\n## ratio of variances \n##            0.69878\n\n# 正規分布と一様分布の分散の均一性の検定\nvar.test(rnorm(10), runif(10))\n## \n##  F test to compare two variances\n## \n## data:  rnorm(10) and runif(10)\n## F = 19.716, num df = 9, denom df = 9, p-value = 0.0001373\n## alternative hypothesis: true ratio of variances is not equal to 1\n## 95 percent confidence interval:\n##   4.897098 79.375252\n## sample estimates:\n## ratio of variances \n##           19.71569\n\n\n\n\n25.8.3 外れ値の検定\nデータが外れ値（outlier）かどうかを判別する場合には、外れ値の検定というものを用いる場合もあります。この検定では、代表値（平均など）から一番外れたデータが外れ値かどうかを検定し、外れ値であれば帰無仮説を棄却するものとなっています。Rではoutlierパッケージ (Komsta 2022)の関数であるchisq.out.test、grubbs.test、dixon.testで検定を行うことができます。\nただし、この検定で外れ値であると判断されても、データは取り除いてはいけません。これらの検定はデータが正規分布していることを仮定しており、正規分布していないデータでは外れ値とはならない場合があります。検定は外れ値を取り除くためのものではなく、外れ値である可能性を把握し、データの取得に問題がなかったか検討したり、分布が正規性を持つかどうかを評価しなおしたりするためのものです。\n基礎研究などで極端な外れ値が取れた場合には何か理由を付けてデータを取り除きたくなるものですが、この検定を用いてもデータを取り除くことはできません。このような検定を用いずに、データと向き合う方が良いように思います。\n\n\n\n外れ値の検定\n\npacman::p_load(outliers)\n\n# 正規乱数\nx &lt;- c(rnorm(10), 10)\n\nchisq.out.test(x)\n## \n##  chi-squared test for outlier\n## \n## data:  x\n## X-squared = 7.9438, p-value = 0.004825\n## alternative hypothesis: highest value 10 is an outlier\n\ngrubbs.test(x)\n## \n##  Grubbs test for one outlier\n## \n## data:  x\n## G = 2.81847, U = 0.12618, p-value = 0.0001353\n## alternative hypothesis: highest value 10 is an outlier\n\ndixon.test(x)\n## \n##  Dixon test for outliers\n## \n## data:  x\n## Q = 0.81998, p-value &lt; 2.2e-16\n## alternative hypothesis: highest value 10 is an outlier\n\n\n\n\n\n\n\n図1：データと対応する検定手法\n図1：第一の過誤と第二の過誤\n図1：交互作用の有無\n\n\n\nAltman, Naomi, and Martin Krzywinski. 2016. “Points of Significance: P Values and the Search for Significance.” Nature Methods 14 (1): 3–4. https://doi.org/10.1038/nmeth.4120.\n\n\nBenjamin, Daniel J, James O Berger, Magnus Johannesson, Brian A Nosek, E-J Wagenmakers, Richard Berk, Kenneth A Bollen, et al. 2018. “Redefine Statistical Significance.” Nature Human Behaviour 2 (1): 6–10.\n\n\nBretz, Frank, Martin Posch, Ekkehard Glimm, Florian Klinglmueller, Willi Maurer, and Kornelius Rohmeyer. 2011. “Graphical Approaches for Multiple Comparison Procedures Using Weighted Bonferroni, Simes or Parametric Tests.” Biometrical Journal 53 (6): 894–913. https://doi.org/10.1002/bimj.201000239.\n\n\nKomsta, Lukasz. 2022. Outliers: Tests for Outliers. https://CRAN.R-project.org/package=outliers.\n\n\nPaux, Gautier, and Alex Dmitrienko. 2019. Mediana: Clinical Trial Simulations. https://CRAN.R-project.org/package=Mediana.\n\n\nSignorell, Andri. 2023. DescTools: Tools for Descriptive Statistics. https://CRAN.R-project.org/package=DescTools.",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>検定</span>"
    ]
  },
  {
    "objectID": "chapter26.html",
    "href": "chapter26.html",
    "title": "26  相関と回帰",
    "section": "",
    "text": "26.1 相関\n相関は、どちらが原因でどちらが結果かはっきりしない2変量（共に数値）の関係を示すときに用いられる分析の方法です。通常は相関係数（correlation coefficient）を用いて評価します。相関係数は2変量の直線的な関係を評価するための数値で、絶対値が1に近いほど2変量の関係は直線的、0に近いほどランダム（2変量は独立）であることを示します。また、相関係数がプラスの場合には片方が増えるともう片方も増える（正の相関）、マイナスの場合には片方が増えるともう片方は減る（負の相関）関係にあることを示します。\nRで相関係数を計算する場合には、cor関数を用います。cor関数は同じ長さのベクター2つを引数に取り、その2つのベクター間の相関係数を計算する関数です。cor関数の引数にデータフレームを与えると、各行の値の総当りの相関係数（相関行列）を返します。\ncor関数は通常ピアソンの相関係数を計算する関数ですが、method=\"kendall\"やmethod=\"spearman\"を指定するとケンドールの相関係数やスピアマンの相関係数（いずれもノンパラメトリックな相関係数計算の手法）を計算することができます。2つの変数が正規分布しない場合や、直線的な関係にない時（例えば反比例するような場合）にはノンパラメトリックな方法を用いる方がよいときもあります。\nまた、相関係数が0ではないこと、つまり相関があることを検定するための関数がcor.test関数です。ただし、データ数が多ければ相関係数が0に近くてもcor.testでは統計的に有意となりやすくなります。\nまた、GGallyパッケージ(Schloerke et al. 2023)のggpairs関数を用いれば、相関係数、cor.testの結果、散布図を一度に確認することができます。\n相関係数の計算\n\n# 2変量の相関（ピアソンの相関係数）\ncor(iris$Sepal.Length, iris$Sepal.Width)\n## [1] -0.1175698\n\n# ケンドールの相関係数\ncor(iris$Sepal.Length, iris$Sepal.Width, method=\"kendall\")\n## [1] -0.07699679\n\n# スピアマンの相関係数\ncor(iris$Sepal.Length, iris$Sepal.Width, method=\"spearman\")\n## [1] -0.1667777\n\n# データフレームを引数にした場合の相関行列の計算\ncor(iris[, 1:4])\n##              Sepal.Length Sepal.Width Petal.Length Petal.Width\n## Sepal.Length    1.0000000  -0.1175698    0.8717538   0.8179411\n## Sepal.Width    -0.1175698   1.0000000   -0.4284401  -0.3661259\n## Petal.Length    0.8717538  -0.4284401    1.0000000   0.9628654\n## Petal.Width     0.8179411  -0.3661259    0.9628654   1.0000000\n\n# 相関係数が0ではないことに関する検定\ncor.test(iris$Sepal.Length, iris$Sepal.Width)\n## \n##  Pearson's product-moment correlation\n## \n## data:  iris$Sepal.Length and iris$Sepal.Width\n## t = -1.4403, df = 148, p-value = 0.1519\n## alternative hypothesis: true correlation is not equal to 0\n## 95 percent confidence interval:\n##  -0.27269325  0.04351158\n## sample estimates:\n##        cor \n## -0.1175698\n\n# GGally::ggpairsで相関係数等を一度に表示する\nGGally::ggpairs(iris[, 1:4])\n## Registered S3 method overwritten by 'GGally':\n##   method from   \n##   +.gg   ggplot2",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>相関と回帰</span>"
    ]
  },
  {
    "objectID": "chapter26.html#相関",
    "href": "chapter26.html#相関",
    "title": "26  相関と回帰",
    "section": "",
    "text": "相関係数の大きさと相関の強さ\n\n\n\n\n\n相関係数の絶対値が1に近ければ相関は強くなるのですが、どの程度の数値であれば相関があると言えるのか、という点についてははっきりしていません。教科書や資料を読むと、0.5ぐらいだと相関があるとしているものもありますし、0.3でも相関として意味があると書いている場合もあります。以下に例として、相関係数が異なるデータのグラフを示します。グラフから、相関係数がどれぐらいならどの程度相関があるのか、イメージして頂ければと思います。\n\n\n\n\n\n\n\n\n\nまた、2変量の関係が直線的でない場合には、何らかの関係が2変量間にあったとしても相関係数は小さくなります。相関係数を調べるだけでなく、グラフで2変量の関係を確認することが重要です。",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>相関と回帰</span>"
    ]
  },
  {
    "objectID": "chapter26.html#線形回帰",
    "href": "chapter26.html#線形回帰",
    "title": "26  相関と回帰",
    "section": "26.2 線形回帰",
    "text": "26.2 線形回帰\n回帰は目的変数も説明変数も数値である場合に、目的変数と説明変数の関係を線形で示す統計解析です。回帰は、目的変数と説明変数の関係を説明するために用いられるものですが、回帰式を用いて説明変数を得た時に目的変数を予測する、予測的なモデルとしても用いることができます。\n前者、説明的な回帰の例としては、作物に与える窒素肥料の量が作物の収率にどの程度影響を及ぼすのか調べるような場合が当てはまります。後者、予測的な回帰の例としては、検量線を引いておいて、吸光度から物質の濃度を計算するような場合が当てはまります。回帰の種類によっては、予測的なモデルが機械学習として取り扱われることもあります。\n説明変数が一つである場合、単回帰と呼ばれる線形回帰を行うことになります。目的変数が正規分布する場合、回帰の結果は直線となります。\n線形回帰では、最小二乗法と呼ばれる手法を用いて回帰を行います。最小二乗法は、直線と各データの点までのy軸方向の距離の2乗の和（2乗誤差）を最小にする直線を求める方法です。図で表すと、以下のグラフの赤線の長さを2乗して合計し、この合計を最小にする線の数式を求めるが最小二乗法です。この最小二乗法は微分を使えば比較的簡単に解けるため、昔からよく用いられてきた方法です。y軸方向（目的変数）の誤差のみを考慮して結果を求めるため、説明変数と目的変数を逆にしてしまうと計算結果が変わります。\n\n\n\n\n\n\nggplot2のコード\n\n\n\n\n\n\nset.seed(0)\nx &lt;- rnorm(50, mean = 10, sd = 2)\ny &lt;- 0.5 * x + 3 + rnorm(50)\n\nlmresult &lt;- lm(y ~ x)\npred &lt;- predict(lmresult)\n\nnew_d &lt;- data.frame(x, y, pred)\n\nnew_d |&gt; \n  ggplot(aes(x = x, y = y, ymax = pred, ymin = y))+\n  geom_linerange(linewidth = 1, color = \"#F8766D\")+\n  geom_point(size = 3, color = \"#00BFC4\")+\n  geom_abline(intercept = lmresult$coefficients[1], slope = lmresult$coefficients[2], color = \"black\", linewidth = 0.25)+\n  labs(title = \"最小二乗法のイメージ\", caption = \"青点：データの点、黒線：線形回帰の線、赤線：最小二乗法で最小とする長さ\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nRで線形回帰を行う場合には、lm関数を用います。lm関数の引数はformulaで、目的変数~説明変数という形で、チルダ（~）の前に結果（目的変数）のデータ、チルダの後に原因（説明変数）のデータをつないで用います。目的変数と説明変数は1対となるため、目的変数と説明変数に指定する変数の長さは同じである必要があります。lm関数の結果として、coefficients（係数、パラメータ）が2つ求まります。1つはIntercept、つまり切片で、もう一つは説明変数に対する傾きです。下の例では、\\(Sepal.Length = 6.5262 - 0.2234 \\cdot Sepal.Width\\)という線形で回帰の式が表されることを示しています。\n\n\n\n線形回帰（単回帰）\n\nlm(iris$Sepal.Length ~ iris$Sepal.Width)\n## \n## Call:\n## lm(formula = iris$Sepal.Length ~ iris$Sepal.Width)\n## \n## Coefficients:\n##      (Intercept)  iris$Sepal.Width  \n##           6.5262           -0.2234\n\n\n\n26.2.1 lmオブジェクトの取り扱い\n線形回帰の結果を変数に代入すると、lmクラスの変数となります。lmクラスのオブジェクトからは、$coefficientsで切片と傾きを取り出すことができます。また、summary関数の引数とすると、回帰の詳細が表示されます。\nsummary関数で示される回帰の詳細には、coefficientsとして、分散分析表のようなものが表示されます。この表のうち、Estimateは切片と傾きの推定値、Std. Errorは切片と傾きの標準誤差、t valueとPr(&gt;|t|)はt検定の結果を示しています。このt検定の結果は、coefficients（切片と傾き）が0と有意に異なっているかを示しています。以下の例では、Interceptは0と有意に異なるのに対して、iris$Sepal.Width、つまり傾きは0とは有意に異ならないことを示しています。つまり、Sepal.Widthは目的変数であるSepal.Lengthにはほとんど影響がないことを表しています。\nMultiple R squaredは決定係数と呼ばれるもので、線形性の高さを示します。決定係数（R2）は相関係数（R）の2乗として計算されるもので、0~1の値を取ります。1に近いほど線形性が高く、0に近いほどあまり線形性がみられないという結果となります。Adjusted R squaredは調整済み決定係数で、説明変数の数でペナルティを付けて計算した決定係数です。\n\n\n\nlmクラスの取り扱い\n\nlmresult &lt;- lm(iris$Sepal.Length ~ iris$Sepal.Width) # 変数にlmの結果を代入\nclass(lmresult) # lmクラスのオブジェクト\n## [1] \"lm\"\n\nlmresult$coefficients # 切片と傾きを取り出す\n##      (Intercept) iris$Sepal.Width \n##        6.5262226       -0.2233611\n\nsummary(lmresult) # 線形回帰の詳細（内容の詳細は?summary.lmで調べることができる）\n## \n## Call:\n## lm(formula = iris$Sepal.Length ~ iris$Sepal.Width)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.5561 -0.6333 -0.1120  0.5579  2.2226 \n## \n## Coefficients:\n##                  Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)        6.5262     0.4789   13.63   &lt;2e-16 ***\n## iris$Sepal.Width  -0.2234     0.1551   -1.44    0.152    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.8251 on 148 degrees of freedom\n## Multiple R-squared:  0.01382,    Adjusted R-squared:  0.007159 \n## F-statistic: 2.074 on 1 and 148 DF,  p-value: 0.1519\n\n\n\n\n26.2.2 predict関数\npredict関数は、lmクラスのオブジェクトを引数に取り、x軸の値を与えた時のy軸側の直線上の値やyの値の信頼区間を計算する関数です。\npredict関数の第一引数はlmクラスのオブジェクトで、第二引数（newdata）に、予測したいx軸上の値をデータフレームで設定します。intervalという引数には、\"none\"、\"confidence\"、\"prediction\"の3つのうちどれかを設定します。\"none\"の場合にはnewdataで与えたxを与えた場合の直線上のyの値のみを返します。\"confidence\"の場合は信頼区間、\"prediction\"の場合は個々の値に関する予測区間が表示されます。区間の幅はlevels引数で指定することができます。levels引数のデフォルト値は0.95なので、levelsを設定しない場合には信頼区間などの区間は95％区間として求まります。\n\n\n\nデータの準備\n\nset.seed(0)\nx &lt;- rnorm(15) # xは平均0、標準偏差1の正規乱数\ny &lt;- x + rnorm(15) # yはxに正規乱数を足したもの\nplot(x, y, xlim = c(-1.75, 2.5), ylim = c(-2, 2.5))\npar(new = T)\nplot(\\(x){x}, xlim = c(-1.75, 2.5), ylim = c(-2, 2.5), xlab = \"\", ylab = \"\")\n\n\n\n\n\n\n\n\n\n\n\n\npredict関数の利用\n\nlmr &lt;- lm(y ~ x)\nnew &lt;- data.frame(x = 1:5) # x=1～5のときの予測値を求める\n\n# fitが直線上の値、lwr、uprがそれぞれ信頼区間の2.5％、97.5％分位値\npredict(lmr, newdata = new, interval = \"confidence\", levels = 0.95)\n##         fit       lwr      upr\n## 1 0.8640845 0.3320906 1.396078\n## 2 1.7973471 0.9638927 2.630801\n## 3 2.7306096 1.5453633 3.915856\n## 4 3.6638722 2.1103261 5.217418\n## 5 4.5971348 2.6682138 6.526056\n\n\n\n\n\n95%信頼区間を加えた回帰のグラフ\n\nggplot()+\n  geom_point(data = data.frame(x, y), aes(x = x, y = y, size = 2)) +\n  geom_ribbon(\n    data = \n      data.frame(\n        x = seq(-2, 2.5, by = 0.1), \n        predict(lmr, newdata = data.frame(x = seq(-2, 2.5, by = 0.1)), interval = \"confidence\", levels = 0.95)),\n    aes(x = x, y = fit, ymax = upr, ymin = lwr, color = factor(1), fill = factor(1), alpha = 0.2)\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n切片と傾きの95％信頼区間\n\nconfint(lmr)\n##                  2.5 %    97.5 %\n## (Intercept) -0.4813949 0.3430386\n## x            0.5469117 1.3196134",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>相関と回帰</span>"
    ]
  },
  {
    "objectID": "chapter26.html#重回帰",
    "href": "chapter26.html#重回帰",
    "title": "26  相関と回帰",
    "section": "26.3 重回帰",
    "text": "26.3 重回帰\n重回帰とは、1つの目的変数に対して、2つ以上の説明変数がある場合の回帰のことです。Rでは重回帰も単回帰と同じくlm関数で計算することができます。重回帰は二元分散分析と同様に、説明変数を+または*でつないでformulaを設定します。+でつないだ場合には交互作用なし、*でつないだ場合には交互作用ありの重回帰となります。ただし、重回帰の交互作用はその意味の理解が難しいため、意味をよく考えた上で交互作用の項を追加するかどうか決める方がよいでしょう。\n\n\n\nlm関数で重回帰\n\n# 交互作用なしモデル\n# Sepal.Length = 2.2491 + 0.5955 * Sepal.Width + 0.4719 * Petal.Length が結果となる\nlm(iris$Sepal.Length ~ iris$Sepal.Width + iris$Petal.Length)\n## \n## Call:\n## lm(formula = iris$Sepal.Length ~ iris$Sepal.Width + iris$Petal.Length)\n## \n## Coefficients:\n##       (Intercept)   iris$Sepal.Width  iris$Petal.Length  \n##            2.2491             0.5955             0.4719\n\n# 交互作用ありモデル\n# Sepal.Length = 1.4044 + 0.8500 * Sepal.Width + \n# 0.7185 * Petal.Length - 0.07701 * Sepal.Width * Petal.Length\nlm(iris$Sepal.Length ~ iris$Sepal.Width * iris$Petal.Length)\n## \n## Call:\n## lm(formula = iris$Sepal.Length ~ iris$Sepal.Width * iris$Petal.Length)\n## \n## Coefficients:\n##                        (Intercept)                    iris$Sepal.Width  \n##                            1.40438                             0.84996  \n##                  iris$Petal.Length  iris$Sepal.Width:iris$Petal.Length  \n##                            0.71846                            -0.07701",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>相関と回帰</span>"
    ]
  },
  {
    "objectID": "chapter26.html#一般線形モデル",
    "href": "chapter26.html#一般線形モデル",
    "title": "26  相関と回帰",
    "section": "26.4 一般線形モデル",
    "text": "26.4 一般線形モデル\n一般線形モデルは、1つの目的変数に対して、数値や因子からなる複数の説明変数がある場合の回帰のことです。重回帰や共分散分析の拡張だと考えるとよいかと思います。Rでは一般線形モデルの計算もlm関数を用いて行います。一般線形モデルも重回帰とほぼ同じで、説明変数同士を+か*でつなぐだけです。\n一般線形モデルでは説明変数として非常にたくさんの数値や因子を登録できますが、すべての説明変数に対して交互作用ありにしてしまうと交互作用項が非常に多くなり、理解が難しくなるので、本当に必要がある部分にだけ交互作用を入れる方がよいでしょう。\n\n\n\n一般線形モデル\n\n# 一般線形モデル\n# 結果は Sepal.Length = 2.39039 + 0.43222 * Sepal.Width + 0.77563 * Petal.Length で、\n# 種がsetosaなら上記の線形式のまま、versicolorなら-0.95581、virginicaなら-1.39410を線形式に足す形となる。\nlm(iris$Sepal.Length ~ iris$Sepal.Width + iris$Petal.Length + iris$Species) |&gt; summary()\n## \n## Call:\n## lm(formula = iris$Sepal.Length ~ iris$Sepal.Width + iris$Petal.Length + \n##     iris$Species)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -0.82156 -0.20530  0.00638  0.22645  0.74999 \n## \n## Coefficients:\n##                        Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)             2.39039    0.26227   9.114 5.94e-16 ***\n## iris$Sepal.Width        0.43222    0.08139   5.310 4.03e-07 ***\n## iris$Petal.Length       0.77563    0.06425  12.073  &lt; 2e-16 ***\n## iris$Speciesversicolor -0.95581    0.21520  -4.442 1.76e-05 ***\n## iris$Speciesvirginica  -1.39410    0.28566  -4.880 2.76e-06 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.3103 on 145 degrees of freedom\n## Multiple R-squared:  0.8633, Adjusted R-squared:  0.8595 \n## F-statistic: 228.9 on 4 and 145 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n交互作用ありの一般線形モデル\n\n# 一般線形モデル（交互作用あり）：たくさんの交互作用項が出てくる\nlm(iris$Sepal.Length ~ iris$Sepal.Width * iris$Petal.Length * iris$Species) |&gt; summary()\n## \n## Call:\n## lm(formula = iris$Sepal.Length ~ iris$Sepal.Width * iris$Petal.Length * \n##     iris$Species)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -0.78535 -0.20750 -0.00579  0.19960  0.66728 \n## \n## Coefficients:\n##                                                           Estimate Std. Error\n## (Intercept)                                                -1.3686     3.9089\n## iris$Sepal.Width                                            1.7230     1.1206\n## iris$Petal.Length                                           2.8759     2.7490\n## iris$Speciesversicolor                                      3.1746     5.4972\n## iris$Speciesvirginica                                      -0.9949     5.2725\n## iris$Sepal.Width:iris$Petal.Length                         -0.7438     0.7854\n## iris$Sepal.Width:iris$Speciesversicolor                    -1.3564     1.8565\n## iris$Sepal.Width:iris$Speciesvirginica                     -0.4274     1.6585\n## iris$Petal.Length:iris$Speciesversicolor                   -2.0675     2.8951\n## iris$Petal.Length:iris$Speciesvirginica                    -1.4233     2.8165\n## iris$Sepal.Width:iris$Petal.Length:iris$Speciesversicolor   0.7161     0.8569\n## iris$Sepal.Width:iris$Petal.Length:iris$Speciesvirginica    0.5649     0.8129\n##                                                           t value Pr(&gt;|t|)\n## (Intercept)                                                -0.350    0.727\n## iris$Sepal.Width                                            1.538    0.126\n## iris$Petal.Length                                           1.046    0.297\n## iris$Speciesversicolor                                      0.577    0.565\n## iris$Speciesvirginica                                      -0.189    0.851\n## iris$Sepal.Width:iris$Petal.Length                         -0.947    0.345\n## iris$Sepal.Width:iris$Speciesversicolor                    -0.731    0.466\n## iris$Sepal.Width:iris$Speciesvirginica                     -0.258    0.797\n## iris$Petal.Length:iris$Speciesversicolor                   -0.714    0.476\n## iris$Petal.Length:iris$Speciesvirginica                    -0.505    0.614\n## iris$Sepal.Width:iris$Petal.Length:iris$Speciesversicolor   0.836    0.405\n## iris$Sepal.Width:iris$Petal.Length:iris$Speciesvirginica    0.695    0.488\n## \n## Residual standard error: 0.3024 on 138 degrees of freedom\n## Multiple R-squared:  0.8765, Adjusted R-squared:  0.8666 \n## F-statistic:    89 on 11 and 138 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>相関と回帰</span>"
    ]
  },
  {
    "objectID": "chapter26.html#一般化線形モデル",
    "href": "chapter26.html#一般化線形モデル",
    "title": "26  相関と回帰",
    "section": "26.5 一般化線形モデル",
    "text": "26.5 一般化線形モデル\nここまでは目的変数が正規分布することを仮定した回帰でしたが、目的変数が正規分布しない場合、例えばポアソン分布や二項分布するときには、分布が上下非対称になります。ですので、最小二乗法を用いた直線での回帰は適していません。\n以下に目的変数が二項分布とポアソン分布するデータの例を示します。いずれも直線で回帰してしまうと、データの特徴を捉えていないことがわかると思います。\n\n二項分布2項分布を直線で回帰\n\n\n二項分布を回帰する場合の典型的な例としては、医薬品の投与量（説明変数）に対して病気が治る確率（目的変数、回復:1と未回復:0の2値）を回帰する場合などが挙げられます。\n\nset.seed(5)\nlogistic &lt;- \\(x, sex){1 / (1 + exp(-3 * x + 150 + 10 * sex)) + rbeta(length(x), 0.5, 1.5)}\nx &lt;- 1:100 ; sex &lt;- rbinom(100, 1, 0.5)\nbinom_d &lt;- data.frame(x, y = if_else(logistic(x, sex) &gt; 0.5, 1, 0), sex = factor(sex))\nbinom_d |&gt; ggplot(aes(x = x, y = y, color = sex)) + geom_point()\n\n\n\n\n\n\n\n\n\n\n\n(binom_d |&gt; \n  ggplot(aes(x = x, y = y, color = sex)) + \n  geom_point() + geom_quantile(quantiles = 0.5)) |&gt; \n  print() |&gt; \n  suppressWarnings()\n\n\n\n\n\n\n\n\n\n\n\n\nポアソン分布ポアソン分布を直線回帰\n\n\nポアソン分布を回帰する典型的な例としては、植物の生育サイズ（説明変数）と種子の数（目的変数、正の整数のみを取る）の関係などが挙げられます。\n\nx &lt;- 1:10\ny &lt;- c(replicate(10, rpois(10, exp(x / 3 + 0.25))), replicate(10, rpois(10, exp(x / 3))))\npois_d &lt;- data.frame(x, y = as.vector(y), fertilizer = factor(rep(c(1, 0), c(100, 100))))\npois_d |&gt; ggplot(aes(x = x, y = y, color = fertilizer)) + geom_jitter(width = 0.1)\n\n\n\n\n\n\n\n\n\n\n\npois_d |&gt; \n  ggplot(aes(x = x, y = y, color = fertilizer)) + \n  geom_jitter(width = 0.1) + \n  geom_quantile(quantiles = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n直線での回帰ができない場合には、最小二乗法を用いることができないため、別の方法を用いて回帰を行います。この回帰の際に用いるのが最尤法（さいゆうほう）と呼ばれる方法で、尤度（ゆうど）というものを最大にするような傾きや切片を選択する方法です。\n尤度は尤（もっと）もらしさの指標で、傾きや切片がある数値の時に、どの程度その傾きや切片の値が尤もらしいかを評価するためのものです。最も尤度が高い、つまり最も尤もらしい傾きや切片の値（最尤推定値）を、回帰における傾きや切片に当たるもの（パラメータ）として求めます。\n\n\n\n\n\n\n尤度と最尤法\n\n\n\n\n\n尤度についてもう少し詳しく説明します。尤度の説明の例として正規分布を挙げます。以下は24章で示した正規分布の確率密度関数です。\n\\[ Norm(x, \\mu, \\sigma)=\\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\cdot \\exp \\left( \\frac{(x-\\mu)^2}{2\\sigma^2} \\right) \\]\nこの数式は間違ってはいないのですが、以下のように書く方が正しい表現です。\n\\[ Norm(x | \\mu, \\sigma)=\\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\cdot \\exp \\left( \\frac{(x-\\mu)^2}{2\\sigma^2} \\right) \\]\n変わっているところは、始めの関数のxとμの間がコンマではなく、縦線（|）になっているところです。この縦線の左は自由な値を取ることができる変数（未知の値、上の式ではx）、縦線の右はあらかじめわかっている数値（既知の値、上の式ではμとσ）を表します。ですので、上の式の意味は、平均値（μ）と標準偏差（σ）がわかっているときの、xという値が得られる確率（密度）を計算している、ということを意味しています。\nしかし、データが取れた時に、あらかじめ平均値や標準偏差がわかっていることはありません。ですので、普通はデータxが取れた時には、xから平均値μや標準偏差σを求める方に興味があるわけです。つまり、上の式では既知のパラメータ（x）と未知のパラメータ（μとσ）の関係が逆になっています。\nですので、既知と未知のパラメータを逆にしてしまえば、上の式はデータが取れた時に平均値や標準偏差が得られる確率にできるはずです。\n\\[ L(\\mu, \\sigma| x)=\\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\cdot \\exp \\left( \\frac{(x-\\mu)^2}{2\\sigma^2} \\right) \\]\nこの、xというデータが取れた時に、特定の平均値μや標準偏差σが得られる確率（\\(L(\\mu, \\sigma| x)\\)）のことを尤度と呼びます。確率密度関数との差は|の左右が逆になっているだけです。ただし、通常データは複数取れる（x1～xn）ので、μとσが得られる確率は以下のように、データの数だけ尤度を掛け算することで計算できます。\n\\[L(\\mu, \\sigma| x_{1}, x_{2}, \\cdots x_{n})=L(\\mu, \\sigma| x_{1}) \\cdot L(\\mu, \\sigma| x_{2}) \\cdots L(\\mu, \\sigma| x_{n})=\\prod_{i=1}^{n}L(\\mu, \\sigma| x_{i})\\]\n最後のΠは総乗の記号で、i=1からnまで掛け算するという意味の式です。掛け算のままでは値が非常に小さくなり、取り扱いが難しくなるので、対数変換し、対数尤度というものを取り扱うのが一般的です。対数を取ることで、データごとの対数尤度の足し算として尤度を取り扱えるようになり、計算しやすくなります。\n\\[logL(\\mu, \\sigma| x_{1}, x_{2}, \\cdots x_{n})=\\sum_{i=1}^{n}logL(\\mu, \\sigma| x_{i})\\]\nこの対数尤度を最大とするμとσ（パラメータ）を求める手法のことを最尤法と呼びます。データが正規分布しているときにはこの最尤法の計算は微分を用いて計算でき、μとσの最尤推定値はそれぞれ平均値と標準偏差になります。\n\n\n\n最尤法を用いて、目的変数の分布に従った回帰を行う手法のことを、一般化線形モデル（generalized linear model、GLM）と呼びます。一般化線形モデルでは、目的変数の分布（Rではfamilyと呼ばれる）によって異なる、リンク関数というものを用いて回帰を計算します。正規分布のリンク関数は直線（identity）で、通常の線形回帰と一致します。\n\n\n\n\n\n\nリンク関数\n\n\n\n\n\n上に示した通り、目的変数が2項分布やポアソン分布する場合には、データを直線で回帰してしまうと実際の結果を正しく反映しない回帰となってしまいます。例えば、二項分布するデータでは0か1かしか取らない結果なのに、直線はその範囲を平気で超えていきます。ポアソン分布はマイナスの値を取れないのに、直線で回帰すると直線はマイナスの値を取ってしまいます。\nこのように、目的変数が正規分布しない場合、直線で回帰すると誤った結果を導いてしまいます。このような問題を解決するためのものが、リンク関数です。リンク関数は、目的変数の変換に関わる関数で、その変換結果を直線で回帰することで目的変数を適切に表現することができる関数です。目的変数が正規分布する場合には、目的変数をそのまま直線で回帰するため、リンク関数はidentity、つまりそのままになります。\n二項分布では、オッズ比（\\(\\frac{p}{1-p}\\)、ベルヌーイ試行の成功確率pと失敗確率1-pの比、pが目的変数）の対数を以下のように線形で回帰します。\n\\[log(\\frac{p}{1-p})=ax+b\\]\n上の式のオッズ比の対数のことをロジット（logit）と呼びます。この時、pは確率ですので、0～1の値を取ります。上の式をpについて解くと、以下の式になります。\n\\[p=\\frac{1}{1+\\exp(-(ax+b))}\\]\nこのpの式をロジスティック式と呼びます。ロジスティック式はpが0～1の値を取り、xは-∞～+∞の値を取ります。この関数は個体群密度のモデル化にも用いられる関数で、二項分布する結果を回帰するのに適しています。目的変数が二項分布の場合はこのロジスティック式で回帰し、二項分布の場合のリンク関数はロジットになります。\n目的変数がポアソン分布の場合には、値の対数を以下のように線形で回帰します。\n\\[log(y)=ax+b\\]\nですので、目的変数yは以下のように指数関数で回帰することになります。\n\\[y=\\exp(ax+b)\\]\nですので、目的変数がポアソン分布する場合には指数関数で回帰し、リンク関数は対数（log）になります。\nこの他にも、目的変数の代表値と分散が一致しないカウントデータ（疑似ポアソン分布）や過分散の二項分布（疑似二項分布）などにもそれぞれ分布とリンク関数が設定されています。Rではこの目的変数の分布とリンク関数のセットのことをfamilyと呼びます。familyで指定されている目的変数の分布、Rのデフォルトのリンク関数、回帰する関数の種類を以下の表に示します。\n\n\n\n\n\n目的変数の分布\nリンク関数\n回帰する関数\n\n\n\n\n二項分布\nlogit\nロジスティック\n\n\n正規分布\nidentity\n直線\n\n\nガンマ分布\ninverse\n反比例\n\n\n逆ガウス分布\n1/mu^{2}\n(1/(ax+b))^0.5\n\n\nポアソン分布\nlog\n指数\n\n\n疑似二項分布\nlogit\nロジスティック\n\n\n疑似ポアソン分布\nlog\n指数\n\n\n\n\n\nリンク関数にはデフォルトのものではなく、自分で選択した関数を別途設定することもできます。\n\n\n\n\n26.5.1 目的変数が正規分布の場合\nRでは、一般化線形モデルの計算をglm関数で行います。glm関数の使い方はlm関数とほぼ同じで、第一引数に目的変数~説明変数の形のformulaを取ります。データフレームのデータを利用する場合には、data引数にデータフレームを指定します。また、glmでは、目的変数の分布をfamily引数に指定します。目的変数が正規分布する場合には、以下のようにfamily=\"gaussian\"と指定します。family=\"gaussian\"の場合、glmでの回帰の結果はlmでの回帰の結果と同一になります。\n\n\n\nglm関数：正規分布\n\n## 一般化線形モデル\n# 正規分布（identityをリンク関数とする）\n# lmと同じなので、結果は Sepal.Length = 6.5262 - 0.2234 * Sepal.Width となる\nglm(Sepal.Length ~ Sepal.Width, data = iris, family = \"gaussian\")\n## \n## Call:  glm(formula = Sepal.Length ~ Sepal.Width, family = \"gaussian\", \n##     data = iris)\n## \n## Coefficients:\n## (Intercept)  Sepal.Width  \n##      6.5262      -0.2234  \n## \n## Degrees of Freedom: 149 Total (i.e. Null);  148 Residual\n## Null Deviance:       102.2 \n## Residual Deviance: 100.8     AIC: 372\n\n\nglm関数の返り値をsummary関数の引数とすることで、lm関数と同様に詳細な計算結果を得ることができます。Estimateが係数であることはlm関数と同じです。\n\n\n\nglm関数：summaryで詳細を調べる\n\nglm(Sepal.Length ~ Sepal.Width, data = iris, family = \"gaussian\") |&gt; summary()\n## \n## Call:\n## glm(formula = Sepal.Length ~ Sepal.Width, family = \"gaussian\", \n##     data = iris)\n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept)   6.5262     0.4789   13.63   &lt;2e-16 ***\n## Sepal.Width  -0.2234     0.1551   -1.44    0.152    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for gaussian family taken to be 0.6807844)\n## \n##     Null deviance: 102.17  on 149  degrees of freedom\n## Residual deviance: 100.76  on 148  degrees of freedom\n## AIC: 371.99\n## \n## Number of Fisher Scoring iterations: 2\n\n\n\n\n26.5.2 目的変数が二項分布の場合\n目的変数が二項分布の場合には、glmの引数にfamily=\"binomial\"（二項分布）を指定します。familyに二項分布を指定すると、リンク関数はロジットとなり、ロジスティック式でデータを回帰することになります。ロジスティック式が表しているのは確率になるため、説明変数に応じてベルヌーイ試行の確率がどのように変化していくのかを示すような回帰を行うことになります。\n以下の例では、回帰の結果はcoefficientsで示されている通り、以下の数式となります。\n\\[ log(\\frac{p}{1-p}) = -4.34896+0.09368x \\]\n上式を変換し、ロジスティック関数にしたものが以下の式です。\n\\[ y = \\frac{1}{1+exp(-(-4.34896+0.09368x))} \\]\n\n\n\nglm関数：二項分布\n\n# 回帰するデータ\nplot(binom_d$x, binom_d$y, xlim = c(0, 100), ylim = c(0, 1))\n\n# 二項分布（logitをリンク関数とする）\nglm(y ~ x, data = binom_d, family = \"binomial\")\n## \n## Call:  glm(formula = y ~ x, family = \"binomial\", data = binom_d)\n## \n## Coefficients:\n## (Intercept)            x  \n##    -4.34896      0.09368  \n## \n## Degrees of Freedom: 99 Total (i.e. Null);  98 Residual\n## Null Deviance:       138 \n## Residual Deviance: 67.48     AIC: 71.48\n\n# 回帰の結果をプロットする\npar(new = T)\nplot(\\(x)(1/(1 + exp(-(-4.34896 + 0.09368 * x)))), xlim = c(0, 100), ylim = c(0, 1), xlab = \"\", ylab = \"\")\n\n\n\n\n\n\n\n\n\n2項分布の成功、失敗回数がわかっている時には、成功回数の列と失敗回数の列を行列で目的変数として指定することもできます。行列を目的変数として指定する場合には、formulaのチルダ（~）の左側に、cbind(成功回数, 失敗回数)の形で行列として指定します。\n\n\n\ncbindで二項分布の成功・失敗を指定\n\n# yはベルヌーイ試行の成功数、zは失敗数\nhead(dbn)\n##   x y  z\n## 1 1 0 10\n## 2 2 0 10\n## 3 3 2  8\n## 4 4 7  3\n## 5 5 3  7\n## 6 6 8  2\n\n# 成功・失敗をmatrixで指定する\nglm(cbind(y, z) ~ x, family = \"binomial\")\n## \n## Call:  glm(formula = cbind(y, z) ~ x, family = \"binomial\")\n## \n## Coefficients:\n## (Intercept)            x  \n##      -5.025        1.119  \n## \n## Degrees of Freedom: 9 Total (i.e. Null);  8 Residual\n## Null Deviance:       90.15 \n## Residual Deviance: 12.9  AIC: 26.97\n\n# 回帰をグラフで表示\ndbn |&gt; \n  ggplot(aes(x = x, y = y / 10))+\n  geom_point()+\n  geom_function(fun=\\(x){1 / (1 + exp(-(-5.025 + 1.119 * x)))})\n\n\n\n\n\n\n\n\n\n\n26.5.2.1 説明変数を増やす\nlm関数と同様に、formulaの右辺に+で説明変数を繋ぐことで、重回帰・一般線形モデルのように説明変数を増やすこともできます。\n\n\n\nglm関数：二項分布で説明変数を増やす\n\nhead(binom_d)\n##   x y sex\n## 1 1 0   0\n## 2 2 0   1\n## 3 3 1   1\n## 4 4 0   0\n## 5 5 0   0\n## 6 6 0   1\n\n# 二項分布（logitをリンク関数とする）\nglm(y ~ x + sex, data = binom_d, family = \"binomial\")\n## \n## Call:  glm(formula = y ~ x + sex, family = \"binomial\", data = binom_d)\n## \n## Coefficients:\n## (Intercept)            x         sex1  \n##    -4.20991      0.09672     -0.52864  \n## \n## Degrees of Freedom: 99 Total (i.e. Null);  97 Residual\n## Null Deviance:       138 \n## Residual Deviance: 66.79     AIC: 72.79\n\n# 回帰の結果をプロットする\nbinom_d |&gt; \n  ggplot(aes(x = x, y = y, color = sex))+\n  geom_point()+\n  geom_function(fun = \\(x){1 / (1 + exp(-(-4.20991 + 0.09672 * x)))}, color = \"blue\") +\n  geom_function(fun = \\(x){1 / (1 + exp(-(-4.20991  - 0.52864 + 0.09672 * x)))}, color = \"red\")\n\n\n\n\n\n\n\n\n\n上の例では、計算結果はcoefficientsから、以下の式となります。sexは0か1ですので、0の時は-0.52864×sexの部分が0に、1の時は―0.52864となります。\n\\[ y = \\frac{1}{1+exp(-(-4.20991 + 0.09672x - 0.52864 \\cdot sex))} \\]\n\n\n\n26.5.3 目的変数がポアソン分布の場合\n目的変数がポアソン分布する場合には、glm関数のfamily引数を、family = \"poisson\"の形で指定します。\n下の例では、coefficientsの計算結果から、回帰の式は以下となります。\n\\[ log(y) = 0.1510 + 0.3331x \\]\n指数関数に変換すると、以下の式となります。\n\\[ y = exp(0.1510 + 0.3331x) \\]\n\n\n\nglm関数：ポアソン分布\n\nhead(pois_d)\n##   x y fertilizer\n## 1 1 3          1\n## 2 2 1          1\n## 3 3 2          1\n## 4 4 2          1\n## 5 5 7          1\n## 6 6 9          1\n\nglm(y ~ x, data = pois_d, family = \"poisson\")\n## \n## Call:  glm(formula = y ~ x, family = \"poisson\", data = pois_d)\n## \n## Coefficients:\n## (Intercept)            x  \n##      0.1510       0.3331  \n## \n## Degrees of Freedom: 199 Total (i.e. Null);  198 Residual\n## Null Deviance:       1847 \n## Residual Deviance: 259.6     AIC: 1003\n\nplot(pois_d$x, pois_d$y, xlim = c(0, 10), ylim = c(0, 50))\npar(new = T)\nplot(\\(x){exp(0.1510 + 0.3331 * x)}, xlim = c(0, 10), ylim = c(0, 50), xlab = \"\", ylab = \"\")\n\n\n\n\n\n\n\n\n\n目的変数がポアソン分布の場合にも、説明変数を+でつなぐことで、重回帰のように説明変数を増やすことができます。\n\n\n\nglm関数：ポアソン分布で説明変数を増やす\n\nglm(y ~ x + fertilizer, data = pois_d, family = \"poisson\")\n## \n## Call:  glm(formula = y ~ x + fertilizer, family = \"poisson\", data = pois_d)\n## \n## Coefficients:\n## (Intercept)            x  fertilizer1  \n##     0.03425      0.33310      0.22131  \n## \n## Degrees of Freedom: 199 Total (i.e. Null);  197 Residual\n## Null Deviance:       1847 \n## Residual Deviance: 232.7     AIC: 977.8\n\npois_d |&gt; \n  ggplot(aes(x = x, y = y, color = fertilizer))+\n  geom_point()+\n  geom_function(fun = \\(x){exp(0.03425 + 0.33310 * x)}, color = \"red\")+\n  geom_function(fun = \\(x){exp(0.03425 + 0.22131 + 0.33310 * x)}, color = \"blue\")\n\n\n\n\n\n\n\n\n\n上の例では、計算結果はcoefficientsから、以下の式となります。fertilizerは0か1ですので、0の時は0.22131×fertilizerの部分が0に、1の時は―0.22131となります。\n\\[ y = exp(0.03425 + 0.33310x + 0.22131 \\cdot fertilizer)\\]",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>相関と回帰</span>"
    ]
  },
  {
    "objectID": "chapter26.html#線形混合モデル",
    "href": "chapter26.html#線形混合モデル",
    "title": "26  相関と回帰",
    "section": "26.6 線形混合モデル",
    "text": "26.6 線形混合モデル\nデータに繰り返しの測定がある場合、例えば、実験で同じ個体を数日間おきに調べ、データを取るような場合には、個体間のばらつきが大きくて正しい線形回帰を得るのが難しい場合があります。また、線形回帰ではデータの各点は独立の（関連性のない）事象として扱われますが、繰り返しの測定がある場合、例えば同じ個体から繰り返し得られたデータは明確に独立ではありません。\nこのように、繰り返しがある場合、個体間に正規分布に従うばらつきがあると仮定して回帰を行う方法が、線形混合モデル（Linear Mixed Model（LMM）またはMixed Model for Repeated Measures（MMRM））です。線形混合モデルは、切片のみにばらつきがある場合（ランダム切片、下図1参照）と、切片にも傾きにもばらつきがある場合（ランダム傾き）の2つに対応し、それぞれ直線で回帰を計算します。線形混合モデルを用いることで、ランダム切片やランダム傾き（合わせてランダム効果）を回帰の結果（固定効果）と分けて評価することで、回帰結果をうまく評価することができます。\n\n\n\n図1：ランダム切片とランダム傾き\n\n\nRで線形混合モデルを計算する場合には、nlmeパッケージ (J. Pinheiro, Bates, and R Core Team 2023; J. C. Pinheiro and Bates 2000)、lme4パッケージ (Bates et al. 2015)、lmerTestパッケージ (Kuznetsova, Brockhoff, and Christensen 2017)のいずれかを使うのが一般的です。lme4はnlmeの改良版、lmerTestはlme4に分散分析の計算方法を追加したパッケージです。どれを用いても大きな差はありませんが、lme4とlmerTestが使われているのをよく見る印象があります。\n以下に線形混合モデルで解析するデータとして、lme4パッケージに登録されているsleepstudyを用います。このsleepstudyは睡眠をとっていない被験者の反応時間を毎日取得したデータです。睡眠をとらない期間が延びると、反応時間が延びていく様子が記録されていますが、被験者ごとに傾きも切片も異なる、ランダム切片＋ランダム傾きを持つように見えるデータとなっています。\n\n\n\nsleepstudyのデータ\n\n# 線形混合モデルのデータ\npacman::p_load(lmerTest)\ndata(\"sleepstudy\", package = \"lme4\")\nhead(sleepstudy)\n##   Reaction Days Subject\n## 1 249.5600    0     308\n## 2 258.7047    1     308\n## 3 250.8006    2     308\n## 4 321.4398    3     308\n## 5 356.8519    4     308\n## 6 414.6901    5     308\n\n# DaysとReactionの関係を調べる\nggplot(sleepstudy, aes(x = Days, y = Reaction, color = Subject, alpha = 0.5)) +\n  geom_point(size = 2) + \n  theme(legend.position = \"none\") +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n26.6.1 ランダム切片モデル\nRで線形混合モデルの計算を行う場合には、lmerTestパッケージ（もしくはlme4パッケージ）のlmer関数を用います。lmer関数の使い方はlm関数とほぼ同じですが、ランダム切片とランダム傾きの項をformulaで表す必要があります。formulaは目的変数+説明変数+(ランダム傾き|ランダム切片)という形で設定し、縦線（|）の左にランダム傾き、右にランダム切片の項を入力します。ランダム切片のみの場合には目的変数+説明変数+(1|ランダム切片)という形で、ランダム傾きの部分に1を入れます。計算結果はFixed effects（固定効果）の部分で示されており、以下の式となります。Random effectsで示されている部分がランダム切片（ランダム効果）で、Subject間の切片の分散が示されています。\n\\[Reaction = 251.4051 + 10.4673 \\cdot Days\\]\n\n\n\nlmer関数でランダム切片モデルを計算\n\nlmer_sleepstudy &lt;- lmer(Reaction ~ Days + (1 | Subject), data = sleepstudy)\nlmer_sleepstudy %&gt;% summary()\n## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: Reaction ~ Days + (1 | Subject)\n##    Data: sleepstudy\n## \n## REML criterion at convergence: 1786.5\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -3.2257 -0.5529  0.0109  0.5188  4.2506 \n## \n## Random effects:\n##  Groups   Name        Variance Std.Dev.\n##  Subject  (Intercept) 1378.2   37.12   \n##  Residual              960.5   30.99   \n## Number of obs: 180, groups:  Subject, 18\n## \n## Fixed effects:\n##             Estimate Std. Error       df t value Pr(&gt;|t|)    \n## (Intercept) 251.4051     9.7467  22.8102   25.79   &lt;2e-16 ***\n## Days         10.4673     0.8042 161.0000   13.02   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##      (Intr)\n## Days -0.371\n\n\n\n\n26.6.2 ランダム傾きモデル\nランダム傾きの項には、傾きを生じる軸（x軸）の値を入力します。上のsleepstudyの場合では、Daysの方向にランダムな傾きが生じるため、ランダム傾きの項にDaysを指定して計算します。演算結果は以下の式となります。ほぼランダム切片モデルと同じになっています。\n\\[Reaction = 251.405 + 10.467 \\cdot Days\\]\n\n\n\nlmer関数でランダム傾きモデルを計算\n\nlmer(Reaction ~ Days + (Days | Subject), sleepstudy) %&gt;% summary()\n## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: Reaction ~ Days + (Days | Subject)\n##    Data: sleepstudy\n## \n## REML criterion at convergence: 1743.6\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -3.9536 -0.4634  0.0231  0.4634  5.1793 \n## \n## Random effects:\n##  Groups   Name        Variance Std.Dev. Corr\n##  Subject  (Intercept) 612.10   24.741       \n##           Days         35.07    5.922   0.07\n##  Residual             654.94   25.592       \n## Number of obs: 180, groups:  Subject, 18\n## \n## Fixed effects:\n##             Estimate Std. Error      df t value Pr(&gt;|t|)    \n## (Intercept)  251.405      6.825  17.000  36.838  &lt; 2e-16 ***\n## Days          10.467      1.546  17.000   6.771 3.26e-06 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##      (Intr)\n## Days -0.138\n\n\n\n\n\n\n\n\nlmer関数の返り値の取り扱い方\n\n\n\n\n\nlmerTest::lmer関数の返り値はS4オブジェクトなので、@や$を用いて計算結果にアクセスすることができます。また、関数を用いて計算結果にアクセスすることもできます。\n\nresult_lmer &lt;- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)\nresult_lmer@sigma # 残差の標準偏差\n## [1] 25.5918\n\nanova(result_lmer, type = \"I\") # type Iの分散分析結果\n## Type I Analysis of Variance Table with Satterthwaite's method\n##      Sum Sq Mean Sq NumDF DenDF F value    Pr(&gt;F)    \n## Days  30031   30031     1    17  45.853 3.264e-06 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncoef(result_lmer) # 個々の被験者の傾きと切片\n## $Subject\n##     (Intercept)       Days\n## 308    253.6637 19.6662617\n## 309    211.0064  1.8476053\n## 310    212.4447  5.0184295\n## 330    275.0957  5.6529356\n## 331    273.6654  7.3973743\n## 332    260.4447 10.1951090\n## 333    268.2456 10.2436499\n## 334    244.1725 11.5418676\n## 335    251.0714 -0.2848792\n## 337    286.2956 19.0955511\n## 349    226.1949 11.6407181\n## 350    238.3351 17.0815038\n## 351    255.9830  7.4520239\n## 352    272.2688 14.0032871\n## 369    254.6806 11.3395008\n## 370    225.7921 15.2897709\n## 371    252.2122  9.4791297\n## 372    263.7197 11.7513080\n## \n## attr(,\"class\")\n## [1] \"coef.mer\"",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>相関と回帰</span>"
    ]
  },
  {
    "objectID": "chapter26.html#一般化線形混合モデル",
    "href": "chapter26.html#一般化線形混合モデル",
    "title": "26  相関と回帰",
    "section": "26.7 一般化線形混合モデル",
    "text": "26.7 一般化線形混合モデル\n線形混合モデルを目的変数が正規分布以外の場合に拡張したものが、一般化線形混合モデル（Generalized Linear Mixed Model、GLMM）です。Rでは、GLMMをlme4パッケージのglmer関数で計算することができます。glmer関数はlmer関数と同じくlme4パッケージの関数ですので、glmer関数の使い方は基本的にlmer関数と同じです。\nGLMMの例として、lme4パッケージに含まれるcbpp（牛肺疫にかかった牛のデータ）での計算例を以下に示します。\n\n\n\ncbppの内容\n\n# cbpp（contagious bovine pleuropneumonia、牛肺疫）に関するデータ\ndata(cbpp, package = \"lme4\") \n\n# herdは牛の群、incidenceは牛肺疫への罹患数、sizeは群内の牛の数、periodは観察時期\nhead(cbpp) \n##   herd incidence size period\n## 1    1         2   14      1\n## 2    1         3   12      2\n## 3    1         4    9      3\n## 4    1         0    5      4\n## 5    2         3   22      1\n## 6    2         1   18      2\n\ncbpp |&gt; \n  ggplot(aes(x = period |&gt; as.character() |&gt; as.numeric(), y = incidence / size, color = herd)) +\n  geom_point() +\n  geom_line()\n\n\n\n\n\n\n\n\n\nglmerの引数の指定は、glmとlmerを合わせたような形になります。ですので、family引数に目的変数の分布を指定し、ランダム切片、ランダム傾きは、formulaに(ランダム傾き|ランダム切片)の形で指定します。演算結果はFixed effectsに示された通り、以下の式となります。\n\\[ incidance = \\frac{1}{1 + exp(-(-0.9323 - 0.5592 \\cdot period))}\\]\n\n\n\nglmer関数で一般化線形混合モデルを計算\n\ncbind(cbpp$incidence, cbpp$size - cbpp$incidence) |&gt; head() # 左が牛肺疫に罹患した牛、右は罹患していない牛\n##      [,1] [,2]\n## [1,]    2   12\n## [2,]    3    9\n## [3,]    4    5\n## [4,]    0    5\n## [5,]    3   19\n## [6,]    1   17\n\n# 一般化線形混合モデル（ランダム切片）\nglmer(cbind(incidence, size - incidence) ~ period |&gt; as.numeric() + (1 | herd), family = \"binomial\", data = cbpp)\n## Generalized linear mixed model fit by maximum likelihood (Laplace\n##   Approximation) [glmerMod]\n##  Family: binomial  ( logit )\n## Formula: cbind(incidence, size - incidence) ~ as.numeric(period) + (1 |  \n##     herd)\n##    Data: cbpp\n##      AIC      BIC   logLik deviance df.resid \n## 192.5699 198.6459 -93.2849 186.5699       53 \n## Random effects:\n##  Groups Name        Std.Dev.\n##  herd   (Intercept) 0.6635  \n## Number of obs: 56, groups:  herd, 15\n## Fixed Effects:\n##        (Intercept)  as.numeric(period)  \n##            -0.9323             -0.5592\n\n\nlme4パッケージの他に、RではGLMMの計算に関わるパッケージとして、glmm (Knudson 2022)やMCMCglmm (Hadfield 2010)などがあります。一般化線形モデル・一般化線形混合モデルについては、やや古典の教科書となってきていますが、データ解析のための統計モデリング入門を読まれるのが良いでしょう。",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>相関と回帰</span>"
    ]
  },
  {
    "objectID": "chapter26.html#ベイズモデル",
    "href": "chapter26.html#ベイズモデル",
    "title": "26  相関と回帰",
    "section": "26.8 ベイズモデル",
    "text": "26.8 ベイズモデル\nGLMMよりも更に複雑な回帰を行いたい場合には、ベイズ統計モデリングというものを用いることになります。ベイズ統計とは、ベイズの法則を用いた統計手法で、複雑な回帰や時系列解析、地理空間情報の解析等に用いられている手法です。\n\n\n\n\n\n\nベイズの定理\n\n\n\n\n\nベイズの定理は条件付き確率に関する法則で、以下の式で表されるものです。\n\\[p(A|B)=\\frac{p(A \\cap B)}{p(B)}\\]\n上式について、下のベン図（venn plot）を利用して考えることにします。全体で50、Aに20、Bに20、AとBの重なっている部分（これが\\(A \\cap B\\)、AかつB）が15とすると、\\(p(A|B)\\)、つまりBの条件のもとでAである確率は、Bである確率\\(p(B)=20/50\\)、AかつBである確率\\(p(A \\cap B)=15/50\\)から、以下の式で求まります。\n\\[p(A|B)=\\frac{p(A \\cap B)}{p(B)}=\\frac{15}{50}/\\frac{20}{50}=15/20\\]\n\n\n\n\n\n\n\n\n\nベイズの定理は、AとBを入れ替えても当然成り立ちます。\n\\[p(B|A)=\\frac{p(A \\cap B)}{p(A)}\\]\n上式の\\(p(A|B)\\)と\\(p(B|A)\\)では、\\(p(A \\cap B)\\)の部分が共通しています。この\\(p(A \\cap B)\\)で両方の式を解くと、\n\\[p(A \\cap B) = p(A|B) \\cdot p(B) = p(B|A) \\cdot p(A)\\]\nとなります。\\(p(A \\cap B)\\)は無視して、この式を\\(p(A|B)\\)について解くと、\n\\[p(A|B) = \\frac{p(B|A) \\cdot p(A)}{p(B)}\\]\nという形に変形することができます。ベイズ統計で用いられるのはこちらの式で、この式もベイズの定理と呼ばれます。分母の\\(p(B)\\)は一旦無視すると、\n\\[p(A|B) \\propto p(B|A) \\cdot p(A)\\]\nという形に変形できます。この式を見ると、\\(p(A)\\)は既知のAの確率、\\(p(B|A)\\)はAとBが入れ替わっている、つまり尤度で、尤度と既知の確率の掛け算に条件付き確率\\(p(A|B)\\)が比例する、という式になっています。この式のうち、\\(p(A)\\)を事前分布、\\(p(B|A)\\)をデータから得られる尤度、\\(p(A|B)\\)を事後分布とします。この式は既知の事前分布とデータから計算できる尤度が分かれば、データが得られた後に更新された事後分布がわかるという、データが取れたときの確率の更新の式として用いられています。\nただし、このベイズの定理を用いて確率を数理的に計算するのは難しいため、数理的に計算ができる事前分布である共役事前分布というものを用いたり、乱数計算（Malkov Chain Monte Carlo法：MCMC）を用いて計算するのが一般的です。\n\n\n\n非常に複雑な回帰を行うときや、時系列・空間地理情報の統計において状態空間モデルというものを利用する場合以外ではベイズモデルを使用することはあまりないと思いますが、ベイズモデルを使って簡単な線形回帰を行うこともできます。\nとりあえずベイズ統計を試してみたいのであれば、brmsパッケージ (Bürkner 2017, 2018, 2021)を利用するのが良いでしょう。brms::brm関数を用いると、glmなどと同じように関数を設定し、回帰を行うことができます。\nベイズ統計では、パラメータ（傾きや切片）は事後分布として、幅をもって推定されます。この事後分布の最頻値をMAP（maximum a posteriori）推定値と呼び、95%区間などの区間推定値をベイズ信用区間と呼びます。また、brmではprior引数に事前分布を設定する必要があります。事前分布の設定がおかしいと計算できない場合もありますので、データを見て慎重に事前分布を定める必要があります。\n以下の計算の例では、Regression CoefficientsのEstimateが各パラメータのMAP推定値、95% CIがベイズ信用区間となります。\n\n# ベイズモデルでの回帰\npacman::p_load(brms)\nfit1 &lt;- brm(rating ~ period + carry + cs(treat),\n            data = inhaler, family = sratio(\"logit\"),\n            prior = set_prior(\"normal(0,5)\"), chains = 2)\n## Compiling Stan program...\n## Start sampling\n## \n## SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\n## Chain 1: \n## Chain 1: Gradient evaluation took 0.000439 seconds\n## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 4.39 seconds.\n## Chain 1: Adjust your expectations accordingly!\n## Chain 1: \n## Chain 1: \n## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 1: \n## Chain 1:  Elapsed Time: 3.465 seconds (Warm-up)\n## Chain 1:                3.08 seconds (Sampling)\n## Chain 1:                6.545 seconds (Total)\n## Chain 1: \n## \n## SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\n## Chain 2: \n## Chain 2: Gradient evaluation took 0.000285 seconds\n## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 2.85 seconds.\n## Chain 2: Adjust your expectations accordingly!\n## Chain 2: \n## Chain 2: \n## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\n## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\n## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\n## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\n## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\n## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\n## Chain 2: \n## Chain 2:  Elapsed Time: 3.448 seconds (Warm-up)\n## Chain 2:                3.115 seconds (Sampling)\n## Chain 2:                6.563 seconds (Total)\n## Chain 2:\nsummary(fit1)\n##  Family: sratio \n##   Links: mu = logit; disc = identity \n## Formula: rating ~ period + carry + cs(treat) \n##    Data: inhaler (Number of observations: 572) \n##   Draws: 2 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 2000\n## \n## Regression Coefficients:\n##              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept[1]     0.55      0.09     0.37     0.74 1.00     2923     1661\n## Intercept[2]     2.38      0.30     1.83     2.98 1.01     1631     1235\n## Intercept[3]     0.48      0.58    -0.69     1.60 1.00     1687     1330\n## period           0.22      0.17    -0.09     0.54 1.00     2571     1548\n## carry           -0.22      0.17    -0.55     0.12 1.00     1476     1225\n## treat[1]        -0.78      0.24    -1.24    -0.30 1.00     1703     1291\n## treat[2]        -1.05      0.61    -2.31     0.07 1.00     1785     1381\n## treat[3]         1.16      1.18    -1.17     3.56 1.00     1684     1522\n## \n## Further Distributional Parameters:\n##      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## disc     1.00      0.00     1.00     1.00   NA       NA       NA\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\n\n# 計算結果をグラフとして表示（ヒストグラムがパラメータの事後分布）\nplot(fit1, ask = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbrm関数はStan (Team 2023)という乱数計算プログラムに依存しています。さらに複雑なベイズ統計を用いる場合には、rstan (Stan Development Team 2023)やCmdStanRといったパッケージを利用し、Stanの言語で統計モデルを直接記述し、計算する必要があります。興味がある方には教科書（データ解析のための統計モデリング入門、RとStanではじめる ベイズ統計モデリングによるデータ分析入門やStanとRでベイズ統計モデリング）を読むことをおススメします。",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>相関と回帰</span>"
    ]
  },
  {
    "objectID": "chapter26.html#ガウス過程回帰",
    "href": "chapter26.html#ガウス過程回帰",
    "title": "26  相関と回帰",
    "section": "26.9 ガウス過程回帰",
    "text": "26.9 ガウス過程回帰\nガウス過程回帰はベイズの法則を用いて、説明変数xと目的変数yの非線形な関係を回帰する方法です。ベイズ推定する回帰の方法ですので、結果は幅を持った形で推定されます。この手法は回帰ではありますが、上記のようなパラメータを求めて数式が得られるような手法ではなく、主に予測的に用いる方法です。predict関数を用いて、ある説明変数に対する目的変数の値の予測を行う形で用います。\nRでは、kernlabパッケージ(Karatzoglou, Smola, and Hornik 2023; Karatzoglou et al. 2004)のgausspr関数を用いて、ガウス過程回帰を計算できます。gausspr関数では説明変数、目的変数に当たる変数をそれぞれx、y引数に設定して計算します。計算結果はgaussprクラスのオブジェクトで、回帰線上の点の位置や標準偏差を求める場合には、predict関数を用いることになります。\n\n\n\nガウス過程回帰\n\npacman::p_load(kernlab)\nx &lt;- seq(-20, 20, 0.1)\nd1 &lt;- data.frame(x = x, y = sin(x) / x + rnorm(401, sd = 0.03))\nplot(d1) # 回帰するデータ\n\n\n\n\n\n\n\n\n\n# これがガウス過程回帰の計算\nfit &lt;- gausspr(x = d1$x, y = d1$y, variance.model = T)\n## Using automatic sigma estimation (sigest) for RBF or laplace kernel\n\n# 回帰の結果を見てもよくわからない\nfit\n## Gaussian Processes object of class \"gausspr\" \n## Problem type: regression \n## \n## Gaussian Radial Basis kernel function. \n##  Hyperparameter : sigma =  15.3468004083976 \n## \n## Number of training instances learned : 400 \n## Train error : 0.015701622\n\n# xに対する代表値・SDを予測する\nd &lt;-data.frame(x, pred = predict(fit, x))\nd$sd &lt;- predict(fit, x, type = \"sdeviation\") \n\n# 結果をプロット\nggplot()+\n  geom_point(data = d1, aes(x = x, y = y, color = 1), size = 1) +\n  geom_ribbon(data = d, aes(x = x, ymax = pred + sd, ymin = pred - sd, color = 2, fill = 2), alpha = 0.5)+\n  geom_line(data = d, aes(x = x, y = pred, color = 2, alpha = 0.5), linewidth = 1)\n## Warning: Removed 1 row containing missing values or values outside the scale range\n## (`geom_point()`).",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>相関と回帰</span>"
    ]
  },
  {
    "objectID": "chapter26.html#説明変数がたくさんある場合の回帰",
    "href": "chapter26.html#説明変数がたくさんある場合の回帰",
    "title": "26  相関と回帰",
    "section": "26.10 説明変数がたくさんある場合の回帰",
    "text": "26.10 説明変数がたくさんある場合の回帰\n一つの目的変数に対して説明変数が数多く存在する場合には、回帰を行う際に問題が生じることがあります。主に注意が必要となるものは、過学習と多重共線性の2つです。この2つの問題に対応するため、数多く存在する説明変数から、特に目的変数への影響が大きく、意味がありそうなものを選択する手法がいくつか存在します。以下に、この説明変数の選択（モデル選択）を行う手法をいくつか紹介します。\n\n\n\n\n\n\n説明変数の数と過学習\n\n\n\n\n\n一般線形モデル（重回帰、分散分析）、一般化線形モデル、線形混合モデルのいずれにおいても、説明変数はデータのある限り、いくらでも追加することができます。しかし、説明変数をデータの数と同じだけ設定すると、決定係数は1、つまり、必ずすべての点を通る線となります。例えば、下図のようにExcelで6次の多項式回帰（説明変数が6つに増えている）を行えば、グネグネした曲線ですべての点を通る線を引けることがわかるでしょう。\n\n\n\n図：Excelで6次の多項式回帰で線を引く\n\n\nしかし、データの特徴を捉えるという意味では、このグネグネした曲線はあまり役に立ちません。例えば、上の多項式近似ではx=1とx=2の間にピークが一つありますが、このピークが現実的に起こりうるかというと、そういうことはなさそうです。したがって、xの値からyの値を予測する場合、多項式近似の曲線より、すべての点を通らない直線の方が、回帰としては意味がありそうです。\nこのように、説明変数が多くなると、回帰はデータを示す点を通りやすくなりますが、予測性は失われていきます。このような回帰の特徴のことを過学習と呼びます。この過学習を避けるために、説明変数の数はできるだけ多くし過ぎず、かつ必要な説明変数を十分に含めた回帰を行うことが望ましいとされています。\n\n\n\n\n\n\n\n\n\n説明変数間の相関と多重共線性\n\n\n\n\n\n説明変数が多くなると、説明変数の間に相関が生じることがあります。説明変数間に相関があると、説明変数の傾きがうまく求まらなくなる問題、多重共線性の問題、というものが生じます。\n多重共線性について直感的に捉えるには、目的変数yの説明変数x1とx2に直線的な関係がある場合（相関係数が1の場合）を考えてみると良いでしょう。\n目的変数yはx1とx2により、直線的な関係で示すことができるとき、以下のような式の関係で表すことができます。\n\\[y = ax_{1} + bx_{2}\\]\naとbは係数（傾き）です。x1とx2が独立、つまりx1とx2に相関がなければ、y、x1、x2の数値の組が2つあれば、aとbを連立方程式で求めることができます。\n一方、x1とx2に直線的な関係がある場合には、x1とx2の関係は以下の式で表すことができます。\n\\[x_{1} = cx_{2}\\]\ncは係数です。この時、aとbを求めることを考えて式を変形すると、\n\\[ y= ax_{1} + bx_{2} = ax_{1} + bcx_{1} = (a+bc)x_{1}\\] \\[ y= ax_{1} + bx_{2} = acx_{2} + bx_{2} = (ac+b)x_{2}\\]\nとなります。この式においてxやyの値が分かれば、a+bcやac+bの値を求めることができます。しかし、この値からわかるのはaとbの関係だけで、aとbを一意に決める、つまりa=◯、b=●といった解を求めることはできません。\nこの例では説明変数間の関係を非常に単純化していますが、説明変数間に相関があると傾きが求まらなくなる、ということはイメージできるかと思います。多重共線性は正確には統計における行列計算に問題が生じることで計算結果が不安定になることを指します。\n多重共線性を避けるためにも説明変数の数を多くしすぎず、互いに相関の無い説明変数だけを選ぶことは重要となります。",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>相関と回帰</span>"
    ]
  },
  {
    "objectID": "chapter26.html#aicによるモデル選択",
    "href": "chapter26.html#aicによるモデル選択",
    "title": "26  相関と回帰",
    "section": "26.11 AICによるモデル選択",
    "text": "26.11 AICによるモデル選択\n「目的変数を説明するのに必要十分な説明変数」を適切に選ぶことが、説明変数が多い回帰では重要となります。例えば、学生の数学の成績を目的変数として回帰を行うときに、くじ引きで決めた学生の座席の位置を説明変数としても普通は何の意味も無いはずです。したがって、座席の位置は説明変数に入れない方がいいということは直感的にわかるかと思います。\nとは言っても、説明変数の組み合わせは説明変数の数が増えると増大していきますし、実際に目的変数に影響を与えうるのかよくわからない説明変数も増えていきます。\n説明変数の組み合わせのことを、回帰の「モデル」と呼びます。説明変数の組み合わせ、つまり数多くあるモデルから、適切なモデルを選び出すことを、モデル選択と呼びます。モデル選択の手法には様々なものがあります。最もよく知られているモデル選択の方法は、AIC（赤池情報量基準、Akaike’s Information Criterion）によるモデル選択です。\nAICは、最尤推定の際に用いる尤度（likelyhood）に、説明変数の数をペナルティとして与えた数値です。AICは以下の計算式で求めることができます。\n\\[ AIC = -\\ln(Likelyhood) + 2 \\cdot K \\]\n上式で、\\(\\ln(Likelyhood)\\)は対数尤度、Kは説明変数の数を示します。AICによるモデル選択では、AICが小さいモデルほど、目的変数をうまく説明できているとして、AICを最小にするモデルを選択します。説明変数の数の2倍を足し算していることで、説明変数がたくさん含まれるモデルにはAICが大きくなるペナルティが付く、つまり選ばれにくくなります。\n一般化線形モデルを計算するglm関数を用いると、AICの計算結果を得ることができます。例えば、以下の例ではirisのSepal.Lengthを回帰する7つのモデル、説明変数の組み合わせ、のAICを計算しています。AICの結果から、最後のモデル、3つ説明変数があるモデルでAICが最小となる、つまりこの3つ説明変数があるモデルを選択するということになります。\n\n\n\nglm関数でAICを求める\n\nc(\n  glm(Sepal.Length ~ Sepal.Width, data = iris, family = \"gaussian\") |&gt; _$aic,\n  glm(Sepal.Length ~ Petal.Length, data = iris, family = \"gaussian\") |&gt; _$aic,\n  glm(Sepal.Length ~ Petal.Width, data = iris, family = \"gaussian\") |&gt; _$aic,\n  glm(Sepal.Length ~ Sepal.Width + Petal.Length, data = iris, family = \"gaussian\") |&gt; _$aic,\n  glm(Sepal.Length ~ Petal.Length + Petal.Width, data = iris, family = \"gaussian\") |&gt; _$aic,\n  glm(Sepal.Length ~ Sepal.Width + Petal.Width, data = iris, family = \"gaussian\") |&gt; _$aic,\n  glm(Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width, data = iris, family = \"gaussian\") |&gt; _$aic\n)\n## [1] 371.99167 160.04042 208.22145 101.02550 158.04682 191.82071  84.64272\n\n\n説明変数が3つぐらいなら\\(_{3}C_{1} +_{3}C_{2}+_{3}C_{3}\\)、つまり7通りのモデルについてAICを調べればモデル選択を行うことができますが、例えば説明変数が20個あれば、1048575通りと膨大なモデルを比較する必要があります。モデルに交互作用を加えると、更に多くの比較が必要となります。\nこのような煩雑なAICの計算のために、RにはAICによるモデル選択を自動的に行ってくれる関数である、step関数が備わっています。lmやglmに説明変数をすべて含むformula（フルモデル）を設定し、その返り値をstep関数の引数とすることで、各モデルのAICを自動的に比較し、AIC最小モデルを選択してくれます。\n\n\n\nstep関数によるAIC最小モデルの選択\n\n# 回帰の返り値をlm_irisに代入\nlm_iris &lt;- \n  lm(iris$Sepal.Length ~ \n       iris$Sepal.Width + \n       iris$Petal.Length + \n       iris$Petal.Width + \n       iris$Species)\n\n# 下の例ではフルモデル（説明変数をすべて含むモデル）が選択されている\n# trace = 1とすると、AIC選択の過程が表示される\nstep(lm_iris, trace = 0) \n## \n## Call:\n## lm(formula = iris$Sepal.Length ~ iris$Sepal.Width + iris$Petal.Length + \n##     iris$Petal.Width + iris$Species)\n## \n## Coefficients:\n##            (Intercept)        iris$Sepal.Width       iris$Petal.Length  \n##                 2.1713                  0.4959                  0.8292  \n##       iris$Petal.Width  iris$Speciesversicolor   iris$Speciesvirginica  \n##                -0.3152                 -0.7236                 -1.0235",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>相関と回帰</span>"
    ]
  },
  {
    "objectID": "chapter26.html#スパース回帰",
    "href": "chapter26.html#スパース回帰",
    "title": "26  相関と回帰",
    "section": "26.12 スパース回帰",
    "text": "26.12 スパース回帰\nAICによるモデル選択はわかりやすく単純ですが、説明変数が多くなると、上記のようにどうしても繰り返し計算回数が多くなり、計算コストがかかるようになります。説明変数が10個ぐらいならまだ何とかなりますが、現代のデータでは説明変数の数が非常に多い場合もあります。あまりに説明変数が多いと、AICによるモデル選択ではモデルを最適化するのに時間がかかってしまいます。\nこのような場合に、ある程度自動的にモデル選択を行うような回帰のことをスパース回帰と呼びます。スパース回帰は、二乗誤差を計算する際に、正則化項というものを加えることで、各説明変数の傾きを調整する回帰の方法です1。正則化項の入れ方によって、スパース回帰はリッジ回帰、ラッソ回帰と、エラスティックネットと呼ばれる手法の3つに分かれます。\nRでスパース回帰を行う場合には、glmnetパッケージ (Friedman, Tibshirani, and Hastie 2010; Simon et al. 2011; Tay, Narasimhan, and Hastie 2023)を用います。\n\n\n\nライブラリの読み込み\n\n## スパース回帰のライブラリ（mlbenchはデータを取得するために読み込み）\npacman::p_load(glmnet, mlbench)\n\n\nBostonHousingは、1970年国勢調査（センサス）におけるボストンの各地域の住宅価格と、その地域の犯罪率、非小売業の面積の割合、築年数の古い建物の割合、高速道路までのアクセス、税金等を表にしたものです。重回帰の例として、住宅価格をその他のデータで説明する、つまり住宅価格を目的変数、その他のデータを説明変数として用いられることの多いデータです。\nこのBousonHousingを用いて、AICによるモデル選択とスパース回帰を比較していきます。\n\n\n\nBostonHousingのデータ\n\ndata(\"BostonHousing\")\nhead(BostonHousing) # データにmlbenchパッケージのBostonHousingを用いる\n##      crim zn indus chas   nox    rm  age    dis rad tax ptratio      b lstat\n## 1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98\n## 2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14\n## 3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03\n## 4 0.03237  0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94\n## 5 0.06905  0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33\n## 6 0.02985  0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21\n##   medv\n## 1 24.0\n## 2 21.6\n## 3 34.7\n## 4 33.4\n## 5 36.2\n## 6 28.7\n\n# 前処理\ntempBoston &lt;- BostonHousing\ntempBoston$chas &lt;- as.numeric(tempBoston$chas)\n\n\n\n26.12.1 データの正規化\n説明変数である地域の犯罪率、非小売業の面積の割合、築年数の古い建物の割合、高速道路までのアクセス、税金等は単位も値もまちまちで、データによって1000倍以上も値が異なります。このような大きく値が異なる説明変数を用いて回帰を行うと、傾き（係数）の単位が大きく異なることとなり、どの説明変数が目的変数に影響を与えているのか、分かりにくくなります。\nこのように、説明変数の桁や平均値等が大きく異なる場合には、まずデータを正規化（normalization）します。正規化とは、データの平均値が0、標準偏差が1となるように、データを変換することを指します。このようなデータの変換を行うことで、説明変数間の桁や平均値を統一し、傾きの意味を理解しやすくすることができます。上記の重回帰や一般化線形モデルなどでも同様に、データをあらかじめ正規化しておくことは重要となります。\nRでデータの正規化を行う場合には、scale関数を用います。scale関数はベクターもしくはデータフレームを引数に取り、ベクターの場合はそのベクターの平均と標準偏差を、データフレームの場合には列ごとの平均と標準偏差をそれぞれ0、1に変換します。\n\n\n\n説明変数の正規化\n\n# 説明変数になるデータをscale関数で正規化\ntempBoston[1:13] &lt;- tempBoston[1:13] |&gt;  scale()\n\n# 平均が0、標準偏差が1になる\ntempBoston[1:13] |&gt; apply(2, mean) |&gt; round(digits = 3)\n##    crim      zn   indus    chas     nox      rm     age     dis     rad     tax \n##       0       0       0       0       0       0       0       0       0       0 \n## ptratio       b   lstat \n##       0       0       0\ntempBoston[1:13] |&gt; apply(2, sd)\n##    crim      zn   indus    chas     nox      rm     age     dis     rad     tax \n##       1       1       1       1       1       1       1       1       1       1 \n## ptratio       b   lstat \n##       1       1       1\n\n\n\n\n26.12.2 AICでモデルを選択する\nまずは、step関数でモデル選択を行います。step関数の引数はlm関数やglm関数の返り値ですので、説明変数をすべて使ったフルモデルのlm関数の返り値が必要となります。\nただし、あまりに説明変数が多いと、一つづつ+でつなぐのは大変です。Rでは、formulaの右辺、説明変数の欄に.（ピリオド）を入力すると、データフレームのうち、目的変数以外のすべての列を説明変数とすることができます。以下の例では、BousonHousingのmedv（家の価格のデータ）を目的変数、その他の列のデータをすべて説明変数としたlm関数の返り値をlm_modelに代入しています。\nこのlm_modelを用いてstep関数でモデル選択をすると、下記のように切片（intercept）を除いて11個の説明変数の傾きが計算されます。このstep関数の計算過程で、indusとage、非小売業の面積の割合と築年数の古い建物の割合の項が抜けていることがわかります。\n\n\n\nstep関数でモデル選択\n\ncolnames(tempBoston) # medvを除くと13列のデータになっている\n##  [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n##  [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"b\"       \"lstat\"   \"medv\"\n\n# とりあえずlmとStepでやってみる\n# 説明変数を.で指定すると、目的変数以外のすべてのデータを説明変数に設定する\nlm_model &lt;- lm(medv ~ ., data = tempBoston)\nstep(lm_model, trace = 0)\n## \n## Call:\n## lm(formula = medv ~ crim + zn + chas + nox + rm + dis + rad + \n##     tax + ptratio + b + lstat, data = tempBoston)\n## \n## Coefficients:\n## (Intercept)         crim           zn         chas          nox           rm  \n##     22.5328      -0.9325       1.0692       0.6905      -2.0135       2.6711  \n##         dis          rad          tax      ptratio            b        lstat  \n##     -3.1432       2.6088      -1.9850      -2.0492       0.8482      -3.7316\n\n\n\n\n26.12.3 ラッソ回帰\n同様の回帰をスパース回帰の一つであるラッソ（lasso）回帰を用いて行います。\nスパース回帰では、まず正規化項の係数（λ、ラムダ）というものを求める必要があります。このλを求めるための関数が、glmnetパッケージのcv.glmnet関数です。\ncv.glmnet関数はformulaを引数に取らず、引数xに各列が説明変数である行列、引数yに目的変数であるベクターを指定します。さらに、glm関数と同様に目的変数の分布としてfamily引数、ラッソ回帰を指定するための引数であるalpha=1をそれぞれ指定します。\nこのcv.glmnet関数の返り値（下の例ではcvlasso_m）をplot関数の引数に取ると、Mean-squared error（平均2乗誤差）とラムダの関係を示したグラフが表示されます。このグラフのうち、縦線が引いてある2本のうちラムダの小さい方の値を、正規化項の係数λとして採用します。ですので、下のBousonHousingの例では、log(λ)=-3.7付近の値をλとして採用し、ラッソ回帰を行うこととなります。\nこの-3.7の点線の上側には、11と記載されています。この11は選択された説明変数の数を示しています。つまり、λを点線の値に指定すると、ラッソ回帰で11個の説明変数が選択され、2つが落とされるということになります。\n\n\n\nラッソ回帰：λを求める\n\n# ラッソ回帰：正規化項の係数を求める\n# 乱数計算を含むため、seedを設定しないと計算値は変化する\ncvlasso_m &lt;- \n  cv.glmnet(\n    x = tempBoston[,1:13] |&gt; as.matrix(), \n    y = tempBoston$medv, \n    family = \"gaussian\", \n    alpha = 1)\n\n# 左側の点線のラムダを採用する\nplot(cvlasso_m)\n\n\n\n\n\n\n\n\n\n# 大きい方のlog(λ)の点線の値\ncvlasso_m$lambda.1se |&gt; log() \n## [1] -0.7843475\n\n# 小さい方のlog(λ)の点線の値（こちらを採用する）\ncvlasso_m$lambda.min |&gt; log() \n## [1] -3.761427\n\nラッソ回帰の計算はglmnet関数で行います。glmnet関数の引数はほぼcv.glmnet関数と同じです。ラムダを指定せずにglmnet関数での計算を行うと、正規化項の大きさ（L1 norm）やラムダと傾きの関係を求めることができます。この関係を求めるときには、glmnet関数の返り値をplot関数の引数とします。ラムダとの関係を知りたい場合にはplot関数の引数にxvar=\"lambda\"を追加します。グラフの上に表示される数値は選択される説明変数の数を示しています。lambdaが大きく、L1 normが小さくなるとグラフは0に収束していきますが、これはlambdaとL1 normに従い、傾きが0、つまり説明変数から脱落するものが多くなっていくことを示しています。\n\n\n\nラッソ回帰：傾きの計算1\n\n# ラッソ回帰：正規化項の係数を入力せずに計算\nlasso_m &lt;- \n  glmnet(x = tempBoston[,1:13], \n         y = tempBoston$medv, \n         family = \"gaussian\", \n         alpha = 1)\n\n# 正則化項（L1）の大きさと傾き\nplot(lasso_m)\n\n\n\n\n\n\n\n\n\n# ラムダの大きさと傾き\nplot(lasso_m, xvar = \"lambda\")\n\n\n\n\n\n\n\n\ncv.glmnet関数でλを計算した値がある場合、glmnet関数のlambda引数にcv.glmnet関数で計算したλの値を指定します。\nこのglmnet関数の結果をそのまま見てもよくわかりませんが、返り値はS4オブジェクトとなっており、$を用いて情報を取り出すことができます。傾きは$betaで呼び出すことができます。\n\n\n\nラッソ回帰：ラムダを指定して傾きの計算\n\n# ラッソ回帰：正規化項の係数を入力して計算\nlasso_m2 &lt;- \n  glmnet(x = tempBoston[,1:13], \n         y = tempBoston$medv, \n         family = \"gaussian\", \n         lambda = cvlasso_m$lambda.min, \n         alpha = 1)\n\n# モデルと自由度、ラムダ等が帰ってくる\nlasso_m2\n## \n## Call:  glmnet(x = tempBoston[, 1:13], y = tempBoston$medv, family = \"gaussian\",      alpha = 1, lambda = cvlasso_m$lambda.min) \n## \n##   Df  %Dev  Lambda\n## 1 11 74.03 0.02325\n\n# 傾きの項（.は傾き0になっている）\nlasso_m2$beta\n## 13 x 1 sparse Matrix of class \"dgCMatrix\"\n##                 s0\n## crim    -0.8613197\n## zn       0.9868506\n## indus    .        \n## chas     0.6831620\n## nox     -1.9105597\n## rm       2.7080499\n## age      .        \n## dis     -2.9772626\n## rad      2.2733465\n## tax     -1.7162450\n## ptratio -2.0187590\n## b        0.8280071\n## lstat   -3.7318761\n\n\n上記の結果を見ると、indusとageの結果（s0）が.（ピリオド）になっています。この.は傾きが0、つまりモデルに組み込まないことを示しています。step関数で落とされたindusとageがラッソ回帰でも落とされていることがわかります。また、rmの傾きが大きく、lstatの傾きが小さいことがわかります。rmは1住居あたりの部屋数、lstatは地位の低い住民の割合ですので、住宅価格は部屋数が増えると高くなり、地位の低い住民の割合が増えると下がる傾向にあることがわかります。\n\n\n26.12.4 リッジ回帰\nリッジ（ridge）回帰は正規化項の種類（L2正規化項）がラッソ回帰（L1正規化項）とは異なる、スパース回帰の一つです。リッジ回帰では、AICによるモデル選択やラッソ回帰とは異なり、説明変数の選択は行われません。リッジ回帰は多重共線性がある、説明変数同士に相関がある場合に、妥当な傾きを計算するのに有用な方法です。\nリッジ回帰の場合にもラッソ回帰と同様に、cv.glmnet関数でλを計算した上で、glmnet関数で傾きを求めます。ただし、リッジ回帰を行うときには引数alphaに0を指定します。\n\n\n\nリッジ回帰：λを求める\n\ncvridge_m &lt;- \n  cv.glmnet(\n    x = tempBoston[,1:13] |&gt; as.matrix(), \n    y = tempBoston$medv, \n    family = \"gaussian\", \n    alpha = 0)\n\nplot(cvridge_m)\n\n\n\n\n\n\n\n\n\ncvridge_m$lambda.min %&gt;% log\n## [1] -0.3889541\n\nラッソ回帰ではグラフの上の数値が右に行くほど減っていきますが、リッジ回帰では減っていかない、つまり説明変数が落とされることはないことがわかります。\n\n\n\nリッジ回帰：傾きを求める\n\nridge_m &lt;- \n  glmnet(\n    x=tempBoston[,1:13], \n    y=tempBoston$medv, \n    family=\"gaussian\", \n    lambda=cvridge_m$lambda.min, \n    alpha=0)\n\nridge_m$beta\n## 13 x 1 sparse Matrix of class \"dgCMatrix\"\n##                 s0\n## crim    -0.7561128\n## zn       0.7604566\n## indus   -0.2629449\n## chas     0.7373398\n## nox     -1.3911543\n## rm       2.8204203\n## age     -0.1087290\n## dis     -2.3602985\n## rad      1.3423202\n## tax     -0.9656940\n## ptratio -1.8528966\n## b        0.8278717\n## lstat   -3.3676987\n\n\n実際に係数を確認すると、ラッソ回帰では.で表示されていたindusとageも0にはなっておらず、説明変数から外されていないことがわかります。\n\n\n26.12.5 エラスティックネット\nエラスティックネットは、ラッソ回帰とリッジ回帰を混ぜ合わせたような、中間的なスパース回帰です。エラスティックネットはラッソ寄り、リッジ寄りのスパース回帰として設定することができます。このラッソ寄り、リッジ寄りの設定は、alpha引数の値で指定し、alphaが1に近いとラッソ寄り、0に近いとリッジ寄りの回帰となります。下の例ではalphaを0.5としていますが、実際にデータに用いる場合にはalphaの値を最適化して用います。このように、計算においてある程度自分で最適化が必要となるパラメータのことを機械学習の分野ではハイパーパラメータと呼びます。\n\n\n\nエラスティックネット\n\n# 実際にはアルファを最適化して利用する\ncven_m &lt;- \n  cv.glmnet(\n    x = tempBoston[,1:13] |&gt; as.matrix(), \n    y = tempBoston$medv, \n    family = \"gaussian\", \n    alpha = 0.5)\n\nplot(cven_m)\n\n\n\n\n\n\n\n\n\ncven_m$lambda.min %&gt;% log\n## [1] -3.254348\n\nen_m &lt;- \n  glmnet(\n    x = tempBoston[,1:13], \n    y = tempBoston$medv, family=\"gaussian\", \n    lambda = cven_m$lambda.min, \n    alpha = 0.5)\n\nen_m$beta\n## 13 x 1 sparse Matrix of class \"dgCMatrix\"\n##                 s0\n## crim    -0.8651428\n## zn       0.9889952\n## indus    .        \n## chas     0.6861788\n## nox     -1.9085252\n## rm       2.7102035\n## age      .        \n## dis     -2.9719136\n## rad      2.2740296\n## tax     -1.7165457\n## ptratio -2.0179396\n## b        0.8311844\n## lstat   -3.7217537",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>相関と回帰</span>"
    ]
  },
  {
    "objectID": "chapter26.html#主成分回帰",
    "href": "chapter26.html#主成分回帰",
    "title": "26  相関と回帰",
    "section": "26.13 主成分回帰",
    "text": "26.13 主成分回帰\n説明変数間に相関があると多重共線性の問題が起こります。ですので、説明変数をうまく変換して説明変数間の相関をなくしてやれば、多重共線性の問題なく回帰を行うことができます。\nデータ変換のうち、主成分分析（Primary Component Analysis、PCA）は多次元のデータの特徴を捉えるために用いられる手法の一つです（28章を参照）。詳細は省きますが、主成分分析で変換すると、変換後のデータ（第一主成分、第二主成分…）の間の相関係数が0、つまり相関のない状態になります。この性質を用いて、主成分分析でデータ変換したものを説明変数にすることで多重共線性を避けて回帰を行う方法のことを主成分回帰（Primary Component Regression、PCR）と呼びます。\n主成分回帰では、まず説明変数を主成分分析を用いて、主成分に変換します。この変換した主成分を用いて目的変数を説明する回帰を行います。主成分への変換に伴い、元の説明変数と目的変数の関係が不明瞭になりますので、回帰をデータの説明に使うのには適していませんが、この回帰の結果を目的変数の予測に用いることができます。\nRでは、主成分分析はprcomp関数で行います。prcompの返り値は主成分への変換を行うためのprcompクラスのオブジェクトで、主成分は$xで取り出します。後はlm関数で説明変数に主成分を指定して回帰を行うだけです。\n$rotationでデータを主成分に変換する際の係数が求まります。また、説明変数を主成分に変換する際にはpredict関数を用います。predict関数の第一引数にprcompオブジェクトを、第二引数に変換したいデータをデータフレームで指定します。計算した主成分を、lmオブジェクトを用いたpredict関数に与えて予測すれば、主成分回帰による予測値を得ることができます。\n\n\n\n主成分回帰\n\n# 主成分への変換\npc &lt;- iris[,2:4] |&gt; prcomp(scale = T)\n\npc$x |&gt; head() # 変換後の主成分（PC1～PC3）\n##            PC1        PC2          PC3\n## [1,] -2.124839 -0.1397433  0.008370721\n## [2,] -1.645199  0.9004078 -0.054584971\n## [3,] -1.873778  0.4988220 -0.070033694\n## [4,] -1.704404  0.6779030 -0.001362832\n## [5,] -2.220767 -0.3477735  0.020961859\n## [6,] -2.231416 -1.1033118 -0.001635822\n\npc$rotation # 主成分への変換の係数\n##                     PC1        PC2         PC3\n## Sepal.Width  -0.4181177 -0.9067335  0.05488053\n## Petal.Length  0.6482670 -0.2555198  0.71725833\n## Petal.Width   0.6363391 -0.3354757 -0.69464280\n\n# 目的変数をデータフレームに付け加える\npc1 &lt;- pc$x |&gt;  as.data.frame()\npc1$Sepal.Length &lt;- iris$Sepal.Length\n\n# 主成分で回帰（主成分4つをすべて用いる）\npcr_lm &lt;- lm(Sepal.Length ~., data = pc1)\n\n# 予測の例\nexample_iris &lt;- data.frame(Sepal.Width = 5, Petal.Length = 6, Petal.Width = 3)\n\n# 予測に用いる説明変数を主成分に変換\npc_example &lt;- predict(pc, example_iris)\npc_example\n##            PC1       PC2        PC3\n## [1,] 0.4630155 -5.158362 -0.4854335\n\n# 主成分を用いて予測値を計算\npredict(pcr_lm, pc_example |&gt; as.data.frame())\n##        1 \n## 7.695527\n\n\n主成分回帰はplsパッケージ (Liland, Mevik, and Wehrens 2023)のpcr関数を用いても行うことができます。\n\n\n\nplsパッケージのpcr関数で主成分回帰\n\npacman::p_load(pls)\ndata(yarn)\n\n# PCRの計算（ncompは回帰に用いる主成分の数）\nyarn.pcr &lt;- pcr(density ~ NIR, ncomp = 6, data = yarn, validation = \"CV\") \nyarn.pcr |&gt; summary() # 回帰結果の表示\n## Data:    X dimension: 28 268 \n##  Y dimension: 28 1\n## Fit method: svdpc\n## Number of components considered: 6\n## \n## VALIDATION: RMSEP\n## Cross-validated using 10 random segments.\n##        (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps\n## CV           27.46    26.84    3.947    2.598    2.594    1.623   0.4685\n## adjCV        27.46    28.72    3.930    2.565    2.618    1.527   0.4578\n## \n## TRAINING: % variance explained\n##          1 comps  2 comps  3 comps  4 comps  5 comps  6 comps\n## X          52.17    98.60    99.47    99.70    99.88    99.97\n## density     5.50    98.15    99.40    99.58    99.95    99.99",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>相関と回帰</span>"
    ]
  },
  {
    "objectID": "chapter26.html#部分的最小二乗回帰",
    "href": "chapter26.html#部分的最小二乗回帰",
    "title": "26  相関と回帰",
    "section": "26.14 部分的最小二乗回帰",
    "text": "26.14 部分的最小二乗回帰\n部分的最小二乗回帰（Partial Least Squares regression、PLS回帰）は主成分回帰（PCR）と同じく説明変数を変換して回帰を行う方法ですが、変換を行う際に、目的変数と変換後の説明変数の間の共分散が大きくなるよう調整することで、多重共線性の問題をより小さくしています。\nPLS回帰は分析化学の分野で、吸光度などのデータから目的変数、例えば物質の濃度など、を予測するために開発され、用いられています。吸光度などの化学データでは、一般的に1検体につき波長ごとの吸光度として1000以上の値が求まりますので、目的変数（1検体に1濃度）に対して非常に多くの説明変数（1検体につき、1000以上の吸光度の数値）がある、つまり多重共線性が非常に起こりやすいデータとなっています。説明変数をPCRよりもうまく変換することで、この多重共線性の問題を起こりにくくした手法がこのPLSです。\n\n26.14.1 PLS：データの準備とクロスバリデーション\nRのPLS回帰の計算では、機械学習でよく用いられるクロスバリデーションという方法が用いられます。クロスバリデーションとは、手持ちのデータを訓練データとテストデータの2つに分割し、訓練データを用いて回帰を行い、テストデータで回帰の精度を評価する方法のことです。クロスバリデーションを行うことで、訓練データに用いていない、新規データでの予測精度を評価することができます。\nPLS回帰に用いる、以下のyarnのデータセットは、PET yarn（ポリエステル糸）の近赤外吸光分光データ（Near Infra Red、NIR）と糸の密度（density）の関係を示したデータです。このデータセットでは、予めクロスバリデーション用にtrainという列が追加されており、21行がTRUE、つまり訓練データで、残りの7行がFALSE、つまりテストデータとなっています。\n\n\n\nPLSに用いるデータ：yarn\n\n# yarnはplsパッケージのデータセット\npacman::p_load(pls)\ndata(yarn) # ポリエステル繊維のNIR（近赤外吸収）データ\ncolnames(yarn) # NIRにはNIR.1～NIR.268の列が登録\n## [1] \"NIR\"     \"density\" \"train\"\n\ndim(yarn)\n## [1] 28  3\n\nsummary(yarn$train) # 21データが訓練、7データがテストデータ\n##    Mode   FALSE    TRUE \n## logical       7      21\n\n\nRでは、plsパッケージのplsr関数を用いてPLS回帰を行うことができます。plsr関数の第一引数はformulaです。ncomp引数は回帰に用いる説明変数変換後のパラメータの数で、増やすとデータへの適合度は高くなりますが、過学習のリスクも大きくなります。\nvalidationには用いるバリデーションの方法を指定します。validation=\"CV\"では、trainの列の論理型を用いてクロスバリデーションを行います。leave-one-outと呼ばれる、データの一つだけをテストデータとして、その他のデータを訓練データとする場合には、validation=\"LOO\"と指定します。\n\n\n\n部分的最小二乗回帰（PLS）\n\nyarn.pls &lt;- \n  plsr(\n    density ~ NIR, \n    ncomp = 6, \n    data = yarn, \n    validation = \"CV\")\nyarn.pls |&gt; summary()\n## Data:    X dimension: 28 268 \n##  Y dimension: 28 1\n## Fit method: kernelpls\n## Number of components considered: 6\n## \n## VALIDATION: RMSEP\n## Cross-validated using 10 random segments.\n##        (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps\n## CV           27.46    5.054    4.139    2.125   0.9281   0.4785   0.4443\n## adjCV        27.46    4.603    4.228    2.103   0.8741   0.4706   0.4366\n## \n## TRAINING: % variance explained\n##          1 comps  2 comps  3 comps  4 comps  5 comps  6 comps\n## X          46.83    98.38    99.46    99.67    99.85    99.97\n## density    98.12    98.25    99.64    99.97    99.99    99.99\n\n\nPLS結果を用いた予測には、predict関数を用います。predict関数の第一引数にplsr関数の返り値、comps引数には上のyarn.pls|&gt;summary()の結果として示されているcompsのうち、回帰に用いるものを指定します。通常はplsr関数のncompに指定した数値までのベクターで指定することになります。newdataには予測したいデータのデータフレームを指定します。\n\n\n\nPLSの結果を用いてデータを予測する\n\n# モデルにデータを与えてpredictすることで用いる\nresult_prediction &lt;- predict(\n  yarn.pls, \n  comps = 1:6, \n  newdata = yarn[!yarn$train,])\n\n# 左がテストデータ、右が予測値\ndata.frame(testresult = yarn[!yarn$train,]$density, result_prediction) |&gt; \n  knitr::kable()\n\n\n\n\n\n\ntestresult\ndensity\n\n\n\n\n110\n51.04\n51.10466\n\n\n22\n50.32\n50.34328\n\n\n31\n32.14\n32.29764\n\n\n41\n34.69\n34.55275\n\n\n51\n30.30\n30.04395\n\n\n61\n20.45\n20.54823\n\n\n71\n20.06\n19.86822\n\n\n\n\n\n回帰からの予測の結果が上の表となります。左の列がテストデータの測定値、右のデータがPLSからの予測値です。概ねどのサンプルでもdensityが正しく予測されているのがわかるかと思います。",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>相関と回帰</span>"
    ]
  },
  {
    "objectID": "chapter26.html#ニューラルネットワーク回帰",
    "href": "chapter26.html#ニューラルネットワーク回帰",
    "title": "26  相関と回帰",
    "section": "26.15 ニューラルネットワーク（回帰）",
    "text": "26.15 ニューラルネットワーク（回帰）\nより機械学習的に、予測的な回帰を行う方法が、ニューラルネットワーク（Neural Network）です。ニューラルネットワークはその名の通り、神経細胞の構造を真似たような形でデータを学習し、予測を行うことができる手法です。ニューラルネットワークには回帰の他に、分類も行うことができます。分類に関するニューラルネットワークについては、次の章で説明します。\nニューラルネットワークは今（2023年）をときめくChatGPTなどの生成AIの根幹技術の一つで、ニューラルネットワークを発展させたディープニューラルネットワーク（DNN）が生成AIの一部に用いられています。\n\n\n\n\n\n\nニューラルネットワークの仕組み\n\n\n\n\n\nニューラルネットワークの基本単位は、単純パーセプトロンと呼ばれるものです。単純パーセプトロンとは以下の図で示すように、a1、a2、a3のデータが与えられたとき、それぞれのデータに重み（w）を掛け、バイアス（b）を足したものです。\n\nただし、このYを求めるときにデータの変換を行います。この変換を行うための関数のことを活性化関数と呼びます。活性化関数にはソフトマックス変換やロジスティック変換、Relu（Yが0以下なら0、Yが0より大きければYをそのままとする式）を用いるのが一般的です。\nソフトマックス変換 \\[\\sigma(z_k)=\\frac{exp(z_k)}{\\sum^{n}_{i=1}exp(z_i)}\\]\nロジスティック変換\n\\[Y=\\frac{1}{1+exp(-(w_{1}a_{1}+w_{2}a_{2}+w_{3}a_{3}+b))}\\]\nReluでの変換\n\\[\\left\\{\\begin{align*}Y = 0 \\quad (Y \\leqq 0) \\\\ Y = w_{1}a_{1}+w_{2}a_{2}+w_{3}a_{3}+b \\quad (Y &gt; 0)\\end{align*}\\right.\\]\nこの単純パーセプトロンで回帰も分類もできるのですが、複雑な問題には対応できません。単純パーセプトロンを組み合わせ、積み重ねたものがニューラルネットワークです。\n\nニューラルネットワークは単純パーセプトロンを組み合わせ、入力層、中間層、出力層の各層としたものです。このニューラルネットワークを用いることで、複雑な回帰や分類にも対応することができます。学習の過程で重みやバイアスが計算されますが、この計算にはバックプロパゲーションと呼ばれる方法が用いられています。このバックプロパゲーションによる計算にはたくさんの行列演算が含まれるため、行列演算をたくさん行うことが得意なGPUが学習に用いられています。\nこのニューラルネットワークの中間層を更に積み重ね、途中で畳み込みやプーリングと呼ばれるデータの変換を用いたもののことをディープニューラルネットワーク（DNN）と呼びます。DNNでは入力層が数万～数十億、中間層が数十層となる場合もあり、非常に複雑な分類問題を予測することが可能です。現在AIと呼ばれているものは、このDNNに強化学習を組み合わせた大規模言語モデル（LLM）と呼ばれるもので、入出力をヒトに見やすい形にしたものだと思います。\n\n\n\nRでニューラルネットワークを用いる場合には、neuralnetパッケージ(Fritsch, Guenther, and Wright 2019)のneuralnet関数を用います。neuralnet関数はformulaを引数に取る関数ですので、まずirisのデータを用いてformulaを準備します。formulaの形はlm関数などと同じで、目的変数~説明変数の形で準備します。\n\n\n\nニューラルネットワーク：formulaの準備\n\npacman::p_load(neuralnet)\nformula_iris &lt;- \n  as.formula(\n    \"Sepal.Length ~\n      Sepal.Width +\n      Petal.Length +\n      Petal.Width +\n      Species\"\n  )\n\n\nneuralnet関数は、このformulaの他に、data、隠れ層（hidden）、活性化関数（act.fct）を引数に取ります。隠れ層とは、ニューラルネットワークの中間層のことを指します。以下の式では、隠れ層としてパーセプトロン3つ、3つの2層をベクター（c(3,3)）で設定しています。\nneuralnet関数の返り値をplotすると、各入力に対する重みとバイアスを図で表示してくれます。黒の数値が重みで、青の数値はバイアスを示します。\n\n\n\nneuralnet関数で2層ニューラルネットワークを計算\n\n# 2層（nodeが3、3）\nset.seed(0)\n\n# 説明変数はスケーリングする\niris_scale &lt;- scale(iris[, 2:4]) |&gt; as.data.frame()\n\n# 種は―1～1にスケーリング\niris_scale$Species &lt;- iris$Species |&gt; as.numeric() - 2 \n\n# 目的変数は0～1にスケーリング\niris_scale$Sepal.Length &lt;-\n  (iris$Sepal.Length - min(iris$Sepal.Length)) / (max(iris$Sepal.Length) - min(iris$Sepal.Length))\n\n\nnn_iris &lt;- neuralnet(\n  formula = formula_iris,\n  data = iris_scale,\n  hidden = c(3, 3),\n  act.fct = \"logistic\", # ソフトマックス（この他に\"tanh\"を選べる）\n  linear.output = T # 出力層に活性化関数を適用するかどうか\n)\nplot(nn_iris, rep = \"best\")\n\n\n\n\n\n\n\n\n\n同様に、パーセプトロンが2個、3個、2個のニューラルネットワークを計算する場合には、hidden=c(2,3,2)と隠れ層を設定します。\n\n\n\nneuralnet関数で3層ニューラルネットワークを計算\n\n# 3層（nodeが2、3、2）\nset.seed(0)\nnn_iris2 &lt;- neuralnet(\n  formula = formula_iris,\n  data = iris_scale,\n  hidden = c(2, 3, 2),\n  act.fct = \"logistic\", \n  linear.output = T\n)\nplot(nn_iris2, rep = \"best\")\n\n\n\n\n\n\n\n\n\nneuralnet関数の返り値をpredict関数の引数にすることで、予測を行うことができます。ただし、データをあらかじめスケーリングしていること、活性化関数がソフトマックスであることから、計算結果は0～1までの値として得られます。この予測値をうまく変換してやれば、元の値を評価することができます。下のニューラルネットワークの構造では悪くはないのですが、正確には予測できていないことがわかります。このような場合には、データ変換の方法、隠れ層や活性化関数、その他の引数を最適化する必要があります。\n\n\n\nneuralnet関数の返り値で予測\n\nnn_iris3 &lt;- neuralnet(\n  formula = formula_iris,\n  data = iris_scale,\n  hidden = c(4, 4),\n  act.fct = \"logistic\", \n  linear.output = T \n)\n\n# 上のニューラルネットワークで予測する\npredict(nn_iris3, iris_scale[1:5,])\n##        [,1]\n## 1 0.2003094\n## 2 0.1113907\n## 3 0.1341587\n## 4 0.1423868\n## 5 0.2179850\n\n# 予測値と実際の値の比較\npred_real &lt;- data.frame(\n  # 予測値を変換\n  prediction = predict(nn_iris3, iris_scale[1:50,]) * (max(iris$Sepal.Length) - min(iris$Sepal.Length)) + min(iris$Sepal.Length),\n  real_value = iris$Sepal.Length[1:50] # 実際の値\n)\n\nplot(pred_real)\n\n\n\n\n\n\n\n\n\nニューラルネットワークに関する他のパッケージには、nnetパッケージ (Venables and Ripley 2002)があります。\n\n\n\n\n\n\nRでディープニューラルネットワーク\n\n\n\n\n\n現代の機械学習やディープニューラルネットワークのほとんどのパッケージはPythonのライブラリとして提供されています。Rでは、これらのPythonのライブラリを用いたRのライブラリを用いることで、Pythonでできるようなディープニューラルネットワークの手法を用いることができるようになっています。\nPythonの機械学習プラットフォームであるTensorflowをRから利用するtensorflowパッケージ、TensorflowのニューラルネットワークライブラリであるKerasをRから利用するkerasパッケージ、RからPythonのニューラルネットワークライブラリであるPytorchを利用するためのライブラリであるtorchなどを用いることで、Rでもディープニューラルネットワークを試すことができます。",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>相関と回帰</span>"
    ]
  },
  {
    "objectID": "chapter26.html#カーネル密度推定",
    "href": "chapter26.html#カーネル密度推定",
    "title": "26  相関と回帰",
    "section": "26.16 カーネル密度推定",
    "text": "26.16 カーネル密度推定\nカーネル密度推定は、データの分布をカーネル密度という、滑らかな曲線に変換する手法です。Rにはこのカーネル密度を表示するための手法がたくさん存在します。その一つが20章で説明したdensity関数です。density関数の引数にベクターを与えるとカーネル密度を計算してくれます。このdensity関数の返り値をplot関数の引数にすると、カーネル密度をグラフにしてくれます。\n同様のグラフはggplot2のgeom_density関数を用いても描画できます。カーネル密度の計算はKernSmoothパッケージ (Wand 2023)のbkde関数を用いても計算することができます。\n\n\n\nカーネル密度推定\n\n# カーネル回帰\nhead(faithful)\n##   eruptions waiting\n## 1     3.600      79\n## 2     1.800      54\n## 3     3.333      74\n## 4     2.283      62\n## 5     4.533      85\n## 6     2.883      55\nx &lt;- faithful$waiting\n\nhist(x, xlim = c(40, 100))\npar(new  =T)\ndensity(x) |&gt; plot(xlim = c(40, 100), main = \"\", xlab = \"\", ylab = \"\", axes = FALSE)\n\n\n\n\n\n\n\n\n\n# KernSmooth::bkde関数を用いる方法\npacman::p_load(KernSmooth)\nest &lt;- bkde(faithful$waiting, bandwidth = 3) %&gt;% as.data.frame\nggplot()+\n  geom_line(data = est, aes(x = x, y = y*950))+\n  geom_histogram(data = faithful, aes(x = waiting, fill = 1), alpha = 0.5)+\n  theme(legend.position = \"none\")\n## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>相関と回帰</span>"
    ]
  },
  {
    "objectID": "chapter26.html#非線形最小二乗法nls関数",
    "href": "chapter26.html#非線形最小二乗法nls関数",
    "title": "26  相関と回帰",
    "section": "26.17 非線形最小二乗法：nls関数",
    "text": "26.17 非線形最小二乗法：nls関数\n上記のガウス回帰過程やニューラルネットワーク、カーネル密度推定とは異なる非線形の回帰の方法として、非線形最小二乗法というものがあります。この非線形最小二乗法では、線形回帰と同様に2乗誤差を最小とすることで回帰を行う方法ですが、求めるパラメータは切片や傾きのような直線性を示すものではなく、自分で設定した関数のものとなる点が異なります。線形回帰と同様に、データが正規分布することを仮定しているため、正規分布しないデータでは適切に回帰を行うことができません。\nまた、2乗誤差を最小化する問題（最適化問題）を解く方法として、ガウス-ニュートン法を用いており、局所最適化と呼ばれる解にしか到達しない問題が起こることもあります。\nRで非線形最小二乗法を行うための関数がnls関数です。nls関数は引数に回帰したい関数の数式と各パラメータの初期値、データフレームを取ります。nls関数の使い方はlm関数とよく似ていて、summary関数を用いれば計算結果の詳細を、predict関数を用いれば回帰からの予測を得ることができます。\n\n\n\nnls関数で非線形最小二乗法\n\nDNase1 &lt;- subset(DNase, Run == 1)\nplot(density ~ conc, data = DNase1)\n\n\n\n\n\n\n\n\n\n# SSlogis関数は初期値を自動設定してくれる（self start）nlsのロジスティック回帰用の関数\nfm1DNase1 &lt;- nls(density ~ SSlogis(log(conc), Asym, xmid, scal), DNase1) \n# Asymは漸近線を示すパラメータ、xmidは変曲点のx軸の値を示すパラメータ、\n# scalはスケールパラメータ\nsummary(fm1DNase1)\n## \n## Formula: density ~ SSlogis(log(conc), Asym, xmid, scal)\n## \n## Parameters:\n##      Estimate Std. Error t value           Pr(&gt;|t|)    \n## Asym  2.34518    0.07815   30.01 0.0000000000002166 ***\n## xmid  1.48309    0.08135   18.23 0.0000000001218541 ***\n## scal  1.04146    0.03227   32.27 0.0000000000000851 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.01919 on 13 degrees of freedom\n## \n## Number of iterations to convergence: 0 \n## Achieved convergence tolerance: 0.000008273\n\n# predict関数で予測することができる\npredict(fm1DNase1, data.frame(conc = seq(0, 12, by=0.1))) |&gt; head()\n## [1] 0.00000000 0.06028535 0.11450622 0.16517079 0.21294860 0.25822909\n\n# 回帰結果のグラフ\nd &lt;- data.frame(conc = seq(0, 12, by=0.1), pred = predict(fm1DNase1, data.frame(conc = seq(0, 12, by = 0.1))))\nggplot()+\n  geom_point(data = DNase1, aes(x = conc, y = density, color = \"#F8766D\"))+\n  geom_line(data = d, aes(x = conc, y = pred), color = \"#00BFC4\")+\n  theme(legend.position = \"none\")",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>相関と回帰</span>"
    ]
  },
  {
    "objectID": "chapter26.html#loesslowess平滑化",
    "href": "chapter26.html#loesslowess平滑化",
    "title": "26  相関と回帰",
    "section": "26.18 LOESS・LOWESS平滑化",
    "text": "26.18 LOESS・LOWESS平滑化\nLOESS平滑化（locally estimated scatterplot smoothing）とLOWESS平滑化（Locally Weighted Scatterplot Smoothing）はどちらも局所回帰と呼ばれる手法を指しており、部分的な回帰をつなぎ合わせて全体として1つの回帰を行う手法です。部分的な回帰には多項式回帰を用いるのが一般的です。多項式回帰と多項式回帰をつなぎ合わせることで、全体として滑らかな曲線でデータを表現することができます。\nRでは、loess関数でLOESS平滑化、lowess関数を用いてLOWESS平滑化の計算を行います。どちらも同じ計算を行う関数ですが、関数の使い方が少し異なります。loess関数はloessオブジェクトを返す関数で、predict関数を用いて予測値を計算する形になっています。また、平滑化の幅を指定するspan引数を設定することで、より細かな値の変動に対応した平滑化を行うこともできます。\n\n\n\nLOESS平滑化\n\nloess_cars &lt;- loess(dist ~ speed, data = cars) # spanのデフォルト値は0.75\nsummary(loess_cars)\n## Call:\n## loess(formula = dist ~ speed, data = cars)\n## \n## Number of Observations: 50 \n## Equivalent Number of Parameters: 4.78 \n## Residual Standard Error: 15.29 \n## Trace of smoother matrix: 5.24  (exact)\n## \n## Control settings:\n##   span     :  0.75 \n##   degree   :  2 \n##   family   :  gaussian\n##   surface  :  interpolate      cell = 0.2\n##   normalize:  TRUE\n##  parametric:  FALSE\n## drop.square:  FALSE\n\nloess_cars2 &lt;- loess(dist ~ speed, cars, span = 0.3) # spanを短く設定\n\n# 赤がspan=0.75、青がspan=0.3\nplot(cars, xlim = c(0, 30), ylim = c(0, 120))\npar(new = T)\nplot(\n  seq(5, 30, by = 0.1), \n  predict(loess_cars, data.frame(speed = seq(5, 30, by = 0.1))), \n  type = \"l\", \n  xlim = c(0, 30), \n  ylim = c(0, 120),\n  xlab = \"\",\n  ylab = \"\",\n  col = 2)\npar(new = T)\nplot(\n  seq(5, 30, by = 0.1), \n  predict(loess_cars2, data.frame(speed = seq(5, 30, by = 0.1))), \n  type = \"l\", \n  xlim = c(0, 30), \n  ylim = c(0, 120),\n  xlab = \"\",\n  ylab = \"\",\n  col = 5)\n\n\n\n\n\n\n\n\n\nlowess関数は平滑化後のxとyのセットをリストとして返す関数で、plot関数やlines関数の引数に取ることで平滑化した線を描画することができます。平滑化計算における説明変数側の値の幅はdelta引数で指定します。デフォルトでは横軸を100分割して平滑化することになっています。部分最適化の幅を指定する引数がfで、fに小さい値を指定することで、より細かな値の変動を捉えることができます。\nloess、lowessのどちらを使っても結果自体には大差はありませんが、loess関数の方が予測値の融通が利きやすい仕様になっています。\n\n\n\nLOWESS平滑化\n\nlowess(cars) # 返り値は同じ長さのxとyのリストになる\n## $x\n##  [1]  4  4  7  7  8  9 10 10 10 11 11 12 12 12 12 13 13 13 13 14 14 14 14 15 15\n## [26] 15 16 16 17 17 17 18 18 18 18 19 19 19 20 20 20 20 20 22 23 24 24 24 24 25\n## \n## $y\n##  [1]  4.965459  4.965459 13.124495 13.124495 15.858633 18.579691 21.280313\n##  [8] 21.280313 21.280313 24.129277 24.129277 27.119549 27.119549 27.119549\n## [15] 27.119549 30.027276 30.027276 30.027276 30.027276 32.962506 32.962506\n## [22] 32.962506 32.962506 36.757728 36.757728 36.757728 40.435075 40.435075\n## [29] 43.463492 43.463492 43.463492 46.885479 46.885479 46.885479 46.885479\n## [36] 50.793152 50.793152 50.793152 56.491224 56.491224 56.491224 56.491224\n## [43] 56.491224 67.585824 73.079695 78.643164 78.643164 78.643164 78.643164\n## [50] 84.328698\n## \n## $call\n## lowess.default(x = cars)\n## \n## attr(,\"class\")\n## [1] \"lowess\"\n\nplot(cars, main = \"lowess(cars)\")\nlines(lowess(cars), col = 2)\nlines(lowess(cars, f = 0.1), col = 5) # 部分最適化の幅を狭くする",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>相関と回帰</span>"
    ]
  },
  {
    "objectID": "chapter26.html#spline回帰",
    "href": "chapter26.html#spline回帰",
    "title": "26  相関と回帰",
    "section": "26.19 spline回帰",
    "text": "26.19 spline回帰\nspline回帰は、loessと似ていますが、多項式の関数（2次関数や3次関数など）でデータを各部分ごとに回帰し、その多項式の微分値が一致する部分で滑らかにつなぐことで、全体として平滑な曲線で回帰する、非線形の回帰の方法です。spline回帰はLOESS平滑化とは計算のアルゴリズムが異なります。\nspline回帰のイメージを以下の図に示します。点で示されているデータを赤と青の2つの2次関数で回帰し、微分値が同じになる点（赤と青の境目）でつなぎ合わせて滑らかな1つの線にしています。このつなぎ目のことをknot（結び目）と呼びます。\n\n\n\n\n\n\n\n\n\nRでspline回帰を行う際には、smooth.spline関数を用います。smooth.spline関数はx（説明変数）、y（目的変数）をそれぞれ引数に取り、smooth.splineクラスのオブジェクトを返す関数です。\nsmooth.spline関数ではcubic smoothing spline（3次スプライン）という、3次関数を滑らかにつなぎ合わせたspline回帰を行います。このcubic smoothing splineでは、knotとknotの間ごとに3次関数への回帰が最小二乗法で計算されます。ただし、この回帰においては、曲線の曲がり具合（wiggliness）が大きいとペナルティがつくような最小二乗法の計算が行われます。ペナルティの大きさはGCV（Generalized Cross Varidation）という手法で自動的に設定されます。別途penalty変数に数値を設定すると、ペナルティの大きさを調整することができます。大きめのpenaltyを設定すればより滑らかな、小さめのpenaltyを設定すればより曲がりくねった形の回帰となります。\nまた、cubic smoothing splineでは、knotの位置をあらかじめ設定しておく必要があります。smooth.spline関数ではknotの数は自動的に設定される仕組みになっています。\n\n\n\nspline回帰\n\nBJsales_d &lt;- as.data.frame(BJsales) |&gt; mutate(time = 1:150)\n\n# スプライン曲線の計算（ペナルティを1.4に設定）、結果にはGCVの結果などが表示される\nsmooth.spline(BJsales_d$time, BJsales_d$x, penalty = 1.4)\n## Call:\n## smooth.spline(x = BJsales_d$time, y = BJsales_d$x, penalty = 1.4)\n## \n## Smoothing Parameter  spar= 0.334997  lambda= 0.0000006884175 (10 iterations)\n## Equivalent Degrees of Freedom (Df): 42.13433\n## Penalized Criterion (RSS): 65.69251\n## GCV: 1.189626\n\n# 黒線が生データ、赤線がスプライン曲線\nplot(BJsales, col = 1, xlim = c(0, 150), ylim = c(200, 260))\npar(new = T)\nsmooth.spline(BJsales_d$time, BJsales_d$x, penalty = 1.4) |&gt; \n  plot(type = \"l\", col = 2, xlim = c(0, 150), ylim = c(200, 260), xlab = \"\", ylab = \"\")",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>相関と回帰</span>"
    ]
  },
  {
    "objectID": "chapter26.html#加法モデルadditive-model",
    "href": "chapter26.html#加法モデルadditive-model",
    "title": "26  相関と回帰",
    "section": "26.20 加法モデル（additive model）",
    "text": "26.20 加法モデル（additive model）\n上記のように、説明変数が1つ、従属変数が1つの場合には、smooth.spline関数を用いた回帰により、滑らかな非線形回帰を行うことができます。このspline回帰を説明変数が複数の場合、つまり重回帰のような場合に拡張したものが加法モデル（additive model）です。\n加法モデルのいいところは、説明変数に対して目的変数が直線的な関係でなくても回帰が行えるということです。上述の線形モデルでは、単調増加・単調減少の現象を取り扱い、回帰する線は直線・指数関数・ロジスティック関数の主に3つとなります。しかし、実際の現象では説明変数に最適値があったり、目的変数が飽和するようなパターンも多くみられます。このような現象に対しては線形モデルではなく、非線形である加法モデルを用いた方がうまく説明できる可能性があります。ただし、説明変数に対する傾きを数値で示すことはできないため、結果の解釈は難しくなります。\nRでは、加法モデルの計算にmgcvパッケージ(S. N. Wood 2011, 2004, 2003; S. N. Wood et al. 2016; S. N. Wood 2017)を用います。mgcvでは、主に3種類のspline回帰を用いて複雑な非線形回帰に対応します。\n\ncubic regression spline：上記のsmooth.splineで用いられているものと同じものです。knotの間隔はデフォルトでは説明変数の幅を10分割する形で設定されます。knotの位置を最適化すれば、非常に滑らかな非線形回帰を行うことができます。\nthin plate regression spline：cubic regression splineと同じく3次関数で非線形回帰を行うspline回帰ですが、knotの位置が自動的に最適化される点が異なります。計算が重く、データ数が多いと時間がかかります。\ntensor product spline：複数の説明変数に対して、多次元的なspline回帰を行うための手法です。thin plate regression splineよりも計算が軽いため、データが多い場合に適しています。\n\nmgcvのデフォルトのspline回帰の手法はthin plate regression splineです。thin plate regression splineはthin plate splineと呼ばれる手法の計算量を小さくしたものです。thin plate spline自体は計算量が大きすぎて使いにくいため、mgcvでは対応していません。この他にB-splineやP-splineなどの、別のsplineの手法を用いることもできますが、特に理由がない限り使用する必要はないでしょう。thin plate splineに関してはこちらの小林景先生（慶應義塾理工学部）のページに詳しく記載されています。\n回帰の計算をペナルティ付き最小二乗法で計算する点もsmooth.spline関数と同じです。ペナルティ付き最小二乗法はP-IRLS（Iteratively Reweighted Least Squares）と呼ばれる繰り返し計算手法で計算します。\nペナルティ付き最小二乗法のペナルティの大きさはsmooth.splineと同じくGCVか、UBRE（Un-biased Risk Estimator）と呼ばれる手法のどちらかで計算されます。特に手法を指定しない場合にはGCVによりGCV-scoreが計算され、GCV-scoreを最小化するペナルティの大きさが決定されます。\n\n26.20.1 一般化加法モデル（Generalized Additive Model、GAM）\n線形モデル（LM）に対して一般化線形モデル（GLM）があるのと同様に、加法モデル（AM）に対しては一般化加法モデル（Generalized Additive Model、GAM）があります。\n加法モデルでは、目的変数が正規分布すると仮定してspline曲線による非線形重回帰を行います。この目的変数の分布を正規分布以外に拡張したものが、一般化加法モデル（GAM）です。目的変数が正規分布することを仮定する加法モデルではペナルティ付き最小二乗法でsplineを求めますが、一般化加法モデルではペナルティ付き最尤法でsplineを求めます。\n一般化加法モデルでは、一般化線形モデルのように目的変数の分布（family）とリンク関数（link）を指定します。GLMと同様に目的変数の分布とリンク関数はセットになっているため、familyを設定すれば、リンク関数を別途設定する必要はありません。\n\n\n26.20.2 mgcvでGAMを計算する\nmgcvパッケージでは、gam関数を用いてGAMを計算することができます。gam関数の使い方はglm関数によく似ていますが、説明変数の設定方法が異なります。\nmgcvパッケージでspline回帰による回帰を行う場合には、説明変数をs関数の引数に取ります。\n以下の例では、31本のブラックチェリー（Purnus serotina）のデータ（trees）において高さ（Height）と直径（Girth）から幹の体積（Volume）を求める演算をGAMで行っています。説明変数であるHeightとGirthはs関数の引数に指定しています。glm関数と同じく、データはデータフレームとして、data引数に指定します。このように指定することで、目的変数-説明変数の関係をsplineによる非線形として設定することができます。s関数内で特に引数を指定しない場合には、thin plate regression splineによる計算が行われます。\ngam関数の返り値をplot関数の引数に指定することで、各説明変数と目的変数の関係をグラフで示すことができます。グラフの実線は推定値で、点線は信頼区間を示します。x軸に示されている短い縦線はデータの位置を示しています。\n\n\n\ngam関数で一般化加法モデルを計算\n\npacman::p_load(mgcv)\n\ngam_trees &lt;- gam(Volume ~ s(Girth) + s(Height), data = trees)\n\nsummary(gam_trees)\n## \n## Family: gaussian \n## Link function: identity \n## \n## Formula:\n## Volume ~ s(Girth) + s(Height)\n## \n## Parametric coefficients:\n##             Estimate Std. Error t value            Pr(&gt;|t|)    \n## (Intercept)  30.1710     0.4816   62.65 &lt;0.0000000000000002 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Approximate significance of smooth terms:\n##             edf Ref.df   F              p-value    \n## s(Girth)  2.693  3.368 207 &lt; 0.0000000000000002 ***\n## s(Height) 1.000  1.000  16             0.000468 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## R-sq.(adj) =  0.973   Deviance explained = 97.7%\n## GCV = 8.4734  Scale est. = 7.1905    n = 31\n\npar(mfrow = c(1, 2))\nplot(gam_trees)\n\n\n\n\n\n\n\n\n\nグラフの縦軸ラベルに記載されている数値はsplineの自由度です。GAMでは自由度が非常に重要な要素の一つで、spline曲線で用いられている係数などの数を反映しています。自由度が大きすぎると過学習である可能性があります。一方で、周期性のある時系列データなどでは、自由度が小さいと結果を十分に説明できなくなるため、自由度がある程度大きい必要があります。s関数ではデフォルトの自由度の最大値として10が設定されています。自由度の最大値はs関数内でk引数を指定することで変更することができます。\nまた、説明変数と目的変数の関係が線形であることが分かっている場合には、s関数の引数とせずにつなぐことで、その説明変数のみsplineとすることなくモデルに組み込むことができます。\n\n\n\nheightのみ線形として演算する\n\ngam_trees1 &lt;- gam(Volume ~ s(Girth) + Height, data = trees)\n\n# 線形の成分はplot関数では表示されない\nplot(gam_trees1)\n\n\n\n\n\n\n\n\n\n\n\n26.20.3 bs引数でsplineの種類を指定する\n以下の例では、1973年のNYの大気汚染データ（airquality）のうち、オゾン量（Ozone）を目的変数、日照（Solar.R）、風量（Wind）、気温（Temp）、5月1日からの日数（days）を説明変数とするGAMの計算を行っています。\n\n\n\nairqualityのデータをGAMで計算\n\npacman::p_load(mgcv)\n\naq &lt;- airquality |&gt; mutate(days = 1:nrow(airquality)) # 前準備\n\n# GAMの演算\nresult_gam &lt;- gam(Ozone ~ s(Solar.R) + s(Wind) + s(Temp) + s(days), data = aq)\n\npar(mfrow = c(2,2))\nplot(result_gam, select = 1);plot(result_gam, select = 2)\nplot(result_gam, select = 3);plot(result_gam, select = 4)\n\n\n\n\n\n\n\n\n\n上の結果では、daysの回帰結果がほぼ一定に見えます。つまり、daysはOzoneにほとんど影響を与えていないように見えます。このような説明変数は、GLMのモデル選択やスパース回帰では取り除かれる可能性があります。\nGAMの結果にstep関数によるモデル選択を適用することはできません。gamでは、step関数の代わりに、s関数内で引数を指定することにより、モデル選択ができるようにしています。\ns関数のbs引数は通常splineの手法を指定するための引数です。bs=\"cr\"でcubic regression spline、bs=\"tp\"でthin plate regression splineを指定することができます（tensor product splineにはsとは別の関数が準備されています。後ほど説明します）。bs引数に指定可能な手法は?smooth.terms（もしくはこちらのページ）にまとめられています。また、cubic regression splineを選択した場合には、knotの位置をknot引数で設定することもできます（thin plate regression splineを用いる場合には原理的にknotを設定する必要がありません）。\nこのbs引数に指定できる手法のうちには、「shrinkageが可能な手法」、というものが含まれています。このshrinkageというのは、s関数の結果をほぼ0とする、つまりスパース回帰のように説明変数を取り除くことができるようにすることを意味します。shrinkageが可能な手法は\"cs\"（cubic regression splineでshrinkage可能な手法）と\"ts\"（thin plate regression splineでshrinkage可能な手法）の2つです。s関数内でbs=\"cs\"もしくはbs=\"ts\"を指定することで、その説明変数が目的変数に影響を与えていない場合には説明変数からある程度取り除くことができます。\nただし、step関数やスパース回帰のようには説明変数をうまく取り除けないので、AICなどを用いたモデル選択も行うことになります。lmやglmと同じく、AIC関数の引数にgamの返り値を取ることでAICを計算することができます。\n同様に、bs引数にはcyclicな、始めと終わりの値が同じとなるsplineを指定することもできます。代表的なcyclicな方法は\"cc\"（cubic regression splineのcyclic版）です。時系列などで、ある一定の時期ごとに同じ値に戻るような場合には、bs=\"cc\"と指定することでより単純で分かりやすいモデルを選択することができます。\n\n\n\nshrinkage可能な手法を用いる\n\nresult_gam2 &lt;- \n  gam(\n    Ozone ~ \n      s(Solar.R, bs = \"ts\") + \n      s(Wind, bs = \"ts\") + \n      s(Temp, bs = \"ts\") + \n      s(days, bs = \"ts\"), \n    data = aq)\n\nplot(result_gam, select = 4) # daysは残っているが、0付近に集まる\n\n\n\n\n\n\n\n\n\n# tsのモデルの方がわずかにAICが小さい\nAIC(result_gam)\n## [1] 962.579\nAIC(result_gam2)\n## [1] 962.2856\n\n\n\n26.20.4 s関数に2つの説明変数を含める\n上記の例では、s関数それぞれに説明変数を設定していましたが、s関数には2つ以上の説明変数を同時に設定することもできます。下の例では、3つの説明変数をs関数の引数に指定しています。このように指定することで、多次元のスプラインを用いてGAMの計算を行うことができます。\nまた、このように複数の説明変数を一度にスプライン回帰する場合には、tensor product splineを用いることで計算コストを小さくすることができます。tensor product splineを用いる場合には、s関数の代わりに、te関数を用います。\nただし、summary関数の結果を見るとわかる通り、複数の説明変数を用いたスプラインを作成すると、結果の解釈はより難しくなる傾向があります。\n\n\n\n複数の説明変数を用いたスプライン\n\n# thin plate regression splineで複数の説明変数を加える\ngam_trees2 &lt;- gam(Volume ~ s(Girth, Height, k = 4), data = trees)\n\n# tensor product splineで複数の説明変数のsplineを作成\ngam_trees3 &lt;- gam(Volume ~ te(Girth, Height), data = trees)\n\nsummary(gam_trees2)\n## \n## Family: gaussian \n## Link function: identity \n## \n## Formula:\n## Volume ~ s(Girth, Height, k = 4)\n## \n## Parametric coefficients:\n##             Estimate Std. Error t value            Pr(&gt;|t|)    \n## (Intercept)   30.171      0.636   47.44 &lt;0.0000000000000002 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Approximate significance of smooth terms:\n##                  edf Ref.df     F             p-value    \n## s(Girth,Height) 2.85  2.977 211.6 &lt;0.0000000000000002 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## R-sq.(adj) =  0.954   Deviance explained = 95.8%\n## GCV = 14.316  Scale est. = 12.538    n = 31\nsummary(gam_trees3)\n## \n## Family: gaussian \n## Link function: identity \n## \n## Formula:\n## Volume ~ te(Girth, Height)\n## \n## Parametric coefficients:\n##             Estimate Std. Error t value            Pr(&gt;|t|)    \n## (Intercept)  30.1710     0.4865   62.02 &lt;0.0000000000000002 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Approximate significance of smooth terms:\n##                  edf Ref.df     F             p-value    \n## te(Girth,Height)   3      3 359.3 &lt;0.0000000000000002 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## R-sq.(adj) =  0.973   Deviance explained = 97.6%\n## GCV = 8.4231  Scale est. = 7.3362    n = 31\n\n# thin plate regression splineでAICが最も小さい\nAIC(gam_trees) # thin plate regression spline\n## [1] 155.4276\nAIC(gam_trees2) # thin plate regression spline（複数の説明変数をs関数に含める）\n## [1] 171.9544\nAIC(gam_trees3) # tensor product spline\n## [1] 155.4692\n\n\n\n\n26.20.5 ペナルティの調整\nペナルティを調整する場合には、gamma引数を指定します。gamma引数のデフォルトは1で、大きくするとより滑らかな、小さくするとより曲がりくねった結果が得られます。教科書(S. N. Wood 2017)では、このgammaを1.4に指定するのがよいとされていますので、デフォルトのgam関数ではやや曲がりくねった結果を得られやすいことになります。\n\n\n\nペナルティをgammaで調整する\n\n# gammaを1.4に指定する\nresult_gam3 &lt;- \n  gam(\n    Ozone ~ \n      s(Solar.R) + s(Wind) + s(Temp), \n    data = aq,\n    gamma = 1.4)\n\n# gammaを0.1に指定する\nresult_gam4 &lt;- \n  gam(\n    Ozone ~ \n      s(Solar.R) + s(Wind) + s(Temp), \n    data = aq,\n    gamma = 0.1)\n\n# 左（gamma = 1.4）は滑らか、右（gamma = 0.1）は曲がりくねった結果になる\npar(mfrow = c(1, 2))\nplot(result_gam3, select = 1)\nplot(result_gam4, select = 1)\n\n\n\n\n\n\n\n\n\n\n\n26.20.6 by引数\ns関数内ではby引数に説明変数を設定することができます。例えばAが目的変数、BとCが説明変数の場合に、gam(A~s(B, by=C))と設定すると、数式モデルとしては以下のように、Bによるスプライン回帰にCを掛けた形での回帰を行うことになります。\n\\[A=f(B) \\cdot C + \\epsilon\\]\nf(x)はスプライン回帰の式を示します。このby引数の使い方はわかりにくいのですが、例えば地域ごとの経済状況を非線形回帰する場合に、国によって施策が異なり、国境線を境に大きく経済状況が異なる場合、その施策の有り・無しを1と0の説明変数としてby引数に設定すれば、施策の効果を評価した上での回帰を行うことができます。\n\n\n\nby引数を設定して評価する\n\nresult_gam7 &lt;- \n  gam(\n    Ozone ~ \n      s(Solar.R, by = days), \n    data = aq)\n\n\n\n\n26.20.7 predict関数で予測する\nlmやglmと同様に、gamでもpredict関数により結果の予測値を出力することができます。predict関数の使い方もlmやglmと類似していて、回帰のオブジェクト（gamオブジェクト）と予測したいデータを含むデータフレームを引数に取ります。また、標準誤差は引数にse.fit=TRUEと設定することで計算することができます。\n\n\n\npredict関数での予測\n\nresult_gam2d &lt;- \n  gam(\n    Ozone ~ \n      s(Solar.R) + s(Wind), \n    data = aq)\n\nd &lt;- \n  expand.grid(\n    Solar.R = seq(7, 334, by = 1),\n    Wind = seq(1.7, 20.7, by = 0.1)\n  )\n\npredict(result_gam2d, d) |&gt; head(5) # ベクターが返ってくる\n##        1        2        3        4        5 \n## 99.11914 99.27418 99.42922 99.58426 99.73930\n\nd.pred &lt;- cbind(d, pred = predict(result_gam2d, d))\n\n# 回帰結果は曲面として得られる（下の図は点の集合になっている）\nd.pred |&gt; \n  plotly::plot_ly(\n    x = ~Solar.R, y=~Wind, z=~pred, size=0.1, color=~pred\n  )\n\n\n\n\n\n\n加法モデルについては、こちらの東京大学の資料も参考になりますので、一読されるとよいでしょう。\n\n\n26.20.8 一般化加法混合モデル（GAMM）\n線形モデルに対して線形混合モデル、一般化線形モデルに対して一般化線形混合モデルがあるように、一般化加法モデルに対しては一般化加法混合モデル（Generalized Additive Mixed Model、GAMM）があります。\n一般化線形混合モデルではlme4やlmerTestなどのライブラリが必要でしたが、GAMMはmgcvパッケージのgam関数を用いて計算することができます。\ngam関数内では、ランダム効果となる説明変数をs関数内で宣言し、bs=\"re\"を引数として設定します。lmerTestのように|を使ってランダム効果を設定する必要はありません。\nGAMMについては論文(Pedersen et al. 2019)に詳しく記載されていますので、一読されることをおすすめいたします。\n\n\n\n一般化加法混合モデル：GAMM\n\n# Pedersen et al. (2019)に記載の例 https://peerj.com/articles/6876/#supplemental-information\nCO2 |&gt; head(5)\n## Grouped Data: uptake ~ conc | Plant\n##   Plant   Type  Treatment conc uptake\n## 1   Qn1 Quebec nonchilled   95   16.0\n## 2   Qn1 Quebec nonchilled  175   30.4\n## 3   Qn1 Quebec nonchilled  250   34.8\n## 4   Qn1 Quebec nonchilled  350   37.2\n## 5   Qn1 Quebec nonchilled  500   35.3\n\nplot(CO2)\n\n\n\n\n\n\n\n\n\nCO2 &lt;- transform(CO2, Plant_uo = factor(Plant, ordered = FALSE))\n\nCO2_modG &lt;- \n  gam(\n    log(uptake) ~ \n      s(log(conc), k = 5, bs = \"tp\") + \n      s(Plant_uo, k = 12, bs = \"re\"), # reはランダム効果\n    data = CO2, \n    method = \"REML\", \n    family = \"gaussian\")\n\n結果の表示にはgratiaパッケージ(Simpson 2024)を用いてみます。gratiaはgamの結果をggplot2ベースのグラフにしてくれるライブラリです。\n\n\n\nGAMMの結果をプロットする\n\npacman::p_load(gratia) # グラフをggplot2準拠にするパッケージ\ndraw(CO2_modG) # concの効果をプロット\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n図1：ランダム切片とランダム傾き\n図：Excelで6次の多項式回帰で線を引く\n\n\n\nBates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015. “Fitting Linear Mixed-Effects Models Using lme4.” Journal of Statistical Software 67 (1): 1–48. https://doi.org/10.18637/jss.v067.i01.\n\n\nBürkner, Paul-Christian. 2017. “brms: An R Package for Bayesian Multilevel Models Using Stan.” Journal of Statistical Software 80 (1): 1–28. https://doi.org/10.18637/jss.v080.i01.\n\n\n———. 2018. “Advanced Bayesian Multilevel Modeling with the R Package brms.” The R Journal 10 (1): 395–411. https://doi.org/10.32614/RJ-2018-017.\n\n\n———. 2021. “Bayesian Item Response Modeling in R with brms and Stan.” Journal of Statistical Software 100 (5): 1–54. https://doi.org/10.18637/jss.v100.i05.\n\n\nFriedman, Jerome, Robert Tibshirani, and Trevor Hastie. 2010. “Regularization Paths for Generalized Linear Models via Coordinate Descent.” Journal of Statistical Software 33 (1): 1–22. https://doi.org/10.18637/jss.v033.i01.\n\n\nFritsch, Stefan, Frauke Guenther, and Marvin N. Wright. 2019. Neuralnet: Training of Neural Networks. https://CRAN.R-project.org/package=neuralnet.\n\n\nHadfield, Jarrod D. 2010. “MCMC Methods for Multi-Response Generalized Linear Mixed Models: The MCMCglmm R Package.” Journal of Statistical Software 33 (2): 1–22. https://www.jstatsoft.org/v33/i02/.\n\n\nKaratzoglou, Alexandros, Alex Smola, and Kurt Hornik. 2023. Kernlab: Kernel-Based Machine Learning Lab. https://CRAN.R-project.org/package=kernlab.\n\n\nKaratzoglou, Alexandros, Alex Smola, Kurt Hornik, and Achim Zeileis. 2004. “Kernlab – an S4 Package for Kernel Methods in R.” Journal of Statistical Software 11 (9): 1–20. https://doi.org/10.18637/jss.v011.i09.\n\n\nKnudson, Christina. 2022. Glmm: Generalized Linear Mixed Models via Monte Carlo Likelihood Approximation. https://CRAN.R-project.org/package=glmm.\n\n\nKuznetsova, Alexandra, Per B. Brockhoff, and Rune H. B. Christensen. 2017. “lmerTest Package: Tests in Linear Mixed Effects Models.” Journal of Statistical Software 82 (13): 1–26. https://doi.org/10.18637/jss.v082.i13.\n\n\nLiland, Kristian Hovde, Bjørn-Helge Mevik, and Ron Wehrens. 2023. Pls: Partial Least Squares and Principal Component Regression. https://CRAN.R-project.org/package=pls.\n\n\nPedersen, Eric J, David L Miller, Gavin L Simpson, and Noam Ross. 2019. “Hierarchical Generalized Additive Models in Ecology: An Introduction with Mgcv.” PeerJ 7: e6876.\n\n\nPinheiro, José C., and Douglas M. Bates. 2000. Mixed-Effects Models in s and s-PLUS. New York: Springer. https://doi.org/10.1007/b98882.\n\n\nPinheiro, José, Douglas Bates, and R Core Team. 2023. Nlme: Linear and Nonlinear Mixed Effects Models. https://CRAN.R-project.org/package=nlme.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz Marbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2023. GGally: Extension to ’Ggplot2’. https://CRAN.R-project.org/package=GGally.\n\n\nSimon, Noah, Jerome Friedman, Robert Tibshirani, and Trevor Hastie. 2011. “Regularization Paths for Cox’s Proportional Hazards Model via Coordinate Descent.” Journal of Statistical Software 39 (5): 1–13. https://doi.org/10.18637/jss.v039.i05.\n\n\nSimpson, Gavin L. 2024. gratia: Graceful ggplot-Based Graphics and Other Functions for GAMs Fitted Using mgcv. https://gavinsimpson.github.io/gratia/.\n\n\nStan Development Team. 2023. “RStan: The R Interface to Stan.” https://mc-stan.org/.\n\n\nTay, J. Kenneth, Balasubramanian Narasimhan, and Trevor Hastie. 2023. “Elastic Net Regularization Paths for All Generalized Linear Models.” Journal of Statistical Software 106 (1): 1–31. https://doi.org/10.18637/jss.v106.i01.\n\n\nTeam, Stan Development. 2023. Stan Modeling Language Users Guide and Reference Manual (version 2.33). https://mc-stan.org.\n\n\nVenables, W. N., and B. D. Ripley. 2002. Modern Applied Statistics with s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nWand, Matt. 2023. KernSmooth: Functions for Kernel Smoothing Supporting Wand & Jones (1995). https://CRAN.R-project.org/package=KernSmooth.\n\n\nWood, S. N. 2017. Generalized Additive Models: An Introduction with r. 2nd ed. Chapman; Hall/CRC.\n\n\nWood, S. N. 2003. “Thin-Plate Regression Splines.” Journal of the Royal Statistical Society (B) 65 (1): 95–114.\n\n\n———. 2004. “Stable and Efficient Multiple Smoothing Parameter Estimation for Generalized Additive Models.” Journal of the American Statistical Association 99 (467): 673–86.\n\n\n———. 2011. “Fast Stable Restricted Maximum Likelihood and Marginal Likelihood Estimation of Semiparametric Generalized Linear Models.” Journal of the Royal Statistical Society (B) 73 (1): 3–36.\n\n\nWood, S. N., N., Pya, and B. S\"afken. 2016. “Smoothing Parameter and Model Selection for General Smooth Models (with Discussion).” Journal of the American Statistical Association 111: 1548–75.\n\n\n大森敏明. 2015. “使える!統計検定・機械学習-v : 回帰問題への機械学習的アプローチ : スパース性に基づく回帰モデリング.” システム／制御／情報 59 (4): 151–56. https://doi.org/10.11509/isciesci.59.4_151.\n\n\n川野秀一. 2017. “スパース正則化に基づく回帰モデリングとその計算アルゴリズム.” 計算機統計学 30 (2): 173–86. https://doi.org/10.20551/jscswabun.30.2_173.",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>相関と回帰</span>"
    ]
  },
  {
    "objectID": "chapter26.html#footnotes",
    "href": "chapter26.html#footnotes",
    "title": "26  相関と回帰",
    "section": "",
    "text": "かなり端折って説明しています。スパース回帰については、文献(大森敏明 2015; 川野秀一 2017)をご参考下さい↩︎",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>相関と回帰</span>"
    ]
  },
  {
    "objectID": "chapter27.html",
    "href": "chapter27.html",
    "title": "27  分類",
    "section": "",
    "text": "27.1 サポートベクターマシン\nサポートベクターマシン（support vector machine、SVM）はデータの境界線をうまく回帰し、その線を分類に用いる手法です。SVMでは、データの境界線に平行で、かつ2つの群のデータに接する平行線を引き（下図左の赤線）、この平行線の幅（下図右の青線の長さ）が最大となるような境界線を求めます。\nただし、実際のデータでは群のデータが混じっていて、線形で分離できないようなこともあるため、ペナルティ等をもう少し複雑な形で与えて境界線を計算することになります。\nRでは、サポートベクターマシンを含めた色々な機械学習の手法がe1071パッケージ (Meyer et al. 2023)により提供されています。\nSVM：e1071ライブラリの読み込み\n\npacman::p_load(e1071)",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>分類</span>"
    ]
  },
  {
    "objectID": "chapter27.html#サポートベクターマシン",
    "href": "chapter27.html#サポートベクターマシン",
    "title": "27  分類",
    "section": "",
    "text": "図2：SVMのイメージ（左：点と接する平行線（赤線）、右：平行線の幅（青線））\n\n\n\n\n\n27.1.1 訓練データとテストデータ\n教師あり学習の機械学習を用いる場合には、まずデータを訓練データとテストデータに分けるのが一般的です。これは前章の部分的最小二乗回帰（PLS）の項で説明したものと同じです。\n訓練データとテストデータを分ける場合には、sample関数を利用してランダムにデータの行を選ぶのが一般的です。\n\n\n\n訓練データとテストデータに分ける\n\nset.seed(0)\ntest_v &lt;- sample(nrow(iris), 25, replace=F) # ランダムに行を選ぶ \ntest_v &lt;- test_v[order(test_v)]\ntest_v # テストデータにする行\n##  [1]   7  14  21  33  34  35  37  43  51  68  70  73  74  79  84  85  89 105 106\n## [20] 110 126 129 141 142 150\n\ntrain.iris &lt;- iris[-test_v, -3:-4] # 訓練データ（125行）\ntest.iris &lt;- iris[test_v, -3:-4] # テストデータ（25行）\n\n\n\n\n\n\n\n\ntidymodelsパッケージでのデータ準備\n\n\n\n\n\n機械学習のデータを取り扱いやすくするためのパッケージであるtidymodels (Kuhn and Wickham 2020)には、データを訓練データとテストデータに分ける専用の関数が準備されています。tidymodelsの使い方にはやや癖があり、学習コストが高めですが、覚えれば様々な機械学習をより簡単に実装できるようになります。\n\npacman::p_load(tidymodels)\n\niris_split &lt;- initial_split(iris, prop = 125/150) # 分け方を指定\ntrain.iris2 &lt;- training(iris_split) # 訓練データ（125行）\ntest.iris2 &lt;- testing(iris_split) # テストデータ（25行）\n\ndim(train.iris2) # 125行のデータフレーム\n## [1] 125   5\n\ndim(test.iris2) # 25行のデータフレーム\n## [1] 25  5\n\n\n\n\nRでサボートベクターマシンを実行する場合には、e1071パッケージのsvm関数を用います。svm関数の使い方はlmとよく似ていて、目的とする分類（因子）を目的変数としたformulaと、データフレーム（data）の2つを引数に取ります。以下の例では、irisデータを用いて、アヤメの種（Species）を予測する分類モデルを訓練データを用いてサポートベクターマシンで作成しています。\n\n\n\nsvm関数で分類器を準備する\n\n# 訓練データでサポートベクターマシンを計算（.は目的変数以外の変数すべてを指す）\nmodel.g &lt;- svm(Species ~ ., data = train.iris) # デフォルトはガウスカーネル\n\n\nサポートベクターマシンは予測を行うための分類器ですので、計算結果をそのまま用いてもあまり意味がありません。svm関数の返り値を用いて、テストデータの分類を予測する場合には、predict関数を用います。\n以下のように、テストデータと、テストデータからpredict関数で予測した値を比較すると、少し間違いはありますが、概ね正しいSpeciesが予測されていることがわかります。予測にはirisの1行目と2行目しか用いていないため精度が低めですが、もっと多くの説明変数を用いれば分類の精度をもう少し上げることもできます。\n\n\n\nSVMでテストデータを用いて予測する\n\n# predict関数で予測結果を求める\npred_svm &lt;- predict(model.g, test.iris)\n\n# 実際の種と予測した種を比較する（上が実際のデータ、下が予測）\ndata.frame(test.iris$Species, pred_svm) |&gt; t()\n##                   7        14       21       33       34       35      \n## test.iris.Species \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\"\n## pred_svm          \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\"\n##                   37       43       51           68           70          \n## test.iris.Species \"setosa\" \"setosa\" \"versicolor\" \"versicolor\" \"versicolor\"\n## pred_svm          \"setosa\" \"setosa\" \"virginica\"  \"versicolor\" \"versicolor\"\n##                   73           74           79           84          \n## test.iris.Species \"versicolor\" \"versicolor\" \"versicolor\" \"versicolor\"\n## pred_svm          \"virginica\"  \"versicolor\" \"versicolor\" \"versicolor\"\n##                   85           89           105         106         110        \n## test.iris.Species \"versicolor\" \"versicolor\" \"virginica\" \"virginica\" \"virginica\"\n## pred_svm          \"versicolor\" \"versicolor\" \"virginica\" \"virginica\" \"virginica\"\n##                   126         129         141         142         150         \n## test.iris.Species \"virginica\" \"virginica\" \"virginica\" \"virginica\" \"virginica\" \n## pred_svm          \"virginica\" \"virginica\" \"virginica\" \"virginica\" \"versicolor\"\n\n\n\n\n27.1.2 カーネル変換サポートベクターマシン\nサポートベクターマシンの基本は図2に示したように、直線で群を分ける方法です。しかし、データによっては群を直線では分けられない場合もあります。このような場合に、SVMではカーネル変換というものを利用して、群を曲線的に分けることができるようにしています。\nRのsvm関数では、このカーネル変換の手法として、ガウスカーネル（kernel=\"radial\"、デフォルトのカーネル）、直線（kernel=\"linear\"）、多項式カーネル（kernel=\"polynomial\"）、シグモイドカーネル（kernel=\"sigmoid\"）の4種類を用いることができます。カーネルの種類はkernel引数で指定します。\nカーネルの選び方によってSVMの予測精度が変化します。train.irisを用いた下記の例では直線カーネルでの精度が高くなっていることがわかります。\n\n\n\nカーネル変換SVM\n\n# カーネルごとの違いを調べる\nmodel.l &lt;- svm(Species ~ ., data = train.iris, kernel = \"linear\") # 直線\nmodel.p &lt;- svm(Species ~ ., data = train.iris, kernel = \"polynomial\") # 多項式\nmodel.s &lt;- svm(Species ~ ., data = train.iris, kernel = \"sigmoid\") # シグモイド\n\n# 正答率\nd.test &lt;- data.frame(\n  type = c(\"ガウス\", \"直線\", \"多項式\", \"シグモイド\"),\n  accuracy = c(\n    sum(predict(model.g, test.iris) == test.iris$Species) / 25,\n    sum(predict(model.l, test.iris) == test.iris$Species) / 25,\n    sum(predict(model.p, test.iris) == test.iris$Species) / 25,\n    sum(predict(model.s, test.iris) == test.iris$Species) / 25\n  )\n)\n\nknitr::kable(d.test)\n\n\n\n\n\ntype\naccuracy\n\n\n\n\nガウス\n0.88\n\n\n直線\n0.92\n\n\n多項式\n0.76\n\n\nシグモイド\n0.88\n\n\n\n\n\n各カーネルでの分類の境界線を示したものが、以下のグラフとなります。直線カーネルのみ分類の境界が直線で、その他のカーネル（ガウス、多項式、シグモイド）では分類の境界が曲線となっていることがわかります。\n\n\n\n\n\n\n作図のスクリプト\n\n\n\n\n\n\n# 分類の境界線を表示\nd.mat &lt;- expand.grid(\n  Sepal.Length = seq(min(iris$Sepal.Length), max(iris$Sepal.Length), by = 0.01), \n  Sepal.Width = seq(min(iris$Sepal.Width), max(iris$Sepal.Width), by = 0.01))\n\nd.mat.g &lt;- cbind(d.mat, Species = predict(model.g, d.mat))\nd.mat.l &lt;- cbind(d.mat, Species = predict(model.l, d.mat))\nd.mat.p &lt;- cbind(d.mat, Species = predict(model.p, d.mat))\nd.mat.s &lt;- cbind(d.mat, Species = predict(model.s, d.mat))\n\npg &lt;- ggplot() +\n  geom_point(data = iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +\n  geom_raster(\n    data = d.mat.g,\n    aes(x = Sepal.Length, y = Sepal.Width, fill = Species),\n    alpha = 0.2\n  ) +\n  theme_light() + theme(legend.position = \"none\") + labs(title = \"ガウスカーネル\")\npl &lt;- ggplot() +\n  geom_point(data = iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +\n  geom_raster(\n    data = d.mat.l,\n    aes(x = Sepal.Length, y = Sepal.Width, fill = Species),\n    alpha = 0.2\n  ) +\n  theme_light() + theme(legend.position = \"none\") + labs(title = \"直線カーネル\")\npp &lt;- ggplot() +\n  geom_point(data = iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +\n  geom_raster(\n    data = d.mat.p,\n    aes(x = Sepal.Length, y = Sepal.Width, fill = Species),\n    alpha = 0.2\n  ) +\n  theme_light() + theme(legend.position = \"none\") + labs(title = \"多項式カーネル\")\nps &lt;- ggplot() +\n  geom_point(data = iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +\n  geom_raster(\n    data = d.mat.s,\n    aes(x = Sepal.Length, y = Sepal.Width, fill = Species),\n    alpha = 0.2\n  ) +\n  theme_light() + theme(legend.position = \"none\") + labs(title = \"シグモイドカーネル\")\n\ngrid.arrange(pg, pl, pp, ps)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nカーネル変換\n\n\n\n\n\nカーネル変換とは、データの写像というものを利用し、元来直線的には分類できないようなデータを写像上で直線的に分類できるようにする手法のことです。写像のイメージとしては、2次元のデータに1次元足して3次元にしているようなものだと思って頂ければよいかと思います。2次元で分離できないものも、1次元追加することで直線（面）で分類できるようになります。この写像の計算の仕方がkernel引数で指定しているものとなります。",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>分類</span>"
    ]
  },
  {
    "objectID": "chapter27.html#ナイーブベイズ",
    "href": "chapter27.html#ナイーブベイズ",
    "title": "27  分類",
    "section": "27.2 ナイーブベイズ",
    "text": "27.2 ナイーブベイズ\nナイーブベイズは、古くからMicrosoftのメーラーであるOutlookなどで迷惑メール（Spam）を通常のメール（Ham）と分類するのに用いられてきた分類器です。ナイーブベイズでは、メール文に含まれる文字列（単語など）に対して、学習から得られた各単語がSpamに含まれる確率とHamに含まれる確率を掛け算して、そのメール文がSpamである確率とHamである確率を計算します。Spamである確率がHamである確率より高ければSpam、そうでなければHamと判断します。\nナイーブベイズでは上記の通り、単語がSpamに含まれる確率とHamに含まれる確率をあらかじめ学習する必要があります。ですので、Ham/Spamであることが判別しているメール文が学習データとして必要となります。\nRでナイーブベイズを用いる場合には、e1071パッケージのnaiveBayes関数を用います。\n以下にRでSpamとHamを見分ける場合のナイーブベイズのスクリプトを記載します。メールのデータには、Githubで提供されているHam/Spamメールのデータセットを用いています。\n\n\n\n\n\n\n文字列を処理する\n\n\n\n\n\nナイーブベイズに限らず、文字列を訓練データとした機械学習は増えています。ChatGPTなどのAIも、入力した文書を分類器などのアルゴリズムに代入し、予測値として回答を返す形となっていると思われます。ただし、文字列には余計な文字（例えばスペースや記号、日本語のような粘着語では助詞など）がたくさん含まれており、そのまま分類器に与えることはできません。\nですので、文字列を用いた機械学習を行う際には、文字列を取り扱うための専用のライブラリやソフトウェアを用いて文字列の前処理を行う必要があります。\n今回の例のように英語であれば、Rのパッケージ（以下に示すtm (Feinerer, Hornik, and Meyer 2008)やSnowballC (Bouchet-Valat 2023)など）を用いて文字列をコーパス（単語のまとまり）にまとめたり、そのコーパスの数を数えたりすることができます。日本語であれば、MeCab（形態素分析という、単語で区切って品詞のラベルをつけるためのツール、RからはRMeCabパッケージ(Ishida and Kudo 2023)を用いて使用できる）などを用いた前処理を必要とします。\n前処理を行った文字列のデータと、Ham/Spamのラベルを組み合わせて分類器の学習を行います。新規のメールの分類では、やはり文字列を同様に前処理した上で分類器に与え、Ham/Spamの判定を行うことになります。\n以下に、前処理のコードを示します。かなり複雑ですが、この流れでナイーブベイズの訓練データ・テストデータを作成することができます。\n\n\n\nナイーブベイズ：文字列の前処理\n\n# 文字列の操作を行うためのライブラリ\npacman::p_load(tm, SnowballC)\n\n# SMS Spam Collection Datasetをロード（kaggleから拾ってくる）\nsns &lt;- read.csv(\"./data/spam.csv\", stringsAsFactors = F, encoding = 'UTF-8')\nsns &lt;- sns[,1:2]\ncolnames(sns) &lt;- c(\"type\", \"text\")\n\n# 文字列をコーパスに変換\ndata_corpus &lt;- VCorpus(VectorSource(sns$text))\n\n# データのクリーニング\nclean_corpus &lt;- tm_map(data_corpus, removeWords,stopwords(kind = \"english\")) # 英語以外の文字を取り除く\nclean_corpus &lt;- tm_map(clean_corpus, stripWhitespace) # 複数のスペースを1つに変換\nclean_corpus &lt;- tm_map(clean_corpus, content_transformer(tolower)) # 大文字を小文字に変換\nclean_corpus &lt;- tm_map(clean_corpus, removePunctuation) # 句読点を取り除く\nclean_corpus &lt;- tm_map(clean_corpus, removeNumbers) # 数字を取り除く\nclean_corpus &lt;- tm_map(clean_corpus, stemDocument) # stem化をする（pay, paid, payingなどをpayに統一）\n\ndados_dtm &lt;- DocumentTermMatrix(clean_corpus) # termと文章を行列にする\n# dados_dtmの中身、行はsnsのテキスト、列は単語、数字が入っていると単語が含まれる\ninspect(dados_dtm[1:5, 1:8]) \n## &lt;&lt;DocumentTermMatrix (documents: 5, terms: 8)&gt;&gt;\n## Non-/sparse entries: 0/40\n## Sparsity           : 100%\n## Maximal term length: 11\n## Weighting          : term frequency (tf)\n## Sample             :\n##     Terms\n## Docs ��� aah aaniy aaooooright aathi aathilov abbey abdomen\n##    1   0   0     0           0     0        0     0       0\n##    2   0   0     0           0     0        0     0       0\n##    3   0   0     0           0     0        0     0       0\n##    4   0   0     0           0     0        0     0       0\n##    5   0   0     0           0     0        0     0       0\n\n# 訓練データとテストデータに分ける\ndata_dtm_train &lt;- dados_dtm[1:4169, ]\ndata_dtm_test &lt;- dados_dtm[4170:5559, ]\n\n# ラベルは別途分ける\ndata_train_labels &lt;- sns[1:4169, ]$type\ndata_test_labels &lt;- sns[4170:5559, ]$type\n\n# スパム/ハムの割合を表示（大体87%ハムで同じ）\nprop.table(table(data_train_labels))\n## data_train_labels\n##       ham      spam \n## 0.8644759 0.1355241\nprop.table(table(data_test_labels))\n## data_test_labels\n##       ham      spam \n## 0.8705036 0.1294964\n\n# 5回以上見つかったWordのみ拾う\nsms_freq_words &lt;- findFreqTerms(data_dtm_train, 5)\n\n# 5文字以上見つかったWordだけを学習・テストデータに使う\nsms_dtm_freq_train &lt;- data_dtm_train[ , sms_freq_words]\nsms_dtm_freq_test &lt;- data_dtm_test[ , sms_freq_words]\n\n# 文字があるかないかの2値に変換する関数\nconvert_counts &lt;- function(x){\n  x &lt;- ifelse(x &gt; 0, \"Yes\", \"No\")\n}\n\n# 数値データをYes/Noのデータに変換\nsms_train &lt;- apply(sms_dtm_freq_train, MARGIN = 2, convert_counts)\nsms_test &lt;- apply(sms_dtm_freq_test, MARGIN = 2, convert_counts)\n\n\n\n\n\nナイーブベイズの分類器を作成するための関数であるnaiveBayesは、訓練データとラベルのベクターを引数に取ります（formulaで訓練データとラベルを与えることもできます）。分類器からの予測には、predict関数を用います。十分な学習データがあれば、かなり高い精度でHam/Spamを分類することができます。\n\n\n\nナイーブベイズでの学習と予測\n\n# ナイーブベイズで学習\nnb_classifier &lt;- naiveBayes(sms_train, data_train_labels)\n\n# テストデータで予測\nsms_test_pred &lt;- predict(nb_classifier, sms_test)\n\n# 検証したデータで、スパム/ハムが見分けられている\ndata_test_labels[21:30]\n##  [1] \"ham\"  \"ham\"  \"ham\"  \"ham\"  \"ham\"  \"spam\" \"ham\"  \"spam\" \"spam\" \"spam\"\nsms_test_pred[21:30] %&gt;% as.character()\n##  [1] \"ham\"  \"ham\"  \"ham\"  \"ham\"  \"ham\"  \"spam\" \"ham\"  \"spam\" \"spam\" \"spam\"\n\n# 正答率は97.8%ぐらい\nsum(sms_test_pred == data_test_labels)/1390\n## [1] 0.9776978",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>分類</span>"
    ]
  },
  {
    "objectID": "chapter27.html#決定木",
    "href": "chapter27.html#決定木",
    "title": "27  分類",
    "section": "27.3 決定木",
    "text": "27.3 決定木\n決定木（decision tree）は弱分類器と呼ばれる、非常に単純な線形分類器（例えば、x＞0のときはA、x&lt;=0のときはBなど）を組み合わせて、複雑な分類を行う手法（アンサンブル学習）です。\n\n\n\n図3：決定木のイメージ\n\n\n決定木は、弱分類器の組み合わせの選び方のアルゴリズムによって、バギングとブースティングと呼ばれる2つの手法に大別されています。これらのうち、バギングと呼ばれるものの一種がランダムフォレスト（Random Forest）と呼ばれる手法です。ランダムフォレストは21世紀初頭から用いられており、優秀な分類器として長く使われています。もう一つのブースティングについては2015年頃から良いアルゴリズムがいくつか開発されており、分類性能の非常に高い分類器として用いられています。\n\n27.3.1 ランダムフォレスト\nランダムフォレストは、ランダムに決定木による分類器をたくさん生成し、その平均や多数決の結果を最終的な分類器とする方法です。Rでランダムフォレストを利用する場合には、randomForestパッケージ(Liaw and Wiener 2002)のrandomForest関数を用います。randomForest関数の使い方はlm関数やsvm関数とほぼ同じで、第一引数にformulaを取ります。予測にpredict関数を用いるところもsvmと同じです。\nランダムフォレストによる分類では、分類の境界は基本的に縦横に配置されます。これは、上記のようにランダムフォレストが決定木の組み合わせからなる分類器であるためです。\n\n\n\nランダムフォレストによる分類\n\n## ランダムフォレスト\npacman::p_load(randomForest)\nrf.iris &lt;- randomForest(Species ~ ., data = train.iris)\npredict(rf.iris, test.iris)\n##          7         14         21         33         34         35         37 \n##     setosa     setosa     setosa     setosa     setosa     setosa     setosa \n##         43         51         68         70         73         74         79 \n##     setosa  virginica  virginica versicolor  virginica versicolor versicolor \n##         84         85         89        105        106        110        126 \n##  virginica     setosa versicolor  virginica  virginica  virginica  virginica \n##        129        141        142        150 \n##  virginica versicolor versicolor versicolor \n## Levels: setosa versicolor virginica\n\n# 正答率\nsum(predict(rf.iris, test.iris) == test.iris$Species) / 25\n## [1] 0.68\n\n# 分類の境界線を記述\nd.mat.rf &lt;- cbind(d.mat, Species = predict(rf.iris, d.mat))\nggplot()+\n  geom_point(data = iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +\n  geom_raster(data = d.mat.rf, aes(x = Sepal.Length, y = Sepal.Width, fill = Species), alpha = 0.2) +\n  theme_light() + theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n27.3.2 ブースティング\nブースティングも決定木の一種ですが、分類器をランダムに生成するのではなく、決定木を少しずつ変化させ最適化するような手法です。ブースティングは以前はそれほど用いられてはいませんでしたが、勾配ブースティングと呼ばれる改良化されたアルゴリズムが開発されてから非常に分類精度の高い手法としてよく用いられています。\nブースティングのアルゴリズムには、昔からあるAdaboostや、2015年以降に開発されたXGBoost、LightGBM、CatBoost等があります。特に2015年以降に開発された後者の分類性能は高いとされています。\nRではAdaboostはJOUSBoostパッケージ (Olson 2017)、XGBoostはxgboostパッケージ (Chen et al. 2023)、LightGBMはlightgbmパッケージ (Shi et al. 2024)、CatBoostはcatboostパッケージ (Prokhorenkova et al. 2017)を用いることで利用できます。ただし、catboostにはPythonのライブラリが必要となるので、Rでは使用の難易度が高めです。\n以下に、XGBoostを利用した分類の例を示します。説明変数となるデータが少なく、モデルの最適化も行っていないため、上記のランダムフォレストと同程度の精度（0.64）となっています。\n\n\n\nXGBoostでの分類器の生成\n\n## ブースティング（XGboost）\npacman::p_load(xgboost)\n\n# xgboostパッケージでは、テストデータをdgCMatrixというクラスに変換する必要がある\nxg.train.iris &lt;- Matrix::sparse.model.matrix(Species ~ . + 0, data = train.iris)\nxg.test.iris &lt;- Matrix::sparse.model.matrix(Species ~ . + 0, data = test.iris)\n\n# ラベルは数値しか受け付けない\nlabel &lt;- train.iris$Species %&gt;% as.numeric - 1\n\n# 全然最適化されていない訓練\nxg.iris &lt;- xgboost(\n  data = xg.train.iris, \n  label = label,\n  nround = 5, # 計算の繰り返し回数\n  num_class = 3, # 分類するクラスの数\n  objective = \"multi:softmax\") # 3値分類以上だとこの形にする。2値なら\"binary:logistic\"を指定\n## [1]  train-mlogloss:0.856284 \n## [2]  train-mlogloss:0.704538 \n## [3]  train-mlogloss:0.598684 \n## [4]  train-mlogloss:0.518844 \n## [5]  train-mlogloss:0.456383\n\n\n\n\n\nXGBoostで生成した分類器での予測\n\n# 予測結果と正答率\nsp &lt;- c(\"setosa\", \"versicolor\", \"virginica\")\nsum(sp[predict(xg.iris, xg.test.iris) + 1] == test.iris$Species)/25\n## [1] 0.64\n\n\n\n\n\nXGBoostでの予測の境界線\n\n# 分類の境界線を記述\nxg.d.mat &lt;- Matrix::sparse.model.matrix(Species ~ . + 0, data = cbind(Species = 0, d.mat))\nd.mat.xg &lt;- cbind(d.mat, Species = sp[predict(xg.iris, xg.d.mat) + 1])\nggplot()+\n  geom_point(data = iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +\n  geom_raster(data = d.mat.xg, aes(x = Sepal.Length, y = Sepal.Width, fill = Species), alpha = 0.2) +\n  theme_light() + theme(legend.position = \"none\")",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>分類</span>"
    ]
  },
  {
    "objectID": "chapter27.html#ニューラルネットワーク",
    "href": "chapter27.html#ニューラルネットワーク",
    "title": "27  分類",
    "section": "27.4 ニューラルネットワーク",
    "text": "27.4 ニューラルネットワーク\n前の章でも紹介したニューラルネットワークは、分類でも用いられる機械学習の手法です。目的変数にカテゴリカルデータを用いる点が回帰とは異なります。\nRでは、回帰と同様にneuralnetパッケージのneuralnet関数を用いてニューラルネットワークでの分類器を作成することができます。neuralnet関数で分類を行う際にはformulaの目的変数の設定が特殊で、(列名=='ラベル')の形で分類するカテゴリを示し、各カテゴリを+でつなぎます。具体的には以下のformulaのように指定します。\n\n\n\nneuralnet：分類を行う際のformulaの設定\n\nformula_iris &lt;- \n  as.formula(\n    # 上の行がラベル、下の行が説明変数\n    \"(Species == 'setosa') + (Species == 'versicolor') +  (Species == 'virginica') ~ \n      Sepal.Length + Sepal.Width\"\n  )\n\n\nneuralnet関数の使い方は回帰の際と同じです。引数として、formula、data、hidden（隠れ層、中間層）、act.fct（活性化関数）を指定します。\nhiddenの指定では、3個のパーセプトロンを2層の場合にはhidden=c(3,3)、2個のパーセプトロンを3層の場合にはhidden=c(2,2,2)とベクターを用いて示します。活性化関数には\"logistic\"（ソフトマックス関数）か\"tanh\"（Hyperbolic tangent）のどちらかを指定します。\n計算した分類器をplot関数の引数に取ることで、重みとバイアスをグラフで表示することができます。\n\n\n\nneuralnet：分類を行う際のformulaの設定\n\npacman::p_load(neuralnet)\n\nset.seed(2)\n\nnn.iris &lt;- neuralnet(\n  formula = formula_iris,\n  data = train.iris,\n  hidden = c(3, 2),\n  act.fct = \"logistic\"\n)\nplot(nn.iris, rep = \"best\")\n\n\n\n\n\n\n\n\n\nneuralnetでの予測にも、predict関数を用います。引数がneuralnet関数の返り値とテストデータのデータフレームである点も、回帰と同じです。ただし、分類の予測は確率として表示されます。各行のうち最も値が高い、つまり確率が高いものが分類結果となります。以下の例では、1列目がsetosa、2列目がversicolor、3列目がvirginicaである確率となります。\n\n\n\nneuralnet：予測\n\n# 予測は確率で出てくる\npred.test &lt;- predict(nn.iris, test.iris)\npred.test |&gt; head()\n##         [,1]          [,2]          [,3]\n## 7  1.0007861 -0.0001940386 -0.0005022254\n## 14 1.0007861 -0.0001940386 -0.0005022254\n## 21 0.9880775 -0.0067728564  0.0187861514\n## 33 1.0007861 -0.0001940386 -0.0005022254\n## 34 1.0007861 -0.0001940386 -0.0005022254\n## 35 1.0007861 -0.0001940386 -0.0005022254\n\n\n結果を種名に変更し、正答率を計算したのが以下のスクリプトです。88%とそこそこの正答率となっています。また、分類の境界線はやや不自然ですが、基本的に直線的な部分が多い曲線で構成されています。ただしニューラルネットワークの境界部分での確率はなだらかに変化しています。例えば、青と緑の境界では、青の確率50％ぐらい、緑の確率50％ぐらいとなっています。\n\n\n\nneuralnet：確率を種に変換\n\npred.sp &lt;- numeric(nrow(pred.test))\nfor(i in 1:nrow(pred.test)){\n  pred.sp[i] &lt;- (pred.test[i,] %&gt;% max == pred.test[i,]) %&gt;% sp[.]\n}\nsum(pred.sp == test.iris$Species)/25\n## [1] 0.88\n\n\n\n\n\nneuralnet：分類の境界線\n\npred.mat &lt;- predict(nn.iris, d.mat)\npred.mat2 &lt;- numeric(nrow(pred.mat))\nfor(i in 1:nrow(pred.mat)){\n  pred.mat2[i] &lt;- (pred.mat[i,] %&gt;% max == pred.mat[i,]) %&gt;% sp[.]\n}\n\nd.mat.nn &lt;- cbind(d.mat, Species = pred.mat2)\nggplot()+\n  geom_point(data = iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species))+\n  geom_raster(data = d.mat.nn, aes(x = Sepal.Length, y = Sepal.Width, fill = Species), alpha = 0.2)+\n  theme_light() + theme(legend.position = \"none\") \n\n\n\n\n\n\n\n\n\n\n\n\nneuralnet：分類の境界線/計算結果をそのまま表示\n\npred.mat &lt;- predict(nn.iris, d.mat) |&gt; scale()\ncolnames(pred.mat) &lt;- c(\"setosa\", \"versicolor\", \"virginica\")\n\nd.mat.nn &lt;- cbind(d.mat, pred.mat)\n\npacman::p_load(patchwork)\n\np1 &lt;- ggplot()+\n  geom_raster(data = d.mat.nn, aes(x = Sepal.Length, y = Sepal.Width, fill = -setosa), alpha = 0.5)+ \n  scale_fill_distiller(palette = \"Reds\")+\n  geom_point(data = iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species))+\n  theme_light()+\n  theme(legend.position = \"none\") + \n  labs(title = \"setosa\")\n\np2 &lt;- ggplot()+\n  geom_raster(data = d.mat.nn, aes(x = Sepal.Length, y = Sepal.Width, fill = -versicolor), alpha = 0.5)+\n  scale_fill_distiller(palette = \"Greens\")+\n  geom_point(data = iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species))+\n  theme_light() + theme(legend.position = \"none\") + labs(title = \"versicolor\")\n  \np3 &lt;- ggplot()+\n  geom_raster(data = d.mat.nn, aes(x = Sepal.Length, y = Sepal.Width, fill = -virginica), alpha = 0.5)+\n  scale_fill_distiller(palette = \"Blues\")+\n  geom_point(data = iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species))+\n  theme_light() + theme(legend.position = \"none\") + labs(title = \"virginica\")\n\np1 + p2 + p3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n図2：SVMのイメージ（左：点と接する平行線（赤線）、右：平行線の幅（青線））\n図3：決定木のイメージ\n\n\n\nBouchet-Valat, Milan. 2023. SnowballC: Snowball Stemmers Based on the c ’Libstemmer’ UTF-8 Library. https://CRAN.R-project.org/package=SnowballC.\n\n\nChen, Tianqi, Tong He, Michael Benesty, Vadim Khotilovich, Yuan Tang, Hyunsu Cho, Kailong Chen, et al. 2023. Xgboost: Extreme Gradient Boosting. https://CRAN.R-project.org/package=xgboost.\n\n\nFeinerer, Ingo, Kurt Hornik, and David Meyer. 2008. “Text Mining Infrastructure in r.” Journal of Statistical Software 25 (5): 1–54. https://doi.org/10.18637/jss.v025.i05.\n\n\nIshida, Motohiro, and Taku Kudo. 2023. RMeCab: Interface to MeCab.\n\n\nKuhn, Max, and Hadley Wickham. 2020. Tidymodels: A Collection of Packages for Modeling and Machine Learning Using Tidyverse Principles. https://www.tidymodels.org.\n\n\nLiaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” R News 2 (3): 18–22. https://CRAN.R-project.org/doc/Rnews/.\n\n\nMeyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2023. E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien. https://CRAN.R-project.org/package=e1071.\n\n\nOlson, Matthew. 2017. JOUSBoost: Implements Under/Oversampling for Probability Estimation. https://CRAN.R-project.org/package=JOUSBoost.\n\n\nProkhorenkova, Liudmila, Gleb Gusev, Aleksandr Vorobev, Anna Veronika Dorogush, and Andrey Gulin. 2017. “CatBoost: Unbiased Boosting with Categorical Features.” https://arxiv.org/abs/1706.09516.\n\n\nShi, Yu, Guolin Ke, Damien Soukhavong, James Lamb, Qi Meng, Thomas Finley, Taifeng Wang, et al. 2024. Lightgbm: Light Gradient Boosting Machine. https://CRAN.R-project.org/package=lightgbm.",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>分類</span>"
    ]
  },
  {
    "objectID": "chapter28.html",
    "href": "chapter28.html",
    "title": "28  教師なし学習",
    "section": "",
    "text": "28.1 クラスタリング\nクラスタリングとは、1つの要素にたくさんのデータが付随している、多次元データを用いて、要素間が互いに似ているかどうかを判断し、互いに似ているもの同士を一つのグループにまとめる方法です。類似した要素のまとまりを見つけるときに用いられます。\n「1つの要素にたくさんのデータ」というのはイメージしにくいかもしれませんが、例えば、ある個人について付随しているデータを考えると、年齢、性別、身長、体重、職業、趣味など、1人にたくさんのデータがくっついてきます。ある個人Aさんと別の個人Bさんでは、異なるデータがくっついていることになります。AさんとBさんの属性が似ているかどうかは、そのデータがどれぐらい似ているかを調べればわかります。このように1人あたりのデータがたくさんある状態のことを多次元データであると考えることができます。\n多次元データがどの程度似ているのかを表現できれば、個々人が似ている・似ていないを判断することができ、似ている人をグループとして分けることができます。この似ている人同士をグループにすることがクラスタリングに当たります。\nクラスタリングするときに、似ているものから順番に線でつないでいく方法のことを階層ありクラスタリング、似ているものを大まかにグループ分けする方法を階層なしクラスタリングと呼びます。",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>教師なし学習</span>"
    ]
  },
  {
    "objectID": "chapter28.html#階層ありクラスタリング",
    "href": "chapter28.html#階層ありクラスタリング",
    "title": "28  教師なし学習",
    "section": "28.2 階層ありクラスタリング",
    "text": "28.2 階層ありクラスタリング\n\n28.2.1 距離行列\n階層ありクラスタリングとは、多次元データ間の距離を計算することで、個々のデータについて似ている度合いを評価し、評価に従って似ているものからクラスターに分けていく手法のことです。まずは、データを距離行列に変換する必要があります。\n距離行列とは、たくさんあるデータとデータの距離を行列としてまとめたものです。最も単純な距離行列は2つのデータの直線距離（ユークリッド距離）です。\n距離行列についてイメージしやすいように、まずは、都道府県の県庁所在地の緯度・経度のデータを用いて距離行列を計算します。都道府県の緯度経度情報はGithub Gistのページからダウンロードしています。\n簡便化のために、関西の都道府県のみを用います。緯度・経度から、関西の都道府県は下のグラフに示すように位置していることがわかります。この時、各県から別の県までの直線距離をそれぞれ求めることができます。これを行列にまとめたのが距離行列です。Rでは、dist関数というものを用いて、緯度・経度のデータからユークリッド距離の距離行列を求めることができます。\n\n\n\nデータの準備\n\nkansai &lt;- read.csv(\"./data/pref_lat_lon.csv\", header = T, fileEncoding = \"CP932\")\n\n# 関西の都道府県データのみ取得する\nkansai &lt;- kansai[24:30, ]\nkansai # 各県の緯度と経度\n##    pref_name      lat      lon\n## 24    三重県 34.73055 136.5086\n## 25    滋賀県 35.00453 135.8686\n## 26    京都県 35.02100 135.7531\n## 27    大阪府 34.68649 135.5190\n## 28    兵庫県 34.69128 135.1831\n## 29    奈良県 34.68530 135.8327\n## 30  和歌山県 34.22481 135.1679\n\nggplot(\n  kansai, \n  aes(x = lon, y = lat, color = pref_name, label = pref_name)) + \n  geom_text() # 県庁所在地の位置\n\n\n\n\n\n\n\n\n\n\n\n\nデータを距離行列に変換\n\n# ユークリッド距離（数値は24から順に三重、滋賀、京都、大阪、兵庫、奈良、和歌山）\ndist(kansai[, 2:3], method=\"euclidean\") \n##           24        25        26        27        28        29\n## 25 0.6962011                                                  \n## 26 0.8094045 0.1166423                                        \n## 27 0.9905981 0.4726170 0.4082964                              \n## 28 1.3261045 0.7536832 0.6585157 0.3359391                    \n## 29 0.6773781 0.3212419 0.3450157 0.3137553 0.6496856          \n## 30 1.4328793 1.0482682 0.9880967 0.5799866 0.4667195 0.8087048\n\n\n上の例では緯度・経度の2つのデータから距離行列を計算していますが、もっとたくさんの列があるデータにおいても同様に距離行列を計算することができます。また、距離行列には、距離の計算の仕方によってさまざまな種類のものがあります。距離としてよく用いられるものは、ユークリッド距離（2点間の直線の距離）とマンハッタン距離（2点間を移動するときの横と縦の移動距離を足したもの）の2つです。\nこの距離行列を用いて、距離が近いもの同士をクラスターにまとめていくものが、階層ありクラスタリング（hierarchical clustering）です。\n\nユークリッド距離最大距離マンハッタン距離キャンベラ距離バイナリ距離ミンコフスキー距離\n\n\n\n# ユークリッド距離\n#（軸の数値は24から順に三重、滋賀、京都、大阪、兵庫、奈良、和歌山）\ndist(kansai[, 2:3], method = \"euclidean\") \n##           24        25        26        27        28        29\n## 25 0.6962011                                                  \n## 26 0.8094045 0.1166423                                        \n## 27 0.9905981 0.4726170 0.4082964                              \n## 28 1.3261045 0.7536832 0.6585157 0.3359391                    \n## 29 0.6773781 0.3212419 0.3450157 0.3137553 0.6496856          \n## 30 1.4328793 1.0482682 0.9880967 0.5799866 0.4667195 0.8087048\n\n\n\n\n# 縦と横の距離の最大値を取る\ndist(kansai[, 2:3], method = \"maximum\") \n##           24        25        26        27        28        29\n## 25 0.6400220                                                  \n## 26 0.7554965 0.1154745                                        \n## 27 0.9896180 0.3495960 0.3345042                              \n## 28 1.3255230 0.6855010 0.5700265 0.3359050                    \n## 29 0.6758650 0.3192360 0.3357002 0.3137530 0.6496580          \n## 30 1.3406600 0.7797260 0.7961902 0.4616860 0.4664740 0.6647950\n\n\n\n\n# マンハッタン距離\ndist(kansai[, 2:3], method = \"manhattan\") \n##           24        25        26        27        28        29\n## 25 0.9140070                                                  \n## 26 1.0459457 0.1319387                                        \n## 27 1.0336730 0.6676360 0.5686257                              \n## 28 1.3647900 0.9987530 0.8997427 0.3406930                    \n## 29 0.7211160 0.3550790 0.4153317 0.3149490 0.6556420          \n## 30 1.8464010 1.4803640 1.3813537 0.8127280 0.4816110 1.1252850\n\n\n\n\n# キャンベラ距離\n#（原点近くの距離を大きく見積もる、2点の距離を原点からの距離の絶対値の和で割る）\ndist(kansai[, 2:3], method = \"canberra\")\n##             24          25          26          27          28          29\n## 25 0.006278704                                                            \n## 26 0.006938945 0.000660247                                                \n## 27 0.004272575 0.005851752 0.005661734                                    \n## 28 0.005444405 0.007023602 0.006833586 0.001309879                        \n## 29 0.003133566 0.004712733 0.005109133 0.001173500 0.002483376            \n## 30 0.012269091 0.013847973 0.013657932 0.007996570 0.006824715 0.009135586\n\n\n\n\n# バイナリ距離（距離が0なら1、0でなければ0を返す）\ndist(kansai[, 2:3], method = \"binary\") \n##    24 25 26 27 28 29\n## 25  0               \n## 26  0  0            \n## 27  0  0  0         \n## 28  0  0  0  0      \n## 29  0  0  0  0  0   \n## 30  0  0  0  0  0  0\n\n\n\n\n# ミンコフスキー距離\n#（ユークリッドとマンハッタンの中間的なもの、pという引数を別途取る。pのデフォルトは2）\ndist(kansai[, 2:3], method = \"minkowski\") \n##           24        25        26        27        28        29\n## 25 0.6962011                                                  \n## 26 0.8094045 0.1166423                                        \n## 27 0.9905981 0.4726170 0.4082964                              \n## 28 1.3261045 0.7536832 0.6585157 0.3359391                    \n## 29 0.6773781 0.3212419 0.3450157 0.3137553 0.6496856          \n## 30 1.4328793 1.0482682 0.9880967 0.5799866 0.4667195 0.8087048\n\n\n\n\n\n\n28.2.2 Rでの階層ありクラスタリング\nRでは、この階層ありクラスタリングをhclust関数を用いて行います。hclust関数の第一引数は距離行列で、上に述べた通りdist関数を用いて計算できるものです。method引数には、クラスタリングの方法を選択します。クラスタリングの方法は、\"complete\"（デフォルト）、\"ward.D\"、\"ward.D2\"、\"single\"、\"average\"、\"mcquitty\"、\"median\"、\"centroid\"の8つから選択します。\nこの、hclust関数の返り値をplotすることで、クラスタリングの結果を確認することができます。hclust関数の返り値自体を確認することはあまりないため、基本的にはplotして使うものだと考えてもらうとよいと思います。plot関数において、hang引数を-1に指定すると、クラスタリングする要素の下端をそろえることができます。\nplot関数で表示されるのは、より近いもの同士も線でつないだ樹形上の図です。線でつながった距離が近いほど、データがよく似ていることを示しています。上記の都道府県の緯度・経度でクラスタリングを行うと、距離の近さとクラスタリングの図上の近さが対応しているのがわかるかと思います。\n\n下揃えなし下揃えあり\n\n\n\n\n\n階層ありクラスタリング\n\nJPll &lt;- read.csv(\"./data/pref_lat_lon.csv\", header = T, row.names = 1, fileEncoding = \"CP932\")\nhc &lt;- hclust(dist(JPll), method = \"complete\") # 引数は距離行列\nplot(hc) # 樹形図の作図\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n階層ありクラスタリング：下を揃える\n\nplot(hc, hang = -1)",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>教師なし学習</span>"
    ]
  },
  {
    "objectID": "chapter28.html#階層なしクラスタリング",
    "href": "chapter28.html#階層なしクラスタリング",
    "title": "28  教師なし学習",
    "section": "28.3 階層なしクラスタリング",
    "text": "28.3 階層なしクラスタリング\n階層ありクラスタリングでは、距離の近いデータ同士をつなぐため、各データのクラスタの近さは厳密に計算されています。一方で、この方法では距離行列を必ず計算する必要があり、データが増えると計算回数がどんどん増えていきます。\nデータ同士の距離ではなく、「クラスターの中心」を定め、この中心からの距離が近いものを同じクラスターであるとしてグループ分けする方法のことを階層なしクラスタリングと呼びます。こちらの方法であれば、計算回数はクラスター数に依存するため、データが増えても大きくは計算回数が増えず、比較的単純な計算でグループ分けを行うことができます。一方で、厳密にデータ間の距離を計算しているわけではないので、階層ありクラスタリングのように細かなデータの類似性を評価することはできません。\nこの階層なしクラスタリングの最も代表的なものが、k-mean法です。",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>教師なし学習</span>"
    ]
  },
  {
    "objectID": "chapter28.html#k-means",
    "href": "chapter28.html#k-means",
    "title": "28  教師なし学習",
    "section": "28.4 k-means",
    "text": "28.4 k-means\nk-means法では、あらかじめ乱数に従い「クラスターの中心」を設定します。このクラスターの中心の数は解析する人が設定する必要があります。次に、このクラスターの中心からの距離が近いデータを、そのクラスターのデータであるとします。この仮のクラスターができたら、次にクラスター内のデータの重心を求めます。重心が定まったら、この重心を新しい「クラスターの中心」として、クラスターの中心の位置を更新します。\nこのクラスターの中心を重心に更新する試行を、重心が移動しなくなるまで繰り返した時のクラスター内のデータをクラスターのメンバーとします。言葉ではわかりにくいので、以下にk-meansによるクラスタリングの図を示します。また、こちらのリンク、もしくはこのWebアプリケーションを見ていただくと、k-meansをよりイメージしやすいかと思います。WebアプリケーションはRで、if(!require(shiny)){install.packages(\"shiny\")};runGitHub(\"kmeans_animated\", \"sb8001at\")を実行することでも利用することができます。\n\n\n\n\n\n\nk-mean：下グラフ描画のスクリプト\n\n\n\n\n\n\nset.seed(0)\n\n# データにはirisのがく片データを使用\ndata &lt;- iris[, 1:2]\ncolnames(data) &lt;- c(\"x\", \"y\")\n\n# クラスターの中心の初期値\ncenter_means &lt;- \n  data.frame(\n    x = rnorm(3, mean(data[ ,1]), sd(data[ ,1])), \n    y = rnorm(3, mean(data[ ,2]), sd(data[ ,2])),\n    clus = 1:3)\n\n# アウトプットを保存する変数\ndata_for_gganimate &lt;- NULL\n\nfor(i in 1:20){ # おそらくi=16ぐらいで収束している\n  \n  # 各中心からの距離の計算\n  dist_d &lt;- data.frame(\n    dist_1 = (data$x - center_means[1, 1]) ^ 2 + (data$y - center_means[1, 2]) ^ 2,\n    dist_2 = (data$x - center_means[2, 1]) ^ 2 + (data$y - center_means[2, 2]) ^ 2,\n    dist_3 = (data$x - center_means[3, 1]) ^ 2 + (data$y - center_means[3, 2]) ^ 2\n  )\n  \n  # 最も近いクラスターを探す\n  min_dist &lt;- apply(dist_d, 1, min)\n  \n  clus &lt;- \n    case_when(\n      dist_d$dist_1 == min_dist ~ 1,\n      dist_d$dist_2 == min_dist ~ 2,\n      dist_d$dist_3 == min_dist ~ 3,\n    )\n  \n  # グラフ用データを準備\n  data_temp &lt;- data.frame(data, clus, xcenter = center_means[clus,]$x, ycenter = center_means[clus,]$y, timestate = 2 * i - 1)\n  \n  data_for_gganimate &lt;- rbind(data_for_gganimate, data_temp)\n  \n  # 重心でクラスターの中心を更新する\n  center_means2 &lt;- data_temp |&gt; group_by(factor(clus)) |&gt; summarise(x = mean(x), y = mean(y))\n  center_means$x &lt;- center_means2$x\n  center_means$y &lt;- center_means2$y\n    \n  # グラフ用データを準備\n  data_temp &lt;- data.frame(data, clus, xcenter = center_means[clus,]$x, ycenter = center_means[clus,]$y, timestate = 2 * i)\n  \n  data_for_gganimate &lt;- rbind(data_for_gganimate, data_temp)\n}\n\npacman::p_load(gganimate)\n\n# gganimateでグラフ化\np &lt;- ggplot()+\n  geom_point(data = data_for_gganimate, aes(x = x, y = y, color = factor(clus), size = 2), alpha = 0.5) +\n  geom_point(data = data_for_gganimate, aes(x = xcenter, y = ycenter, color = factor(clus), size = 3), alpha = 0.7)+\n  geom_segment(data = data_for_gganimate, aes(x = x, y = y, xend = xcenter, yend = ycenter, color = factor(clus)), alpha = 0.5)+\n  theme(legend.position = \"none\")+\n  transition_states(timestate, transition_length = 1, state_length = 1, wrap = TRUE)+\n  ease_aes('linear')\n\nanim_save(\"./image/p_kmeans.gif\", animate(p, renderer = gifski_renderer()))\n\n\n\n\n\nRではk-meansでのクラスタリングをkmeans関数を用いて行うことができます。kmeans関数の引数はデータフレームとクラスターの数（centers）です。以下の例では、irisのデータを3つのクラスターに分けています。k-meansのクラスター中心の初期値は乱数で決められますので、クラスターの結果は計算のたびに少しずつ変化します。また、初期値を特定の値としてcenters引数に行列で与えることもできます。\n\n\n\nkmeans関数でクラスタリング\n\n## k-means\nset.seed(0) # k-meansは乱数計算なので、シードを設定\nk.cent3 &lt;- kmeans(iris[ ,1:4], centers = 3) # 3つのクラスタに分ける\nk.cent3$cluster # 計算結果\n##   [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n##  [38] 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n##  [75] 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 1 1 1 1 3 1 1 1 1\n## [112] 1 1 3 3 1 1 1 1 3 1 3 1 3 1 1 3 3 1 1 1 1 1 3 1 1 1 1 3 1 1 1 3 1 1 1 3 1\n## [149] 1 3\n\n\n\n\n\nクラスターの中心を指定\n\nk.cents &lt;- kmeans(iris[ ,1:4], centers = iris[c(1, 51, 101), 1:4]) # 初期値を各種の始めの値に設定\nk.cents$cluster\n##   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n##  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n##  [75] 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 3 3 3 3 2 3 3 3 3\n## [112] 3 3 2 2 3 3 3 3 2 3 2 3 2 3 3 2 2 3 3 3 3 3 2 3 3 3 3 2 3 3 3 2 3 3 3 2 3\n## [149] 3 2\n\n\n以下では、k-meansでクラスター分けしたデータと、irisのSpeciesの関係を示しています。k-meansでクラスター分けした結果がSpeciesとほぼ重なることを確認できます。\n\n\n\nクラスターとirisの種の比較\n\nspvec &lt;- iris$Species |&gt; levels()\n\nk.cent3$cluster &lt;- k.cent3$cluster - 1\nk.cent3$cluster &lt;- if_else(k.cent3$cluster == 0, 3, k.cent3$cluster)\n\ncbind(iris, cluster = spvec[k.cent3$cluster]) |&gt; \n  gather(tag, value, 5:6) |&gt; \n  ggplot(aes(x = Sepal.Length, y = Sepal.Width, color = value))+\n    geom_point(size = 3)+\n    facet_wrap(~ tag)",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>教師なし学習</span>"
    ]
  },
  {
    "objectID": "chapter28.html#c-means",
    "href": "chapter28.html#c-means",
    "title": "28  教師なし学習",
    "section": "28.5 c-means",
    "text": "28.5 c-means\nc-means法はfuzzy c-means法とも呼ばれる、クラスターへの所属を確率で求める手法です。c-means法もk-means法と同じく、データとクラスターの距離をもとにクラスタリングを行う手法の一つです。Rでは、c-means法の計算をe1071パッケージ (Meyer et al. 2023)のcmeans関数で行うことができます。cmeans関数もkmeans関数と同様に、データフレームと中心の数（centers）を引数に取ります。クラスターの中心の初期値は行列で与えることもできます。\n\n\n\nc-means法\n\npacman::p_load(e1071)\n# クラスタリングの計算（中心を指定）\niris.c &lt;- cmeans(iris[,1:4], centers = iris[c(1, 51, 101), 1:4])\n\n# クラスターとirisの種の比較\ncbind(iris, cluster = spvec[iris.c$cluster]) |&gt;  \n  gather(tag, value, 5:6) |&gt; \n  ggplot(aes(x = Sepal.Length, y = Sepal.Width, color = value))+\n  geom_point(size = 3)+\n  facet_wrap(~ tag)\n## Warning: attributes are not identical across measure variables; they will be\n## dropped",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>教師なし学習</span>"
    ]
  },
  {
    "objectID": "chapter28.html#スペクトラルクラスタリング",
    "href": "chapter28.html#スペクトラルクラスタリング",
    "title": "28  教師なし学習",
    "section": "28.6 スペクトラルクラスタリング",
    "text": "28.6 スペクトラルクラスタリング\nスペクトラルクラスタリングは、上記のk-meansやc-meansのように、中心からの距離だけでは分離するのが難しいようなクラスタリングを行うときに有効な手法です。スペクトラルクラスタリングでは、近くにあるデータは同じクラスターに分類されやすくするようにアルゴリズムが組まれていて、k-meansやc-meansでは分離不能なクラスタをきれいに分けることができます。\nRではスペクトラルクラスタリングをkernlabパッケージ (Karatzoglou, Smola, and Hornik 2023; Karatzoglou et al. 2004)のspecc関数を用いて行うことができます。specc関数の使い方はkmeans関数やcmeans関数とほぼ同じで、データフレームとcentersを引数に取ります。また、返り値をplot関数の引数にすることで、簡単にクラスターをグラフにすることもできます。\n\n\n\nスペクトラルクラスタリング\n\npacman::p_load(kernlab)\n\n# データにはkernlabのspiralsを用いる\ndata(spirals)\nhead(spirals)\n##            [,1]        [,2]\n## [1,]  0.8123568 -0.98712687\n## [2,] -0.2675890 -0.32552004\n## [3,]  0.3739746 -0.01293652\n## [4,]  0.2576481  0.04130805\n## [5,] -0.8472613  0.32939461\n## [6,]  0.4097649  0.03205686\n\nsc &lt;- specc(spirals, centers = 2) # スペクトラルクラスタリング\nplot(spirals, col = sc) # 結果の表示（色がクラスターを示す）\n\n\n\n\n\n\n\n\n\nただし、このスペクトラルクラスタリングは必ずしも良いクラスタリングの方法ではなく、例えばirisのクラスタリングに用いると、3クラスターを指定しても、ほとんど2クラスターしか出てこなくなってしまいます。クラスター同士の距離が近く、接していると正しくクラスタリングできないようです。スペクトラルクラスタリングを用いる時にはデータの構造をよく確認する必要があります。\n\n\n\nirisでスペクトラルクラスタリング\n\n# 3クラスタとなるよう設定\nsc.iris &lt;- specc(iris[,1:4] |&gt; as.matrix(), centers = 3)\n\n# 結果に1がほとんどなく、ほぼ2クラスターになっている\nsc.iris@.Data \n##   [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n##  [38] 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n##  [75] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n## [112] 3 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n## [149] 3 3",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>教師なし学習</span>"
    ]
  },
  {
    "objectID": "chapter28.html#主成分分析",
    "href": "chapter28.html#主成分分析",
    "title": "28  教師なし学習",
    "section": "28.7 主成分分析",
    "text": "28.7 主成分分析\n主成分分析は、多次元のデータを第一主成分・第二主成分…という主成分にデータ変換する手法です。この第一主成分というのは、データを空間に配置したときに、ばらつきが最も大きくなる軸に沿った値を指します。このようにばらつきが最も大きくなる軸を選んで主成分とすることで、多次元のデータからデータの損失を抑えつつ、そのデータの特徴を残したようなパラメータに変換することができます。要は、多次元のデータだと特徴を捉えにくい場合においても、主成分に変換することでデータの特徴を捉えやすくすることができます。\n第二主成分は、第一主成分を定めた軸に垂直な面において、最もばらつきが多い軸に沿った値となります。第一主成分の軸と第二主成分の軸は互いに直行している、90度に交わっているので、第一主成分と第二主成分の相関はほぼゼロになります。この特徴のため、26章で説明した主成分回帰では説明変数同士が相関しているときに起こる問題、多重共線性を避けることができます。\n以下に、主成分分析の軸のイメージを示します。軸は互いに垂直に交わっているのがわかると思います。PC1を横に、PC2を縦になるように回転させたのが、下の第一主成分と第二主成分でのプロットのイメージとなります。\n\n\n\n\n\n\n主成分分析における主成分の軸のイメージ（スクリプト）\n\n\n\n\n\n\niris_temp &lt;- iris |&gt; filter(Species != \"setosa\") |&gt; _[ ,1:3]\niris.pc2 &lt;- prcomp(iris_temp)\n\npc1 &lt;- iris.pc2$x[ ,1]\npc2 &lt;- iris.pc2$x[ ,2]\npc3 &lt;- iris.pc2$x[ ,2]\ncenter1 &lt;- iris.pc2$center[1]\ncenter2 &lt;- iris.pc2$center[2]\ncenter3 &lt;- iris.pc2$center[3]\n\niris_temp$pc1_Sepal.Length &lt;- pc1 * iris.pc2$rotation[1, 1] + center1\niris_temp$pc1_Sepal.Width &lt;- pc1 * iris.pc2$rotation[2, 1] + center2\niris_temp$pc1_Petal.Length &lt;- pc1 * iris.pc2$rotation[3, 1] + center3\niris_temp$pc2_Sepal.Length &lt;- pc2 * iris.pc2$rotation[1, 2] + center1\niris_temp$pc2_Sepal.Width &lt;- pc2 * iris.pc2$rotation[2, 2] + center2\niris_temp$pc2_Petal.Length &lt;- pc2 * iris.pc2$rotation[3, 2] + center3\niris_temp$pc3_Sepal.Length &lt;- pc3 * iris.pc2$rotation[1, 3] + center1\niris_temp$pc3_Sepal.Width &lt;- pc3 * iris.pc2$rotation[2, 3] + center2\niris_temp$pc3_Petal.Length &lt;- pc3 * iris.pc2$rotation[3, 3] + center3\n\npacman::p_load(plotly)\n\nfig &lt;- \n  plot_ly(\n    iris_temp, \n    x =~ Sepal.Length, \n    y =~ Sepal.Width, \n    z =~ Petal.Length, \n    type = \"scatter3d\",\n    mode = \"markers\",\n    name = 'data',  \n    marker = list(size = 2)) |&gt; \n  add_trace(\n    x =~ pc1_Sepal.Length, \n    y =~ pc1_Sepal.Width, \n    z =~ pc1_Petal.Length, \n    type = \"scatter3d\", \n    mode = \"markers+lines\",\n    name = 'PC1', \n    marker = list(color = \"red\", size = 0.1),\n    line = list(color = \"red\", width = 5)) |&gt; \n  add_trace(\n    x =~ pc2_Sepal.Length, \n    y =~ pc2_Sepal.Width, \n    z =~ pc2_Petal.Length, \n    type = \"scatter3d\",\n    mode = \"markers+lines\",\n    name = 'PC2',\n    marker = list(color = \"red\", size = 0.1),\n    line = list(color = \"blue\", width = 5)) |&gt; \n  add_trace(\n    x =~ pc3_Sepal.Length, \n    y =~ pc3_Sepal.Width, \n    z =~ pc3_Petal.Length, \n    type = \"scatter3d\", \n    mode = \"markers+lines\",\n    name = 'PC3',\n    marker = list(color=\"red\", size=0.1),\n    line = list(color=\"green\", width=5))\n\nfig\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n主成分分析は、主成分回帰のようなデータの前処理の他に、次元を圧縮することでデータの類似性や違いを分かりやすく示す場合に用いられています。\n例えば、ヒトのDNAには無数のSNP（Single Nucleotide polymorphism、一塩基多型）があります。このSNPというのは、DNAの塩基が置き換わっているもの（例えば、AがCに代わっている）を指し、置き換わりが各個々人によって異なることを意味しています。私のDNAのある位置の塩基がAで、別の方ではCになっている、というように、多型を示すことがSNPです。ヒトのDNAの長さは大体3×109塩基あります。この長いDNAには、SNPが6000万個ぐらいあります。\nヒトを含め、分子系統樹と呼ばれる祖先からの遺伝子変化の流れを調べる場合には、近年ではこのSNPを指標に系統樹を書きます（以前はミトコンドリアDNAやリボソーム蛋白のDNAのSNPや反復配列の長さが使われていたような気がします）。もちろんこの6000万個のすべてのSNPを用いるわけではありませんが、通常取り扱うSNPは非常に多くなります。このたくさんあるSNPを用いて、例えば日本人と韓国人の違いを示すことを考えると、ひとつづつSNPを見て特徴を捉えていては、いつまでたっても違いはわかりません。このように、膨大なデータ（の次元）がある場合に、主成分分析は力を発揮します。膨大なデータを第一主成分と第二主成分に変換してしまえば、2次元のプロットを利用して日本人と韓国人の違いを表すことができます。ヒトの歴史的な移動に関して、このSNPと主成分分析を用いて論文が発表されています(Consortium 2012)。この論文を見ていただければわかる通り、主成分分析を用いれば膨大なSNPのデータを2次元に集約し、わかりやすい表現で説明することができます。\nただし、この第一主成分や第二主成分などの主成分が何を意味しているのかは、その時々によって異なりますし、理解が難しいことも多いです。「主成分が近いものは類似している」ぐらいの意味しかわからない場合もあると考えるとよいでしょう。\n\n28.7.1 Rで主成分分析\nRでは、prcomp関数で主成分分析の計算を行うことができます。prcomp関数は引数に行列やデータフレームを取ります。prcomp関数の返り値は各主成分方向の標準偏差（standard deviations）と、回転（Rotation）です。回転は、データを主成分に変換するときの係数を示します。\n\n\n\n主成分分析\n\niris.pc &lt;- prcomp(iris[ ,1:4])\n\niris.pc\n## Standard deviations (1, .., p=4):\n## [1] 2.0562689 0.4926162 0.2796596 0.1543862\n## \n## Rotation (n x k) = (4 x 4):\n##                      PC1         PC2         PC3        PC4\n## Sepal.Length  0.36138659 -0.65658877  0.58202985  0.3154872\n## Sepal.Width  -0.08452251 -0.73016143 -0.59791083 -0.3197231\n## Petal.Length  0.85667061  0.17337266 -0.07623608 -0.4798390\n## Petal.Width   0.35828920  0.07548102 -0.54583143  0.7536574\n\n\nprcomp関数の返り値をsummary関数の引数に取ると、標準偏差、分散の配分（Proportion of Variance）、積算の分配の配分（Cumulative Proportion）が示されます。このうち、分散の配分はその主成分によってばらつきをどれだけ説明できているかを示すものです。下の例では、PC1で92.5%程度のばらつきを示すことができている、つまり、PC1でデータの差を十分説明できていることがわかります。\n\n\n\nsummaryの結果\n\niris.pc |&gt; summary()\n## Importance of components:\n##                           PC1     PC2    PC3     PC4\n## Standard deviation     2.0563 0.49262 0.2797 0.15439\n## Proportion of Variance 0.9246 0.05307 0.0171 0.00521\n## Cumulative Proportion  0.9246 0.97769 0.9948 1.00000\n\n\n主成分分析では、Cumulative Proportionにもよりますが、第一主成分（PC1）と第二主成分（PC2）に変換したデータをプロットして、データの類似性などを示すことが一般的です。変換後の主成分は、$xで呼び出すことができます。以下のように、irisの種が同じ、つまりよく似たデータであれば、比較的近い位置に変換後のデータが集まるのがわかります。\n\n\n\n第一主成分と第二主成分をプロット\n\niris.pc &lt;- prcomp(iris[ ,1:4])\nirispcd &lt;- iris.pc$x |&gt; as.data.frame()\nirispcd$Species &lt;- iris$Species\nggplot(irispcd, aes(x = PC1, y = PC2, color = Species)) + geom_point(size = 2)",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>教師なし学習</span>"
    ]
  },
  {
    "objectID": "chapter28.html#因子分析",
    "href": "chapter28.html#因子分析",
    "title": "28  教師なし学習",
    "section": "28.8 因子分析",
    "text": "28.8 因子分析\n因子分析も主成分分析と同じく、多次元のデータをいくつかの因子に変換することで、データの性質を簡単に理解できるようにするための手法です。主成分分析との違いは、主成分分析では主成分の意味を理解するのが難しいのに対して、因子分析では因子の意味付けが比較的容易であること、因子間の相関は必ずしも0とはならないこと、主成分分析が射影の計算であるのにたいして、因子分析は回転の計算を行うことなどです。\nRでは、因子分析をfactanal関数を用いて行うことができます。以下の例では、鹿児島大学が成績サンプルデータとして提供しているデータを用いて因子分析を行っています。\nfactanal関数はデータフレームまたは行列を第一引数に取り、因子の数（factors）、回転の方法（rotation）、算出するスコアのタイプ（scores）を引数として設定して用います。\nfactorsには、出力として得たい因子の数を指定します。以下の例では、理系・文系科目の得意・不得意を評価する因子を作成するため、因子数を2としています。\nrotationには\"varimax\"か\"promax\"のどちらかを選択するのが一般的です。varimax回転はデータをそのまま回転させる方法（直交回転）、promax回転はデータの軸の角度を変換させて回転させる方法（斜交回転）です。promax回転では因子間に相関が生じるのが特徴です。\nscoresには計算して得られる数値（因子スコア）の計算方法を指定します。方法には\"none\"、\"Bartlett\"、\"regression\"のいずれかを選択します。\"none\"を指定するとスコアが算出されないので、\"Bartlett\"か\"regression\"のいずれかを選択します。\nfactanal関数の返り値のうち、Loadingが各データの寄与率を示す値となります。以下のvarimax変換の例では、Factor1（因子1）では数学、物理、化学、Factor2では国語、英語の値が高いため、Factor1は理系科目の、Factor2は文系科目の評価を反映していることがわかります。\n\n\n\n因子分析：バリマックス変換\n\nm1 &lt;- read.csv(\"./data/testresult.csv\", fileEncoding = \"CP932\")\nm1v &lt;- factanal(m1[ ,2:6], factors = 2, scores = \"Bartlett\") # varimax変換\nm1v\n## \n## Call:\n## factanal(x = m1[, 2:6], factors = 2, scores = \"Bartlett\")\n## \n## Uniquenesses:\n##  国語  英語  数学  物理  化学 \n## 0.005 0.436 0.171 0.191 0.279 \n## \n## Loadings:\n##      Factor1 Factor2\n## 国語         0.994  \n## 英語 0.362   0.658  \n## 数学 0.882   0.226  \n## 物理 0.893   0.109  \n## 化学 0.793   0.302  \n## \n##                Factor1 Factor2\n## SS loadings      2.343   1.575\n## Proportion Var   0.469   0.315\n## Cumulative Var   0.469   0.784\n## \n## Test of the hypothesis that 2 factors are sufficient.\n## The chi square statistic is 1.47 on 1 degree of freedom.\n## The p-value is 0.225\n\n\n同様にpromax回転での因子分析でも、Factor1が理系科目、Factor2が文系科目の成績を反映していることがわかります。ただし、寄与率はバリマックスとは異なり、Factor1での理系科目の寄与率もFactor2での文系科目の寄与率もvarimax回転より高いため、こちらの方がより理系度・文系度を反映していることがわかります。\n\n\n\n因子分析：プロマックス変換\n\nm1p &lt;- factanal(m1[,2:6], factors = 2, rotation = \"promax\", scores = \"Bartlett\") # promax変換\nm1p\n## \n## Call:\n## factanal(x = m1[, 2:6], factors = 2, scores = \"Bartlett\", rotation = \"promax\")\n## \n## Uniquenesses:\n##  国語  英語  数学  物理  化学 \n## 0.005 0.436 0.171 0.191 0.279 \n## \n## Loadings:\n##      Factor1 Factor2\n## 国語 -0.149   1.060 \n## 英語  0.239   0.607 \n## 数学  0.923         \n## 物理  0.964  -0.158 \n## 化学  0.806         \n## \n##                Factor1 Factor2\n## SS loadings      2.509   1.524\n## Proportion Var   0.502   0.305\n## Cumulative Var   0.502   0.807\n## \n## Factor Correlations:\n##         Factor1 Factor2\n## Factor1   1.000  -0.475\n## Factor2  -0.475   1.000\n## \n## Test of the hypothesis that 2 factors are sufficient.\n## The chi square statistic is 1.47 on 1 degree of freedom.\n## The p-value is 0.225\n\n\n以下に、varimax回転、promax回転それぞれでの因子のスコアをプロットした結果を示します。スコアは$scoresで呼び出すことができます。varimax回転でもpromax回転でも、概ね理系・文系科目の得意さを因子で評価できています。\n\nvarimax回転promax回転\n\n\n\nm1vs &lt;- m1v$scores |&gt; as.data.frame() # 計算したスコアをデータフレームに変換\nm1vs$student &lt;- 1:nrow(m1vs) # 生徒のIDを追加\n\nggplot(m1vs, aes(x = Factor1, y = Factor2, color = student, label = student))+\n  geom_text(size = 3)+\n  theme(legend.position = \"none\")+\n  labs(title = \"バリマックス回転\", x = \"理系度\", y = \"文系度\")\n\n\n\n\n\n\n\n\n\n\n\nm1ps &lt;- m1p$scores |&gt; as.data.frame()\nm1ps$student &lt;- 1:nrow(m1ps)\n\nggplot(m1ps, aes(x = Factor1, y = Factor2, color = student, label = student))+\n  geom_text(size = 3)+\n  theme(legend.position = \"none\")+\n  labs(title = \"プロマックス回転\", x = \"理系度\", y = \"文系度\")",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>教師なし学習</span>"
    ]
  },
  {
    "objectID": "chapter28.html#多次元尺度法",
    "href": "chapter28.html#多次元尺度法",
    "title": "28  教師なし学習",
    "section": "28.9 多次元尺度法",
    "text": "28.9 多次元尺度法\n多次元尺度法は主成分分析や因子分析とは少し異なる次元圧縮の方法です。多次元尺度法は、距離行列から互いの点の位置を求める、距離行列演算の逆のような変換を行う手法です。\n以下の例では、都道府県の県庁所在地の緯度・経度をdist関数で距離行列に変換し、距離行列を多次元尺度法で位置の情報に変換しています。\n\n\n\n緯度・経度を距離行列に変換\n\nJPD &lt;- read.csv(\"./data/pref_lat_lon.csv\", header = T, fileEncoding = \"CP932\")\n\nprefecture &lt;- JPD[,1] %&gt;% unlist()\nJPD &lt;- JPD[,-1] %&gt;% dist() # 距離行列を計算\n\n\nRでは多次元尺度法の計算をMASSパッケージのsammon関数を用いて行うことができます。sammon関数の引数は距離行列です。距離行列をsammon関数で変換すると、xとyという、位置を示す2つの変数が求まります。\n\npacman::p_load(MASS)\nJPpos &lt;- JPD |&gt; sammon() |&gt; _$points\n## Initial stress        : 0.00000\n## stress after  10 iters: 0.00000, magic = 0.500\nhead(JPpos)\n##           [,1]         [,2]\n## [1,] -8.669485 -3.467358210\n## [2,] -6.924994 -1.936485347\n## [3,] -6.649247 -0.774450379\n## [4,] -5.622341  0.266109548\n## [5,] -5.782950 -1.366731569\n## [6,] -5.181832  0.008206893\n\n以下に、sammon関数の返り値をプロットしたものを示します。xとyの単位はありませんが、都道府県の位置関係を正確に反映していることが見て取れると思います。ただし、距離行列には方角のデータが含まれていないため、東西南北の方向は回転したり反転したりすることになります。\n\n\n\n多次元尺度法の結果をプロットする\n\nJPpos &lt;- as.data.frame(JPpos)\ncolnames(JPpos) &lt;- c(\"x\", \"y\")\nJPpos$prefecture &lt;- prefecture\n\nggplot(JPpos, aes(x = -x, y = -y, label = prefecture, color = prefecture))+\n  geom_text(size = 3)+\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\ncmdscale関数を用いても多次元尺度法の計算を行うことができます。\n\n\n\ncmdscale関数で多次元尺度法\n\nJPpos2 &lt;- JPD %&gt;% cmdscale %&gt;% as.data.frame\ncolnames(JPpos2) &lt;-  c(\"x\", \"y\")\nJPpos2$prefecture &lt;- prefecture\n\nggplot(JPpos2, aes(x = x, y = y, label = prefecture, color = prefecture))+\n  geom_text(size = 3)+\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConsortium, Japanese Archipelago Human Population Genetics. 2012. “The History of Human Populations in the Japanese Archipelago Inferred from Genome-Wide SNP Data with a Special Reference to the Ainu and the Ryukyuan Populations.” Journal of Human Genetics 57 (12): 787–95. https://cir.nii.ac.jp/crid/1523106605673180672.\n\n\nKaratzoglou, Alexandros, Alex Smola, and Kurt Hornik. 2023. Kernlab: Kernel-Based Machine Learning Lab. https://CRAN.R-project.org/package=kernlab.\n\n\nKaratzoglou, Alexandros, Alex Smola, Kurt Hornik, and Achim Zeileis. 2004. “Kernlab – an S4 Package for Kernel Methods in R.” Journal of Statistical Software 11 (9): 1–20. https://doi.org/10.18637/jss.v011.i09.\n\n\nMeyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2023. E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien. https://CRAN.R-project.org/package=e1071.",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>教師なし学習</span>"
    ]
  },
  {
    "objectID": "chapter29.html",
    "href": "chapter29.html",
    "title": "29  時系列分析",
    "section": "",
    "text": "29.1 ホワイトノイズ\n測定したすべての期間の平均値が一定で、一定の分散（標準偏差、ばらつき）を持つ時系列データのことを、ホワイトノイズと呼びます。典型的なホワイトノイズの例はラジオやテレビのノイズです。ホワイトノイズを数式で表すと以下のようになります。\n\\[y_{t}=c+\\epsilon_{t}\\]\nytは時点tにおける値、cは切片、εtは下に示すように、平均0、標準偏差σの正規分布に従う誤差項です。cが0であれば、ytは平均0、標準偏差σの正規分布に従うランダムな値となります。\n\\[\\epsilon_{t} \\sim Normal(0, \\sigma) \\]\nホワイトノイズをグラフで示したものが以下の図です。時間tに伴いyの値は上下に揺れますが、平均すると概ね一定で、ばらつきの幅も一定となります。\nホワイトノイズ\n\nt &lt;- seq(1:200)\ny &lt;- rnorm(200, 0, 0.5)\n\nggplot(\n  data.frame(t, y),\n  aes(x = t, y = y)\n)+\n  geom_point(size = 2, alpha = 0.5)+\n  geom_line(linewidth = 0.5, alpha = 0.5)",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>時系列分析</span>"
    ]
  },
  {
    "objectID": "chapter29.html#ランダムウォーク",
    "href": "chapter29.html#ランダムウォーク",
    "title": "29  時系列分析",
    "section": "29.2 ランダムウォーク",
    "text": "29.2 ランダムウォーク\n上に示したεtを時間tまで合計し、切片項cを足したものをランダムウォークと呼びます。ランダムウォークはその名の通り、上にふらふら、下にふらふら移動する、予想のつきにくい変動をする時系列データです。ランダムウォークの時系列は以下の式で表すことができます。\n\\[y_{t}=c+\\sum_{i=1}^{t} \\epsilon_{i}\\]\nランダムウォークは時点tと時点t-1の値の差分系列（1階差分、\\(y_{t}-y_{t-1}\\)）を取ると、εt、つまりホワイトノイズになるという性質を持ちます。\n\\[y_{t} - y_{t-1}=\\epsilon_{t}\\]\nランダムウォークをグラフで示したものが以下の図です。値が上下にギザギザと動くだけでなく、時に大きく値が変動します。ランダムウォークでは平均値が一定とならず、分散も一定とはなりません。株価や為替変動などが典型的なランダムウォークの時系列データの例です。\n\n\n\nランダムウォーク\n\ny1 &lt;- NULL\ntemp &lt;- 0\nfor(i in 1:200){\n  temp &lt;- temp + y[i]\n  y1 &lt;- c(y1, temp)\n}\n\nggplot(\n  data.frame(t, y1),\n  aes(x = t, y = y1)\n)+\n  geom_point(size = 2, alpha = 0.5)+\n  geom_line(linewidth = 0.5, alpha = 0.5)",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>時系列分析</span>"
    ]
  },
  {
    "objectID": "chapter29.html#季節性",
    "href": "chapter29.html#季節性",
    "title": "29  時系列分析",
    "section": "29.3 季節性",
    "text": "29.3 季節性\n時系列には、一定の周期ごとに値が似ている場合があります。例えば、アイスクリームの売上には夏に高く、冬に低いような周期があります。このような周期性のことを、季節性と呼びます。季節性には色々な形のものがあり、年次の周期（4半期周期や12ヶ月周期）、週の周期（曜日ごとの周期）などがあります。季節性のあるデータは、ランダムなばらつきを持ちつつ、ある周期で上下する、以下の図のような変動を持ちます。\n\n\n\n季節性\n\n# 季節性ありのデータ\nys &lt;- y + rep(c(0, 0.5, 1.5, 2.5, 3, 2.5, 1.5, 0.5, 0, 0, 0, 0), 10)\nggplot(\n  data.frame(t, ys),\n  aes(x = t, y = ys)\n)+\n  geom_point(size = 2, alpha = 0.5)+\n  geom_line(linewidth = 0.5, alpha = 0.5)",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>時系列分析</span>"
    ]
  },
  {
    "objectID": "chapter29.html#トレンド",
    "href": "chapter29.html#トレンド",
    "title": "29  時系列分析",
    "section": "29.4 トレンド",
    "text": "29.4 トレンド\n時系列データには、時間とともに徐々に値が大きくなったり小さくなったりするものがあります。例えば、ダウ平均株価を2000年ぐらいから調べると、下の図のようにその値が徐々に大きくなっていることがわかるかと思います。このような、時間とともに徐々に上昇・下降していくような傾向のことをトレンドと呼びます。\n\n\n\nトレンドを持つデータ：ダウ平均株価の推移\n\n# kaggleよりデータを取得\n#（https://www.kaggle.com/datasets/mnassrib/dow-jones-industrial-average）\ndjm &lt;- read_csv(\"./data/Dow Jones Industrial Average Historical Data.csv\")\n## Rows: 2766 Columns: 7\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \",\"\n## chr (3): Date, Vol., Change %\n## num (4): Price, Open, High, Low\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\ndjm$Date &lt;- lubridate::mdy(djm$Date)\ndjm$Price &lt;- djm$Price |&gt; str_remove_all(\",\") |&gt; as.numeric()\nggplot(djm, aes(x = Date, y = Price))+\n  geom_line(linewidth = 0.5)\n\n\n\n\n\n\n\n\n\nトレンドを持つデータは、季節性やホワイトノイズに時間とともに変化するような関数を足し合わせたような形を持つ、以下のようなデータとなります。\n\n\n\nトレンド\n\nyt &lt;- ys + t * 0.1\nggplot(\n  data.frame(t, yt),\n  aes(x = t, y = yt)\n)+\n  geom_point(size = 2, alpha = 0.5)+\n  geom_line(linewidth = 0.5, alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n29.4.1 TSstudioパッケージで季節性・トレンドを図示\n季節性とトレンドを持つデータの例としては、大気中二酸化炭素（CO2）濃度の変化があります。\n1950年頃からマウナロア（ハワイの活火山）で大気中CO2濃度がデータとして取得されており、Rではco2データセットとして登録されています。co2は1959～1997年の毎月のCO2濃度を記録したデータセットで、単位はppm（μmol/mol）です。\n大気中のCO2濃度は、北半球の夏に合わせて減少し、冬に合わせて増加する傾向があります（実際には少し遅れて、10月頃に最小、5月頃に最大となります）。これは、北半球の針葉樹林（タイガ）のCO2吸収量が夏季に大きく、冬季に小さくなるためです。また、CO2濃度は化石燃料の消費と共に増加しており、20世紀末で360ppm、2023年時点では420ppm程度になっています。1960～2000年の伸びが50ppm程度ですので、CO2の増加が倍程度に加速していることがわかります。この「夏季に低く冬季に高い」傾向が季節性、「化石燃料の消費と共に増加」の部分がトレンドに当たります。\nTSstudioパッケージ(Krispin 2023)は時系列データをplotlyを用いてグラフにする関数を備えたライブラリです。ts_plot関数は時系列をそのままプロットする、ts_seasonal関数は季節ごとの値を、ts_heatmapは年と月の季節性をそれぞれヒートマップとして表示する関数です。いずれも季節性やトレンドを持つデータをグラフにする、データの傾向を捉える場合に便利な関数です。いずれも17章で紹介したtsクラスの時系列データを引数に取ります。\n\n\n\nco2データセット：TSstudioの関数で季節性データを表示\n\nco2 |&gt; class() # tsクラスのオブジェクト\n## [1] \"ts\"\n\npacman::p_load(TSstudio)\n\nco2 |&gt; ts_plot() # 時系列をplotlyでプロット\n\n\n\n\n\n\nco2 |&gt; ts_seasonal() # 時系列を季節で分離してグラフ化\n\n\n\n\n\nco2 |&gt; ts_heatmap() # 時系列をヒートマップで表示",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>時系列分析</span>"
    ]
  },
  {
    "objectID": "chapter29.html#定常性",
    "href": "chapter29.html#定常性",
    "title": "29  時系列分析",
    "section": "29.5 定常性",
    "text": "29.5 定常性\nここまでにホワイトノイズ、ランダムウォーク、季節性、トレンドと4つの時系列の要素について説明しました。多くの時系列データは、この4つが様々なバランスで合わさったような形をしています。\n\\[時系列データ=ノイズ+季節性+トレンド+(ランダムウォーク)\\]\nこのような時系列データを統計的に適切に取り扱えればいいのですが、時系列を解析する最も基本的な統計の枠組み（ARIMAモデル）では、基本的には定常性という特徴を持つデータを取り扱うこととなっており、この定常性を持たないデータは統計的に取り扱いにくいとされています。\n定常性とは、時系列データをある時間間隔で切り取ったとき、どの時期を切り取っても値の平均値と分散（ばらつき）がおおむね一定であることを指します。\nホワイトノイズは乱数の系列ですので、どの時間でも平均値は一定で、分散も一定となります。したがって、ホワイトノイズは定常過程となります。一方で、ランダムウォークやトレンドを持つデータは、平均値が移動するため定常では無い時系列データ、つまり非定常過程となります。季節性に関しては、ある程度長めの系列では平均値と分散は一定ですが、短い期間で切ると平均値と分散が上下する、非定常過程となります。",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>時系列分析</span>"
    ]
  },
  {
    "objectID": "chapter29.html#自己回帰arモデル",
    "href": "chapter29.html#自己回帰arモデル",
    "title": "29  時系列分析",
    "section": "29.6 自己回帰（AR）モデル",
    "text": "29.6 自己回帰（AR）モデル\n自己回帰（Auto regression、AR）とは、簡単に説明すると、時点tの値がそれ以前の値（時点t-1や時点t-2）によく似ている、という性質を持つ時系列データのことを指します。数式で書くと、AR(p)モデルは以下のような形で書くことができます。\n\\[y_{t}=\\alpha_{1} \\cdot y_{t-1}+\\alpha_{2} \\cdot y_{t-2}+ \\cdots \\alpha_{p} \\cdot y_{t-p}+\\epsilon_{t}\\]\nAR(p)のpを次数（order）と呼びます。AR(1)モデルであれば、\\(\\alpha_{1} \\cdot y_{t-1}\\)のみ、AR(2)モデルでは\\(\\alpha_{1} \\cdot y_{t-1}+\\alpha_{2} \\cdot y_{t-2}\\)となります。αは係数です。AR(1)モデルで、かつα1が1である場合には、以下のようにランダムウォークとなります。\n\\[y_{t} =1 \\cdot y_{t-1}+\\epsilon_{t}\\]\n\n\n\n\n\n\n時系列データの生成：arima.sim関数について\n\n\n\n\n\narima.sim関数は、後に説明するARモデル、MAモデル、和分（I）を用いてシミュレーションした時系列データを生成する関数です。AR、I、MAの次数をorder、AR、MAの係数をar、maとして、以下のようにリストで引数modelに与えることで、時系列データを生成することができます。また、時系列の長さは引数nに指定します。以下の例では、AR(2)、I(0)、MA(0)のモデルで、ARの係数が0.5、0.5の場合の時系列データ200時点分を生成しています。\n\n\n\narima.sim関数\n\narima.sim(model = list(order = c(2, 0, 0), ar = c(0.5, 0.5)), n = 200)\n\n\nただし、この関数では定常過程となるARの係数を指定する必要があります（定常過程とならない係数を指定した場合にはエラーが出ます）。MAは常に定常過程なので、様々な係数を設定することができます。定常過程となる条件は以下の計算式（特性方程式の解が1以上であることの判定式）がTRUEとなることです。\n\n\n\nARの係数から定常過程であるか判定する\n\nar &lt;- c(0.2, 0.2, 0.5) # ARの係数のベクター\n\n# ARの係数が定常過程となるかどうかの判定（FALSEなら非定常）\nmin(Mod(polyroot(c(1, -ar)))) &gt; 1\n## [1] TRUE\n\n\n以下のAR、MAの例では、このarima.sim関数を用いてAR、MAの時系列を生成しています。\n\n\n\nARモデルの例として、AR(1)モデル、AR(2)モデル、AR(3)モデルの時系列をそれぞれ以下に図示します。\n\nAR(1)モデルAR(2)モデルAR(3)モデル\n\n\n\\[y_{t}=\\alpha_{1} \\cdot y_{t-1}+\\epsilon_{t}\\]\n\n\n\nAR(1)に従うモデル\n\ny1a &lt;- arima.sim(model = list(order = c(1, 0, 0), ar = 0.6), 200)\n\nplot(y1a)\n\n\n\n\n\n\n\n\n\n\n\n\\[y_{t}=\\alpha_{2} \\cdot y_{t-2} +  \\alpha_{1} \\cdot y_{t-1} + \\epsilon_{t}\\]\n\n\n\nAR(2)に従うモデル\n\ny2 &lt;- arima.sim(model = list(order = c(2, 0, 0), ar = c(0.1, 0.6)), 200)\n\nplot(y2)\n\n\n\n\n\n\n\n\n\n\n\n\\[y_{t}=\\alpha_{3} \\cdot y_{t-3} + \\alpha_{2} \\cdot y_{t-2} + \\alpha_{1} \\cdot y_{t-1} + \\epsilon_{t}\\]\n\n\n\nAR(3)に従うモデル\n\ny3 &lt;- arima.sim(model = list(order = c(3, 0, 0), ar = c(0.1, 0.1, 0.6)), 200)\n\nplot(y3)",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>時系列分析</span>"
    ]
  },
  {
    "objectID": "chapter29.html#自己相関と偏自己相関",
    "href": "chapter29.html#自己相関と偏自己相関",
    "title": "29  時系列分析",
    "section": "29.7 自己相関と偏自己相関",
    "text": "29.7 自己相関と偏自己相関\nARモデルは、時間tの値とそれ以前の値がよく似ている時系列です。この「よく似ている」度合いを評価するためのものが、自己相関と偏自己相関です。\n自己相関とは、時系列の値ytとp時点前の値yt-pの値の相関のことを指します。pには整数が入り、pのことをラグ（log）と呼びます。\n\n\n\n図1：自己相関のイメージ\n\n\n自己相関は、Rでは以下のように計算することができます。\n\n\n\n自己相関の計算\n\n# y1はランダムウォークのデータ\nhead(y1)\n## [1] 0.6314771 0.4683605 1.1332601 1.7694748 1.9767955 1.2068205\n\n# p = 1のとき\ncor(y1[1:199], y1[2:200])\n## [1] 0.947694\n\n# p = 2のとき\ncor(y1[1:198], y1[3:200])\n## [1] 0.8920951\n\n# p = 3のとき\ncor(y1[1:197], y1[4:200])\n## [1] 0.8312737\n\n\n上のスクリプトで用いている時系列はランダムウォークですが、ランダムウォークではpが大きくなると少しずつ自己相関が小さくなっていく傾向があります。これは、以下の式のように、時点tの値は時点t-1の値で、時点t-1の値は時点t-2の値で説明できることから、時点tの値は時点t-2の値にも依存するためです。\n\\[y_{t} =1 \\cdot y_{t-1}+\\epsilon_{t}\\] \\[y_{t-1} =1 \\cdot y_{t-2}+\\epsilon_{t-1}\\] \\[y_{t} =1 \\cdot y_{t-2}+\\epsilon_{t}+\\epsilon_{t-1}\\]\nただし、ランダムウォークでは1段階差の相関が最も重要です。このような、1段階差が似ているために2段階差以降にも自己相関が出てしまうような効果を取り除いたものを偏自己相関と呼びます。偏自己相関は自己相関ほどには簡単に求まりませんが、時系列が以前のどの時点とよく似ているのかを調べるのに有用です。\n\n29.7.1 acf、pacf関数\n上記のようにcor関数を用いれば自己相関は求まりますが、各時点の自己相関・偏自己相関をいちいちcor関数で計算するのは大変です。\nRには、自己相関・偏自己相関を計算する関数として、acf関数とpacf関数が備わっています。いずれも時系列データを引数に取り、自己相関・偏自己相関の値を返す関数です。ただし、デフォルトではplot引数がTRUEに設定されているため、acf関数は自己相関プロット・pacf関数は偏自己相関プロットを自動的に表示します。数値として自己相関・偏自己相関を得る場合には、引数にplot=FALSEを指定します。\nグラフの横軸は階差（ラグ、Lag）で、Lag=0は時点tの値と時点tの値の相関、つまり同じもの同士の相関ですので、必ず1になります。Lag=1が1段階差の（偏）自己相関、Lag=2だと2段階差の（偏）自己相関ということになります。\n\n\n\nacf関数とpacf関数\n\nacf(y1) # 自己相関（グラフが表示される、plot=FALSEとすると数値が返ってくる）\n\n\n\n\n\n\n\n\npacf(y1) # 偏自己相関\n\n\n\n\n\n\n\n\nTSstudioパッケージのts_cor関数を用いれば、自己相関と偏自己相関のグラフを一度に表示することができます。また、ts_lags関数を用いると、引数lagに指定したラグでの相関について、散布図を表示することもできます。\n\nts_cor(y1 |&gt; as.ts()) # 自己相関と偏自己相関プロット\n\n\n\n\nts_lags(y1 |&gt; as.ts(), lag = 1:3) # lagで指定した系列との散布図\n\n\n\n\n\n以下に、ホワイトノイズ、ランダムウォーク、AR(1)、AR(2)、AR(3)モデル、季節性、トレンドの自己相関と偏自己相関を示します。\n\nホワイトノイズランダムウォークAR(1)モデルAR(2)モデルAR(3)モデル季節性ありトレンドあり\n\n\nホワイトノイズでは、自己相関はLag=0だけ1となり、自己相関も偏自己相関も0に近い値となります。\n\n\n\nホワイトノイズの自己相関\n\nts_cor(y |&gt; as.ts())\n\n\n\n\n\n\n\n\nランダムウォークでは、自己相関はLagが大きくなるほど減っていきます。偏自己相関はLag=1だけが高い値となります。\n\n\n\nランダムウォークの自己相関\n\nts_cor(y1 |&gt; as.ts())\n\n\n\n\n\n\n\n\nAR(1)モデルはランダムウォークとよく似た自己相関・偏自己相関を示します。\n\n\n\nAR(1)モデルの自己相関\n\nts_cor(y1a |&gt; as.ts())\n\n\n\n\n\n\n\n\nAR(2)モデルでは、（係数によりますが）自己相関はlag2つ置きに高い値を示し、偏自己相関はlag=2で高くなります。\n\n\n\nAR(2)モデルの自己相関\n\nts_cor(y2 |&gt; as.ts())\n\n\n\n\n\n\n\n\nAR(3)モデルでは、（係数によりますが）自己相関はlag3つ置きに高い値を示し、偏自己相関はlag=3で高くなります。\n\n\n\nAR(3)モデルの自己相関\n\nts_cor(y3 |&gt; as.ts())\n\n\n\n\n\n\n\n\n季節性がある場合には、自己相関に季節周期の波が生じます。偏自己相関には際立った特徴はありません。\n\n\n\n季節性ありの自己相関\n\nts_cor(ys |&gt; as.ts())\n\n\n\n\n\n\n\n\nトレンドの傾向にもよりますが、直線的なトレンドがある場合には、AR(1)とよく似た自己相関・偏自己相関を示します。\n\n\n\nトレンドありの自己相関\n\nts_cor(yt |&gt; as.ts())\n\n\n\n\n\n\n\n\n\n\n\n29.7.2 ar関数でモデルを推定\n上記のように、「前の値とよく似ている」のがARモデルです。ただし、時系列データがARモデルを取っているということがあらかじめわかっているという場合は稀です。ですので、時系列データが取れたときに、その時系列がAR(1)モデルなのかAR(2)モデルなのか、ARの係数αがいくつなのか、といったことが求まる方が、その時系列の理解が深まります。\n時系列データが得られた時に、ARのモデルと係数をそれぞれ求めるための関数がar関数です。ar関数は時系列データ（ベクター）を引数に取り、ARの次数と係数を返します。ar関数はAICによるモデル選択でARの次数を求めています。以下に様々な時系列におけるar関数の計算結果を示します。必ずしも正しい次数・係数が求まるわけではありませんが、データが増えればar関数でより正確にARモデルを求めることができます。\n\nホワイトノイズランダムウォークAR(1)モデルAR(2)モデルAR(3)モデル季節性ありトレンドあり\n\n\nホワイトノイズはARモデルで示せないため、次数（order）は0、係数は示されません。\n\nar(y)\n## \n## Call:\n## ar(x = y)\n## \n## \n## Order selected 0  sigma^2 estimated as  0.2131\n\n\n\nランダムウォークはAR(1)の特別な場合（\\(\\alpha=1\\)）なので、Orderは1（AR(1)モデル）で、係数（Coefficients）はほぼ1となります。\n\nar(y1)\n## \n## Call:\n## ar(x = y1)\n## \n## Coefficients:\n##      1  \n## 0.9458  \n## \n## Order selected 1  sigma^2 estimated as  0.2145\n\n\n\nAR(1)モデルのorderは1になるはずですが、lag=8の自己相関が大きめに出るためにAR(8)が選ばれています。1次の係数は設定した0.6に近い値を示します。\n\nar(y1a)\n## \n## Call:\n## ar(x = y1a)\n## \n## Coefficients:\n##       1        2        3        4        5        6        7        8  \n##  0.5407  -0.0620  -0.0189  -0.0634  -0.0018   0.0673  -0.1407  -0.1459  \n## \n## Order selected 8  sigma^2 estimated as  0.9814\n\n\n\nAR(2)モデルのorderは2で、Coefficientsとして1次は0.08で設定値0.1に近い値、2次は0.68で設定値0.6に近い値となっています。\n\nar(y2)\n## \n## Call:\n## ar(x = y2)\n## \n## Coefficients:\n##      1       2  \n## 0.0842  0.6803  \n## \n## Order selected 2  sigma^2 estimated as  0.9906\n\n\n\nAR(3)モデルのorderは3で、Coeffientsは0.08、0.07、0.62と、設定値の0.1、0.1、0.6に近い値が得られています。\n\nar(y3)\n## \n## Call:\n## ar(x = y3)\n## \n## Coefficients:\n##      1       2       3  \n## 0.0846  0.0714  0.6225  \n## \n## Order selected 3  sigma^2 estimated as  1.057\n\n\n\n12ごとの周期性のある季節性データでは、AR(12)が選ばれています。\n\nar(ys)\n## \n## Call:\n## ar(x = ys)\n## \n## Coefficients:\n##       1        2        3        4        5        6        7        8  \n##  0.3344   0.0616  -0.2348  -0.2019   0.1221  -0.0921  -0.1720  -0.0091  \n##       9       10       11       12  \n## -0.1220   0.0198   0.1262   0.2771  \n## \n## Order selected 12  sigma^2 estimated as  0.3312\n\n\n\n季節性とトレンドを含むデータでは、AR(14)が選ばれ、1次の係数が1に近い値（0.9908）になっています。\n\nar(yt)\n## \n## Call:\n## ar(x = yt)\n## \n## Coefficients:\n##       1        2        3        4        5        6        7        8  \n##  0.9908  -0.0001  -0.1176   0.0442   0.0554  -0.0791   0.0767  -0.0475  \n##       9       10       11       12       13       14  \n## -0.0666   0.1996   0.0148   0.0866  -0.0260  -0.1554  \n## \n## Order selected 14  sigma^2 estimated as  1.658",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>時系列分析</span>"
    ]
  },
  {
    "objectID": "chapter29.html#移動平均",
    "href": "chapter29.html#移動平均",
    "title": "29  時系列分析",
    "section": "29.8 移動平均",
    "text": "29.8 移動平均\n時系列データでは、通常ホワイトノイズに準じたばらつきが生じます。このばらつきが大きい場合には、全体としての時系列のトレンドがはっきりとしなくなる場合があります。ばらつきの大きい時系列データでは、このようなばらつきを平滑化して、時系列のトレンドが明確になるようにすることがあります。\n平滑化の方法には様々なものがありますが、最も簡単な平滑化の手法が移動平均（rolling mean）です。移動平均では、y1、y2、y3、… ytの時系列データがあった時、例えばy1、y2、y3の平均、y2、y3、y4の平均、y3、y4、y5の平均…といった風に、一定の時間間隔のデータを平均していきます。このとき、3つの平均を取るときには3 rolling windowの移動平均を取る、といったように、英語では平均を取る個数のことを「窓（window）」で表現するのが一般的です。ただし、移動平均を取ると窓の幅に応じて時系列の長さが短くなるという特徴があります。\nRでは、zooパッケージ(Zeileis and Grothendieck 2005)のrollmean関数で移動平均を計算することができます。rollmean関数は第一引数に時系列、第二引数にwindow（引数名はk）を取り、移動平均計算の結果を返します。以下に移動平均を5、10、20のwindowの設定で計算した結果を示します。windowを大きく設定するほど時系列は短くなり、よりギザギザのない、平滑な線になっていくのがわかります。\n\nもとのデータ5時点の移動平均10時点の移動平均20時点の移動平均\n\n\n\ny2.1 &lt;- y2\n\nggplot(data.frame(t, y2.1), aes(x = t, y = y2.1))+\n  geom_point(size = 2, alpha = 0.5)+\n  geom_line(linewidth = 0.5, alpha = 0.5)+\n  expand_limits(x = 0)\n\n\n\n\n\n\n\n\n\n\n\ny2.5 &lt;- zoo::rollmean(y2, 5)\n\nggplot(data.frame(t = t[5:200], y2.5), aes(x = t, y = y2.5))+\n  geom_point(size = 2, alpha = 0.5)+\n  geom_line(linewidth = 0.5, alpha = 0.5)+\n  expand_limits(x = 0)\n\n\n\n\n\n\n\n\n\n\n\ny2.10 &lt;- zoo::rollmean(y2, 10)\n\nggplot(data.frame(t = t[10:200], y2.10), aes(x = t, y = y2.10))+\n  geom_point(size = 2, alpha = 0.5)+\n  geom_line(linewidth = 0.5, alpha = 0.5)+\n  expand_limits(x = 0)\n\n\n\n\n\n\n\n\n\n\n\ny2.20 &lt;- zoo::rollmean(y2, 20)\n\nggplot(data.frame(t = t[20:200], y2.20), aes(x = t, y = y2.20))+\n  geom_point(size = 2, alpha = 0.5)+\n  geom_line(linewidth = 0.5, alpha = 0.5)+\n  expand_limits(x = 0)",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>時系列分析</span>"
    ]
  },
  {
    "objectID": "chapter29.html#maモデル",
    "href": "chapter29.html#maモデル",
    "title": "29  時系列分析",
    "section": "29.9 MAモデル",
    "text": "29.9 MAモデル\n移動平均と日本語では同じ名前の時系列モデルとして、MA（Moving average）モデルというものがあります。MAモデルは上で説明したrolling meanとは少し異なり、時間tにおける値ytが正規分布に従う乱数εと係数の積を足した値に従うようなモデルとなります。以下の数式では、MA(q)モデルとして、係数とεの積をq個足しあわせた式を示します。\n\\[y_{t}=\\epsilon_{t} + \\theta_{1} \\cdot \\epsilon_{t-1}  + \\cdots \\theta_{q} \\cdot \\epsilon_{t-q}\\] \\[\\epsilon_{t} \\sim Normal(0, \\sigma)\\]\n以下に、MA(1)～MA(3)モデルの式とグラフ、自己相関・偏自己相関を示します。MAモデルは定常過程で、平均値や分散が時間とともに大きく変化しないような過程となります。MAモデルでは、自己相関にはあまり特徴がなく、偏自己相関には比較的大きい値が維持されるような傾向をもちます。\n\nMA(1)モデルMA(2)モデルMA(3)モデル\n\n\n\\[y_{t}=\\epsilon_{t} + \\theta_{1} \\cdot \\epsilon_{t-1} \\]\n\n\n\nMA(1)モデルの例\n\nym1 &lt;- arima.sim(model = list(order = c(0, 0, 1), ma = 0.8), 200)\n\nplot(ym1)\n\n\n\n\n\n\n\n\n\n\nts_cor(ym1 |&gt; as.ts())\n\n\n\n\n\n\n\n\\[y_{t}=\\epsilon_{t} + \\theta_{1} \\cdot \\epsilon_{t-1}  + \\theta_{2} \\cdot \\epsilon_{t-2}\\]\n\n\n\nMA(2)モデルの例\n\nym2 &lt;- arima.sim(model = list(order = c(0, 0, 2), ma = c(0.3, 0.7)), 200)\n\nplot(ym2)\n\n\n\n\n\n\n\n\n\n\nts_cor(ym2 |&gt; as.ts())\n\n\n\n\n\n\n\n\\[y_{t}=\\epsilon_{t} + \\theta_{1} \\cdot \\epsilon_{t-1}  + \\theta_{2} \\cdot \\epsilon_{t-2}  + \\theta_{3} \\cdot \\epsilon_{t-3}\\]\n\n\n\nMA(3)モデルの例\n\nym3 &lt;- arima.sim(model = list(order = c(0, 0, 3), ma = c(0.2, 0.2, 0.4)), 200)\n\nplot(ym3)\n\n\n\n\n\n\n\n\n\n\nts_cor(ym3 |&gt; as.ts())",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>時系列分析</span>"
    ]
  },
  {
    "objectID": "chapter29.html#単位根過程と反転可能性",
    "href": "chapter29.html#単位根過程と反転可能性",
    "title": "29  時系列分析",
    "section": "29.10 単位根過程と反転可能性",
    "text": "29.10 単位根過程と反転可能性\n\n29.10.1 単位根過程\n単位根過程（unit root）とは、特性方程式というものの解が1を含むような過程のことを指します。特性方程式とは以下のような式で、Φについて解くことで解を求めます。\n\\[1-\\alpha_{1}\\phi - \\alpha_{2}\\phi^2 -\\alpha_{3}\\phi^3 \\cdots -\\alpha_{p}\\phi^p=0\\]\n上のarima.sim関数の説明で、以下のようにARの係数から定常過程の判定を行うRのスクリプトを記載していますが、この下の式の一部が特性方程式の解を求めるスクリプトになっています。特性方程式の解の最小値が1以上なら定常過程、解に1を含むなら単位根過程となります。\n\n\n\n特性方程式の解\n\nar &lt;- c(0.2, 0.2, 0.5) # ARの係数のベクター\n\n# これが特性方程式の解の最小値を求める計算式\n# （正確には解の原点からの距離の最小値）\nmin(Mod(polyroot(c(1, -ar))))\n## [1] 1.045891\n\n\n…定義上はこのように単位根過程であるかどうかを判定するのですが、正直よくわからないと思います。我々が最低限知っておくべきこととしては、ランダムウォークが単位根過程であることです。以下の2つの式から分かる通り、ランダムウォークはAR(1)でかつα1=1なので、特性方程式Φの解が1になります。\n\\[y_{t}=y_{t-1}+\\epsilon_{t}\\] \\[1 - 1 \\cdot \\phi = 0\\]\n\n\n29.10.2 独立な単位根過程同士で相関を取る\n単位根過程である時系列データには、「2つの独立な単位根過程では、その2つの相関を取ると有意な相関が得られる」、という特殊な性質があります。この相関には全く意味は無いので、時系列データ同士の相関を取る場合には注意が必要です。\n\n\n\n独立な単位根過程間の相関\n\n# y1とy1_2は乱数から作った2つの独立な単位根過程\ny1_2 &lt;- NULL\ntemp &lt;- 0\nfor(i in 1:200){\n  temp &lt;- temp+rnorm(1, 0, 1)\n  y1_2 &lt;- c(y1_2, temp)\n}\n\n# 相関係数が-0.6\ncor(y1, y1_2) \n## [1] -0.5992427\n\n# 相関の有意性を検定すると有意になる\ncor.test(y1, y1_2)\n## \n##  Pearson's product-moment correlation\n## \n## data:  y1 and y1_2\n## t = -10.533, df = 198, p-value &lt; 2.2e-16\n## alternative hypothesis: true correlation is not equal to 0\n## 95 percent confidence interval:\n##  -0.6813376 -0.5022593\n## sample estimates:\n##        cor \n## -0.5992427\n\n# バラバラしているけど相関がある\nplot(y1, y1_2)\n\n\n\n\n\n\n\n\n\n例えば、トルコリラの為替変動と日経平均株価は共にランダムウォークの過程ですが、相関を取ると有意な相関がある、という結果が得られます。だからといって、トルコリラが上がった（又は下がった）から日経平均株価も上がるだろうと想定して株を買い込むと痛い目にあいます。\n\n\n29.10.3 単位根検定\nとは言っても、時系列データが単位根過程であるか判定するための特性方程式はαp、つまりARモデルの係数がわからないと解くことができませんし、時系列データが得られればαpが求まるというものでもありません。得られた時系列データが単位根過程であるかどうかを判定する場合には、特性方程式を解くのではなく、通常は単位根検定という検定手法を用いることになります。\n時系列データが単位根過程であるかどうかは、ADF検定というものを用いて検定します。ADF検定は「単位根過程である」場合を帰無仮説とし、棄却された場合、つまりp値が十分に小さい場合には「単位根過程である」という帰無仮説を棄却して、「単位根過程ではない」という対立仮説を採用する検定手法です。要はp値が小さい場合には単位根過程では無いと判断します。\nRではCADFtestパッケージ(Lupi 2009)のCADFtest関数を用いてADF検定を行います。\n\n\n\nADF検定で単位根過程の判定\n\npacman::p_load(CADFtest)\nCADFtest(y1)\n## \n##  ADF test\n## \n## data:  y1\n## ADF(1) = -3.2007, p-value = 0.08728\n## alternative hypothesis: true delta is less than 0\n## sample estimates:\n##       delta \n## -0.09773805\n\n\n以下に、CADFtest関数を用いた各種時系列データの検定結果を示します。\n\nホワイトノイズランダムウォークランダムウォークの差分AR(1)モデルAR(2)モデルAR(3)モデル\n\n\nホワイトノイズは単位根過程ではないので、帰無仮説は棄却されます。\n\nCADFtest(y)\n## \n##  ADF test\n## \n## data:  y\n## ADF(1) = -9.1384, p-value = 3.329e-13\n## alternative hypothesis: true delta is less than 0\n## sample estimates:\n##      delta \n## -0.9116643\n\n\n\nランダムウォークは単位根過程なので、帰無仮説は棄却されません。\n\nCADFtest(y1)\n## \n##  ADF test\n## \n## data:  y1\n## ADF(1) = -3.2007, p-value = 0.08728\n## alternative hypothesis: true delta is less than 0\n## sample estimates:\n##       delta \n## -0.09773805\n\n\n\nランダムウォークの差分系列を取ると、ホワイトノイズとなるため、単位根過程ではなくなります。\n\nCADFtest(y1 |&gt;  diff())\n## \n##  ADF test\n## \n## data:  diff(y1)\n## ADF(1) = -9.2234, p-value = 2.166e-13\n## alternative hypothesis: true delta is less than 0\n## sample estimates:\n##      delta \n## -0.9191055\n\n\n\nAR(1)モデルでかつαが1でない場合には、単位根過程ではありません。\n\nCADFtest(y1a)\n## \n##  ADF test\n## \n## data:  y1a\n## ADF(1) = -7.243, p-value = 8.453e-09\n## alternative hypothesis: true delta is less than 0\n## sample estimates:\n##      delta \n## -0.4944694\n\n\n\nAR(2)モデル以降は係数によって単位根過程かどうかが変わります。以下の例は単位根過程ではない場合です。\n\nCADFtest(y2)\n## \n##  ADF test\n## \n## data:  y2\n## ADF(1) = -3.5976, p-value = 0.03252\n## alternative hypothesis: true delta is less than 0\n## sample estimates:\n##      delta \n## -0.2281931\n\n\n\nAR(3)モデルも係数によって単位根過程かどうかが変わります。以下の例は単位根過程ではない場合です。\n\nCADFtest(y3)\n## \n##  ADF test\n## \n## data:  y3\n## ADF(1) = -6.921, p-value = 4.41e-08\n## alternative hypothesis: true delta is less than 0\n## sample estimates:\n##     delta \n## -0.593555\n\n\n\n\n単位根検定には他にKPSS検定と呼ばれる、帰無仮説が「単位根過程ではない」、つまり棄却された場合に単位根過程であるとされる検定もあります。Rでは、tseriesパッケージ(Trapletti and Hornik 2023)のkpss.test関数を用いてKPSS検定を行うことができます。\n\n\n\ntseries::kpss.testでKPSS検定\n\npacman::p_load(tseries)\nkpss.test(y1)\n## Warning in kpss.test(y1): p-value smaller than printed p-value\n## \n##  KPSS Test for Level Stationarity\n## \n## data:  y1\n## KPSS Level = 1.9409, Truncation lag parameter = 4, p-value = 0.01\n\n\n\n\n29.10.4 反転可能性\nMAモデルの一部は、AR(∞)モデルの形に書き換えることができます。このAR(∞)モデルに書き換えることができることを反転可能性と呼びます。反転可能なMAモデルは反転不可能なモデルよりも統計的には取り扱いやすいとされています。\n反転可能性の条件は以下の特性方程式の解がすべて1以上となることです。\n\\[1+\\theta_{1}\\phi + \\theta_{2}\\phi^2 +\\theta_{3}\\phi^3 \\cdots +\\theta_{q}\\phi^q=0\\]\nARモデルの特性方程式と同じように、MAモデルの特性方程式も以下のスクリプトで計算することができ、下の式がTRUEになる場合は反転可能、FALSEになる場合は反転不可能となります。\n\n\n\nMAモデル：特性方程式の解\n\nma &lt;- c(0.2, 0.2, 0.5) # MAの係数のベクター\n\n# 特性方程式の解の最小値が1以上なら反転可能\nmin(Mod(polyroot(c(1, ma)))) &gt; 1\n## [1] TRUE",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>時系列分析</span>"
    ]
  },
  {
    "objectID": "chapter29.html#armaモデル",
    "href": "chapter29.html#armaモデル",
    "title": "29  時系列分析",
    "section": "29.11 ARMAモデル",
    "text": "29.11 ARMAモデル\n以上のように、ARモデルやMAモデルで時系列データを説明することはできるのですが、では時系列データが得られた時にARの次数（order）がいくつで、MAの次数がいくつで、それぞれの係数はいくつになるのか、というのはよくわからないままです。このAR・MAの次数や係数を定めるときに用いられるのがARMAモデルです。\nARMAモデルは、その名の通りARモデルとMAモデルを含んだ時系列モデルです。平均値一定で分散が時間とともに大きく変化しない、定常性を持つ時系列データはこのARMAモデルで記述することができます。ARMAモデルは、ARの次数pとMAの次数qを用いて、ARMA(p,q)という形で示します。例えば、ARMA(1,2)であれば、AR(1)モデルでかつMA(2)モデルであることを示しています。\n上に示したar関数では、ARモデルの次数と係数を求めることができましたが、MAモデルが混じっているARMAモデルの次数と係数を求めることはできません。\nRでARMAモデルの次数と係数を求めるときには、tseriesパッケージのarma関数を用います。arma関数は時系列データ（ベクターやtsオブジェクト）と次数を引数に取り、AR、MAの係数、切片項（intercept）をそれぞれ計算してくれます。ただし、arma関数は次数を与えずに計算させるとARMA(1,1)であるとして計算してしまうので、可能であれば次数をorder引数に与える必要があります。以下に、各種時系列データをarma関数で分析したときの結果を示します。\n\nホワイトノイズランダムウォークAR(1)モデルAR(2)モデルAR(3)モデルMA(1)モデルMA(2)モデルMA(3)モデル\n\n\n\narma(y, order=c(0, 0)) # 切片項だけが得られる\n## Warning in optim(coef, err, gr = NULL, hessian = TRUE, ...): one-dimensional optimization by Nelder-Mead is unreliable:\n## use \"Brent\" or optimize() directly\n## \n## Call:\n## arma(x = y, order = c(0, 0))\n## \n## Coefficient(s):\n## intercept  \n## -0.005762\n\n\n\n\narma(y1, order=c(1, 0)) # ランダムウォークはARMA(1,0)\n## \n## Call:\n## arma(x = y1, order = c(1, 0))\n## \n## Coefficient(s):\n##       ar1  intercept  \n##   0.94703   -0.03081\n\n\n\n\narma(y1a, order=c(1, 0)) # AR(1)モデルはARMA(1,0)\n## \n## Call:\n## arma(x = y1a, order = c(1, 0))\n## \n## Coefficient(s):\n##       ar1  intercept  \n##   0.54624    0.04701\n\n\n\n\narma(y2, order=c(2, 0)) # AR(2)モデルはARMA(2,0)\n## \n## Call:\n## arma(x = y2, order = c(2, 0))\n## \n## Coefficient(s):\n##       ar1        ar2  intercept  \n##   0.07898    0.69440   -0.04239\n\n\n\n\narma(y3, order=c(3, 0)) # AR(3)モデルはARMA(3,0)\n## \n## Call:\n## arma(x = y3, order = c(3, 0))\n## \n## Coefficient(s):\n##       ar1        ar2        ar3  intercept  \n##   0.08845    0.06730    0.62943    0.02617\n\n\n\n\narma(ym1, order=c(0, 1)) # MA(1)モデルはARMA(0,1)\n## \n## Call:\n## arma(x = ym1, order = c(0, 1))\n## \n## Coefficient(s):\n##       ma1  intercept  \n##    0.7059    -0.3002\n\n\n\n\narma(ym2, order=c(0, 2)) # MA(2)モデルはARMA(0,2)\n## \n## Call:\n## arma(x = ym2, order = c(0, 2))\n## \n## Coefficient(s):\n##       ma1        ma2  intercept  \n##   0.31962    0.59392    0.08629\n\n\n\n\narma(ym3, order=c(0, 3)) # MA(3)モデルはARMA(0,3)\n## \n## Call:\n## arma(x = ym3, order = c(0, 3))\n## \n## Coefficient(s):\n##       ma1        ma2        ma3  intercept  \n##    0.1585     0.1494     0.3318    -0.1404",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>時系列分析</span>"
    ]
  },
  {
    "objectID": "chapter29.html#arimaモデル",
    "href": "chapter29.html#arimaモデル",
    "title": "29  時系列分析",
    "section": "29.12 ARIMAモデル",
    "text": "29.12 ARIMAモデル\nARMAは基本的に定常過程を対象とするモデルです。しかし、単位根過程となる時系列は定常過程ではなく、ARMAでは取り扱いにくい場合があります。このような単位根過程となる時系列にも対応したモデルがARIMA（auto-regression integrated moving average）モデルです。ARIMAモデルは、ARモデルとMAモデルに和分(I)を付け加えたモデルとなります。\n典型的な単位根過程であるランダムウォークの差分を取るとホワイトノイズとなるように、単位根過程の何段階かの差分を取ると、定常過程を得ることができます。このことから、単位根過程である時系列は、定常過程を足し合わせたもの、つまり和分であるとすることができます。\n単位根過程の時系列データで、d階差分を取ると定常過程となる場合、そのデータはI(d)、つまりd次の和分であるとします。この和分I(d)をARMAモデルに加えたものがARIMAモデルで、AR(p)、I(d)、MA(q)のぞれぞれの次数を合わせてARIMA(p,d,q)という形でモデルを表現します。\nARIMAモデルの計算では、まず時系列が単位根過程であるかを判定し、その後I(d)のdの次数を決定します。その後差分系列のAR、MAの次数と係数を決定するという過程で、ARIMA(p,d,q)のp、d、qの部分を求めます。Rでは、arima関数でARIMAモデルの係数を求めることができます。ただし、arima関数ではあらかじめ(p,d,q)の次数を引数に与える必要があります。\n\n\n\narima関数\n\narima(y1, c(1, 0, 0)) # ARIMA(1, 0, 0)として係数を求める\n## \n## Call:\n## arima(x = y1, order = c(1, 0, 0))\n## \n## Coefficients:\n##          ar1  intercept\n##       0.9451    -0.3930\n## s.e.  0.0217     0.5385\n## \n## sigma^2 estimated as 0.205:  log likelihood = -126.45,  aic = 258.91\n\n\nしかし、時系列データを得た時に、そのデータがARIMA(1,1,0)である、といった風に、次数をあらかじめ決めることは普通はできません。Rには次数を含めてARIMAモデルを計算してくれる、auto.arima関数が備わっています。実際に時系列分析を行う際には、arima関数を用いることはほぼなく、auto.arima関数を用いることになります。auto.arima関数はAICに従いモデル選択を行う関数で、26章で説明したAICによるモデル選択におけるstep関数のARIMA版のようなものになります。\nauto.arima関数には、モデルを総当り計算するかステップワイズな計算をするかを決定するstepwise引数を設定できます。stepwise=Tとするとステップワイズ計算を行い、計算が速くなります。一方でstepwise=Fとすると、総当り計算を行うため計算は正確になりますが、モデルが複雑な場合には計算に時間がかかります。また、trace引数をTRUEに設定すると、繰り返し計算をすべて表示してくれます。\n以下に、auto.arima関数を用いて各種の時系列データを分析した例を示します。\n\nホワイトノイズランダムウォークAR(1)モデルAR(2)モデルAR(3)モデルMR(1)モデルMR(2)モデルMR(3)モデル\n\n\nホワイトノイズはARIMA(0,0,0)モデルですので、正しくモデルが求まっています。\n\nauto.arima(ts(y), stepwise = T, trace = F) |&gt; summary()\n## Series: ts(y) \n## ARIMA(0,0,0) with zero mean \n## \n## sigma^2 = 0.2121:  log likelihood = -128.71\n## AIC=259.43   AICc=259.45   BIC=262.72\n## \n## Training set error measures:\n##                        ME      RMSE       MAE MPE MAPE      MASE       ACF1\n## Training set -0.005720777 0.4605318 0.3724083 100  100 0.7227597 0.02846469\n\n\n\nランダムウォークは単位根ありの和分過程ですので、ARIMA(0,1,0)となります。\n\nauto.arima(ts(y1), stepwise = T, trace = F) |&gt; summary()\n## Series: ts(y1) \n## ARIMA(0,1,0) \n## \n## sigma^2 = 0.2112:  log likelihood = -127.63\n## AIC=257.26   AICc=257.28   BIC=260.55\n## \n## Training set error measures:\n##                        ME     RMSE       MAE      MPE     MAPE      MASE\n## Training set -0.008875005 0.458362 0.3692541 25.84799 116.8924 0.9950085\n##                    ACF1\n## Training set 0.03107499\n\n\n\n単位根の無いAR(1)モデルはARIMA(1,0,0)ですが、ARIMA(2,0,1)と推定されています。\n\nauto.arima(ts(y1a), stepwise = T, trace = F) |&gt; summary()\n## Series: ts(y1a) \n## ARIMA(2,0,1) with zero mean \n## \n## Coefficients:\n##          ar1      ar2      ma1\n##       1.4858  -0.5857  -0.9430\n## s.e.  0.0600   0.0574   0.0284\n## \n## sigma^2 = 0.9733:  log likelihood = -280.02\n## AIC=568.05   AICc=568.25   BIC=581.24\n## \n## Training set error measures:\n##                     ME      RMSE       MAE      MPE     MAPE      MASE\n## Training set 0.1115677 0.9791473 0.7685823 32.28064 229.3899 0.8382321\n##                     ACF1\n## Training set -0.01643774\n\n\n\nAR(2)モデルはARIMA(2,0,0)モデルですが、ARIMA(3,0,0)と推定されています。\n\nauto.arima(ts(y2), stepwise = T, trace = F) |&gt; summary()\n## Series: ts(y2) \n## ARIMA(3,0,0) with non-zero mean \n## \n## Coefficients:\n##          ar1     ar2     ar3     mean\n##       0.0185  0.6854  0.0985  -0.2964\n## s.e.  0.0702  0.0510  0.0712   0.3328\n## \n## sigma^2 = 0.9577:  log likelihood = -278.16\n## AIC=566.31   AICc=566.62   BIC=582.81\n## \n## Training set error measures:\n##                      ME      RMSE       MAE      MPE     MAPE      MASE\n## Training set 0.01878576 0.9687765 0.7920465 66.62805 144.2256 0.5901585\n##                    ACF1\n## Training set 0.00562248\n\n\n\nAR(3)モデルはARIMA(3,0,0)モデルですが、ARIMA(0,0,3)と推定されています。\n\nauto.arima(ts(y3), stepwise = T, trace = F) |&gt; summary()\n## Series: ts(y3) \n## ARIMA(0,0,3) with zero mean \n## \n## Coefficients:\n##          ma1     ma2     ma3\n##       0.1581  0.1368  0.5761\n## s.e.  0.0601  0.0687  0.0556\n## \n## sigma^2 = 1.211:  log likelihood = -302.02\n## AIC=612.04   AICc=612.25   BIC=625.24\n## \n## Training set error measures:\n##                      ME     RMSE       MAE      MPE     MAPE      MASE\n## Training set 0.03989579 1.092088 0.8902643 207.5248 257.3231 0.6549154\n##                    ACF1\n## Training set 0.01566343\n\n\n\nMA(1)モデルはARIMA(0,0,1)モデルなので、正しく推定されています。\n\nauto.arima(ts(ym1), stepwise = T, trace = F) |&gt; summary()\n## Series: ts(ym1) \n## ARIMA(0,0,1) with non-zero mean \n## \n## Coefficients:\n##          ma1     mean\n##       0.7085  -0.2820\n## s.e.  0.0577   0.1275\n## \n## sigma^2 = 1.129:  log likelihood = -295.28\n## AIC=596.56   AICc=596.68   BIC=606.46\n## \n## Training set error measures:\n##                        ME     RMSE       MAE      MPE     MAPE      MASE\n## Training set -0.002073118 1.057302 0.8466552 58.08614 210.9915 0.7558314\n##                     ACF1\n## Training set -0.06563672\n\n\n\nMA(2)モデルはARIMA(0,0,2)モデルなので、正しく推定されています。\n\nauto.arima(ts(ym2), stepwise = T, trace = F) |&gt; summary()\n## Series: ts(ym2) \n## ARIMA(0,0,2) with zero mean \n## \n## Coefficients:\n##          ma1     ma2\n##       0.3216  0.5933\n## s.e.  0.0571  0.0627\n## \n## sigma^2 = 0.9629:  log likelihood = -279.46\n## AIC=564.92   AICc=565.04   BIC=574.82\n## \n## Training set error measures:\n##                      ME      RMSE       MAE      MPE     MAPE      MASE\n## Training set 0.04296999 0.9763719 0.7801817 57.34941 177.9415 0.7341903\n##                     ACF1\n## Training set -0.02243839\n\n\n\nMA(3)モデルはARIMA(0,0,3)モデルですが、ARIMA(3,0,1)モデルと推定されています。\n\nauto.arima(ts(ym3), stepwise = T, trace = F) |&gt; summary()\n## Series: ts(ym3) \n## ARIMA(3,0,1) with zero mean \n## \n## Coefficients:\n##           ar1     ar2     ar3     ma1\n##       -0.3327  0.2490  0.3377  0.5132\n## s.e.   0.1998  0.0814  0.0678  0.2110\n## \n## sigma^2 = 1.009:  log likelihood = -282.83\n## AIC=575.66   AICc=575.97   BIC=592.16\n## \n## Training set error measures:\n##                       ME      RMSE       MAE      MPE     MAPE      MASE\n## Training set -0.07330069 0.9942121 0.7860151 54.59213 167.2121 0.7073544\n##                    ACF1\n## Training set -0.0121561\n\n\n\n\n上記のようにauto.arima関数を用いれば必ず正しいモデルが計算できる、というわけではありませんし、MAモデルが反転可能な場合にはARとMAの次数が逆転することもありますが、時系列のデータ数が十分に多ければ、ある程度信頼できる結果を返してくれます。\n\n\n\n\n\n\nARIMAモデルをシミュレートする\n\n\n\n\n\nauto.arima関数の結果と次数、データ数の関係をより調べたい方は、以下のリンクにあるシミュレーションを触ってみて下さい。また、下のスクリプトをRで実行することでもシミュレーションを動かすことができます。\nARIMAシミュレーター\n\nif(!require(shiny)){install.packages(\"shiny\")};runGitHub(\"ARIMAsim\", \"sb8001at\")\n\nこのシミュレーターでは、arima.sim関数で生成した時系列に対してauto.arima関数や単位根検定を行った結果を確認することができます。\n\n\n\n\n29.12.1 ARIMAモデルを用いた予測\n上記のように、auto.arima関数を用いれば、ARIMAモデルの次数と係数を求めることができます。とは言っても、次数と係数が求まったら何かわかるのかと言われると、イマイチよくわかりません。ARIMA(3,2,1)モデルがどんな形をしていて、どういう意味があるのか、パッと分かる人はなかなかいないでしょう。\nARIMAモデルの意味がわからなくても、この計算したARIMAモデルがあれば、その時系列の将来の変化を予測することはできます。\nRではforecastパッケージのforecast関数を用いることで、ARIMAモデルでの予測を行うことができます。forecast関数は第一引数にauto.arima関数の返り値を、第二引数に予測する期間の長さ（h）を取ります。forecast関数の返り値はデータフレームで、予測値とその推定区間を返してくれます。予測区間を見るとわかりますが、明確なトレンドや季節性が無いデータでは、予測する時期が遠い未来になると点推定値も範囲推定値もほぼ一定になります。\n\n\n\nforecast関数で予測する\n\npacman::p_load(\"forecast\")\n# auto.arimaの返り値を変数に代入\ny1a_arima &lt;- auto.arima(ts(y1a), ic = \"aic\", stepwise = F, trace = F) \nfc &lt;- forecast(y1a_arima, h = 5, level = 95) # 5時点先まで予測する\n# 左から点推定値、95％下限推定値、95％上限推定値\nfc\n##     Point Forecast     Lo 95    Hi 95\n## 201     0.61331914 -1.320332 2.546970\n## 202    -0.03486291 -2.235006 2.165280\n## 203    -0.41103196 -2.652208 1.830144\n## 204    -0.59029108 -2.831552 1.650970\n## 205    -0.63630478 -2.888439 1.615829\n\n\n\n\n\n\n\n\n下のグラフを描画するスクリプト\n\n\n\n\n\n\nfc &lt;- forecast(y1a_arima, h = 100) |&gt; as.data.frame()\nfc$t &lt;- 201:300\nggplot()+\n  geom_line(data = data.frame(t = 1:200, y1a), aes(x = t, y = y1a))+\n  geom_line(data = fc, aes(x = t, y = `Point Forecast`, color = \"red\", linewidth=3))+\n  geom_ribbon(data = fc, aes(x = t, y = `Point Forecast`, ymax = `Hi 95`, ymin = `Lo 95`, color = \"red\", fill = \"red\", alpha = 0.2))+\n  labs(caption = \"赤の太線が点推定値、リボンが95%推定区間\")",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>時系列分析</span>"
    ]
  },
  {
    "objectID": "chapter29.html#arima以外の時系列分析手法",
    "href": "chapter29.html#arima以外の時系列分析手法",
    "title": "29  時系列分析",
    "section": "29.13 ARIMA以外の時系列分析手法",
    "text": "29.13 ARIMA以外の時系列分析手法\n上記のARIMAモデルが時系列分析手法では最も有名な手法の一つですが、時系列分析にはARIMAの他に、以下のような手法があります。\n\nSARIMA：季節性を含めたARIMAモデルの拡張\nARIMAX：共変量（例えば、Nileの例であればアスワンハイダムの建造など）を含めたARIMAモデルの拡張\nVAR：複数の関連する時系列を一度に取り扱う、多変量時系列解析の手法\nARCH・GARCH：分散の変動（ボラティリティ、volatility）に注目した統計手法\n\nRではそれぞれ以下のライブラリ・関数を用いて計算することができます。\n\nSARIMA：auto.arima関数のseasonal引数をTRUEに設定\nARIMAX：auto.arima関数のxreg引数に共変量をベクターで設定\nVAR：varsパッケージ(Bernhard Pfaff 2008; B. Pfaff 2008)のVAR関数\nARCH・GARCH：fGarchパッケージ(Wuertz et al. 2023)のgarchFit関数",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>時系列分析</span>"
    ]
  },
  {
    "objectID": "chapter29.html#時系列の要素を分離する",
    "href": "chapter29.html#時系列の要素を分離する",
    "title": "29  時系列分析",
    "section": "29.14 時系列の要素を分離する",
    "text": "29.14 時系列の要素を分離する\n上に述べたARIMAやその他の分析が時系列分析手法の主なものになりますが、もうちょっと手軽に季節性やトレンドを評価する方法もあります。最も単純なものは、20章で説明したdecompose関数を用いる方法です。decompose関数は時系列データをトレンド、季節性、ランダム要素の3つに分離してくれる関数です。decompose関数の返り値をそのままplot関数に与えると、時系列データを分離してグラフにしてくれます。\n\n\n\ndecompose関数でトレンド・季節性を分ける\n\nts(co2, frequency = 12) |&gt; decompose() |&gt; plot()\n\n\n\n\n\n\n\n\n\n同様の関数に、TSstudioパッケージのts_decompose関数があります。こちらはdecompose関数で分離したものをplotlyでグラフにしてくれる関数です。\n\n\n\nTSstudio::ts_decompose関数\n\nts_decompose(ts(co2, frequency = 12))\n\n\n\n\n\n\n季節性・トレンドの成分をさらに詳しく評価したい場合には、facebook（Meta）の技術者が開発したprophetパッケージを用いるとよいでしょう。prophetはrstanパッケージ(Stan Development Team 2023)（もしくはcmdstanrパッケージ(Gabry, Cesnovar, and Johnson 2023)）を用いて時系列を解析するアルゴリズムを使用しています。このアルゴリズムでは、下に説明する状態空間モデルとは少し異なるアプローチ（論文に記載の通り、一般化加法モデル（26章参照）で分析）を取っています。prophetを用いれば、季節性やトレンドの分離、予測、休日の影響やデータの欠測の処理などを比較的簡単に取り扱うことができます。\n\n\n\nprophetパッケージでデータを取り扱う\n\npacman::p_load(rstan, prophet)\n\ndf &lt;- read.csv('https://raw.githubusercontent.com/facebook/prophet/main/examples/example_wp_log_peyton_manning.csv')\n\n# 状態空間モデルの推定（rstanパッケージが必要）\nm &lt;- prophet(df) \n\n# 未来の365日分のデータフレームを作成\nfuture &lt;- make_future_dataframe(m, periods = 365) \ntail(future)\n\n# predictで将来予測\nforecast &lt;- predict(m, future)\ntail(forecast[c('ds', 'yhat', 'yhat_lower', 'yhat_upper')])\n\n# 推定値をプロット\nplot(m, forecast)\n\n# 季節性、トレンドを分けて表示\nprophet_plot_components(m, forecast)",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>時系列分析</span>"
    ]
  },
  {
    "objectID": "chapter29.html#状態空間モデル",
    "href": "chapter29.html#状態空間モデル",
    "title": "29  時系列分析",
    "section": "29.15 状態空間モデル",
    "text": "29.15 状態空間モデル\n状態空間モデル（state space model）は時系列データや地理空間データの統計に用いられる統計モデルの一つです。状態空間モデルでは、時系列データを以下の図のように、真の値の系列である状態モデルと、その真の値を我々が観測したときのばらつきを含む観測モデルからなるものであるとします。\n\n真の値を示す状態モデルでは、時点tの値は時点t-1の値によく似ているとする、AR(1)モデルに似たような構造を持つとします。\n\\[\\mu_{t}=\\mu_{t-1}+\\epsilon_{t}\\] \\[\\epsilon_{t} \\sim Normal(0, \\sigma)\\]\n観測モデルは、状態モデルに観測時に起こるばらつきが含まれるものであるとします。\n\\[Y_{t}=\\mu_{t}+\\eta_{t}\\] \\[\\eta_{t} \\sim Normal(0, \\sigma)\\]\n我々が観測したデータ、つまり時系列データは、この観測モデルの左辺、Ytとなります。Ytからμtを求めることで観測等のばらつきを取り除いた真の状態の変化を調べようとするのが状態空間モデルの概略です。\nこの状態空間モデルのいいところは、モデルをある程度自由に決められることです。状態モデルをAR(1)モデルっぽくしてもAR(2)モデルっぽくしても良いですし、切片項や係数を設定しても良いですし、季節性や説明変数の項を追加することもできます。ただし、auto.arima関数のように、「自動的にモデルを選択してくれる」ような手法ではないため、データをよく見て適したモデルを自分で選択する必要があります。また、上に説明したような分析手法よりはるかに計算が複雑で、計算に時間がかかります。\n\n29.15.1 カルマンフィルタ\nこの状態空間モデルを用いた分析手法の一つがカルマンフィルタです。カルマンフィルタは、GPSのような、時系列データに大きなノイズが乗っているようなデータを取り扱う時に、ノイズの成分を減らして真のシグナル（GPSなら真の位置や方角）を求めるために利用されています。カルマンフィルタは、ノイズを減らすフィルタリング、長期的な変動を滑らかな曲線として示すための平滑化、将来の変動を予測する予測の3つの目的で用いられます。フィルタリング・平滑化・予測ではそれぞれ以下のような変換を行います。\n\nフィルタリング：\\(E(y_{t}|Y_{t})\\) 今の値から今の値の代表値を推定\n平滑化：\\(E(y_{t}|Y_{T})\\) 測定済みのすべての値から、ある時点の代表値を推定\n予測：\\(E(y_{t}|Y_{t-1})\\) 今までの値から次の値を予測\n\nE(yt)というのが変換後の値、Ytはその時点での測定値、YTはその時点までのすべての測定値を指します。したがって、フィルタリング・平滑化・予測を図で示すと以下のようになります。\n\n\n\n図2：カルマルフィルタのイメージ\n\n\nRでは、dlmパッケージ(Petris 2010; Petris, Petrone, and Campagnoli 2009)やKFASパッケージ(Helske 2017)を用いることでカルマンフィルタの計算を行うことができます。以下にdlmパッケージでのカルマンフィルタの例を示します。\n\n\n\ndlmパッケージでカルマンフィルタ\n\n# ?dlm::dlmFilter（dlmFilterのヘルプ）に記載されている使用例\npacman::p_load(dlm)\n\nnileBuild &lt;- function(par){\ndlmModPoly(1, dV = exp(par[1]), dW = exp(par[2]))\n}\n\nnileMLE &lt;- dlmMLE(Nile, rep(0, 2), nileBuild)\nnileMod &lt;- nileBuild(nileMLE$par)\n\nnileFilt &lt;- dlmFilter(Nile, nileMod) # フィルタリング\nnileSmooth &lt;- dlmSmooth(nileFilt) # 平滑化\nplot(cbind(Nile, nileFilt$m[-1], nileSmooth$s[-1]), plot.type = 's',\ncol = c(\"black\", \"red\", \"blue\"), ylab = \"Level\", main = \"Nile river\", lwd = c(1, 2, 2))\n\n\n\n\n\n\n\n\n\nカルマンフィルタについては詳しい教科書がたくさんあるので（例えばRではこの教科書など (野村 2016)）、詳しく学びたい方は教科書を一読されることをおススメいたします。\n\n\n29.15.2 Stan\nもっと複雑で自由度の高い状態空間モデルを用いる場合には、Stanという統計モデリングの言語を用いることになります。Rでは上記のprophetの部分で少し紹介したrstanまたはcmdstanrパッケージを用いて、Stan言語の統計モデルを書き、計算することになります。Stanについては入門として紹介するには複雑すぎるためココには記載しませんが、興味のある方はStanについてのホームページや教科書(松浦 and 石田 2016)を読むことをおすすめします。\n\n\n\n\n\n図1：自己相関のイメージ\n図2：カルマルフィルタのイメージ\n\n\n\nGabry, Jonah, Rok Cesnovar, and Andrew Johnson. 2023. Cmdstanr: R Interface to ’CmdStan’. https://mc-stan.org/cmdstanr/.\n\n\nHelske, Jouni. 2017. “KFAS: Exponential Family State Space Models in R.” Journal of Statistical Software 78 (10): 1–39. https://doi.org/10.18637/jss.v078.i10.\n\n\nKrispin, Rami. 2023. TSstudio: Functions for Time Series Analysis and Forecasting. https://CRAN.R-project.org/package=TSstudio.\n\n\nLupi, Claudio. 2009. “Unit Root CADF Testing with R.” Journal of Statistical Software 32 (2): 20.\n\n\nPetris, Giovanni. 2010. “An R Package for Dynamic Linear Models.” Journal of Statistical Software 36 (12): 1–16. https://www.jstatsoft.org/v36/i12/.\n\n\nPetris, Giovanni, Sonia Petrone, and Patrizia Campagnoli. 2009. Dynamic Linear Models with r. useR! Springer-Verlag, New York.\n\n\nPfaff, B. 2008. Analysis of Integrated and Cointegrated Time Series with r. Second. New York: Springer. https://www.pfaffikus.de.\n\n\nPfaff, Bernhard. 2008. “VAR, SVAR and SVEC Models: Implementation Within R Package vars.” Journal of Statistical Software 27 (4). https://www.jstatsoft.org/v27/i04/.\n\n\nStan Development Team. 2023. “RStan: The R Interface to Stan.” https://mc-stan.org/.\n\n\nTrapletti, Adrian, and Kurt Hornik. 2023. Tseries: Time Series Analysis and Computational Finance. https://CRAN.R-project.org/package=tseries.\n\n\nWuertz, Diethelm, Yohan Chalabi, Tobias Setz, Martin Maechler, and Georgi N. Boshnakov. 2023. fGarch: Rmetrics - Autoregressive Conditional Heteroskedastic Modelling. https://CRAN.R-project.org/package=fGarch.\n\n\nZeileis, Achim, and Gabor Grothendieck. 2005. “Zoo: S3 Infrastructure for Regular and Irregular Time Series.” Journal of Statistical Software 14 (6): 1–27. https://doi.org/10.18637/jss.v014.i06.\n\n\n松浦健太郎, and 石田基広. 2016. StanとRでベイズ統計モデリング (Wonderful r 2). Edited by 市川太祐, 高橋康介, 高柳慎一, and 福島真太朗. 単行本. 共立出版. https://www.amazon.co.jp/dp/4320112423/.\n\n\n野村俊一. 2016. カルマンフィルタ ーrを使った時系列予測と状態空間モデルー (統計学One Point 2). 単行本. 共立出版. https://lead.to/amazon/jp/?op=bt&la=ja&key=4320112539.",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>時系列分析</span>"
    ]
  },
  {
    "objectID": "chapter30.html",
    "href": "chapter30.html",
    "title": "30  生存時間解析",
    "section": "",
    "text": "30.1 ハザードと累積ハザード\nハザードとは、ある時間にイベントが起きる確率を指します。ある時間tにおけるハザードは以下の式で表されるものです。\n\\[h(t)=\\lim_{\\delta \\to 0} \\frac{P(t &lt; T &lt; t + \\delta | T &gt; t)}{\\delta}\\]\nこの式で、h(t)はある時間tにおけるハザード、δは微小な時間、P(t&lt;T&lt;t+δ|T&gt;t)はある微小時間t～t+δにイベントが起きる確率です。このハザードを積分したものが累積ハザードと呼ばれます。\n\\[H(t)=\\int^{t}_{0} h(t)dt\\]\nH(t)は累積ハザードで、累積ハザードはハザードh(t)を時間0からtまで積分したものとなります。H(t)はその時間までにイベントが起きる確率を示すものとなります。",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>生存時間解析</span>"
    ]
  },
  {
    "objectID": "chapter30.html#生存時間",
    "href": "chapter30.html#生存時間",
    "title": "30  生存時間解析",
    "section": "30.2 生存時間",
    "text": "30.2 生存時間\n生存時間とは、ある集団のうち、イベントが起きなかった集団の割合のことです。生存時間は累積ハザードを用いて、以下の式で表されます。\n\\[S(t)=\\exp(-H(t))\\]\nですので、ハザードを積分し、マイナスの符号を付けて指数変換したものが生存時間です。生存時間解析で取り扱うものは、ほぼすべてこのハザード、累積ハザード、生存時間の3つに関わっています。",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>生存時間解析</span>"
    ]
  },
  {
    "objectID": "chapter30.html#確率分布と生存時間",
    "href": "chapter30.html#確率分布と生存時間",
    "title": "30  生存時間解析",
    "section": "30.3 確率分布と生存時間",
    "text": "30.3 確率分布と生存時間\n生存時間を取り扱うときに、生存時間をうまく表現できる分布がある方が便利です。生存時間は指数分布で取り扱うことができるとされています。\n指数分布は以下の式で表される分布です。\n\\[Exp(x, \\lambda)=\\lambda \\cdot \\exp(-\\lambda x)\\]\n指数分布に関しては24章でごく簡単に取り扱っています。指数分布は平均値1/λ、標準偏差も1/λとなる分布です。ただし、この指数分布では、ハザードが時間に対して一定である場合のみ生存時間をうまく表現することができます。\nハザードが一定とならない場合には、生存時間はワイブル分布やガンマ分布で表現されます。ワイブル分布やガンマ分布を用いると、ハザードが単調増加したり、単調減少したりするような現象を表現することができます。\n\n\n\n\n\n\n実際のハザードについて\n\n\n\n\n\n分布を用いたハザードの表現では、ハザード一定か、単調増加・単調減少する現象を説明することができます。一方で、実際のハザードは必ずしも一定や単調増加になるわけではありません。例えば、日本人の寿命と死亡率からハザードを求めたものがe-statで公開されています（出典：「政府統計の総合窓口(e-Stat)」、調査項目を調べる－厚生労働省 人口動態・保健社会統計室 基幹統計「生命表」）。ハザードを図示すると、0歳児のハザードが80歳半ばの人と同じぐらいの値となっており、全体としては両側が高く、真ん中が極端に低いような推移を示し、一定でも単調変化でもない変化を取ります。\n\n\n\n\n\n\n\n\n\n\n\n\nここで、f(t)を分布関数、F(t)を累積分布関数とすると、F(t)はf(t)の積分ですので、f(t)とF(t)の関係は以下の式で表されます。\n\\[F(t)=\\int_{0}^{t}f(t)dt\\]\n要は、F(t)を微分するとf(t)に、f(t)を積分するとF(t)となるわけです。時間tはマイナスの値を取らないため、積分の下限は0です。F(t)は時間tまでにイベントが起きる割合として、以下の式で表されます。\n\\[F(t)=P(T &lt; t)\\]\n生存時間S(t)は時間tまでにイベントが起こらない割合となりますので、全体の割合1からイベントが起きる割合F(t)を引いた値となります。\n\\[S(t)=1-F(t)\\]\nですので、f(t)は生存時間S(t)を微分した値にマイナスを付けたものとなります。\n\\[f(t)=\\frac{d}{dt}F(t)dt=\\frac{d}{dt}(1-S(t))dt=-\\frac{d}{dt}S(t)dt\\]\nまた、ハザードh(t)と分布f(t)、生存時間S(t)の関係は以下の式で表されます。\n\\[h(t)= \\frac{f(t)}{S(t)}\\]\n以上のように、確率分布f(t)、累積確率分布F(t)、生存時間S(t)、ハザードh(t)は互いに関連しており、生存時間S(t)が分かればハザードや確率分布が分かりますし、確率分布から生存時間やハザードを決めることもできます。",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>生存時間解析</span>"
    ]
  },
  {
    "objectID": "chapter30.html#確率分布と生存時間のシミュレーション",
    "href": "chapter30.html#確率分布と生存時間のシミュレーション",
    "title": "30  生存時間解析",
    "section": "30.4 確率分布と生存時間のシミュレーション",
    "text": "30.4 確率分布と生存時間のシミュレーション\nRでは、乱数を用いることで比較的簡単に生存時間をシミュレートすることができます。\n\n\n\n指数分布を仮定した場合の生存時間のシミュレーション\n\nrexp(10, rate=0.01) |&gt; round()\n##  [1]  18  15  14  44 289 123  54  96  15 139\n\n\n以下に、指数分布、ワイブル分布、ガンマ分布を仮定した場合の生存時間、ハザードの形状を示します。f(t)には、この他に対数正規分布や対数ロジスティック分布などを仮定する場合もあるようです(武冨 and 山本 2023)。\n\n\n\n\n\n\n生存時間と分布のシミュレーション\n\n\n\n\n\n以下のコードを実行することで生存時間と分布のシミュレーションを実行することができます。\n\nif(!require(shiny)){install.packages(\"shiny\")};runGitHub(\"surv_sim\", \"sb8001at\")\n\n\n\n\n\n指数分布ワイブル分布ガンマ分布\n\n\n確率分布の式\n\\[Exp(x, \\lambda)=\\lambda \\cdot \\exp(-\\lambda x)\\]\n\nrexp(10, rate = 0.01) |&gt; round() \n##  [1]  76 124 442 105 104 188  65  34  59 236\n\n\n\n\n\n\n\n\n\n\n\n\n確率分布の式\n\\[Weibull(x, \\lambda, k)=\\frac{k}{\\lambda}(\\frac{x}{\\lambda})^{k-1} \\cdot \\exp(-\\frac{x}{\\lambda})^k\\]\n\nrweibull(10, shape = 0.8, scale = 100) |&gt; round()\n##  [1]   8  94  32   8  17  27 434  74 169  17\n\n\n\n\n\n\n\n\n\n\n\n\n確率分布の式\n\\[Gamma(x, \\gamma, \\beta)=\\frac{(\\frac{x}{\\beta})^{\\gamma-1} \\cdot \\exp(-\\frac{x}{\\beta})}{\\beta \\cdot \\Gamma(\\gamma)}\\]\n\nrgamma(10, shape = 0.8, scale = 100) |&gt; round()\n##  [1]  11 157 104  68  10  27 234 121  20  65",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>生存時間解析</span>"
    ]
  },
  {
    "objectID": "chapter30.html#survivalパッケージ",
    "href": "chapter30.html#survivalパッケージ",
    "title": "30  生存時間解析",
    "section": "30.5 survivalパッケージ",
    "text": "30.5 survivalパッケージ\nRでの生存時間解析は、主にsurvivalパッケージ (Therneau 2023; Terry M. Therneau and Patricia M. Grambsch 2000)を用いて行います。\n\npacman::p_load(survival)\n\n\n30.5.1 生存時間解析のデータ\nsurvivalパッケージには、生存時間解析に用いることができる数多くのデータセットが登録されています。survivalに含まれているデータセットは生物的（あるいは医学的）なものと工学的な故障に関するもので、以降に紹介する概念や手法を理解するのに便利なものがそろっています。以下にデータセットの一覧を示します。\n\n\n\n\n\n\n\n\n\nデータセット\nデータの内容\n\n\n\n\naml\n急性骨髄性白血病患者のデータ\n\n\nbladder\n膀胱がんの再発に関するデータ（85名分）\n\n\nbladder1\n膀胱がんの再発に関するデータ（118名分）\n\n\nbladder2\n膀胱がんの再発に関するデータ（左側打ち切りあり）\n\n\ncancer\nNCCTG（臨床研究グループ）の肺がん患者のデータ\n\n\ncapacitor\nガラスのコンデンサの寿命に関するデータ\n\n\ncgd\n慢性肉芽腫に対するγインターフェロンの効果に関するプラセボ対照研究\n\n\ncolon\n結腸がんに対する化学療法に関するデータ\n\n\ncracks\nタービンに生じたクラックに関するデータ\n\n\ndiabetic\n糖尿病網膜症のレーザー治療に関するデータ\n\n\nflchain\n血清免疫グロブリン遊離軽鎖と死亡率に関するデータ\n\n\ngbsg\nドイツで実施された乳がん患者に関する調査のデータ\n\n\ngenfan\nディーゼルエンジンのファンに生じた故障のデータ\n\n\nheart\nスタンフォードで実施された心臓移植のデータ\n\n\nhoel\nオスマウスにガンが生じるまでの日数のデータ\n\n\nifluid\n絶縁流体の電気的な破損に関するデータ\n\n\nimotor\nモーターの絶縁破壊と温度の関係に関するデータ\n\n\nkidney\n透析患者にカテーテルを挿入し、感染が起こるまでの時間\n\n\nlogan\n職業カテゴリの移動に関するデータ\n\n\nmgus\n免疫グロブリン異常症患者のデータ\n\n\nmyeloid\n急性骨髄性白血病のシミュレーションデータ\n\n\nmyeloma\n多発性骨髄腫患者のデータ\n\n\nnafld1\n非アルコール性脂肪肝疾患（NAFLD）のデータ\n\n\nnwtco\n腫瘍の組織学的判定と生存率の関係のデータ\n\n\novarian\n卵巣ガンに対し2治療を行ったランダム化比較試験のデータ\n\n\npbc\n原発性硬化性胆管炎に関するランダム化比較試験の結果\n\n\nrats\nラットでの発がんを評価したデータ\n\n\nrats2\nラットに発がん性物質を注射し、治療処理したデータ\n\n\nrhDNase\n嚢胞性線維症へのrhDNaseの効果を評価したデータ\n\n\nrotterdam\nロッテルダム腫瘍バンクに登録されている原発性乳がん患者のデータ\n\n\nsolder\n電子部品を基板につける際のはんだ付けの不良のデータ\n\n\nsurvexp.us\n1940～2012年のアメリカの年齢と性別のデータ\n\n\ntobin\nトービット・モデルの論文で用いられたデータ\n\n\ntransplant\n肝移植を待つ患者のデータ\n\n\nturbine\nタービンのホイールに生じたクラックに関するデータ\n\n\nudca\n原発性胆汁性肝硬変に対するウルソデオキシコール酸投与試験のデータ\n\n\nvalveSeat\nディーゼルエンジンのバルブシートの交換時期に関するデータ\n\n\nveteran\n退官軍人の肺がんのデータ",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>生存時間解析</span>"
    ]
  },
  {
    "objectID": "chapter30.html#打ち切り",
    "href": "chapter30.html#打ち切り",
    "title": "30  生存時間解析",
    "section": "30.6 打ち切り",
    "text": "30.6 打ち切り\n打ち切り（censoring）とは、イベントとは別の理由で治験に参加している患者や耐久性を検査しているボルトの試験が中止してしまうような場合を指します。\n治験であれば、副作用によって治験に参加し続けるのをあきらめる場合や、対象となるイベント（ガンの治験であれば死亡など）以外の理由（例えば交通事故など）で患者が亡くなるのが典型的な打ち切りです。ボルトの耐久性試験でも、破断の前にボルトが緩んで抜けてしまったり、繋ぎとめている部材が先に破断してしまうような場合には、打ち切りとして取り扱うことになります。特に治験では打ち切りはほぼ必ず起こります。\n\n\n\n図1：打ち切り（censoring）\n\n\n\n30.6.1 Surv関数\nRでのデータセットを見ると、特にガン関連のデータセットではほぼ必ず打ち切りに関する列が登録されています。以下はcancerデータセットの始めの6行です。各行はそれぞれ一人の患者のデータであり、timeが観察期間、statusが打ち切り（status=1）または死亡（status=2）です。このstatusが打ち切りを表すラベルとなります。\n\n\n\nガンのデータセットでの打ち切り\n\ncancer |&gt; head()\n##   inst time status age sex ph.ecog ph.karno pat.karno meal.cal wt.loss\n## 1    3  306      2  74   1       1       90       100     1175      NA\n## 2    3  455      2  68   1       0       90        90     1225      15\n## 3    3 1010      1  56   1       0       90        90       NA      15\n## 4    5  210      2  57   1       1       90        60     1150      11\n## 5    1  883      2  60   1       0      100        90       NA       0\n## 6   12 1022      1  74   1       1       50        80      513       0\n\n\nRで打ち切りを取り扱う場合には、まずSurv関数を用いて時間と打ち切りデータをSurvクラスのオブジェクトに変換する必要があります。Surv関数は時間（上の例のtime）と打ち切りのデータ（上の例のstatus）を引数にする関数で、返り値では打ち切りのデータに+が付くことになります。survivalパッケージでは、この+が付いたデータを打ち切りとして、解析で取り扱います。打ち切りデータは、打ち切り/死亡をそれぞれ0/1、FALSE/TRUE、1/2のいずれかで取り扱うことになります。\n\n\n\nSurv関数と打ち切り\n\n# 生存時間と打ち切りデータを引数にする\nSurv(cancer$time, cancer$status) |&gt; \n  head(20)\n##  [1]  306   455  1010+  210   883  1022+  310   361   218   166   170   654 \n## [13]  728    71   567   144   613   707    61    88\n\n\n\n\n30.6.2 左側打ち切りのデータ\n打ち切りは通常開始後に起こるのですが、開始時に打ち切りが起こることもあります。時間の軸が左から右に進むと考えて、通常の打ち切りのことを右側打ち切り（right-censoring）、開始時の打ち切りを左側打ち切り（left-censoring）と呼びます。\n左側打ち切りは、例えば病気の進行を調べる際に、診断から時間が空いてから投薬や観察を始める場合などがあります。この場合、診断から観察開始までに亡くなる方は観察できないため、左側打ち切りとして取り扱う必要が生じます。\nSurv関数で左側打ち切りを取り扱う場合には、Surv関数は3つ引数を取ることになります。第一引数に観察開始時間、第二引数に観察終了時間、第三引数は打ち切りデータとなります。左側打ち切りのあるデータの場合、Surv関数の返り値は開始時間、終了時間と打ち切りを示す+の3つで示される形となります。\n\n\n\n左側打ち切りありのデータ\n\n# startが組み入れ時間、stopが死亡または打ち切り時間、\n# eventが打ち切り（0が打ち切り例）\nhead(survival::heart)\n##   start stop event        age      year surgery transplant id\n## 1     0   50     1 -17.155373 0.1232033       0          0  1\n## 2     0    6     1   3.835729 0.2546201       0          0  2\n## 3     0    1     0   6.297057 0.2655715       0          0  3\n## 4     1   16     1   6.297057 0.2655715       0          1  3\n## 5     0   36     0  -7.737166 0.4900753       0          0  4\n## 6    36   39     1  -7.737166 0.4900753       0          1  4\n\nSurv(heart$start, heart$stop, heart$event) |&gt; head(10)\n##  [1] ( 0, 50]  ( 0,  6]  ( 0,  1+] ( 1, 16]  ( 0, 36+] (36, 39]  ( 0, 18] \n##  [8] ( 0,  3]  ( 0, 51+] (51,675]",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>生存時間解析</span>"
    ]
  },
  {
    "objectID": "chapter30.html#カプランマイヤー曲線",
    "href": "chapter30.html#カプランマイヤー曲線",
    "title": "30  生存時間解析",
    "section": "30.7 カプランマイヤー曲線",
    "text": "30.7 カプランマイヤー曲線\n生存時間分析で用いられる統計手法のうち、最もよく用いられているものは、カプランマイヤー曲線（Kaplan-Meier）、ログランク検定（log-rank test）、Cox回帰の3つです。このうち、カプランマイヤー曲線は一般的に生存時間曲線として、治験や耐久性試験の結果で示されています。\nカプランマイヤー曲線は上記の生存時間S(t)をデータから計算する方法です。qtをその時間tにイベントが起きた割合としたとき、カプランマイヤー曲線は以下の式で表されます。要は、イベントが起きる度に、その時間における生存者の割合を計算し、その時点までの生存者の割合をすべて掛け算することで、生存時間を計算します。\n\\[S(t)=\\prod_{i=1}^{t}1-q_{t}\\]\nこの表現では分かりにくいため、例を挙げて説明します。以下のようなデータがあり、イベントはdayに起こり、打ち切りが起こった場合にはcensored=0であるとします。\n\n\n\n\n\nsubject\nday\ncensored\n\n\n\n\n1\n1\n1\n\n\n2\n1\n1\n\n\n3\n2\n1\n\n\n4\n2\n0\n\n\n5\n3\n1\n\n\n6\n3\n1\n\n\n7\n4\n1\n\n\n8\n4\n1\n\n\n\n\n\n打ち切りを考慮した場合・しない場合のそれぞれについて、以下の表のようにカプランマイヤーの計算を行います。最も右の列である生存時間は、その時間までの生存割合の積となっています。\n打ち切りありとなしで異なるのは、day2、つまり打ち切りがある場合には、打ち切りされた例は生存していると換算して計算し、day3ではリスク集団（その時点の事前まで生存しており、イベントが起きる可能性がある集団）が打ち切り+死亡により2人減って4名になる、という変化を取ることです。下に示した通り、表の計算式で計算した左のカプランマイヤー曲線は、右のsurvivalパッケージで計算した結果と一致します。\n\n打ち切りを考慮しない場合打ち切りを考慮した場合\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nday\nリスク集団\n生存者数\n時点の生存割合\nカプランマイヤーの計算式\n生存割合\n\n\n\n\n0\n8\n8\n8/8\n8/8\n1.00\n\n\n1\n8\n6\n6/8\n8/8×6/8\n0.75\n\n\n2\n6\n4\n4/6\n8/8×6/8×4/6\n0.50\n\n\n3\n4\n2\n2/4\n8/8×6/8×4/6×2/4\n0.25\n\n\n4\n2\n0\n0/2\n8/8×6/8×4/6×2/4×0/2\n0.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nday\nリスク集団\n生存者数\n時点の生存割合\nカプランマイヤーの計算式\n生存割合\n\n\n\n\n0\n8\n8\n8/8\n8/8\n1.0000\n\n\n1\n8\n6\n6/8\n8/8×6/8\n0.7500\n\n\n2\n6\n5\n5/6\n8/8×6/8×5/6\n0.6250\n\n\n3\n4\n2\n2/4\n8/8×6/8×5/6×2/4\n0.3125\n\n\n4\n2\n0\n0/2\n8/8×6/8×5/6×2/4×0/2\n0.0000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n30.7.1 survfit関数\nこのように、カプランマイヤー曲線は打ち切りを考慮したリスク集団と生存者数が分かれば計算できます。Rでは、この計算をsurvfit関数で行うことができます。\nsurvfit関数はformulaを引数に取りますが、このformulaの左辺は上で紹介したSurv関数の返り値となります。通常はこの左辺に直接Surv関数を書き込んで用います。生存時間に対する説明変数がない場合には、formulaの右辺は1とします。data引数にデータフレームを指定するのは線形回帰のlm関数と同じです。\nsurvfit関数の返り値として、カプランマイヤー曲線で示されているリスク集団の数（n）、イベントの起こった回数（events）、生存割合が50％となる日数（median）、生存割合が50％となる日数の95％信頼区間（0.95LCL、0.95UCL）が表示されます。\n\n\n\nsurvfit関数でカプランマイヤー曲線の計算\n\nresult_km &lt;- survfit(Surv(time, status) ~ 1, data = cancer)\n\nresult_km\n## Call: survfit(formula = Surv(time, status) ~ 1, data = cancer)\n## \n##        n events median 0.95LCL 0.95UCL\n## [1,] 228    165    310     285     363\n\n\nまた、survfit関数の返り値をplot関数の引数とすると、カプランマイヤー曲線がグラフとして表示されます。点線は生存時間の95％信頼区間を示します。\n\n\n\nカプランマイヤー曲線の表示\n\nplot(result_km)\n\n\n\n\n\n\n\n\n\n\n\n30.7.2 ggsurvfitパッケージ\nsurvminerパッケージ(Kassambara, Kosinski, and Biecek 2021)とggsurvfitパッケージ (Sjoberg et al. 2023)はいずれもカプランマイヤー曲線を表示するggplot2のExtensionです。前者の方が機能が多く、後者はカプランマイヤー曲線の描画に特化したパッケージです。カプランマイヤー曲線をグラフにするためだけであれば後者のggsurvfitを用いるとよいでしょう。\nggsurvfitパッケージのggsurvfit関数は、survfit関数の返り値を引数に取り、ggplot2でグラフを描画する関数です。\n\n\n\nggsurvfit::ggsurvfit関数\n\npacman::p_load(ggsurvfit)\nresult_km |&gt; ggsurvfit()\n\n\n\n\n\n\n\n\n\nggplot2のように、+で関数を繋ぐと表示する内容を変更することができます。add_confidence_intervalを用いれば信頼区間、add_risktableを用いればリスクテーブル（リスク集団とイベント数の表）、add_censor_markを用いれば打ち切りが起きた点を表示してくれます。\n\n\n\nggsurvfitに要素を追加する\n\npacman::p_load(ggsurvfit)\nresult_km |&gt; \n  ggsurvfit() +\n  add_confidence_interval() + # 信頼区間の表示\n  add_risktable() + # リスクテーブル（下の表）の表示\n  add_censor_mark() # 打ち切り点（グラフ上のプラス）の表示\n\n\n\n\n\n\n\n\n\n\n\n30.7.3 説明変数がある場合のカプランマイヤー曲線\nsurvfit関数を始めとしたsurvivalパッケージの関数では、formulaの右辺に説明変数を追加することで、説明変数による生存時間への影響を解析できるようになっています。survfit関数では、説明変数で分けて評価した場合のカプランマイヤー曲線の計算が行われます。\n\n\n\n説明変数を加えた場合のカプランマイヤー曲線\n\nresult_km2 &lt;- survfit(Surv(time, status) ~ sex, data = cancer)\nresult_km2\n## Call: survfit(formula = Surv(time, status) ~ sex, data = cancer)\n## \n##         n events median 0.95LCL 0.95UCL\n## sex=1 138    112    270     212     310\n## sex=2  90     53    426     348     550\n\n\n\n\n\n説明変数ありのカプランマイヤー曲線の表示\n\nresult_km2 |&gt; \n  ggsurvfit() +\n  add_confidence_interval()",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>生存時間解析</span>"
    ]
  },
  {
    "objectID": "chapter30.html#log-rank検定",
    "href": "chapter30.html#log-rank検定",
    "title": "30  生存時間解析",
    "section": "30.8 log-rank検定",
    "text": "30.8 log-rank検定\nlog-rank検定は生存時間が説明変数によって異なるかどうかを検定する、ノンパラメトリックな検定手法です。治験の生存時間解析において、p値の計算は主にこのlog-rank検定を用いて行われています。\nRでは、survdiff関数を用いてlog-rank検定の計算を行うことができます。survdiff関数はsurvfit関数と同様に、左辺にSurv関数の返り値、右辺に説明変数を取るformulaを引数に取ります。data引数にデータフレームを設定できるのもsurvfit関数と同様です。\n\n\n\nlog-rank検定\n\nsurvdiff(Surv(time, status) ~ sex, data = cancer)\n## Call:\n## survdiff(formula = Surv(time, status) ~ sex, data = cancer)\n## \n##         N Observed Expected (O-E)^2/E (O-E)^2/V\n## sex=1 138      112     91.6      4.55      10.3\n## sex=2  90       53     73.4      5.68      10.3\n## \n##  Chisq= 10.3  on 1 degrees of freedom, p= 0.001\n\n\n\n30.8.1 survfit2関数でlog-rank検定\nggsurvfitパッケージには、survfit2関数という、survfitと似た関数が設定されています。このsurvfit2関数はsurvfitとsurvdiffを同時に行うような関数となっており、計算結果にlog-rank検定のp値を含んでいます。このsurvfit2関数の返り値を用いると、ggsurvfit関数によるカプランマイヤー曲線の表示にadd_pvalue関数でlog-rank検定のp値を付け加えることができます。\n\n\n\nsurvfit2関数とlog-rank検定\n\n# log-rankのp値を含める場合は、survfit2が必要（survfit2はggsurvfitの関数）\nresult_km2 &lt;- survfit2(Surv(time, status) ~ sex, data = cancer)\n\nresult_km2 |&gt; survfit2_p() # log-rankのp値を表示\n## [1] \"p=0.001\"\n\n# survfit関数と同じようにplotでカプランマイヤーを表示できる\nresult_km2 |&gt; plot() \n\n\n\n\n\n\n\n\n\nresult_km2 |&gt; \n  ggsurvfit() +\n  add_confidence_interval() +\n  add_pvalue() # p値を表記",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>生存時間解析</span>"
    ]
  },
  {
    "objectID": "chapter30.html#cox回帰",
    "href": "chapter30.html#cox回帰",
    "title": "30  生存時間解析",
    "section": "30.9 Cox回帰",
    "text": "30.9 Cox回帰\nCox回帰は、説明変数間でハザードの比（ハザード比）がどの時間でも一定であるとして、生存時間を回帰する手法です。\nCox回帰では、ある条件でのハザードh1(t)と対照条件でのハザードh0(t)に以下のような関係があるとします。\n\\[h_{1}(t)=\\psi h_{0}(t)\\]\nこの関係が成り立つ、つまりハザード比が一定であることを、比例ハザード性と呼びます。このψを以下の式で置き換えることで、生存時間を回帰的に分析することができます。\n\\[\\psi=\\exp(ax)\\]\nここで、xは説明変数、aは係数となります。例えば性別間での差を知りたい場合には、男性：x=0、女性：x=1として、\\(h_{F}(t)=\\exp(a) \\cdot h_{M}(t)\\)という形で、男性のハザードに対して女性のハザードが\\(\\exp(a)\\)倍となるとします。\nCox回帰では、このψの説明変数を重回帰のように増やすこともできます。\n\\[\\psi=\\exp(a_{1}x_{1}+a_{2}x_{2}+ \\cdots +a_{p}x_{p})\\]\nCox回帰では比例ハザード性を仮定しているため、比例ハザード性が成立しない、つまりハザード比が時間とともに変化するような場合には結果が不正確になります。\nRでは、Cox回帰の計算をcoxph関数で行います。引数はカプランマイヤーのsurvfit関数やlog-rank検定のsurvdiff関数と同じく、formulaとdataになります。\n説明変数が1つである場合には、検定の結果としてLikelihood ratio test（尤度比検定）、Wald test（Wald検定）、Score (logrank) test（スコア検定）の結果が表示されます。一般的にはWald検定の結果を用いることが多いようです。\n\n\n\nCox回帰\n\nresult_km2_cox &lt;- coxph(Surv(time, status) ~ sex, data = cancer)\nsummary(result_km2_cox)\n## Call:\n## coxph(formula = Surv(time, status) ~ sex, data = cancer)\n## \n##   n= 228, number of events= 165 \n## \n##        coef exp(coef) se(coef)      z Pr(&gt;|z|)   \n## sex -0.5310    0.5880   0.1672 -3.176  0.00149 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n##     exp(coef) exp(-coef) lower .95 upper .95\n## sex     0.588      1.701    0.4237     0.816\n## \n## Concordance= 0.579  (se = 0.021 )\n## Likelihood ratio test= 10.63  on 1 df,   p=0.001\n## Wald test            = 10.09  on 1 df,   p=0.001\n## Score (logrank) test = 10.33  on 1 df,   p=0.001\n\n\n\n30.9.1 Cox回帰のモデル選択\nCox回帰では、26章で説明したAICによるモデル選択で、説明変数を選択することができます。Rでモデル選択を行う場合には、まずcoxph関数のformulaに説明変数をすべて足した式（フルモデル）を設定します。この式をstep関数の引数に取ることで、AICによるモデル選択の計算が行われます。\n以下の例では、cancerデータセットのCox回帰に関するモデル選択を行っています。モデル選択の結果、ageがモデルから外されている、つまり年齢は生存時間に大きな影響がないとして説明変数から取り除かれていることがわかります。\n\n\n\nCox回帰のモデル選択\n\n\nmodel_All_coxph &lt;- \n  coxph(Surv(time, status) ~ sex + age + ph.ecog + ph.karno, data = cancer |&gt; na.omit())\n\nresult_step &lt;- step(model_All_coxph, trace = 0)\n\nresult_step\n## Call:\n## coxph(formula = Surv(time, status) ~ sex + ph.ecog + ph.karno, \n##     data = na.omit(cancer))\n## \n##              coef exp(coef) se(coef)      z        p\n## sex      -0.53142   0.58777  0.19735 -2.693 0.007085\n## ph.ecog   0.74917   2.11524  0.21182  3.537 0.000405\n## ph.karno  0.01778   1.01794  0.01112  1.598 0.110009\n## \n## Likelihood ratio test=22.16  on 3 df, p=6.038e-05\n## n= 167, number of events= 120",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>生存時間解析</span>"
    ]
  },
  {
    "objectID": "chapter30.html#cox回帰のモデル評価",
    "href": "chapter30.html#cox回帰のモデル評価",
    "title": "30  生存時間解析",
    "section": "30.10 Cox回帰のモデル評価",
    "text": "30.10 Cox回帰のモデル評価\nCox回帰での計算が正しく行われていることを確認する場合には、残差を調べます。Cox回帰でチェックされる残差は主にマルチンゲール残差（Martingale residuals）とシェーンフェルド残差（Schoenfeld residuals）の2つです。\n計算は簡単で、coxph関数の返り値をresiduals関数の引数に取るだけです。マルチンゲール残差を計算する場合には引数にtype=\"martingale\"を、シェーンフェルド残差を計算する場合にはtype=\"schoenfeld\"を設定します。\n\n\n\nマルチンゲール残差とシェーンフェルド残差\n\n# マルチンゲール残差\nresult_km2_cox |&gt; residuals(type=\"martingale\") |&gt; head()\n##          1          2          3          4          5          6 \n##  0.1719970 -0.3880051 -3.5060567  0.4814561 -2.5060567 -3.5060567\n\n# シェーンフェルド残差\nresult_km2_cox |&gt; residuals(type=\"schoenfeld\") |&gt; head()\n##          5         11         11         11         12         13 \n##  0.7228149 -0.2764095 -0.2764095 -0.2764095 -0.2793553 -0.2816122\n\n\nマルチンゲール残差やシェーンフェルド残差を確認する場合には、survminerパッケージのggcoxdiagnostics関数を用いるのが簡単でよいでしょう。ggcoxdiagnostics関数は引数にcoxph関数の返り値と残差のtypeを取ります。計算結果はグラフで表示され、青の線が概ね一定であれば比例ハザード性が成立しているとします。\n\n\n\nggcoxdiagnostics関数でCox回帰を評価する\n\npacman::p_load(survminer)\n\nresult_step |&gt; ggcoxdiagnostics(type=\"martingale\")\n\n\n\n\n\n\n\n\n\nresult_step |&gt; ggcoxdiagnostics(type=\"schoenfeld\")",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>生存時間解析</span>"
    ]
  },
  {
    "objectID": "chapter30.html#ハザード比",
    "href": "chapter30.html#ハザード比",
    "title": "30  生存時間解析",
    "section": "30.11 ハザード比",
    "text": "30.11 ハザード比\n治験などでは、ハザード比の計算にCox回帰が用いられています。このハザード比は上の式で示したψで、ある条件におけるハザードh1(t)と対照のハザードh0(t)の比になります。\n\\[\\psi=\\frac{h_{1}(t)}{h_{0}(t)}\\]\nハザード比は一般的にフォレストプロットと呼ばれる、代表値を点、信頼区間を線で表した図で表記されます。フォレストプロットについてはggplot2の章で簡単に紹介しています。\nRでのハザード比の計算とフォレストプロットの作成には、survivalAnalysisパッケージ (Wiesweg 2022)を用いるのが便利です。cox_as_data_frame関数を用いると、各説明変数ごとのハザード比（HR、hazard ratio）、95%信頼区間（Lower_CI、Upper_CI）を含むデータフレームを返してくれます。\n以下のグラフでは、sexとph.ecogのハザード比の信頼区間が1に被っていない形になっています。この図から、sex、ph.ecogのハザード比は1ではなく、いずれも生存時間に統計的に有意な影響を与えていることがわかります。\n\n\n\nハザード比\n\npacman::p_load(survivalAnalysis)\n\n# coxph関数の返り値をcox_as_data_frame関数の引数に与える\ndf_step &lt;- \n  survivalAnalysis::cox_as_data_frame(result_step)\n\n# Cox回帰の結果をデータフレームにまとめてくれる\ndf_step\n##   factor.id factor.name factor.value        HR  Lower_CI  Upper_CI    Inv_HR\n## 1       sex         sex &lt;continuous&gt; 0.5877701 0.3992326 0.8653444 1.7013455\n## 2   ph.ecog     ph.ecog &lt;continuous&gt; 2.1152378 1.3965408 3.2037956 0.4727601\n## 3  ph.karno    ph.karno &lt;continuous&gt; 1.0179354 0.9959836 1.0403710 0.9823806\n##   Inv_Lower_CI Inv_Upper_CI            p\n## 1    1.1556092     2.504806 0.0070849192\n## 2    0.3121298     0.716055 0.0004051125\n## 3    0.9611956     1.004033 0.1100091086\n\n# フォレストプロットの表示\ndf_step |&gt; \n  ggplot(aes(x = HR, xmax = Upper_CI, xmin = Lower_CI, y = factor.id, color = factor.id)) +\n  geom_point(size = 3) +\n  geom_linerange(linewidth = 1)+\n  geom_vline(xintercept = 1)",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>生存時間解析</span>"
    ]
  },
  {
    "objectID": "chapter30.html#パラメトリックな手法",
    "href": "chapter30.html#パラメトリックな手法",
    "title": "30  生存時間解析",
    "section": "30.12 パラメトリックな手法",
    "text": "30.12 パラメトリックな手法\nカプランマイヤー曲線、log-rank検定はノンパラメトリックな手法、Cox回帰はセミパラメトリックな手法であるとされています。これは、いずれも明確な確率分布に基づいて計算する統計手法では無いからです。\n一方で、明確な確率分布に基づいたパラメトリックな手法、つまり指数分布やワイブル分布を仮定して生存曲線やハザードを直接計算する方法もあります。\nRでパラメトリックな手法を用いる場合には、survreg関数を用います。survreg関数はカプランマイヤーのsurvfit、log-rank検定のsurvdiff、Cox回帰のcoxph関数と同様に、Surv関数を含むformulaと確率分布（dist）を引数に取る関数です。確率分布には、ハザード一定であればdist=\"exponential\"を、ハザードが変化する場合にはdist=\"weibull\"を指定します。\n以下の例では、ハザード一定モデルを用いてsurvregの計算した結果と、ハザードのグラフを示します。\n\n\n\nハザード一定モデルでのsurvreg関数\n\n# ハザード一定モデル\nset.seed(0)\ntime_s &lt;- rexp(1000, rate = 0.01) |&gt; round() + 1\n\n# survreg関数でハザード一定モデルを計算する\nts_survreg &lt;- survreg(Surv(time_s, rep(1, 1000)) ~ 1, dist = \"exponential\")\nts_survreg\n## Call:\n## survreg(formula = Surv(time_s, rep(1, 1000)) ~ 1, dist = \"exponential\")\n## \n## Coefficients:\n## (Intercept) \n##    4.644025 \n## \n## Scale fixed at 1 \n## \n## Loglik(model)= -5644   Loglik(intercept only)= -5644\n## n= 1000\n\n# survregから計算したrate\n-ts_survreg$coefficients |&gt; exp() # rate（=1/scale）\n## (Intercept) \n## 0.009618899\n1 / ts_survreg$scale # shape\n## [1] 1\n\n# ハザード（=rate）の計算\nplot(1:100, rep((-ts_survreg$coefficients) |&gt; exp(), 100), type = \"l\")\n\n\n\n\n\n\n\n\n\nハザード一定モデルをdist=\"weibull\"で解析した場合の結果は以下の通りです。ハザードが一定とは少し異なる値を示します。\n\n\n\nハザード一定モデルのデータをワイブル分布として計算\n\n# ハザード一定モデル（Weibullとしてsurvregで計算）\nts_survreg &lt;- survreg(Surv(time_s, rep(1, 1000)) ~ 1, dist = \"weibull\")\nts_survreg\n## Call:\n## survreg(formula = Surv(time_s, rep(1, 1000)) ~ 1, dist = \"weibull\")\n## \n## Coefficients:\n## (Intercept) \n##    4.668915 \n## \n## Scale= 0.9388375 \n## \n## Loglik(model)= -5640.8   Loglik(intercept only)= -5640.8\n## n= 1000\n\nts_survreg$coefficients |&gt; exp() # scale（=1/rate）\n## (Intercept) \n##     106.582\n1 / ts_survreg$scale # shape\n## [1] 1.065147\n\n# ハザードを計算する関数\nhazard_f &lt;- function(time, intercept, slope){\n  slope * intercept * time ^ (slope - 1)\n}\n\nhazards &lt;- hazard_f(1:100, (-ts_survreg$coefficients |&gt; exp()), 1 / ts_survreg$scale)\nplot(1:100, hazards, type = \"l\", ylim=c(0, 0.014))\n\n\n\n\n\n\n\n\n\n\n30.12.1 ワイブル分布でのハザードの計算\n以下は、ワイブル分布から生成した生存時間をsurvreg関数で解析したものです。survreg関数から計算したハザードと、生存時間生成に用いたワイブル分布のパラメータからの計算結果がほぼ一致することがわかります。\n\n\n\nワイブル分布から生成したデータでのsurvregの計算\n\n# ワイブル分布での生存時間解析（scaleは1/rateに当たるもの、shapeは形状パラメータ）\nsv &lt;- rweibull(1000, shape = 0.85, scale = 100) |&gt; round() + 1\n\n# survregで計算する\nts_survreg &lt;- survreg(Surv(sv, rep(1, 1000)) ~ 1, dist = \"weibull\")\nts_survreg\n## Call:\n## survreg(formula = Surv(sv, rep(1, 1000)) ~ 1, dist = \"weibull\")\n## \n## Coefficients:\n## (Intercept) \n##     4.66072 \n## \n## Scale= 1.149131 \n## \n## Loglik(model)= -5714.7   Loglik(intercept only)= -5714.7\n## n= 1000\n\n# 上がscale、下がshape\nts_survreg$coefficients |&gt; exp() # scale（105.7でほぼ合っている）\n## (Intercept) \n##    105.7122\n1 / ts_survreg$scale # shape （0.870でほぼ合っている）\n## [1] 0.8702231\n\nhazards &lt;- hazard_f(1:100, (-ts_survreg$coefficients |&gt; exp()), 1 / ts_survreg$scale)\nplot(1:100, hazards, type = \"l\", ylim = c(0, 0.014))\npar(new = T)\nhazards &lt;- hazard_f(1:100, 1/100, 0.85)\nplot(1:100, hazards, type = \"l\", ylim = c(0, 0.014), col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n図1：打ち切り（censoring）\n\n\n\nKassambara, Alboukadel, Marcin Kosinski, and Przemyslaw Biecek. 2021. Survminer: Drawing Survival Curves Using ’Ggplot2’. https://CRAN.R-project.org/package=survminer.\n\n\nSjoberg, Daniel D., Mark Baillie, Charlotta Fruechtenicht, Steven Haesendonckx, and Tim Treis. 2023. Ggsurvfit: Flexible Time-to-Event Figures. https://CRAN.R-project.org/package=ggsurvfit.\n\n\nTerry M. Therneau, and Patricia M. Grambsch. 2000. Modeling Survival Data: Extending the Cox Model. New York: Springer.\n\n\nTherneau, Terry M. 2023. A Package for Survival Analysis in r. https://CRAN.R-project.org/package=survival.\n\n\nWiesweg, Marcel. 2022. survivalAnalysis: High-Level Interface for Survival Analysis and Associated Plots. https://CRAN.R-project.org/package=survivalAnalysis.\n\n\n武冨奈菜美, and 山本和嬉. 2023. “生存時間解析・信頼性解析のための統計モデル.” 日本統計学会誌 52 (2): 69–112. https://doi.org/10.11329/jjssj.52.69.",
    "crumbs": [
      "統計解析の基礎",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>生存時間解析</span>"
    ]
  },
  {
    "objectID": "chapter31.html",
    "href": "chapter31.html",
    "title": "31  purrr",
    "section": "",
    "text": "31.1 map関数\nmap関数はベクターもしくはリストと関数を引数に取り、ベクター/リストの要素を関数の引数とした返り値のリストを返す関数です。map関数はapply関数のmapply関数が最もよく似た機能を持つ関数ですが、mapplyのように返り値がベクターになったりリストになったりとすることはなく、常にリストを返します。\n下の例では、c(1, 2, 3)のベクターを引数とし、関数f（引数に3を足す関数）を各要素に適用します。返り値はそれぞれの計算結果のリストとなっています。\nベクターを引数とするmap関数\n\nf &lt;- \\(x){x + 3} # xに3を足す関数\nvec &lt;- 1:3\nmap(vec, f) # ベクターの要素を関数の引数とし、結果をリストで返す\n## [[1]]\n## [1] 4\n## \n## [[2]]\n## [1] 5\n## \n## [[3]]\n## [1] 6\nリストを引数に取った時にも同様に、map関数はリストの要素を関数の引数としたリストを返します。こちらの計算はほぼlapplyと同じです。\nリストを引数とするmap関数\n\nlst &lt;- list(1, c(1, 3), c(1, 3, 4))\nmap(lst, f)\n## [[1]]\n## [1] 4\n## \n## [[2]]\n## [1] 4 6\n## \n## [[3]]\n## [1] 4 6 7\n\nlapply(lst, f) # 結果はlapplyと同じ\n## [[1]]\n## [1] 4\n## \n## [[2]]\n## [1] 4 6\n## \n## [[3]]\n## [1] 4 6 7",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>purrr</span>"
    ]
  },
  {
    "objectID": "chapter31.html#map関数",
    "href": "chapter31.html#map関数",
    "title": "31  purrr",
    "section": "",
    "text": "ベクターを引数にしたときのmap関数\n\n\n\n\n\n\n\n\nリストを引数とするときのmap関数\n\n\n\n\n31.1.1 返り値がベクターのmap関数\n上記のmap関数は返り値がリストですが、map関数の後ろに型名がついた関数群（map_chr、map_lgl、map_int、map_dbl、map_vec）は返り値がベクターになる関数です。\n使い方はmap関数とほぼ同じで、ベクター/リストと関数を引数に取り、型名に従った型のベクターを返します。map_chrは文字列ベクター、map_lglは論理型ベクター、map_intは整数型ベクター、map_dblは数値型ベクターをそれぞれ返します。この設定された返り値の型を返さない関数を適用した場合には、これらのmap関数はエラーを返します。ただし、map_vec関数では返り値の型が引数に用いる関数の設定に従います。\n\n\n\nmap_vec：ベクターを返す\n\n\nまた、関数の返り値が2つ以上の要素からなる場合にもエラーが返ってきます。\n\n\n\nベクターを返り値とするmap関数\n\nmap_chr(1:3, class) # ベクターを引数に取る場合\n## [1] \"integer\" \"integer\" \"integer\"\n\nmap_chr(lst, mode) # リストを引数に取る場合\n## [1] \"numeric\" \"numeric\" \"numeric\"\n\nmap_lgl(lst, is.atomic) # 論理型（TRUEとFALSE）が返ってくる\n## [1] TRUE TRUE TRUE\n\nmap_int(lst, mean) # integerが返ってくる（エラーが出る）\n## Error in `map_int()`:\n## ℹ In index: 3.\n## Caused by error:\n## ! Can't coerce from a number to an integer.\n\nmap_dbl(lst, mean) # doubleが返ってくる\n## [1] 1.000000 2.000000 2.666667\n\nmap_dbl(lst, f) # 関数の返り値が1つでない場合はエラー\n## Error in `map_dbl()`:\n## ℹ In index: 2.\n## Caused by error:\n## ! Result must be length 1, not 2.\n\nmap_vec(lst, class) # 返り値の型を特定しない場合\n## [1] \"numeric\" \"numeric\" \"numeric\"\n\n\n\n\n\n\n\n\nmap関数と返り値の型\n\n\n\n\n\nRでは、演算の過程で型が変化してうまく演算が行われない、というエラーがしばしば起こります。変数等にデータ型を定義する過程がないために、変数の型が変わってもエラーを出す仕組みがないためです。型名付きのmap関数を用いることで、計算結果の型を縛ることができ、型の問題を起こりにくくすることができます。\n\n\n\n\n\n31.1.2 第一引数を計算に用いない場合のmap関数\nmap関数の第二引数にすでに引数ありの関数を用いる場合、関数名の前にチルダ（~）を用います。このように引数を指定して関数を用いる場合には、第一引数に指定したベクターは用いられません。このような場合には、第一引数の長さ分だけ単に第二引数で設定した計算を繰り返すことになります。この演算ではreplicate関数と同じような計算を行うことになります。ただしmap関数の返り値はリストで、replicate関数の返り値は行列となります。\n\n\n\nmap：チルダで関数を指定する\n\n\n\n\n\nチルダで引数あり関数を指定する\n\nset.seed(0)\n# 1~10から15回サンプリングする試行を4回繰り返す（返り値はリスト）\nmap(1:4, ~ sample(1:10, 15, replace = T)) \n## [[1]]\n##  [1]  9  4  7  1  2  7  2  3  1  5  5 10  6 10  7\n## \n## [[2]]\n##  [1]  9  5  5  9  9  5  5  2 10  9  1  4  3  6 10\n## \n## [[3]]\n##  [1] 10  6  4  4 10  9  7  6  9  8  9  7  8  6 10\n## \n## [[4]]\n##  [1]  7  3 10  6  8  2  2  6  6  1  3  3  8  6  7\n\nset.seed(0)\n# 同じ計算をreplicateで行う（返り値は行列）\nreplicate(4, sample(1:10, 15, replace = T))\n##       [,1] [,2] [,3] [,4]\n##  [1,]    9    9   10    7\n##  [2,]    4    5    6    3\n##  [3,]    7    5    4   10\n##  [4,]    1    9    4    6\n##  [5,]    2    9   10    8\n##  [6,]    7    5    9    2\n##  [7,]    2    5    7    2\n##  [8,]    3    2    6    6\n##  [9,]    1   10    9    6\n## [10,]    5    9    8    1\n## [11,]    5    1    9    3\n## [12,]   10    4    7    3\n## [13,]    6    3    8    8\n## [14,]   10    6    6    6\n## [15,]    7   10   10    7",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>purrr</span>"
    ]
  },
  {
    "objectID": "chapter31.html#applyとmap",
    "href": "chapter31.html#applyとmap",
    "title": "31  purrr",
    "section": "31.2 applyとmap",
    "text": "31.2 applyとmap\nデータフレームは基本的にリストですので、map関数の引数に取ることができます。この時の計算はapply関数で列方向（MARGIN=2）での計算とほぼ同じになります。ただし、apply関数の返り値はベクターで、map関数の返り値はリストです。apply関数と一致した結果を返す関数はmap_vec（返り値が数値の場合はmap_dbl）になります。\n\n\n\napplyとmap関数の演算\n\napply(iris[, 1:4], 2, mean)\n## Sepal.Length  Sepal.Width Petal.Length  Petal.Width \n##     5.843333     3.057333     3.758000     1.199333\n\nmap(iris[, 1:4], mean)\n## $Sepal.Length\n## [1] 5.843333\n## \n## $Sepal.Width\n## [1] 3.057333\n## \n## $Petal.Length\n## [1] 3.758\n## \n## $Petal.Width\n## [1] 1.199333\n\nmap_dbl(iris[, 1:4], mean)\n## Sepal.Length  Sepal.Width Petal.Length  Petal.Width \n##     5.843333     3.057333     3.758000     1.199333\n\n\n\n31.2.1 map関数とmap_dbl関数の違い\n上で少し述べた通り、関数の返り値の要素が2つ以上の場合、ベクターを返すmap_vec関数（map_dblなど）はエラーを返します。一方で通常のmap関数の返り値はリストですので、複数の返り値をリストの要素として返すことができます。\n\n\n\nmap関数とmap_vec関数の違い\n\nf2 &lt;- \\(x){cumprod(x)}\n\nmap(lst, f2) # mapは複数要素の結果を返す\n## [[1]]\n## [1] 1\n## \n## [[2]]\n## [1] 1 3\n## \n## [[3]]\n## [1]  1  3 12\n\n# map_dblはベクターを返すので、複数要素の結果を受け付けない（エラー）\nmap_dbl(lst, f2) \n## Error in `map_dbl()`:\n## ℹ In index: 2.\n## Caused by error:\n## ! Result must be length 1, not 2.\n\n\n\n\n31.2.2 関数内で引数の位置を指定する\nmap関数の第2引数に指定する関数には無名関数を用いることができます。また、関数内で引数の位置を指定する場合には、関数の前にチルダ（~）を置いたうえで、.xの形で引数が代入される位置を指定します（パイプ演算子における.や_と同じです）。この時、.がないxを引数として指定すると、関数外で定義されたxを拾ってきて計算する形となります。定義されていなければ当然エラーとなります。\n\n\n\n関数内で引数の位置を指定する\n\n2:4 |&gt; cumprod() # 累積積のベクターを返すcumprod関数\n## [1]  2  6 24\n\nmap(lst, \\(x){cumprod(x)}) # xを関数内で定義\n## [[1]]\n## [1] 1\n## \n## [[2]]\n## [1] 1 3\n## \n## [[3]]\n## [1]  1  3 12\n\nmap(lst, ~cumprod(.x)) # 第一引数が代入される位置を指定（上と同じ）\n## [[1]]\n## [1] 1\n## \n## [[2]]\n## [1] 1 3\n## \n## [[3]]\n## [1]  1  3 12\n\n# .がないと関数外のxを拾ってくる\nx &lt;- c(2, 3, 4)\nmap(lst, ~cumprod(x))\n## [[1]]\n## [1]  2  6 24\n## \n## [[2]]\n## [1]  2  6 24\n## \n## [[3]]\n## [1]  2  6 24\n\n# 定義していない変数yを用いるとエラーとなる\nmap(lst, ~cumprod(y))\n## Error in `map()`:\n## ℹ In index: 1.\n## Caused by error in `.f()`:\n## ! object 'y' not found\n\n\n\n\n\n\n\n\n関数とスコープ\n\n\n\n\n\nプログラム中で宣言した変数が有効に定義されている範囲のことをスコープと呼びます。Rではスコープの問題で困ることはほとんどないのですが、関数を定義するときや、35章で説明するShinyというWebアプリを作成するライブラリを用いるときには注意が必要となる概念です。\nRでは、ほとんどの変数はグローバルスコープと呼ばれる、どこでも大体呼び出せるスコープで定義されます。ただし、関数の定義の中で宣言した変数は関数外から呼び出すことはできません。これは関数の中での変数宣言がローカルスコープ（その場だけで呼び出せるスコープ）になっているからです。\nmap関数では、.xはローカルスコープの変数を呼び出し、xはグローバルスコープの変数を呼び出している形となります。\n\n# 関数内はローカルスコープなので、yはグローバルスコープには存在しない\nf &lt;- function(x){y &lt;- 1; x}\ny\n## Error in eval(expr, envir, enclos): object 'y' not found\n\n# 関数内（ローカルスコープ）でyに代入しても、グローバルスコープのyには影響しない\ny &lt;- 2\nf &lt;- function(x){y &lt;- 1; x}\ny\n## [1] 2\n\n# for文の中はグローバルスコープ\nfor(i in 1:5){\n  y &lt;- 5\n}\ny\n## [1] 5\n\n\n\n\n\n\n31.2.3 チルダの有無での結果の違い\n第一引数が関数の引数として用いられないときには、チルダ（~）の有無によって結果が変わります。チルダがない場合には、関数の結果が返ってこず、単に第一引数をリストにしたものが返ってきます。一方でチルダがある場合には、関数の演算が3回評価されて、結果がリストで返ってきます。\n\n\n\nチルダの有無による違い\n\nmap(1:3, runif(2)) # runif(2)は返ってこない\n## [[1]]\n## [1] 1\n## \n## [[2]]\n## [1] 2\n## \n## [[3]]\n## [1] 3\n\nmap(1:3, ~runif(2)) # runif(2)が返ってくる\n## [[1]]\n## [1] 0.4346595 0.7125147\n## \n## [[2]]\n## [1] 0.3999944 0.3253522\n## \n## [[3]]\n## [1] 0.7570871 0.2026923\n\n\n\n\n31.2.4 関数の位置に数値を入れる\n関数の位置に数値を入れると、インデックスとして取り扱われます。lstの各要素のインデックス[1]はすべて1になっているため、map_dbl(lst, 1)は1が3つのベクターが返ってきます。map_dbl(lst, 2)の場合、lstの1つ目の要素のインデックス[2]は定義されていないため、演算ができずエラーが返ってきます。\n\nlst # lstの各要素の始めのインデックスは1\n## [[1]]\n## [1] 1\n## \n## [[2]]\n## [1] 1 3\n## \n## [[3]]\n## [1] 1 3 4\n\nmap_dbl(lst, 1) # c(1, 1, 1)が返ってくる\n## [1] 1 1 1\n\n# lst[1]には2個目の要素がないのでエラー\nmap_dbl(lst, 2) \n## Error in `map_dbl()`:\n## ℹ In index: 1.\n## Caused by error:\n## ! Result must be length 1, not 0.\n\n\n\n31.2.5 複数の引数を指定する\n関数に複数の引数を指定する場合には、後に説明するmap2やpmapというものを用いる方法もありますが、map関数でも複数の引数を指定することはできます。\nmap関数で2つの引数を指定する場合、1つ目の引数はmap関数の始めの引数として指定し、2つ目の引数は関数（第2引数）の後、map関数の第3引数として指定します。\nただし、2つ目の引数を指定する場合には、後に説明するmap2やpmapを用いるほうがわかりやすくて良いでしょう。\n\n\n\nmap関数で2つ目の引数を指定する\n\nf3 &lt;- \\(x, y){c(x, y)} # 単にベクターをつなぐ関数\nvec\n## [1] 1 2 3\n\nmap(vec, f3, runif(1)) # xにvec、yにrunif(1)が設定される\n## [[1]]\n## [1] 1.0000000 0.7111212\n## \n## [[2]]\n## [1] 2.0000000 0.7111212\n## \n## [[3]]\n## [1] 3.0000000 0.7111212\n\nmap(vec, f3, runif(2)) # yにrunif(2)（一様乱数2つ）が設定される\n## [[1]]\n## [1] 1.0000000 0.1216919 0.2454885\n## \n## [[2]]\n## [1] 2.0000000 0.1216919 0.2454885\n## \n## [[3]]\n## [1] 3.0000000 0.1216919 0.2454885\n\n\n\n\n31.2.6 パイプ演算子とmap関数\npurrrはtidyverseに含まれるパッケージの一つです。他のtidyverseのパッケージ、dplyrやtidyr、stringr、forcatと同様に、purrrも基本的にはパイプ演算子（%&gt;%もしくは|&gt;、16章を参照）を使用しやすいように設計されています。パイプ演算子を用いることで、map関数を2つ実行し、2回演算後のベクターを取得するなどの演算を簡単に行うことができます。\n\n\n\nパイプ演算子を利用したmap関数の演算\n\nlst\n## [[1]]\n## [1] 1\n## \n## [[2]]\n## [1] 1 3\n## \n## [[3]]\n## [1] 1 3 4\n\nlst |&gt; map(cumprod) # 累積積を計算したリスト\n## [[1]]\n## [1] 1\n## \n## [[2]]\n## [1] 1 3\n## \n## [[3]]\n## [1]  1  3 12\n\nlst |&gt; map(cumprod) |&gt; map_dbl(sum) # 累積積の和をベクターで返す\n## [1]  1  4 16\n\n\n\n\n31.2.7 統計でのmap関数の使用\n線形回帰などを一度にたくさん行う際に、map関数は活躍します。split関数はデータフレームを因子の列で分割し、データフレームのリストとする関数です。この関数の返り値を引数としてmap関数を計算することで線形回帰などの統計の計算を一度に行うことができます。\n下の例では、irisを種（Species）ごとに分割したリスト（irisPL）をsplit関数で作成しています。このirisPLはsetosa、versicolor、virginicaと名前のついた3つのデータフレームのリストです。\nこのリストの要素である3つのデータフレームに対してそれぞれ線形回帰を行います。map関数では、チルダを用いてlm関数を呼び出し、リストの要素はdata=.xの形でdata引数として呼び出しています。dataにはirisPL$setosa、irisPL$versicolor、irisPL$virginicaのそれぞれのデータフレームが代入されますので、列名を用いて線形回帰を行うことができます。この形で計算した結果は線形回帰の結果オブジェクト（lmクラスのオブジェクト）のリストとなります。\nこのlmオブジェクトのリストから係数を取り出す場合には、上記の回帰結果にmap(coef)をパイプで繋ぎます。このcoef関数はlmオブジェクトを引数に取り、切片と傾き（coefficients）を返す関数です。さらにmap_dbl(2)をパイプで繋ぐことで、coef関数の返り値の2番目の要素、つまり傾きだけを取り出したベクターを求めることができます。\n\n\n\nmap関数を用いて一度に線形回帰を計算する\n\nirisPL &lt;- split(iris, iris$Species) # speciesで3つのデータフレームのリストにする\n\n# irisPLはデータフレーム3つのリスト\nirisPL$setosa[1:3,]; irisPL$versicolor[1:3,]; irisPL$virginica[1:3,]\n##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 1          5.1         3.5          1.4         0.2  setosa\n## 2          4.9         3.0          1.4         0.2  setosa\n## 3          4.7         3.2          1.3         0.2  setosa\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n## 51          7.0         3.2          4.7         1.4 versicolor\n## 52          6.4         3.2          4.5         1.5 versicolor\n## 53          6.9         3.1          4.9         1.5 versicolor\n##     Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n## 101          6.3         3.3          6.0         2.5 virginica\n## 102          5.8         2.7          5.1         1.9 virginica\n## 103          7.1         3.0          5.9         2.1 virginica\n\n# 線形回帰を3つ同時に行う。.xにirisPLの各要素が代入される\nirisPL |&gt; map(~lm(Sepal.Length ~ Sepal.Width, data = .x)) \n## $setosa\n## \n## Call:\n## lm(formula = Sepal.Length ~ Sepal.Width, data = .x)\n## \n## Coefficients:\n## (Intercept)  Sepal.Width  \n##      2.6390       0.6905  \n## \n## \n## $versicolor\n## \n## Call:\n## lm(formula = Sepal.Length ~ Sepal.Width, data = .x)\n## \n## Coefficients:\n## (Intercept)  Sepal.Width  \n##      3.5397       0.8651  \n## \n## \n## $virginica\n## \n## Call:\n## lm(formula = Sepal.Length ~ Sepal.Width, data = .x)\n## \n## Coefficients:\n## (Intercept)  Sepal.Width  \n##      3.9068       0.9015\n\n# 各線形回帰の係数をリストで返す\nirisPL |&gt; map(~lm(Sepal.Length ~ Sepal.Width, data = .x)) |&gt; map(coef) \n## $setosa\n## (Intercept) Sepal.Width \n##   2.6390012   0.6904897 \n## \n## $versicolor\n## (Intercept) Sepal.Width \n##   3.5397347   0.8650777 \n## \n## $virginica\n## (Intercept) Sepal.Width \n##   3.9068365   0.9015345\n\n# 線形回帰の係数のうち、傾き（2つ目の要素）だけをベクターで取り出す\nirisPL |&gt; map(~lm(Sepal.Length ~ Sepal.Width, data = .x)) |&gt; map(coef) |&gt; map_dbl(2)\n##     setosa versicolor  virginica \n##  0.6904897  0.8650777  0.9015345\n\n\n16章で紹介したように、このmapによる計算はdplyrのgroup_by関数・nest関数と合わせて用いることができます。かなり使い方が複雑ですが、うまく用いることでデータフレームの列として線形回帰の結果や係数などを出力することができます。\n\n\n\nmap関数でネストしたデータフレームを取り扱う\n\n# ネストしたデータフレームでのmap\nd &lt;- \n  iris |&gt; \n  group_by(Species) |&gt; \n  nest() |&gt; \n  mutate(\n    lmcalc = \n      map(data, ~lm(Sepal.Length ~ Sepal.Width, data = .)) |&gt; \n      map(coef)\n  )\n\nd # dの要素はネストされたデータフレームやlmオブジェクト\n## # A tibble: 3 × 3\n## # Groups:   Species [3]\n##   Species    data              lmcalc   \n##   &lt;fct&gt;      &lt;list&gt;            &lt;list&gt;   \n## 1 setosa     &lt;tibble [50 × 4]&gt; &lt;dbl [2]&gt;\n## 2 versicolor &lt;tibble [50 × 4]&gt; &lt;dbl [2]&gt;\n## 3 virginica  &lt;tibble [50 × 4]&gt; &lt;dbl [2]&gt;\n\nd[1, 3] |&gt; _[[1]] # setosaでの線形回帰の係数（切片・傾き）を呼び出し\n## [[1]]\n## (Intercept) Sepal.Width \n##   2.6390012   0.6904897\n\n\n\n\n\n\n\n\n複雑さと抽象化\n\n\n\n\n\npurrrの関数はかなり複雑な計算を1関数で行うことができるものばかりです。purrrの関数による計算をfor文などで行うと、数行～数十行のプログラムが必要となります。purrrは、複雑なプログラムを関数というブラックボックスに入れてしまうことで、演算を抽象化し、単純に見えるようにしています。\nプログラミングでは、プログラミング言語の複雑さとプログラムの複雑さの和がおおよそ一定になるとされています。以下のリンクでは、Rubyの開発者であるまつもとゆきひろさんの記事を載せています。プログラミング言語と複雑さ、抽象化の重要性が説明されています。\n単純すぎて流行らなかった「FORTH」、複雑すぎてうまくいかなかった「PL/I」\n抽象データと継承\n抽象化のいいところは、演算したいことを単純な表現で、後から読んでわかりやすく実装することができる点です。抽象化される演算をきちんと理解さえしていれば、メンテナンス性のよい、わかりやすいコードを記述することができます。\n一方で、このpurrrやapply関数群、dplyr・tidyrの関数など、高度に抽象化された関数は、その挙動を理解するのが難しく、演算を理解するまでは何をやっているのかよくわからない、ということがよく起こります。tidyverseではデータを大幅にいじる関数を用いるため、この理解にかかる時間が長めです。ですので、学習コストが高くなり、学習を乗り越えた人同士でしかコードを理解できなくなります。\n特にpurrrは他の関数と比べても抽象化の度合いが高いため、学習コストがかなり高めです。いろいろ試して挙動を理解するのがよいでしょう。",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>purrr</span>"
    ]
  },
  {
    "objectID": "chapter31.html#map関数群",
    "href": "chapter31.html#map関数群",
    "title": "31  purrr",
    "section": "31.3 map関数群",
    "text": "31.3 map関数群\nmap関数の一覧を以下に示します。列名には返り値の型、横軸には引数の数を示します。\n\nd &lt;- readxl::read_excel(\"./data/purrr_functions.xlsx\")\n\nd |&gt; knitr::kable(caption=\"表1：purrrの関数群\")\n\n\n表1：purrrの関数群\n\n\n\n\n\n\n\n\n\n引数\n返り値がリスト\n返り値がベクター\n返り値が入力と同じ型\n返り値なし\n\n\n\n\n引数が1個\nmap\nmap_vec\nmodify\nwalk\n\n\n引数が2個\nmap2\nmap2_vec\nmodify2\nwalk2\n\n\n引数が1個＋インデックス\nimap\nimap_vec\nimodify\niwalk\n\n\n引数がN個\npmap\npmap_vec\nー\npwalk",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>purrr</span>"
    ]
  },
  {
    "objectID": "chapter31.html#引数と返り値の型が同じmodify関数",
    "href": "chapter31.html#引数と返り値の型が同じmodify関数",
    "title": "31  purrr",
    "section": "31.4 引数と返り値の型が同じ：modify関数",
    "text": "31.4 引数と返り値の型が同じ：modify関数\n上記の通り、map関数の返り値はリスト、map_dblの返り値は数値のベクターですが、引数と返り値の型が同じとしたい場合もあります。典型的な例はデータフレームです。データフレームを引数としてデータフレームが返ってくれば、dplyrやtidyrと合わせて用いやすくなります。このように、引数の型と返り値の型が同一となる関数がmodify関数です。使い方はmap関数と同じで、引数にリスト（データフレーム）と関数を取ります。\n\n\n\nmodify関数\n\n# 引数にデータフレームを準備する\nd &lt;- data.frame(\n  x = 1:3,\n  y = 2:4\n)\n\nmap(d, cumsum) # 返り値がリスト\n## $x\n## [1] 1 3 6\n## \n## $y\n## [1] 2 5 9\n\nmap_dbl(d, sum) # 返り値はベクター\n## x y \n## 6 9\n\nmodify(d, cumsum) # 返り値はデータフレーム\n##   x y\n## 1 1 2\n## 2 3 5\n## 3 6 9",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>purrr</span>"
    ]
  },
  {
    "objectID": "chapter31.html#map2関数",
    "href": "chapter31.html#map2関数",
    "title": "31  purrr",
    "section": "31.5 map2関数",
    "text": "31.5 map2関数\n引数に2つのリスト・ベクターを取ることができるのが、map2関数です。map2関数は2つ引数を取る関数を用いて、第一、第二引数に設定したリスト・ベクターを用いた演算を行います。apply関数群のうちのmapplyに似た働きをする関数ですが、引数の順番が異なること（mapplyは関数を第一引数とする）、返り値の型が一定（リスト）であることが異なります。map関数でも同じようなことはできますが、引数の順番・名称からmap2関数を用いるほうが理解しやすいでしょう。\n\n\n\nmap2関数\n\n\nmap2関数にもmap関数と同様に、ベクターを返す関数（map2_vec関数など）、与えた引数と同じ型を返すmodify2関数が設定されています。\nmap2関数で引数を数値とすると、この数値がリサイクルされ、第一引数の要素の数と揃えたうえで計算が行われることになります。また、第4引数を設定すると、この第4引数も関数の引数に適用することができます。\n\n\n\n引数を2つ取る：map2関数\n\nlst\n## [[1]]\n## [1] 1\n## \n## [[2]]\n## [1] 1 3\n## \n## [[3]]\n## [1] 1 3 4\n\nvec\n## [1] 1 2 3\n\nmap2(lst, vec, sum) # lstの要素とvecの要素をすべて足し合わせたリスト\n## [[1]]\n## [1] 2\n## \n## [[2]]\n## [1] 6\n## \n## [[3]]\n## [1] 11\n\nmap2_dbl(lst, vec, sum) # 返り値がベクターになる\n## [1]  2  6 11\n\nmapply(sum, lst, vec) # mapplyと同じ（引数の順番が異なる）\n## [1]  2  6 11\n\nmap2_dbl(lst, 100, sum) # 引数はリサイクルされる\n## [1] 101 104 108\n\nmap2_dbl(lst, vec, sum, 100) # 100もsumの引数に含まれる\n## [1] 102 106 111",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>purrr</span>"
    ]
  },
  {
    "objectID": "chapter31.html#walk関数",
    "href": "chapter31.html#walk関数",
    "title": "31  purrr",
    "section": "31.6 walk関数",
    "text": "31.6 walk関数\n関数の中には、返り値を得ることを目的としないものもあります。返り値を得ることを目的としない代表的な関数はwrite.table関数やprint関数などです。これらの関数では、ファイルを保存したり文字列を表示したりすることが目的であり、返り値を得ることを特に求めません。\nこのような、返り値を求めない関数と相性が良い関数がwalk関数です。walk関数はmap関数と同じく、第一引数で指定した引数を第二引数に指定した関数の引数として演算を行う関数ですが、返り値がありません。map関数でprint関数を用いると、print関数での表示と同時に返り値として文字列のリストが返ってきます。walk関数では、この文字列のリストを得ることなく、文字列の表示だけを行うことができます。\n\n\n\nwalk関数\n\n\n\n\n\n返り値を返さない：walk関数\n\nf &lt;- function(x){print(paste(x, \"the first\"))}\n\nmonth.name # 月の名前の文字列\n##  [1] \"January\"   \"February\"  \"March\"     \"April\"     \"May\"       \"June\"     \n##  [7] \"July\"      \"August\"    \"September\" \"October\"   \"November\"  \"December\"\n\nmap(month.name, f) # print（文字列表示）とリストが両方返ってくる\n## [1] \"January the first\"\n## [1] \"February the first\"\n## [1] \"March the first\"\n## [1] \"April the first\"\n## [1] \"May the first\"\n## [1] \"June the first\"\n## [1] \"July the first\"\n## [1] \"August the first\"\n## [1] \"September the first\"\n## [1] \"October the first\"\n## [1] \"November the first\"\n## [1] \"December the first\"\n## [[1]]\n## [1] \"January the first\"\n## \n## [[2]]\n## [1] \"February the first\"\n## \n## [[3]]\n## [1] \"March the first\"\n## \n## [[4]]\n## [1] \"April the first\"\n## \n## [[5]]\n## [1] \"May the first\"\n## \n## [[6]]\n## [1] \"June the first\"\n## \n## [[7]]\n## [1] \"July the first\"\n## \n## [[8]]\n## [1] \"August the first\"\n## \n## [[9]]\n## [1] \"September the first\"\n## \n## [[10]]\n## [1] \"October the first\"\n## \n## [[11]]\n## [1] \"November the first\"\n## \n## [[12]]\n## [1] \"December the first\"\n\nwalk(month.name, f) # print（文字列表示）だけが返ってくる\n## [1] \"January the first\"\n## [1] \"February the first\"\n## [1] \"March the first\"\n## [1] \"April the first\"\n## [1] \"May the first\"\n## [1] \"June the first\"\n## [1] \"July the first\"\n## [1] \"August the first\"\n## [1] \"September the first\"\n## [1] \"October the first\"\n## [1] \"November the first\"\n## [1] \"December the first\"\n\nf2 &lt;- function(x, y){print(paste(x, \"the first\", y))}\nwalk2(month.name, \"was a sunny day.\", f2) # 引数を2つ取る場合\n## [1] \"January the first was a sunny day.\"\n## [1] \"February the first was a sunny day.\"\n## [1] \"March the first was a sunny day.\"\n## [1] \"April the first was a sunny day.\"\n## [1] \"May the first was a sunny day.\"\n## [1] \"June the first was a sunny day.\"\n## [1] \"July the first was a sunny day.\"\n## [1] \"August the first was a sunny day.\"\n## [1] \"September the first was a sunny day.\"\n## [1] \"October the first was a sunny day.\"\n## [1] \"November the first was a sunny day.\"\n## [1] \"December the first was a sunny day.\"",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>purrr</span>"
    ]
  },
  {
    "objectID": "chapter31.html#imap関数",
    "href": "chapter31.html#imap関数",
    "title": "31  purrr",
    "section": "31.7 imap関数",
    "text": "31.7 imap関数\nimap関数は第一引数に指定したリスト・ベクターのインデックスを利用した計算を行うための関数です。imap関数では、チルダを用いた関数表現において、引数が入る位置.xの他に、リストのインデックス・名前を.yで呼び出すことができます。リストの要素に名前がついているときには.yは文字列の名前、名前がついていないときにはインデックスの数値が.yに代入され、計算が行われます。\n\n\n\nimap関数\n\nimap(iris, ~paste(.y, \"is\", .x[[1]])) # .yにcolnames（要素の名前）が入っている\n## $Sepal.Length\n## [1] \"Sepal.Length is 5.1\"\n## \n## $Sepal.Width\n## [1] \"Sepal.Width is 3.5\"\n## \n## $Petal.Length\n## [1] \"Petal.Length is 1.4\"\n## \n## $Petal.Width\n## [1] \"Petal.Width is 0.2\"\n## \n## $Species\n## [1] \"Species is setosa\"\n\nimap(lst, ~paste(.y, sum(.x), sep=\" / \")) # .yに要素の番号が入っている\n## [[1]]\n## [1] \"1 / 1\"\n## \n## [[2]]\n## [1] \"2 / 4\"\n## \n## [[3]]\n## [1] \"3 / 8\"",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>purrr</span>"
    ]
  },
  {
    "objectID": "chapter31.html#pmap関数",
    "href": "chapter31.html#pmap関数",
    "title": "31  purrr",
    "section": "31.8 pmap関数",
    "text": "31.8 pmap関数\npmap関数はデータフレームでのapply(x, 1, FUN)のような、行方向の計算に近いものを返す関数です。リストでは含まれるベクターの要素の数がそろっていない場合があるため、長さの異なる要素からなるリストを引数に取った時には、短いベクターをリサイクルして計算することになります。リサイクルが起きると予期せぬ計算が行われる場合があるため、やや使い方が難しい関数です。\n\n\n\npmap関数\n\nd &lt;- data.frame(\n  x = 1:4,\n  y = 4:1,\n  z = rep(100, 4)\n)\n\nd\n##   x y   z\n## 1 1 4 100\n## 2 2 3 100\n## 3 3 2 100\n## 4 4 1 100\n\n# 各列の1項目、2項目、3項目、4項目のそれぞれの和\npmap_dbl(d, sum) \n## [1] 105 105 105 105\n\n# apply(iris[1:5, 1:4], 1, sum)と同じで、横方向に合計を計算している\niris[1:5, 1:4] |&gt; pmap_dbl(sum)\n## [1] 10.2  9.5  9.4  9.4 10.2",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>purrr</span>"
    ]
  },
  {
    "objectID": "chapter31.html#reduceaccumulate関数",
    "href": "chapter31.html#reduceaccumulate関数",
    "title": "31  purrr",
    "section": "31.9 reduce・accumulate関数",
    "text": "31.9 reduce・accumulate関数\nreduce関数はリストやベクターを引数に取り、前から順番に関数を適用し、返り値として長さ1のベクターを返す関数です。accumulate関数は計算としてはreduce関数とほぼ同じことを行う関数ですが、計算の過程をすべてベクターの要素として返す関数です。\n\n\n\nreduce・accumulate関数\n\nreduce(1:4, `-`) # ((1-2)-3)-4の計算\n## [1] -8\n\nreduce(1:4, sum) # ((1+2)+3)+4の計算\n## [1] 10\n\naccumulate(1:4, sum) # 上の演算を順々にベクターとして返す\n## [1]  1  3  6 10\n\n\nreduce関数やaccumulate関数を用いると、for文での繰り返し計算を行うことなく、簡単に複雑な計算を行うことができます。下の例では、3つのベクターからなるリストを用いて、各ベクターのすべてに含まれる要素をreduce関数を用いて計算しています。また、accumulate関数を用いるとreduce関数での計算過程を追うことができるため、計算をトレースすることができます。\n\nset.seed(0)\ntemp &lt;- map(1:3, ~sample(1:10, 5, replace = TRUE))\ntemp # 1:10から5つサンプリングしたベクター3つのリスト\n## [[1]]\n## [1] 9 4 7 1 2\n## \n## [[2]]\n## [1] 7 2 3 1 5\n## \n## [[3]]\n## [1]  5 10  6 10  7\n\n# [[1]]と[[2]]に共に存在する要素で、[[3]]に含まれるものを計算\ntemp[[1]] |&gt; intersect(temp[[2]]) |&gt; intersect(temp[[3]])\n## [1] 7\n\n# 上と同じ演算\ntemp |&gt; reduce(intersect) \n## [1] 7\n\n# 上の演算を順々に計算する\ntemp |&gt; accumulate(intersect)\n## [[1]]\n## [1] 9 4 7 1 2\n## \n## [[2]]\n## [1] 7 1 2\n## \n## [[3]]\n## [1] 7",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>purrr</span>"
    ]
  },
  {
    "objectID": "chapter31.html#map_ifとmap_at関数",
    "href": "chapter31.html#map_ifとmap_at関数",
    "title": "31  purrr",
    "section": "31.10 map_ifとmap_at関数",
    "text": "31.10 map_ifとmap_at関数\nmap_if関数は第二引数に条件式を取り、条件式がTRUEとなる場合のみ第三引数に取った関数を適用する関数です。irisのように、数値と因子（Species）が混じっているような場合に、数値の列のみを計算の対象としたい場合などに利用できます。また、map_at関数は第二引数にインデックスを取り、インデックスで指定したリストの位置のみを計算の対象とする関数です。\n\n# 数値だけ平均に変換する\niris |&gt; map_if(is.numeric, mean) |&gt; str()\n## List of 5\n##  $ Sepal.Length: num 5.84\n##  $ Sepal.Width : num 3.06\n##  $ Petal.Length: num 3.76\n##  $ Petal.Width : num 1.2\n##  $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n# 4列目と5列目だけ関数で評価する\niris |&gt; map_at(c(4, 5), is.character) |&gt; str()\n## List of 5\n##  $ Sepal.Length: num [1:150] 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n##  $ Sepal.Width : num [1:150] 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n##  $ Petal.Length: num [1:150] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n##  $ Petal.Width : logi FALSE\n##  $ Species     : logi FALSE\n\n\n\n\n\n\nベクターを引数にしたときのmap関数\nリストを引数とするときのmap関数\nmap_vec：ベクターを返す\nmap：チルダで関数を指定する\nmap2関数\nwalk関数\n\n\n\nWickham, Hadley, and Lionel Henry. 2023. Purrr: Functional Programming Tools. https://CRAN.R-project.org/package=purrr.",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>purrr</span>"
    ]
  },
  {
    "objectID": "chapter32.html",
    "href": "chapter32.html",
    "title": "32  地理空間情報",
    "section": "",
    "text": "32.1 ベクタとラスタ\n地理空間情報はベクタとラスタの2つに大きく分けることができます。\nベクタとは、座標上で始点と終点が定まっており、その間を直線などで結ぶ形で構成される地理情報です。始点と終点の座標だけが定められているため、拡大・縮小しても線が滑らかなままであるという特徴があります。\nラスタとは、格子状に空間を分け、その格子ごとに値が設定されているようなデータを指します。空間を格子状に分けているため、拡大するとその格子のサイズによっては荒く見えることになります。デジタル写真などが典型的なラスタデータです。\n時と場合によりますが、地理空間上で区域がはっきり決まっているもの、例えば国や県、市町村などはベクタで、区域が決まっていないもの、例えば降雨量や人口密度などはラスタで取り扱うとよいかと思います。\nベクタは画像ソフトでの「ドロー系」（Adobe Illustratorなど）、ラスタは「ペイント系」（Adobe PhotoshopやWindows標準のペイントなど）に相当します。\nRで地理空間情報を取り扱う場合、ベクタもラスタも利用可能ですが、用いるライブラリは異なります。ベクタを取り扱う最も代表的なパッケージはsfパッケージ(Pebesma and Bivand 2023a; Pebesma 2018)です。ラスタを取り扱うパッケージはいくつかありますが、2023年現在ではstarsパッケージ(Pebesma and Bivand 2023b)か、terraパッケージ(Hijmans 2024)を用いるのが一般的になっています。",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>地理空間情報</span>"
    ]
  },
  {
    "objectID": "chapter32.html#sfパッケージ",
    "href": "chapter32.html#sfパッケージ",
    "title": "32  地理空間情報",
    "section": "32.2 sfパッケージ",
    "text": "32.2 sfパッケージ\nsfは「simple feature」の略で、地理空間をベクタで表記するISOの規格（ISO 19125）を指します。このISO規格に従い地理空間情報を表現し、データフレームと同じような形で地理空間情報を取り扱えるようにしたライブラリがsfです。\n\n\n\nsfの読み込み\n\npacman::p_load(sf)\n\n\nsfでのデータの例を以下に示します。worldはspDataパッケージ(Bivand, Nowosad, and Lovelace 2023)によって提供されているsfクラスのデータで、各国家の面積、人口、平均寿命、一人当たりGDPと地理空間情報を結び付けたデータとなっています。\nworldの中身を見ると、ほぼデータフレームと同じような表が表示されますが、追加で様々な情報が表示されています。データは177行11列のデータで、各行が各国の情報、列がその国のデータを表します。また、11列目はgeom（geometryの略）という列になっており、MULTIPOLYGONという型である、という形で表示されています。この地理情報の列についての説明は後ほど行います。\n\n\n\nsfの例：world\n\npacman::p_load(spData)\n\nworld\n## Simple feature collection with 177 features and 10 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -180 ymin: -89.9 xmax: 180 ymax: 83.64513\n## Geodetic CRS:  WGS 84\n## # A tibble: 177 × 11\n##    iso_a2 name_long continent region_un subregion type  area_km2     pop lifeExp\n##  * &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n##  1 FJ     Fiji      Oceania   Oceania   Melanesia Sove…   1.93e4  8.86e5    70.0\n##  2 TZ     Tanzania  Africa    Africa    Eastern … Sove…   9.33e5  5.22e7    64.2\n##  3 EH     Western … Africa    Africa    Northern… Inde…   9.63e4 NA         NA  \n##  4 CA     Canada    North Am… Americas  Northern… Sove…   1.00e7  3.55e7    82.0\n##  5 US     United S… North Am… Americas  Northern… Coun…   9.51e6  3.19e8    78.8\n##  6 KZ     Kazakhst… Asia      Asia      Central … Sove…   2.73e6  1.73e7    71.6\n##  7 UZ     Uzbekist… Asia      Asia      Central … Sove…   4.61e5  3.08e7    71.0\n##  8 PG     Papua Ne… Oceania   Oceania   Melanesia Sove…   4.65e5  7.76e6    65.2\n##  9 ID     Indonesia Asia      Asia      South-Ea… Sove…   1.82e6  2.55e8    68.9\n## 10 AR     Argentina South Am… Americas  South Am… Sove…   2.78e6  4.30e7    76.3\n## # ℹ 167 more rows\n## # ℹ 2 more variables: gdpPercap &lt;dbl&gt;, geom &lt;MULTIPOLYGON [°]&gt;\n\n\nworldのクラスはsf及びデータフレーム（正確にはtibble）で、各列には国名や短縮した国の記号などが記載されています。sfクラスはデータフレームでもあるため、おおむね通常のデータフレームと同じように取り扱うことができます。最後の列にあるgeomが地理空間情報で、summary関数の結果を見るとepsg:4326と記載されています。epsg:4326というのは世界測地系（WGS84）と呼ばれるものです。測地系については後ほど説明します。\n\n\n\nsfデータのクラス\n\nclass(world)\n## [1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nsummary(world)\n##     iso_a2           name_long          continent          region_un        \n##  Length:177         Length:177         Length:177         Length:177        \n##  Class :character   Class :character   Class :character   Class :character  \n##  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n##                                                                             \n##                                                                             \n##                                                                             \n##                                                                             \n##   subregion             type              area_km2             pop           \n##  Length:177         Length:177         Min.   :    2417   Min.   :5.630e+04  \n##  Class :character   Class :character   1st Qu.:   46185   1st Qu.:3.755e+06  \n##  Mode  :character   Mode  :character   Median :  185004   Median :1.040e+07  \n##                                        Mean   :  832558   Mean   :4.282e+07  \n##                                        3rd Qu.:  621860   3rd Qu.:3.075e+07  \n##                                        Max.   :17018507   Max.   :1.364e+09  \n##                                                           NA's   :10         \n##     lifeExp        gdpPercap                   geom    \n##  Min.   :50.62   Min.   :   597.1   MULTIPOLYGON :177  \n##  1st Qu.:64.96   1st Qu.:  3752.4   epsg:4326    :  0  \n##  Median :72.87   Median : 10734.1   +proj=long...:  0  \n##  Mean   :70.85   Mean   : 17106.0                      \n##  3rd Qu.:76.78   3rd Qu.: 24232.7                      \n##  Max.   :83.59   Max.   :120860.1                      \n##  NA's   :10      NA's   :17\n\n\nsfクラスのデータはplot関数（plot.sf）やggplot2のgeom_sf関数を用いることで地図として表示することができます。以下の例では、世界地図に一人当たりGDPの対数を色で示した地図（コロプレス図、choropleth map）を表示しています。\n\n\n\nggplot2でsfをプロットする\n\nworld |&gt; \n  ggplot() +\n  geom_sf(aes(fill = log(gdpPercap)))\n\n\n\n\n\n\n\n\n\n\n32.2.1 GeoJSONを取り扱う\n地理データの一部はインターネットで公開されており、ダウンロードして用いることができます。例えばsmartnews-smri/japan-topographyや、国土数値情報ダウンロードサイトでは、日本の地理情報をGeoJSONと呼ばれる形式で公開しています。GeoJSONとは、他言語ではよく用いられているデータの形式であるjavascript object notation（json）を使って地理空間情報を表現したものです。sfでは、このGeoJSONを読み込み、sfオブジェクトに変換することができます。読み込みにはst_read関数を用います。\n\n\n\ngeojsonをsfに変換する\n\n# 上記のsmartnewsのgithubからGeoJSONをダウンロードする\nurl &lt;- \"https://raw.githubusercontent.com/smartnews-smri/japan-topography/main/data/municipality/geojson/s0010/N03-21_210101.json\"\n\n# GeoJSONを読み込み、sfオブジェクトとする\nsfobj &lt;- st_read(url)\n## Reading layer `N03-21_210101' from data source \n##   `https://raw.githubusercontent.com/smartnews-smri/japan-topography/main/data/municipality/geojson/s0010/N03-21_210101.json' \n##   using driver `GeoJSON'\n## Simple feature collection with 1906 features and 5 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: 122.9393 ymin: 24.04587 xmax: 153.9866 ymax: 45.55563\n## Geodetic CRS:  WGS 84\n\nsummary(sfobj)\n##    N03_001            N03_002            N03_003            N03_004         \n##  Length:1906        Length:1906        Length:1906        Length:1906       \n##  Class :character   Class :character   Class :character   Class :character  \n##  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n##    N03_007                   geometry   \n##  Length:1906        MULTIPOLYGON :1906  \n##  Class :character   epsg:4326    :   0  \n##  Mode  :character   +proj=long...:   0\n\n\n\n\n32.2.2 日本のGeoJSONデータの取得\n日本のGeoJSONデータを取り扱う場合には、国土数値情報ダウンロードサイト（国土交通省）からGeoJSONをダウンロードするのが最も正確でよいでしょう。このGeoJSONデータは日本測地系2011（JGD2011）と呼ばれる、日本の測地系での値が指定されています（JGD2011は世界測地系WGS84とほぼ同一です）。国土数値情報ダウンロードサイトからダウンロードした地理情報を用いた解析結果を公表する場合には、以下のような形で出典を記載する必要があります。\n出典：「国土数値情報（行政区域データ）」（国土交通省）を加工して作成\n\n\n\n国土数値情報ダウンロードサイトからのデータを利用する\n\n# あらかじめダウンロードしたGeoJSONファイルをst_read関数で読み込む\nNara_sfobj &lt;- st_read(\"./data/N03-23_29_230101.geojson\")\n## Reading layer `N03-23_29_230101' from data source \n##   `D:\\R入門\\data\\N03-23_29_230101.geojson' using driver `GeoJSON'\n## Simple feature collection with 40 features and 5 fields\n## Geometry type: POLYGON\n## Dimension:     XY\n## Bounding box:  xmin: 135.5397 ymin: 33.85896 xmax: 136.2299 ymax: 34.78136\n## Geodetic CRS:  JGD2011\nNara_sfobj\n## Simple feature collection with 40 features and 5 fields\n## Geometry type: POLYGON\n## Dimension:     XY\n## Bounding box:  xmin: 135.5397 ymin: 33.85896 xmax: 136.2299 ymax: 34.78136\n## Geodetic CRS:  JGD2011\n## First 10 features:\n##    N03_001 N03_002 N03_003    N03_004 N03_007                       geometry\n## 1   奈良県    &lt;NA&gt;    &lt;NA&gt;     奈良市   29201 POLYGON ((135.9271 34.75692...\n## 2   奈良県    &lt;NA&gt;    &lt;NA&gt; 大和高田市   29202 POLYGON ((135.7597 34.5323,...\n## 3   奈良県    &lt;NA&gt;    &lt;NA&gt; 大和郡山市   29203 POLYGON ((135.7327 34.66603...\n## 4   奈良県    &lt;NA&gt;    &lt;NA&gt;     天理市   29204 POLYGON ((135.9307 34.6418,...\n## 5   奈良県    &lt;NA&gt;    &lt;NA&gt;     橿原市   29205 POLYGON ((135.8042 34.53756...\n## 6   奈良県    &lt;NA&gt;    &lt;NA&gt;     桜井市   29206 POLYGON ((135.9206 34.59121...\n## 7   奈良県    &lt;NA&gt;    &lt;NA&gt;     五條市   29207 POLYGON ((135.6879 34.40235...\n## 8   奈良県    &lt;NA&gt;    &lt;NA&gt;     御所市   29208 POLYGON ((135.7519 34.48149...\n## 9   奈良県    &lt;NA&gt;    &lt;NA&gt;     生駒市   29209 POLYGON ((135.7125 34.78074...\n## 10  奈良県    &lt;NA&gt;    &lt;NA&gt;     香芝市   29210 POLYGON ((135.6564 34.54167...\n\nplot(Nara_sfobj)\n\n\n\n\n\n\n\n\n\n\n\n32.2.3 sfオブジェクトの保存と読み込み\n上記のように、GeoJSONファイルはst_read関数で読み込み、sfオブジェクトに変換することができます。逆に、このsfオブジェクトをファイルとして保存する際にはst_write関数を用います。st_write関数はファイル名の拡張子によりファイル形式を判別して保存してくれる、ggplot2におけるggsave関数のような働きを持ちます。sfオブジェクトは通常.shpファイルとして保存します。また、st_write関数はGeoJSONへの書き出しにも対応しています。Rやsfだけでなく、他の原語やライブラリを利用する際には、GeoJSONの方が取り扱いやすいでしょう。\n\n\n\nsfオブジェクトのI/O\n\n# .shp（シェープファイル）で保存\nst_write(sfobj, \"./data/smartnews-smri_japan-topography.shp\",  layer_options = \"ENCODING=UTF-8\", append = FALSE)　\n\n# geojsonで保存\nst_write(sfobj, \"./data/smartnews-smri_japan-topography.geojson\",  layer_options = \"ENCODING=UTF-8\", append = FALSE)　\n\n# shpファイルの読み込み\njpsf &lt;- st_read(\"./data/smartnews-smri_japan-topography.shp\")\njpsf\n\n# geojsonも読み込める\njpsf &lt;- st_read(\"./data/smartnews-smri_japan-topography.geojson\")\n\n# urlからjsonを読み込むこともできる\nsfobj &lt;- st_read(url)\n\n\n\n\n32.2.4 他の地理情報データとの統合\nsfオブジェクトはデータフレームでもあるため、地理情報と関連付けられたデータがあれば、sfオブジェクトの列として登録し、データとして利用することができます。地理情報と関連されたデータを自分で集めるのは難しいですが、政府統計であればe-statから簡単にダウンロードできます。\n以下の例では、2020年の国勢調査のデータをダウンロードし、上記の国土数値情報から作成したsfオブジェクトに国勢調査データの2020年人口を登録しています。e-statのデータを用いた解析結果を公表する場合には下のような出典の記載が必要です。\n出典：「政府統計の総合窓口(e-Stat)」、調査項目を調べる－国勢調査（総務省）「令和２年国勢調査 / 人口等基本集計」\ne-statのデータはそのデータの種類ごとにファイル形式や列名の記載方法が異なるため、Rではやや読み込みにくいです。\ne-statのデータを整理して読み込みます。読み込んだデータフレームとsfオブジェクトを結合させるためには、両方のオブジェクトに共通する列が必要となります。下の例では、sfオブジェクトに含まれるN03_004（市町村名）の列をデータフレーム側にも準備することで、市町村名を用いてデータを結合できるようにしています。\nデータフレームとsfオブジェクトの結合には、16章で説明したdplyrのjoin関数を用いるのが良いでしょう。この際に、joinで結合する先をsfオブジェクトとすること、共通する列をby=join_by(列名)で指定することが重要となります。sfオブジェクト側ではなく、データフレーム側を結合先にしてしまうとgeometryの列がなくなります。\n下の例では、sfオブジェクト（Nara_sfobj）を第一引数、データフレームを第二引数とし、left_join関数で結合することで、データフレームのデータを左側のsfオブジェクトに結合しています。\n\n\n\nsfオブジェクトへのデータの登録\n\nd &lt;- read.csv(\"./data/FEH_00200521_240321113104.csv\", header = T, skip = 12) # 人口データを読み込み\n\n# 文字列となっている列を数値に変換\nd$`総数` &lt;- d$`総数` |&gt; str_remove_all(\",\") |&gt; as.numeric()\nd$`男` &lt;- d$`男` |&gt; str_remove_all(\",\") |&gt; as.numeric()\nd$`女` &lt;- d$`女` |&gt; str_remove_all(\",\") |&gt; as.numeric()\nd &lt;- d[, c(4, 6:8)]\n\n# 共通の列として、市町村名を設定（N03_004）\ncolnames(d) &lt;- c(\"N03_004\", \"total_pop\", \"male_pop\", \"female_pop\") \n\n# left_join関数でデータをsfに結合\nNara_sfobj &lt;- left_join(Nara_sfobj, d, by = join_by(N03_004)) # sfが前、結合するデータフレームが後\nNara_sfobj &lt;- Nara_sfobj |&gt; select(N03_001, N03_004, total_pop, male_pop, female_pop)\n\n# データ登録されたsfオブジェクト\nNara_sfobj\n## Simple feature collection with 42 features and 5 fields\n## Geometry type: POLYGON\n## Dimension:     XY\n## Bounding box:  xmin: 135.5397 ymin: 33.85896 xmax: 136.2299 ymax: 34.78136\n## Geodetic CRS:  JGD2011\n## First 10 features:\n##    N03_001    N03_004 total_pop male_pop female_pop\n## 1   奈良県     奈良市    354630   164846     189784\n## 2   奈良県 大和高田市     61744    28981      32763\n## 3   奈良県 大和郡山市     83285    39249      44036\n## 4   奈良県     天理市     63889    31275      32614\n## 5   奈良県     橿原市    120922    57336      63586\n## 6   奈良県     桜井市     54857    25909      28948\n## 7   奈良県     五條市     27927    13180      14747\n## 8   奈良県     御所市     24096    11122      12974\n## 9   奈良県     生駒市    116675    55107      61568\n## 10  奈良県     香芝市     78113    36925      41188\n##                          geometry\n## 1  POLYGON ((135.9271 34.75692...\n## 2  POLYGON ((135.7597 34.5323,...\n## 3  POLYGON ((135.7327 34.66603...\n## 4  POLYGON ((135.9307 34.6418,...\n## 5  POLYGON ((135.8042 34.53756...\n## 6  POLYGON ((135.9206 34.59121...\n## 7  POLYGON ((135.6879 34.40235...\n## 8  POLYGON ((135.7519 34.48149...\n## 9  POLYGON ((135.7125 34.78074...\n## 10 POLYGON ((135.6564 34.54167...\n\n\n\n\n32.2.5 geometryの種類と変換の方法\nsfにおける最も基本的なgeometryは以下の3種類です。\n\nPOINT：地図上の点\nLINESTRING：地図上の線\nPOLYGON：地図上の平面\n\nそれぞれのgeometryにおいて、地図上の位置はX（経度（longitude））、Y（緯度（latitude））の2次元（XY）、Z（高度）を加えた3次元（XYZ）、M（データの精度や時間）を加えた3次元（XYM）、ZとMを加えた4次元のデータ（XYZM）のいずれかで指定されます。\nまた、複数のPOINT、LINESTRING、POLYGONをまとめたgeometryとして以下の3種類があります。\n\nMULTIPOINT：地図上の複数の点\nMULTILINESTRING：地図上の複数の線\nMULTIPOLYGON：地図上の複数の平面\n\nまた、1つのgeometryではなく、別々のgeometry（POINTとPOLYGONなど）をまとめたものがGEOMETRYCOLLECTIONです。\nこの他にもCITCULARSTRINGやCOMPOUNDCURVE、CURVEPOLYGONなどの曲線を示すgeometryもありますが、とりあえず上の7つを理解しておけばsfの取り扱いには困らないでしょう。\n最も単純な3つのgeometryはst_point、st_linestring、st_polygon関数で作成することができます。st_pointはX（経度）とY（緯度）のベクター、st_linestring、st_polygonは1列目にX（経度）、2列目にY（緯度）を設定した行列を引数とすることで作成することができます。\n\n\n\ngeometryの作成\n\n# st_pointの引数はベクター\nst_point(c(135, 35), dim = \"XY\") \n## POINT (135 35)\n\n# st_linestringの引数は行列\nst_linestring(rbind(c(135, 35), c(130, 30))) \n## LINESTRING (135 35, 130 30)\n\n# st_polygonの引数は行列のリスト（平面が閉じていないとエラーになる）\nst_polygon(list(rbind(c(135, 35), c(135, 30), c(130, 30), c(130, 35), c(135, 35))))\n## POLYGON ((135 35, 135 30, 130 30, 130 35, 135 35))\n\n## 左からPOINT、LINESTRING、POLYGONをplotする\npar(mfrow = c(1, 3))\nst_point(c(135, 35), dim = \"XY\") |&gt; plot()\nst_linestring(rbind(c(135, 35), c(130, 30))) |&gt; plot()\nst_polygon(list(rbind(c(135, 35), c(135, 30), c(130, 30), c(130, 35), c(135, 35)))) |&gt; plot()\n\n\n\n\n\n\n\n\n\nMULTIPOINT、MULTILINESTRING、MULTIPOLYGONはそれぞれst_multipoint、st_multilinestring、st_multipolygon関数で作成することができます。\n\n\n\ngeometryの作成:MULTI\n\n# st_multipointの引数は行列\nst_multipoint(rbind(c(135, 35), c(130, 30))) \n## MULTIPOINT ((135 35), (130 30))\n\n# c関数でPOINTを結合してもMULTIPOINTを作成できる\nc(st_point(c(135, 35), dim = \"XY\"), st_point(c(130, 30), dim = \"XY\"))\n## MULTIPOINT ((135 35), (130 30))\n\n# st_multilinestringの引数は行列のリスト\nst_multilinestring(list(rbind(c(135, 35), c(130, 30)), rbind(c(130, 30), c(125, 20)))) \n## MULTILINESTRING ((135 35, 130 30), (130 30, 125 20))\n\n# st_multipolygonの引数は行列のリストのリスト（平面が閉じていないとエラーとなる）\nst_multipolygon(\n  list(\n    list(rbind(c(135, 35), c(135, 30), c(130, 30), c(130, 35), c(135, 35))),\n    list(rbind(c(100, 50), c(100, 40), c(120, 40), c(120, 50), c(100, 50)))\n    )\n  )\n## MULTIPOLYGON (((135 35, 135 30, 130 30, 130 35, 135 35)), ((100 50, 100 40, 120 40, 120 50, 100 50)))\n\n# MULTIPOINT、MULTISTRING、MULTIPOLYGONをプロットする\npar(mfrow = c(1, 3))\nst_multipoint(rbind(c(135, 35), c(130, 30))) |&gt; plot()\nst_multilinestring(list(rbind(c(135, 35), c(130, 30)), rbind(c(130, 30), c(125, 20)))) |&gt; plot()\nst_multipolygon(\n  list(\n    list(rbind(c(135, 35), c(135, 30), c(130, 30), c(130, 35), c(135, 35))),\n    list(rbind(c(100, 50), c(100, 40), c(120, 40), c(120, 50), c(100, 50)))\n    )\n  ) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\n32.2.6 geometryの編集\nst_pointの返り値に足し算を行うことで、その点の位置を変更することができます。単に数値を足した場合にはXとYの両方に、要素が2つのベクターで足した場合にはインデックス[1]の要素がXに、インデックス[2]の要素がYに足されて位置を更新することになります。\n\n\n\nPOINTの移動\n\nst_point(c(1, 1)) + 1 # 数値を足すことができる\n## POINT (2 2)\n\nst_point(c(1, 1)) + c(1, 4) # ベクターで足すと要素ごとの足し算になる\n## POINT (2 5)\n\n\nまた、sfクラスのうち、geometryの列に関しては、掛け算することで拡大・縮小を行うこともできます。\n\n\n\ngeometryの拡大・縮小\n\n# わかりにくいが、地域の中心を基準に0.85倍に縮小している\n((Nara_sfobj |&gt; st_geometry() - st_centroid(Nara_sfobj |&gt; st_geometry())) * 0.85 + st_centroid(Nara_sfobj |&gt; st_geometry())) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\n32.2.7 geometryのクラス：sfg\nst_pointやst_polygonで作成したgeometryはsfgクラスのオブジェクトとなります。sfgはsfパッケージで定義されているクラスで、plot関数の引数とすることで描画することができます。\n\n\n\nsfgクラスとplot関数による描画\n\nst_point(c(1, 1)) |&gt; class() # sfgクラスのオブジェクト\n## [1] \"XY\"    \"POINT\" \"sfg\"\n\nst_point(c(1, 1)) |&gt; plot() # sfgクラスはplot関数で描画できる\n\n\n\n\n\n\n\n\n\n\n\n32.2.8 geometryのクラス：sfc\nsfgをいくつか合わせてひとまとまりのgeometryとしたものがsfcクラスのオブジェクトです。sfcはst_sfc関数に1個～複数のsfgクラスのオブジェクトを引数とすることで作成することができます。sfクラスのgeometryの列がこのsfcクラスです。\n\n\n\nsfcクラス\n\nst_point(c(1, 1)) |&gt; st_sfc() |&gt; class() # sfcクラスに変換\n## [1] \"sfc_POINT\" \"sfc\"\n\nst_point(c(1, 1)) |&gt; st_sfc() |&gt; st_sf() |&gt; class() # sfクラスに変換\n## [1] \"sf\"         \"data.frame\"\n\n\n\n\n32.2.9 sfオブジェクトの構造\nsfcクラスはsfgクラスのリストとして実装されており、sfgもリストですので、sfcは「リストのリスト」になっています。このsfcをさらにst_sf関数の引数とすると、sfクラスのオブジェクトとなります。sfクラスはデータフレーム、つまりリストですので、sfクラスは「リストのリストのリスト」になっています。sf、sfc、sfgオブジェクトは基本的にはすべてリストですので、二重カッコ（[[]]）で下位の要素（sfからsfc、sfcからsfg）を取り出すことができます。\nまた、sfオブジェクトからgeometryだけを取り出す場合には、st_geometry関数を用います。st_geometry関数の返り値はsfcクラスのオブジェクトとなります。\n\n\n\nsfオブジェクトの構造\n\n# geometryを選択\nsfobj[[6]]\n## Geometry set for 1906 features \n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: 122.9393 ymin: 24.04587 xmax: 153.9866 ymax: 45.55563\n## Geodetic CRS:  WGS 84\n## First 5 geometries:\n## MULTIPOLYGON (((141.3552 43.06859, 141.3433 43....\n## MULTIPOLYGON (((141.3552 43.06859, 141.3527 43....\n## MULTIPOLYGON (((141.3896 43.0686, 141.3965 43.0...\n## MULTIPOLYGON (((141.3664 43.05797, 141.3848 43....\n## MULTIPOLYGON (((141.3524 43.02288, 141.3527 43....\n\n# 2重リストは個別のgeometry\nsfobj[[6]][[1]] |&gt; head()\n## MULTIPOLYGON (((141.3552 43.06859, 141.3433 43.06682, 141.335 43.06914, 141.3364 43.07113, 141.3324 43.07601, 141.3283 43.08612, 141.3266 43.08228, 141.3223 43.08022, 141.3224 43.07733, 141.3143 43.06464, 141.3063 43.06878, 141.2927 43.05801, 141.2841 43.05441, 141.2844 43.04716, 141.2856 43.04371, 141.2848 43.03798, 141.2799 43.03634, 141.2711 43.03945, 141.2657 43.03944, 141.2638 43.04216, 141.2582 43.04203, 141.2496 43.0372, 141.2483 43.03159, 141.2449 43.02679, 141.2297 43.0152, 141.2248 43.01587, 141.2127 43.0156, 141.2024 43.01925, 141.2019 43.01673, 141.2116 43.01254, 141.2146 43.01027, 141.2205 43.00882, 141.2374 43.00678, 141.245 43.0038, 141.2514 43.00347, 141.2542 42.99783, 141.2599 42.99766, 141.2667 43.00442, 141.2722 43.00431, 141.2829 43.00935, 141.2859 43.01337, 141.2904 43.01389, 141.2934 43.02012, 141.3041 43.02643, 141.3108 43.02808, 141.3068 43.03198, 141.3103 43.03576, 141.3144 43.03393, 141.3193 43.03551, 141.3237 43.02969, 141.3282 43.02846, 141.3363 43.0281, 141.3407 43.02424, 141.346 43.0171, 141.3524 43.02288, 141.356 43.03531, 141.3599 43.04286, 141.3631 43.05453, 141.3664 43.05797, 141.369 43.06146, 141.3896 43.0686, 141.3863 43.06953, 141.3732 43.06841, 141.3552 43.06859)))\n\n# 4重リストに緯度・経度の行列が保存されている\nsfobj[[6]][[1]][[1]][[1]] |&gt; head() \n##          [,1]     [,2]\n## [1,] 141.3552 43.06859\n## [2,] 141.3433 43.06682\n## [3,] 141.3350 43.06914\n## [4,] 141.3364 43.07113\n## [5,] 141.3324 43.07601\n## [6,] 141.3283 43.08612\n\nsfobj |&gt; st_geometry() # geometryだけ取り出す（クラスはsfc）\n## Geometry set for 1906 features \n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: 122.9393 ymin: 24.04587 xmax: 153.9866 ymax: 45.55563\n## Geodetic CRS:  WGS 84\n## First 5 geometries:\n## MULTIPOLYGON (((141.3552 43.06859, 141.3433 43....\n## MULTIPOLYGON (((141.3552 43.06859, 141.3527 43....\n## MULTIPOLYGON (((141.3896 43.0686, 141.3965 43.0...\n## MULTIPOLYGON (((141.3664 43.05797, 141.3848 43....\n## MULTIPOLYGON (((141.3524 43.02288, 141.3527 43....\n\n\n\n\n\nsfオブジェクトのクラス\n\nsfobj[[6]] |&gt; class() # sfcクラスのオブジェクト\n## [1] \"sfc_MULTIPOLYGON\" \"sfc\"\n\nsfobj[[6]][[1]] |&gt; class() # sfgクラスのオブジェクト\n## [1] \"XY\"           \"MULTIPOLYGON\" \"sfg\"\n\n\n\n\n32.2.10 sfオブジェクトを作成する\n緯度・経度のデータからsfオブジェクトを作成する場合には、上記のst_point、st_linestring、st_polygonを使うことになります。下の例では、都道府県の県庁所在地のデータをsfcオブジェクトに変換しています。\nデータフレームをMULTIPOINTのsfgに変換する場合には、まずデータフレームの列を経度・緯度の順に並べ替え、次にas.matrix関数で行列に変換します。この行列をst_multipoint関数の引数とすれば、MULTIPOINTのsfgを作成することができます。\nまた、このsfgをst_sfc関数の引数に取ることでMULTIPOINTのsfcオブジェクトを作成することができます。\nMULTIPOINTからPOINTのsfgを作成する場合には、st_cast関数を用います。st_cast関数はgeometryの変換を行うための関数です。st_castの第二引数に\"POINT\"を指定することで、MULTIPOINTからPOINTへの変換を行うことができます。ただし、st_castで変換すると、MULTIPOINTの一番初めの点のみがPOINTに変換され、残りのPOINTは削除されてしまいます。\n\n\n\nデータからsfcを作成する\n\n# 県庁所在地の緯度・経度\nd &lt;- read.csv(\"./data/pref_lat_lon.csv\", header=T, fileEncoding = \"CP932\")\nhead(d) # latが緯度、lonが経度\n##   pref_name      lat      lon\n## 1    北海道 43.06436 141.3474\n## 2    青森県 40.82429 140.7401\n## 3    岩手県 39.70353 141.1527\n## 4    宮城県 38.26874 140.8722\n## 5    秋田県 39.71818 140.1034\n## 6    山形県 38.24013 140.3625\n\n# sfgクラス（経度、緯度の順に並べ替えている）\nd[,c(3, 2)] |&gt; \n  as.matrix() |&gt; \n  st_multipoint() \n## MULTIPOINT ((141.3474 43.06436), (140.7401 40.82429), (141.1527 39.70353), (140.8722 38.26874), (140.1034 39.71818), (140.3625 38.24013), (140.4668 37.75015), (140.4468 36.34182), (139.8835 36.56575), (139.0609 36.3912), (139.6478 35.85777), (140.1232 35.60456), (139.6916 35.68919), (139.6423 35.4475), (139.0227 37.9017), (137.2113 36.69527), (136.6256 36.59473), (136.2216 36.06522), (138.569 35.6651), (138.181 36.65128), (136.7222 35.39116), (138.3831 34.97699), (136.9067 35.18025), (136.5086 34.73055), (135.8686 35.00453), (135.7531 35.021), (135.519 34.68649), (135.1831 34.69128), (135.8327 34.6853), (135.1679 34.22481), (134.2383 35.50346), (133.0508 35.47225), (133.9344 34.66132), (132.4596 34.39603), (131.4708 34.18565), (134.5593 34.06573), (134.043 34.34014), (132.7659 33.84165), (133.5309 33.55969), (130.4182 33.60677), (130.2988 33.24937), (129.873 32.74454), (130.7423 32.79039), (131.6127 33.2382), (131.4239 31.91109), (130.5579 31.56022), (127.6811 26.21154))\n\n# sfcクラス（1つのMULTIPOINTとなる）\nd[,c(3, 2)] |&gt; \n  as.matrix() |&gt; \n  st_multipoint() |&gt; \n  st_sfc() \n## Geometry set for 1 feature \n## Geometry type: MULTIPOINT\n## Dimension:     XY\n## Bounding box:  xmin: 127.6811 ymin: 26.21154 xmax: 141.3474 ymax: 43.06436\n## CRS:           NA\n## MULTIPOINT ((141.3474 43.06436), (140.7401 40.8...\n\n# sfcクラス（始めの1点だけになる\nd[,c(3, 2)] |&gt; \n  as.matrix() |&gt; \n  st_multipoint() |&gt; \n  st_cast(\"POINT\") |&gt; \n  st_sfc()\n## Warning in st_cast.MULTIPOINT(st_multipoint(as.matrix(d[, c(3, 2)])), \"POINT\"):\n## point from first coordinate only\n## Geometry set for 1 feature \n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: 141.3474 ymin: 43.06436 xmax: 141.3474 ymax: 43.06436\n## CRS:           NA\n## POINT (141.3474 43.06436)\n\n\nそもそも上の例では、各都道府県の県庁所在地の位置ですので、MULTIPOINTではなく、POINTの集合となっているsfcオブジェクトを作成したいところです。\nこのような変換には、lapply関数やpurrr::pmap関数を用います。lapplyの場合にはデータフレーム（リスト）を引数にしてst_point関数を適用する形で、purrr::pmap関数ではst_pointの引数の位置を.x、.yで指定する形で設定します。\n\n\n\nlapply/purrr::pmapでsfcを作成\n\n# applyではうまく計算できない（返り値がベクターだから）\napply(d[,c(3, 2)], 1, st_point) |&gt; st_sfc() \n## Error in vapply(lst, class, rep(NA_character_, 3)): values must be length 3,\n##  but FUN(X[[1]]) result is length 2\n\n# lapplyを使うと複数のPOINTをsfcに変換できる\nd[,c(3, 2)] |&gt; t() |&gt; data.frame() |&gt; lapply(st_point) |&gt; st_sfc() \n## Geometry set for 47 features \n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: 127.6811 ymin: 26.21154 xmax: 141.3474 ymax: 43.06436\n## CRS:           NA\n## First 5 geometries:\n## POINT (141.3474 43.06436)\n## POINT (140.7401 40.82429)\n## POINT (141.1527 39.70353)\n## POINT (140.8722 38.26874)\n## POINT (140.1034 39.71818)\n\n# pmapを使うと複数のPOINTをsfcに変換できる\npurrr::pmap(d[,c(3, 2)], ~st_point(c(.x, .y))) |&gt; st_sfc()\n## Geometry set for 47 features \n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: 127.6811 ymin: 26.21154 xmax: 141.3474 ymax: 43.06436\n## CRS:           NA\n## First 5 geometries:\n## POINT (141.3474 43.06436)\n## POINT (140.7401 40.82429)\n## POINT (141.1527 39.70353)\n## POINT (140.8722 38.26874)\n## POINT (140.1034 39.71818)\n\n\nsfcをlapply関数やpurrr::pmap関数を用いて作成した後、この作成したsfcをst_sf関数の引数とすることで、sfオブジェクトを作成することができます。sfオブジェクトはデータフレームと同じように取り扱うことができるので、このsfオブジェクトに情報を追加していく形でデータを整理することができます。\n\n\n\nsfcからsfに変換する\n\n# sfcをsfに変換\nd1 &lt;- pmap(d[,c(3, 2)], ~st_point(c(.x, .y))) |&gt; st_sfc() |&gt; st_sf()\n\n# sfにはデータフレームと同様に情報を追加することができる\nd1$pref &lt;- d$pref_name\nd1$flag &lt;- rep(c(0, 1), c(25, 22))\n\nd1 |&gt;  ggplot() + geom_sf(aes(color = factor(flag)))\n\n\n\n\n\n\n\n\n\n\n\n32.2.11 WKT、WKB\nwell-known-text（WKT）とwell-known-binary (WKB)は、sfで示されているgeometryをテキストやバイナリ（16進法の数値）で表す方法です。sfパッケージにはgeometryをWKT・WKBの形に変換する方法と、逆にWKTやWKBをsfオブジェクトとする方法を備えています。\nsfgをWKTに変換するための関数がst_as_text関数、sfgをWKBに変換するための関数がst_as_binary関数です。WKT、WKBのいずれもst_as_sfc関数の引数とすることで、sfcオブジェクトに変換することができます。\n\n\n\nWKT、WKBの変換\n\n# sfgをテキストに変換\nst_point(c(135, 35), dim=\"XY\") |&gt; st_as_text() \n## [1] \"POINT (135 35)\"\n\n# テキストからsfcを作成\nst_point(c(135, 35), dim=\"XY\") |&gt; st_as_text() |&gt; st_as_sfc()\n## Geometry set for 1 feature \n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: 135 ymin: 35 xmax: 135 ymax: 35\n## CRS:           NA\n## POINT (135 35)\n\n# sfgをバイナリに変換\nst_point(c(135, 35), dim=\"XY\") |&gt; st_as_binary() \n##  [1] 01 01 00 00 00 00 00 00 00 00 e0 60 40 00 00 00 00 00 80 41 40\n\n# バイナリからsfcを作成\nst_point(c(135, 35), dim=\"XY\") |&gt; st_as_binary() |&gt; st_as_sfc()\n## Geometry set for 1 feature \n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: 135 ymin: 35 xmax: 135 ymax: 35\n## CRS:           NA\n## POINT (135 35)\n\n\n\n\n32.2.12 sfcオブジェクトの演算\nsfcオブジェクトを用いると、その地形データから面積、重心、周辺の長さ、各点の距離などを計算することができます。\nPOLYGONの面積を計算する関数がst_area関数です。st_area関数はPOLYGONからなるsfcオブジェクトを引数に取り、そのPOLYGONで示される面積を返します。\nst_area関数の返り値はunitsクラスのオブジェクトになります。このunitsクラスはunitsパッケージ(Pebesma, Mailund, and Hiebert 2016)で設定されているクラスです。unitsパッケージは数値に単位を付けたunitsクラスと、その単位の変換に関する演算の方法を提供しています。\n\n\n\ngeometryの演算:st_area関数\n\nst_area(Nara_sfobj$geometry) # 面積の計算（classはunits）\n## Units: [m^2]\n##  [1] 276977005.00  16487502.70  42692980.17  86433581.81  39571913.33\n##  [6]  98925013.70 292085799.37  60590616.91  53160356.49  24267341.43\n## [11]  33727305.87 247544023.87  66532128.14  23901170.56   8796113.79\n## [16]  14272062.29   4311321.59   5934339.36   5934339.36   4064488.78\n## [21]  21097189.12  47769513.83  79591272.16  25792308.87  24104619.91\n## [26]   6144410.59   7011660.23  16307488.75     71151.84   8156116.81\n## [31]  95664612.09  38109367.32  62002635.34  47715340.25 175700899.55\n## [36] 154941450.09 672577543.67 133425918.55 274291762.08 269321938.62\n## [41] 269321938.62 131680340.60\n\n# sfはデータフレームと同じように取り扱うことができる\n# sfの列に計算した面積を設定している\nNara_sfobj$area &lt;- st_area(Nara_sfobj$geometry) |&gt; as.numeric()\n\nNara_sfobj |&gt; \n  ggplot()+\n  geom_sf(aes(fill = log(area)))\n\n\n\n\n\n\n\n\n\ngeometryがPOINTである場合には、st_distanceで各POINT間の距離行列を求めることができます（距離行列については28章を参照）。また、geometryがLINESTRINGである場合には、st_lengthでそのLINESTRINGの長さを計算することができます。POLIGON間の距離や、POINTの長さ、LINESTRINGの面積は求めることができない、つまりgeometryが関数の設定と異なると計算はできません。\n\n\n\ngeometryの演算2\n\n# 距離行列（地理空間上の距離）、POINTのみ計算できる\nd1 |&gt; st_distance() |&gt; _[1:4, 1:4]\n##          1        2        3        4\n## 1 0.000000 2.320952 3.366469 4.819115\n## 2 2.320952 0.000000 1.194304 2.558970\n## 3 3.366469 1.194304 0.000000 1.461952\n## 4 4.819115 2.558970 1.461952 0.000000\n\nd1[[1]] |&gt; st_distance() |&gt; _[1:4, 1:4] # stcでも計算できる\n##          1        2        3        4\n## 1 0.000000 2.320952 3.366469 4.819115\n## 2 2.320952 0.000000 1.194304 2.558970\n## 3 3.366469 1.194304 0.000000 1.461952\n## 4 4.819115 2.558970 1.461952 0.000000\n\n# 地理空間上の距離、LINESTRINGのみ計算できる\nst_linestring(rbind(c(135, 35), c(130, 30))) |&gt; st_length()\n## [1] 7.071068\n\n# 地理空間上の面積、POLYGONのみ計算できる\nst_area(Nara_sfobj$geometry) |&gt; head()\n## Units: [m^2]\n## [1] 276977005  16487503  42692980  86433582  39571913  98925014\n\n\nst_centroidはgeometryの重心を求める関数です。また、st_point_on_surfaceは重心ではなく、POLYGON内にある中心に近い点を求める関数です。コロプレス図のPOLYGON内にバブルチャートでデータを表示する場合には、st_centroidよりst_point_on_surfaceの方が使いやすいでしょう。\nまた、同様の演算をggplot2中で行うこともできます。geom関数内でstat=\"st_coordinates\"を引数に取ることで、st_point_on_surfaceに相当する演算を行うことができます。\n\n\n\n重心を求める\n\n# 重心を求める\nst_centroid(Nara_sfobj |&gt; st_geometry())\n## Geometry set for 42 features \n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: 135.6445 ymin: 34.01064 xmax: 136.1594 ymax: 34.70791\n## Geodetic CRS:  JGD2011\n## First 5 geometries:\n## POINT (135.891 34.67449)\n## POINT (135.7437 34.51008)\n## POINT (135.7747 34.63392)\n## POINT (135.8643 34.59562)\n## POINT (135.7899 34.50139)\n\n# 重心に近いPOLYGON中の点を求める\nst_point_on_surface(Nara_sfobj |&gt; st_geometry())\n## Warning in st_point_on_surface.sfc(st_geometry(Nara_sfobj)):\n## st_point_on_surface may not give correct results for longitude/latitude data\n## Geometry set for 42 features \n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: 135.6577 ymin: 34.00617 xmax: 136.1604 ymax: 34.71393\n## Geodetic CRS:  JGD2011\n## First 5 geometries:\n## POINT (135.8778 34.65789)\n## POINT (135.7442 34.50449)\n## POINT (135.78 34.63122)\n## POINT (135.8641 34.59657)\n## POINT (135.7933 34.50031)\n\n# ggplot2ではstat=\"sf_coordinates\"で計算できる（st_point_on_surfaceを利用）\nNara_sfobj |&gt; \n  ggplot()+\n  geom_sf()+\n  geom_point(\n    aes(geometry = geometry, color = total_pop, size = total_pop), \n    stat=\"sf_coordinates\")\n## Warning in st_point_on_surface.sfc(sf::st_zm(x)): st_point_on_surface may not\n## give correct results for longitude/latitude data\n\n\n\n\n\n\n\n\n\n\n\n32.2.13 境界線の演算\nあるPOINTやLINESTRING、POLYGONから一定の距離にある、境界を演算するための関数がst_buffer関数です。st_buffer関数はそのPOINTやPOLYGONからの距離であるdistを引数に取ります。st_bufferの返り値はPOLYGONになります。\n\n\n\nst_buffer・st_simplify関数\n\n# 135, 35からの距離が5の境界線（POLYGONが返ってくる）\nst_point(c(135, 35), dim=\"XY\") |&gt; st_buffer(dist = 5) |&gt; st_simplify(dTolerance = 0.5)\n## POLYGON ((140 35, 138.5355 31.46447, 135 30, 131.4645 31.46447, 130 35, 131.4645 38.53553, 135 40, 138.5355 38.53553, 140 35))\n\n# 点からの距離が5の円\nst_point(c(135, 35), dim=\"XY\") |&gt; st_buffer(dist = 5) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\n32.2.14 geometryの単純化\n日本全体の市町村のPOLYGONを取り扱う場合、高解像度のPOLYGONを用いるとデータサイズがとても大きくなることがあります。例えば、上で紹介した国土数値情報ダウンロードサイト（国土交通省）からダウンロードできる日本全国のGeoJSONデータは427MBもあり、コロプレス図などにそのまま用いると演算に時間がかかります。このようなgeometryデータを簡素化し、データサイズを減らす関数がst_simplify関数です。簡素化の程度はdTolerance引数で指定します。\n\n\n\nst_buffer・st_simplify関数\n\n# st_simplifyでPOLYGONの解像度を下げる\nst_point(c(135, 35), dim=\"XY\") |&gt; st_buffer(dist = 5) |&gt; st_simplify(dTolerance = 0.5) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\n32.2.15 geometryの接触の判定\ngeometry同士が重なっている・接触しているかどうかを判別するための関数がst_intersects関数・st_touches関数です。st_intersects関数はgeometryが重なっている場合にはTRUE、重なっていない場合にはFALSEを返します。また、st_touches関数はgeometry同士が接触していればTRUEを、接触していなければFALSEを返します。\n\n\n\ngeometryの重なり・接触の評価\n\nd1 &lt;- st_polygon(list(rbind(c(135, 35), c(135, 25), c(130, 25), c(130, 35), c(135, 35))))\nd2 &lt;- st_polygon(list(rbind(c(137.5, 32.5), c(137.5, 30), c(125, 30), c(125, 32.5), c(137.5, 32.5))))\nd3 &lt;- st_polygon(list(rbind(c(135, 35), c(135, 25), c(140, 25), c(140, 35), c(135, 35))))\n\n# 上の3つのPOLYGONをプロットする\npar(mfrow = c(1, 2))\nst_sfc(d1, d2) %&gt;% plot()\nst_sfc(d1, d3) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n# sfg間に重なりがあるかどうかを評価\nst_intersects(d1, d2, sparse = FALSE) \n##      [,1]\n## [1,] TRUE\nst_intersects(d1, d3, sparse = FALSE)\n##      [,1]\n## [1,] TRUE\n\n# sfg間に接触があるかどうかを評価\nst_touches(d1, d2, sparse = FALSE) \n##       [,1]\n## [1,] FALSE\nst_touches(d1, d3, sparse = FALSE)\n##      [,1]\n## [1,] TRUE\n\n\n\n32.2.16 geometry同士の差分\ngeometry同士の差分を取るための関数がst_difference関数です。st_difference関数は第一引数に指定したgeometryから、第二引数に指定したgeometryの部分を取り除きます。ですので、st_difference(d1, d2)ではd1からd2の部分を除き、st_difference(d2, d1)ではd2からd1の部分を除く形となっています。\n\n\n\ngeometryの差分\n\n# d1は縦長、d2は横長で、d1からd2の部分を取り除く\nst_difference(d1, d2) %&gt;% plot() \n\n\n\n\n\n\n\n\n\n# d2からd1の部分を取り除く\nst_difference(d2, d1) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n\n32.2.17 CRS（測地系）\n測地系（CRS：Coordinate Reference System）は緯度・経度で地表上の座標を示すための系です。測地系が異なると同じ緯度・経度の点でも地表上の位置が異なります。現在ではWGS84（世界測地系）を用いるのが最も一般的です。日本の測地系としてはJPD2011（測地成果2011、東日本大震災後の地形変化を考慮した測地系）が用いられていますが、このJPD2011はWGS84とほぼ同じものとなっています。GeoJSONなどの地理データでは、使用した測地系が何であるか通常表記されていますので、正しい測地系が設定されているか確認し、異なっている場合には測地系を変更するとよいでしょう。\nデータの測地系を確認する場合には、st_crs関数を用います。st_crs()&lt;-という形で測地系の名前を代入することにより、sfオブジェクトの測地系を変更することもできます。\n\n\n\n測地系の表示\n\nst_crs(Nara_sfobj) # JGD2011のデータ\n## Coordinate Reference System:\n##   User input: JGD2011 \n##   wkt:\n## GEOGCRS[\"JGD2011\",\n##     DATUM[\"Japanese Geodetic Datum 2011\",\n##         ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n##             LENGTHUNIT[\"metre\",1]]],\n##     PRIMEM[\"Greenwich\",0,\n##         ANGLEUNIT[\"degree\",0.0174532925199433]],\n##     CS[ellipsoidal,2],\n##         AXIS[\"geodetic latitude (Lat)\",north,\n##             ORDER[1],\n##             ANGLEUNIT[\"degree\",0.0174532925199433]],\n##         AXIS[\"geodetic longitude (Lon)\",east,\n##             ORDER[2],\n##             ANGLEUNIT[\"degree\",0.0174532925199433]],\n##     ID[\"EPSG\",6668]]\nst_crs(Nara_sfobj) &lt;- 4326 # WGS84に変更する（warningが出るが、変換される）\n## Warning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\n## that",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>地理空間情報</span>"
    ]
  },
  {
    "objectID": "chapter32.html#ラスタデータの取り扱いstars",
    "href": "chapter32.html#ラスタデータの取り扱いstars",
    "title": "32  地理空間情報",
    "section": "32.3 ラスタデータの取り扱い：stars",
    "text": "32.3 ラスタデータの取り扱い：stars\n現在（2023年）ではRでのベクタの取り扱いにはほぼsfが用いられていると思いますが、ラスタデータの取り扱いでは、terraパッケージ(Hijmans 2024)とstarsパッケージ(Pebesma and Bivand 2023b)が両方用いられています。\nterraは昔から用いられているラスタデータの取り扱いに関するライブラリであるrasterパッケージ(Hijmans 2023)を更新したライブラリで、sfとの連携が組み込まれています。\nstarsはsfの開発者が作成したラスタデータの取り扱いに関数ライブラリです。terraと比べるとややダウンロードされていないパッケージではありますが、ココではterraではなくstarsについて説明することとします。\n\n\n\nstarsパッケージのロード\n\npacman::p_load(stars)\n\n\nまずは、starsパッケージに登録されている、ランドサット7号が撮影したブラジルのOlindaという都市の衛星画像をstarsのオブジェクトとしたL7_ETMsを示します。このデータは位置を表すx、yと、その位置における値を示すbandからなるデータです。\n\n\n\nstarsオブジェクト\n\nL7_ETMs # ランドサット7号の衛星写真データ\n## stars_proxy object with 1 attribute in 1 file(s):\n## $L7_ETMs\n## [1] \"[...]/L7_ETMs.tif\"\n## \n## dimension(s):\n##      from  to  offset delta                     refsys point x/y\n## x       1 349  288776  28.5 SIRGAS 2000 / UTM zone 25S FALSE [x]\n## y       1 352 9120761 -28.5 SIRGAS 2000 / UTM zone 25S FALSE [y]\n## band    1   6      NA    NA                         NA    NA\n\nL7_ETMs |&gt; class() # クラスはstars_proxyとstars\n## [1] \"stars_proxy\" \"stars\"\n\ndim(L7_ETMs) # L7_ETMsはx、y、bandの3次元データ\n##    x    y band \n##  349  352    6\n\n\nL7_ETMsを呼び出すと、以下のようにx、y、bandに関する表が示されます。\nx、yで示される位置は、fromの位置からtoの位置までdeltaの間隔で示されています。xは横（東西）方向の位置、yは縦（南北）方向の位置を意味します。xとyのdeltaの絶対値が同じですので、このラスタデータは正方形の位置データの集まりとなっています。starsのルールとして、xのdeltaはプラス、yのdeltaはマイナスで示します。\noffsetはfromに当たる位置の情報です。他のgeometryデータと共に利用する場合にはこの位置を参照して位置合わせを行うことになります。\nrefsysは参照系、上で説明した測地系の情報です。このデータではSIRGAS 2000（EPSG:4674）という南米地域の測地系のデータになっています。\npointは位置情報が点であるか（TRUE）、面であるか（FLASE）を示しており、最後のx/yはその列がx（東西方向の位置）であるか、y（南北方向の位置）であるかを示しています。\n最後の行に示されているbandはL7_ETMsに含まれているラスタデータの値を示すもので、1から6、つまり各位置に値が6つずつ存在することを示しています。L7_ETMsの場合では、光の波長ごとに撮影した6つの衛星写真となっています（詳しくは?L7_ETMsで確認してみて下さい）。\nstarsの表の各列の意味を以下の表にまとめます。\n\n\n\n\n\n列名\n意味\n\n\n\n\nfrom\nはじめのインデックス\n\n\nto\n最後のインデックス\n\n\noffset\nインデックス1の位置\n\n\ndelta\nピクセルのサイズ\n\n\nrefsys\n測地系\n\n\npoint\nセルが点であるかどうか\n\n\nvalues\nその他の値\n\n\n\n\n\nstarsオブジェクトをplot関数の引数にすることで、starsオブジェクトが示すラスタデータをプロットすることができます。上に示した通り、L7_ETMsには6つのbandデータが含まれるため、それぞれのbandに対する画像がプロットされます。\n\n\n\nplot関数でラスタデータをプロットする\n\nplot(L7_ETMs)\n\n\n\n\n\n\n\n\n\n\n32.3.1 GeoTIFFデータの読み込み\nラスタデータは衛星などからの写真・画像として得られることもあります。starsでは、GeoTIFFファイル（地理情報を含むTIFFファイル）を読み込んでstarsファイルとすることができます。以下の例では、ライブラリのフォルダからL7_ETMsのGeoTIFF画像をread_stars関数で読み込んでいます。読み込んだデータのクラスはstarsのみで、上で示したstars_proxyとは少し表示が異なります。starsはS3クラスで、中身はリストです。\n\n\n\ntiff画像をstarsとして読み込む\n\n# ライブラリのフォルダ内のファイルへのパスを取得\ntif &lt;- system.file(\"tif/L7_ETMs.tif\", package = \"stars\") \n\n# 読み込み\nx &lt;- read_stars(tif)\nx # GeoTIFFには測地系などの情報が付随している\n## stars object with 3 dimensions and 1 attribute\n## attribute(s):\n##              Min. 1st Qu. Median     Mean 3rd Qu. Max.\n## L7_ETMs.tif     1      54     69 68.91242      86  255\n## dimension(s):\n##      from  to  offset delta                     refsys point x/y\n## x       1 349  288776  28.5 SIRGAS 2000 / UTM zone 25S FALSE [x]\n## y       1 352 9120761 -28.5 SIRGAS 2000 / UTM zone 25S FALSE [y]\n## band    1   6      NA    NA                         NA    NA\n\nclass(x) # クラスはstars\n## [1] \"stars\"\n\nmode(x) # starsはリスト(S3オブジェクト)\n## [1] \"list\"\n\n\n\n\n32.3.2 starsのデータ構造\nstarsのリストの要素は3次元のarrayです。また、starsをデータフレームに変換すると、xとy、bandの番号とその値からなる、4列のデータフレームになります。\n\n\n\nstarsの構造\n\nclass(x[[1]]) # starsの要素はarray\n## [1] \"array\"\n\ndim(x[[1]]) # 3次元アレイになっている\n##    x    y band \n##  349  352    6\n\nas.data.frame(x) |&gt; head() # データフレームに変換できる\n##          x       y band L7_ETMs.tif\n## 1 288790.5 9120747    1          69\n## 2 288819.0 9120747    1          69\n## 3 288847.5 9120747    1          63\n## 4 288876.0 9120747    1          60\n## 5 288904.5 9120747    1          61\n## 6 288933.0 9120747    1          61\n\n\n\n\n32.3.3 netCDFの読み込み\nnetCDF（Network Common Data Form）は、気象や海洋などのラスタデータを取り扱う際に広く用いられているバイナリ形式のファイルです。read_stars関数でこのnetCDFをstarsオブジェクトとして読み込むことで、R上で取り扱うことができます。\n下の例では、北米の降雨量・気温・時間をまとめたnetCDFデータをライブラリのフォルダからread_stars関数で読み込み、starsオブジェクトとしています。bcsd_obs_1999.ncというファイルがnetCDFファイルで、拡張子には.ncが用いられます。読み込み時には登録されているデータの名前（pr：降雨量、tas：気温）が返ってきます。\n\n# pr（降水量）とtas（気温）があることが返ってくる\nw &lt;- system.file(\"nc/bcsd_obs_1999.nc\", package = \"stars\") |&gt;\n    read_stars()\n## pr, tas,\n\n# prとtasはstars（S3、リスト）の要素\nw |&gt; str(max.level = 1)\n## List of 2\n##  $ pr : Units: [mm/m] num [1:81, 1:33, 1:12] 224 225 233 226 223 ...\n##  $ tas: Units: [C] num [1:81, 1:33, 1:12] 4.73 4.53 4.81 4.71 4.33 ...\n##  - attr(*, \"dimensions\")=List of 3\n##   ..- attr(*, \"raster\")=List of 4\n##   .. ..- attr(*, \"class\")= chr \"stars_raster\"\n##   ..- attr(*, \"class\")= chr \"dimensions\"\n##  - attr(*, \"class\")= chr \"stars\"\n\n# wは12時点のデータ\ndim(w)\n##    x    y time \n##   81   33   12\n\n\n\n32.3.4 ggplot2でstarsオブジェクトをプロットする\nstarsライブラリにはggplot2でstarsオブジェクトをプロットするためのgeom関数であるgeom_stars関数が備わっています。geom_stars関数内でデータを設定することで、自動的にaesの内容が決定されてプロットされる仕組みになっています。ggplot2のその他の関数（下の例ではfacet_wrapやscale_fill_viridis関数）はggplot2と同様に利用することができます。\n\n\n\nggplo2でstarsオブジェクトからプロットを作成する\n\npacman::p_load(viridis)\n\nggplot() +\n  geom_stars(data = w[1], alpha = 0.8) +\n  facet_wrap(~ time) +\n  scale_fill_viridis()\n\n\n\n\n\n\n\n\n\n\n\n32.3.5 starsクラスの構造\nstarsクラスから特定の要素を抜き出す場合には、split関数を用います。split関数では、第一引数にstarsオブジェクト、第二引数に抜き出す要素（x、y、bandなど）を文字列で指定します。starsオブジェクトに要素を追加する場合にはmerge関数を用います。\n\n\n\nsplit関数で要素を取り出す\n\nst_dimensions(x) # dimensionの情報を取り出す\n##      from  to  offset delta                     refsys point x/y\n## x       1 349  288776  28.5 SIRGAS 2000 / UTM zone 25S FALSE [x]\n## y       1 352 9120761 -28.5 SIRGAS 2000 / UTM zone 25S FALSE [y]\n## band    1   6      NA    NA                         NA    NA\n\nsplit(x, \"x\") |&gt; head(5) # xの要素を取り出す\n## stars object with 2 dimensions and 5 attributes\n## attribute(s):\n##     Min. 1st Qu. Median     Mean 3rd Qu. Max.\n## X1    20      52   64.5 66.79972      79  177\n## X2    19      53   65.0 67.42188      79  162\n## X3    16      55   66.0 68.44318      78  166\n## X4    18      55   65.0 68.16525      78  180\n## X5    12      54   65.0 67.37879      78  153\n## dimension(s):\n##      from  to  offset delta                     refsys point\n## y       1 352 9120761 -28.5 SIRGAS 2000 / UTM zone 25S FALSE\n## band    1   6      NA    NA                         NA    NA\n\nsplit(x, \"y\") |&gt; head(5)\n## stars object with 2 dimensions and 5 attributes\n## attribute(s):\n##     Min. 1st Qu. Median     Mean 3rd Qu. Max.\n## X1    14      55     70 72.22541      88  180\n## X2    15      54     69 71.36199      87  163\n## X3    16      53     68 70.44126      85  160\n## X4    15      54     68 70.06256      84  161\n## X5     9      55     70 71.06590      86  164\n## dimension(s):\n##      from  to offset delta                     refsys point\n## x       1 349 288776  28.5 SIRGAS 2000 / UTM zone 25S FALSE\n## band    1   6     NA    NA                         NA    NA\n\nsplit(x, \"band\") |&gt; head(5)\n## stars object with 2 dimensions and 5 attributes\n## attribute(s):\n##     Min. 1st Qu. Median     Mean 3rd Qu. Max.\n## X1    47      67     78 79.14772      89  255\n## X2    32      55     66 67.57465      79  255\n## X3    21      49     63 64.35886      77  255\n## X4     9      52     63 59.23541      75  255\n## X5     1      63     89 83.18266     112  255\n## dimension(s):\n##   from  to  offset delta                     refsys point x/y\n## x    1 349  288776  28.5 SIRGAS 2000 / UTM zone 25S FALSE [x]\n## y    1 352 9120761 -28.5 SIRGAS 2000 / UTM zone 25S FALSE [y]\n\n\n\n\n32.3.6 sfでラスタデータを切り抜き（crop）する\nsfのベクタデータを利用して、starsのラスタデータを切り出すこともできます。ラスタデータの位置に対応したsfオブジェクト（正確にはsfcオブジェクト）を準備し、starsオブジェクトのインデックスにsfオブジェクトを与えると、そのsfcオブジェクトで指定した範囲のラスタデータのみが抽出されます。下の例では、circleはPOLIGONのsfcオブジェクトで、xがstarsオブジェクトです。x[circle]という形でstarsのインデックスにsfを指定することで、starsのラスタデータをクロップ（切り抜き）することができます。\n\n\n\nsfでstarsオブジェクトを切り抜きする\n\n# circleはPOLIGONのsfcオブジェクト\ncircle = st_sfc(st_buffer(st_point(c(293749.5, 9115745)), 400), crs = st_crs(x))\n\n# sfcで呼び出すと切り出し（crop）ができる\nplot(x[circle][, , , 1], reset = FALSE) # x[circle]でsfでのcropを行っている\npar(new = T)\nplot(circle, col = NA, border = 'red', add = TRUE, lwd = 2)\n\n\n\n\n\n\n\n\n\n\n\n32.3.7 starsオブジェクトの整形\nstarsオブジェクトのデータの整形は、dplyrを用いて行うことができます。starsオブジェクトはarrayのリストであるため、arrayデータの整形に関わるライブラリであるcubelyrパッケージ(Wickham 2022)をロードしておいた方がよい場合もあります。\n\n\n\nstarsオブジェクトの整形\n\nw # 上でロードした北米の降雨量・気温のラスタデータ\n## stars object with 3 dimensions and 2 attributes\n## attribute(s):\n##                 Min.   1st Qu.   Median      Mean   3rd Qu.      Max. NA's\n## pr [mm/m]  0.5900000 56.139999 81.88000 101.26433 121.07250 848.54999 7116\n## tas [C]   -0.4209678  8.898887 15.65763  15.48932  21.77979  29.38581 7116\n## dimension(s):\n##      from to offset  delta  refsys                    values x/y\n## x       1 81    -85  0.125      NA                      NULL [x]\n## y       1 33  37.12 -0.125      NA                      NULL [y]\n## time    1 12     NA     NA POSIXct 1999-01-31,...,1999-12-31\n\n# pacman::p_load(cubelyr) # なくてもよい\n\n# xの範囲を指定する（offset ～ offset + delta * (to - 1)の間を指定する必要がある）\nw |&gt; filter(x &gt; -80, x &lt; -70)\n## stars object with 3 dimensions and 2 attributes\n## attribute(s):\n##                Min.   1st Qu.   Median      Mean   3rd Qu.      Max. NA's\n## pr [mm/m] 11.130000 54.117499 85.09000 119.11238 136.03000 848.54999 7068\n## tas [C]    3.290161  9.328485 16.36981  16.30875  22.35612  28.87371 7068\n## dimension(s):\n##      from to offset  delta  refsys                    values x/y\n## x       1 41    -80  0.125      NA                      NULL [x]\n## y       1 33  37.12 -0.125      NA                      NULL [y]\n## time    1 12     NA     NA POSIXct 1999-01-31,...,1999-12-31\n\n# リストの要素を追加する\nw |&gt; mutate(pr_per_tas = pr / tas) # 降水量を気温で割った値を追加している\n## stars object with 3 dimensions and 3 attributes\n## attribute(s):\n##                        Min.     1st Qu.       Median         Mean      3rd Qu.\n## pr [mm/m]         0.5900000 56.13999939 81.879997253 1.012643e+02 1.210725e+02\n## tas [C]          -0.4209678  8.89888668 15.657626152 1.548932e+01 2.177979e+01\n## pr_per_tas [1/C] -3.1607183  0.00371323  0.005873292 9.045726e-03 9.713252e-03\n##                        Max. NA's\n## pr [mm/m]        848.549988 7116\n## tas [C]           29.385807 7116\n## pr_per_tas [1/C]   7.348576 7116\n## dimension(s):\n##      from to offset  delta  refsys                    values x/y\n## x       1 81    -85  0.125      NA                      NULL [x]\n## y       1 33  37.12 -0.125      NA                      NULL [y]\n## time    1 12     NA     NA POSIXct 1999-01-31,...,1999-12-31\n\n# リストの要素を選択する\nw |&gt; select(pr)\n## stars object with 3 dimensions and 1 attribute\n## attribute(s):\n##           Min. 1st Qu. Median     Mean  3rd Qu.   Max. NA's\n## pr [mm/m] 0.59   56.14  81.88 101.2643 121.0725 848.55 7116\n## dimension(s):\n##      from to offset  delta  refsys                    values x/y\n## x       1 81    -85  0.125      NA                      NULL [x]\n## y       1 33  37.12 -0.125      NA                      NULL [y]\n## time    1 12     NA     NA POSIXct 1999-01-31,...,1999-12-31\n\n\n\n\n32.3.8 starsオブジェクトを作成する\nラスタデータはx、yの位置とその位置に対応する値からなるデータです。このようなデータは行列があれば表現することができます。starsでは行列からst_as_stars関数を用いてstarsオブジェクトを作成することができます。ただし、この行列からstarsを作成する場合には、行方向がx（東西）、列方向がy（南北）に相当するとされるため、行列が90度回転した形でstarsに変換されます。\n\n\n\nmatrixからstarsを作成\n\n# matrixからstarsオブジェクトを作成する\nma &lt;- matrix(1:20, nrow = 4)\ndim(ma) = c(x = 4, y = 5) # 軸名をつける\nma &lt;- st_as_stars(ma)\nma # starsオブジェクトの表示、値はattributeとなっている\n## stars object with 2 dimensions and 1 attribute\n## attribute(s):\n##     Min. 1st Qu. Median Mean 3rd Qu. Max.\n## A1     1    5.75   10.5 10.5   15.25   20\n## dimension(s):\n##   from to offset delta point x/y\n## x    1  4      0     1 FALSE [x]\n## y    1  5      0     1 FALSE [y]\n\n# dimでは位置情報の次元が返ってくる（転置しているので、縦長になる）\nma |&gt; dim()\n## x y \n## 4 5\n\n# リストにはmatrixが登録されている\nma |&gt; _[[1]] \n##      [,1] [,2] [,3] [,4] [,5]\n## [1,]    1    5    9   13   17\n## [2,]    2    6   10   14   18\n## [3,]    3    7   11   15   19\n## [4,]    4    8   12   16   20\n\n# 90度回転した結果が帰ってきている（行方向が1次元目、列方向が2次元目となるため）\nma |&gt; image(text_values = TRUE) \n\n\n\n\n\n\n\n\n\n\n\n32.3.9 ラスタの形状の変更\n上記のL7_ETMsでは、x、yのdeltaの絶対値が同じ値（28.5）であったため、ラスタの1点の形は正方形でした。一方で、starsではラスタの形状を正方形だけでなく、長方形や平行四辺形のような、ゆがめた形（シアー、shear、ずれた形）を取ったり、ラスタデータを回転させることもできます。\nラスタの形状データはアトリビュートとして設定されており、attributes中のaffineがシアーの設定となります。このaffineにベクターを代入することでシアーの角度を調整することができます。また、curvilinearは曲面座標系の設定となります。\n\n\n\nシアー・回転等の設定\n\n# rasterの要素にグリッドの回転・シアー(shear)を設定する\n# affineが回転/シアー、curvilinearは曲線座標を示す\nst_dimensions(ma) |&gt; str(list.len = 4)\n## List of 2\n##  $ x:List of 7\n##   ..$ from  : num 1\n##   ..$ to    : int 4\n##   ..$ offset: num 0\n##   ..$ delta : num 1\n##   .. [list output truncated]\n##   ..- attr(*, \"class\")= chr \"dimension\"\n##  $ y:List of 7\n##   ..$ from  : num 1\n##   ..$ to    : int 5\n##   ..$ offset: num 0\n##   ..$ delta : num 1\n##   .. [list output truncated]\n##   ..- attr(*, \"class\")= chr \"dimension\"\n##  - attr(*, \"raster\")=List of 4\n##   ..$ affine     : num [1:2] 0 0\n##   ..$ dimensions : chr [1:2] \"x\" \"y\"\n##   ..$ curvilinear: logi FALSE\n##   ..$ blocksizes : NULL\n##   ..- attr(*, \"class\")= chr \"stars_raster\"\n##  - attr(*, \"class\")= chr \"dimensions\"\n\nma1 &lt;- ma\n\n# affineを変更することで、シアーの角度を設定する\nattr(attr(ma1, \"dimensions\"), \"raster\")$affine = c(0.1, 0.2)\nst_dimensions(ma1) |&gt; str(list.len = 4)\n## List of 2\n##  $ x:List of 7\n##   ..$ from  : num 1\n##   ..$ to    : int 4\n##   ..$ offset: num 0\n##   ..$ delta : num 1\n##   .. [list output truncated]\n##   ..- attr(*, \"class\")= chr \"dimension\"\n##  $ y:List of 7\n##   ..$ from  : num 1\n##   ..$ to    : int 5\n##   ..$ offset: num 0\n##   ..$ delta : num 1\n##   .. [list output truncated]\n##   ..- attr(*, \"class\")= chr \"dimension\"\n##  - attr(*, \"raster\")=List of 4\n##   ..$ affine     : num [1:2] 0.1 0.2\n##   ..$ dimensions : chr [1:2] \"x\" \"y\"\n##   ..$ curvilinear: logi FALSE\n##   ..$ blocksizes : NULL\n##   ..- attr(*, \"class\")= chr \"stars_raster\"\n##  - attr(*, \"class\")= chr \"dimensions\"\n\nimage(ma1)\n\n\n\n\n\n\n\n\n\n\n\n32.3.10 sfをラスタに変換\nsfをstarsに変換するのに用いる関数が、st_rasterize関数です。sfオブジェクトをそのままラスタにすると、列が自動的に選ばれてデータとして設定されます。sfでは、インデックスに列名を指定すると、その列とgeometryだけが残ったsfオブジェクトが得られます。この特徴を利用して、インデックス指定したsfをst_rasterizeの引数とするとよいでしょう。また、x、yのdeltaはそれぞれdx、dy引数で設定することができます。\n\n\n\nsfをラスタに変換\n\n# sfをラスタ化する\nst_rasterize(Nara_sfobj, dx = 0.01, dy = 0.01)\n## stars object with 2 dimensions and 4 attributes\n## attribute(s):\n##                Min.  1st Qu.    Median         Mean   3rd Qu.      Max. NA's\n## total_pop       357     1176      3061     41352.00     28121    354630 2883\n## male_pop        176      567      1663     19400.84     13374    164846 2883\n## female_pop      181      609      1398     21951.16     14747    189784 2883\n## area        4064489 95664616 247544016 263988281.22 292085792 672577536 2883\n## dimension(s):\n##   from to offset delta refsys point x/y\n## x    1 70  135.5  0.01 WGS 84 FALSE [x]\n## y    1 93  34.78 -0.01 WGS 84 FALSE [y]\n\n# male_popの列だけ選んでラスタ化する\nst_rasterize(Nara_sfobj[\"male_pop\"], dx = 0.01, dy = 0.01) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\n32.3.11 starsオブジェクトをsfに変換\n\n32.3.11.1 contour（等高線）への変換\nstarsオブジェクトをsfに変換する方法はいくつかあります。まず紹介するのは、st_contour関数を用いて、等高線を示すLINESTRINGに変換する方法です。contour_lines引数にはLINESTRINGを返すかどうか（FALSEならPOLIGONが返ってきます）、breaks引数には等高線の間隔を指定します。\n\n\n\nstarsを等高線のLINESTRINGに変換\n\n# 等高線のLINESTRINGに変換\nst_contour(ma, contour_lines = TRUE, breaks = 1:20) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\n32.3.11.2 POINT、POLYGONへの変換\nstarsオブジェクトをPOINTやPOLYGONに変換する場合には、st_as_sf関数を用います。as_point引数にTRUEを指定した場合にはPOINTのsfが、FALSEを指定した場合にはPOLYGONのsfが返ってきます。\n\n\n\nstarsをPOINT・POLYGONのsfに変換\n\nst_as_sf(ma, as_points = TRUE) |&gt; plot() # POINTSに変換\n\n\n\n\n\n\n\n\n\nst_as_sf(ma, as_points = FALSE) |&gt; plot() # POLYGONに変換",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>地理空間情報</span>"
    ]
  },
  {
    "objectID": "chapter32.html#インタラクティブなマップの表示",
    "href": "chapter32.html#インタラクティブなマップの表示",
    "title": "32  地理空間情報",
    "section": "32.4 インタラクティブなマップの表示",
    "text": "32.4 インタラクティブなマップの表示\n上述のように、sfでもstarsでも、オブジェクトをplot関数の引数に取ることで地図を描画することができます。また、ggplot2にもsfやstarsオブジェクトを表示するための手法が存在します。一方で地図データでは比較的大きい面積を占める地理空間と、狭い面積を占める空間（参考：面積が大きい・小さい市町村）があり、どうしても狭い面積を占める空間は見にくくなってしまいます。この問題は、plotやggplot2のグラフが静的であることが原因で起こります。\n地理情報を表示する場合には、静的な図ではなく、例えばgoogle mapのように、地図を拡大・縮小して確認できた方が情報を利用しやすく、理解しやすくなります。このような拡大・縮小に対応した、インタラクティブな地図を書くライブラリがRにはいくつも備わっています。インタラクティブな地図を描画するライブラリの代表的なものが、tmapパッケージ(Tennekes 2018)とleafletパッケージ(Cheng et al. 2023)です。\ntmapはggplot2風に用いることができる、比較的簡単に静的・インタラクティブな地図を描画するパッケージです、一方でleafletはより本格的にインタラクティブな地図を描画することができるパッケージです。以下では、まずtmapについて紹介し、その後leafletについて紹介します。\n\n32.4.1 tmapパッケージ\ntmapパッケージは、設定により静的・インタラクティブな地図の描画を切り替えることができる、ggplot2-likeな地図描画ライブラリです。\ntmapパッケージで地図を描画するときには、まずsfオブジェクトをtm_shape関数の引数に取ります。ggplot2でのggplot関数と同様に、tm_shape関数だけでは地図を描画することはできず、この関数に+で他の関数をつないでいくことで地図を描画することができます。たとえば、POLYGONの中身を埋め、境界線を表示した地図を描画する場合には、以下のようにtm_polygons関数を+でつなぎます。\n\n\n\ntmapで地図を描画する\n\npacman::p_load(tmap)\n\nNara_sfobj |&gt; \n  tm_shape() +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n同様に、POLYGONの境界線を描画する場合には、tm_borders関数を+でつなぎます。\n\n\n\n境界線を描画する：tm_borders関数\n\nNara_sfobj |&gt; \n  tm_shape() +\n  tm_borders()\n\n\n\n\n\n\n\n\n\nまた、境界線を描画することなくPOLYGONを埋めるように描画する場合にはtm_fillを用います。tm_fillとtm_bordersを同時に描画しているのがtm_polygonsになります。\n\nNara_sfobj |&gt; \n  tm_shape() +\n  tm_fill()\n\n\n\n\n\n\n\n\n\n\n32.4.2 コロプレス図を描画する\nコロプレス図を描画する場合には、tm_polygons関数のcol引数に、描画したい値を文字列で指定します。凡例（legend）や色は自動的に作成され、表示されます。\n\n\n\nコロプレス図を描画する\n\nNara_sfobj |&gt; \n  tm_shape() +\n  tm_polygons(col = \"total_pop\")\n## Some legend labels were too wide. These labels have been resized to 0.60, 0.60, 0.60. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\n\n\n\n32.4.2.1 静的マップとインタラクティブマップ\nここまではtmapで描画されているのは静的な、拡大・縮小などができないマップでした。tmapでは、静的なマップ・インタラクティブなマップを表示するモードをtmap_mode関数で変更できます。tmap_mode(\"view\")と指定すると、インタラクティブなマップが、tmap_mode(\"plot\")と指定すると静的なマップが表示されるようになります。モードの設定を行っていないときは静的なマップが表示されます。インタラクティブな地図の表示には、後ほど説明するleafletパッケージでも利用されている、Javascriptの地図表示ライブラリであるleafletが使用されています。\n\n\n\nviewモードでインタラクティブな地図を表示\n\ntmap_mode(\"view\")\n## tmap mode set to interactive viewing\nNara_sfobj |&gt; \n  tm_shape() +\n  tm_polygons(col = \"total_pop\")\n\n\n\n\n\n\n\n\n\nplotモードで静的な地図を表示\n\ntmap_mode(\"plot\")\n## tmap mode set to plotting\nNara_sfobj |&gt; \n  tm_shape() +\n  tm_polygons(col = \"total_pop\")\n## Some legend labels were too wide. These labels have been resized to 0.60, 0.60, 0.60. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\n\n\n\n\n\n32.4.3 legendの表示\nlegend（凡例）の表示方法を変える場合には、tm_legend関数を用います。tm_legend関数には凡例の表示を変えるためだけでなく、地図のタイトルや位置、色等を変更するための引数を指定することができます。legendの表示をしない場合には、引数にshow=FALSEを指定します。\n\n\n\n凡例（legend）などの編集\n\nNara_sfobj |&gt; \n  tm_shape() +\n  tm_polygons(col = \"total_pop\") +\n  tm_legend(show = FALSE) # viewモードではshow=FALSEは機能しない\n\n\n\n\n\n\n\n\n\n\n\n32.4.4 バブルチャートの作成\n地図上に値を点のサイズ・色で表現したい場合には、tm_symbols関数を用います。col引数にsfの列を文字列で指定すると点の色が、sizeに指定すると点のサイズがその列の値に従い変更されます。scaleは点のサイズを調整する引数です。\n\n\n\nバブルチャートを描画する\n\nNara_sfobj |&gt; \n  tm_shape() +\n  tm_polygons() +\n  tm_symbols(col = \"total_pop\", size = \"total_pop\", scale = 3) +\n  tm_legend(show = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n32.4.5 faceting\nggplot2と同様に、tmapでもfacetingにより複数のマップを簡単に並べて表示することができます。tmapではfacetingの関数としてtm_facetsを用います。tm_facetsではby引数に文字列でsfの列を取ることで、その列のラベルに従いグラフが分割されます。\n\n\n\nfaceting\n\n# 奈良の市町村を北・南で2分割する\nNara_sfobj$ns &lt;- rep(c(\"North\", \"South\"), c(30, 12)) \nNara_sfobj$ns[7] &lt;- \"South\"\n\n# tm_facetsで北部・南部を別のマップとして描画する\nNara_sfobj |&gt; \n  tm_shape() +\n  tm_polygons() +\n  tm_symbols(col = \"total_pop\", size = \"total_pop\", scale = 3) +\n  tm_legend(show = FALSE)+\n  tm_facets(by = \"ns\")\n\n\n\n\n\n\n\n\n\n\n\n32.4.6 地図を並べる：tmap_arrange\nfacetingを用いるのではなく、複数作成したtmapの地図を並べて表示することもできます。地図を並べて表示する場合には、tmapのオブジェクトを変数に代入し、その変数をtmap_arrange関数の引数に取ります。並べ方はncol、nrowなどの引数で、グラフのサイズはwidth、heightsなどの引数で指定することができます。\n\n\n\n地図を並べて表示する\n\n# tmapのオブジェクトを準備する\nmap_north &lt;- Nara_sfobj |&gt; \n  filter(ns == \"North\") |&gt; \n  tm_shape() +\n  tm_polygons()\n\nmap_south &lt;- Nara_sfobj |&gt; \n  filter(ns == \"South\") |&gt; \n  tm_shape() +\n  tm_polygons()\n\n# 北側と南側の地図を左右に並べて表示する\ntmap_arrange(map_north, map_south)\n\n\n\n\n\n\n\n\n\n\n\n32.4.7 その他の設定\ntmapにはたくさんの関数・引数が設定されており、うまく用いることで地図の表示を様々にカスタマイズすることができます。以下の例ではtm_layout関数のbg.color引数に色を指定することで、背景色を青色にしています。また、starsのラスタデータを描画する場合にはtm_raster関数を用います。\n\n\n\n背景色を変更する\n\nNara_sfobj |&gt; \n  tm_shape() +\n  tm_polygons(col = \"total_pop\") +\n  tm_layout(bg.color = \"blue\") +\n  tm_legend(show = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\nstarsを表示する\n\n# sfをラスタに変換\nNara_raster &lt;- st_rasterize(Nara_sfobj[\"male_pop\"], dx = 0.01, dy = 0.01)\n\n# ラスタを表示する\nNara_raster |&gt; \n  tm_shape() +\n  tm_raster() +\n  tm_legend(show = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n32.4.8 tmapオブジェクトを保存する\nggplot2におけるggsaveのように、tmapにはマップを保存するための関数であるtmap_save関数があります。tmap_save関数ではtmapのオブジェクトとfilenameを引数として指定します。filenameの拡張子に従い保存する形式を変更することができ、.pngや.jpgなどを用いれば画像で、.htmlを指定すればインタラクティブなJavascriptのマップとして保存することができます。\n\n\n\ntmapを保存する\n\ntmap_save(map_north, filename = \"naramap_north.png\")\n\ntmap_save(map_north, filename = \"naramap_north.html\")",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>地理空間情報</span>"
    ]
  },
  {
    "objectID": "chapter32.html#leafletパッケージ",
    "href": "chapter32.html#leafletパッケージ",
    "title": "32  地理空間情報",
    "section": "32.5 leafletパッケージ",
    "text": "32.5 leafletパッケージ\nインタラクティブなマップを作成したい場合には、tmapでも紹介したJavascriptのライブラリであるleafletをRで用いることができるようにした、leafletパッケージを用いるのが最もよいでしょう。tmapは（部分的に）leafletパッケージのwrapperとなっていて、tmapでインタラクティブなマップを書くこともできますが、leafletパッケージでは細かく引数を設定することで、より思い通りのマップを作成することができます。\n\n\n\nleafletを読み込む\n\npacman::p_load(leaflet)\n\n\n\n32.5.1 基本のマップ\nleafletはggplot2やtmapのように+でつなぐタイプのグラフィックライブラリではなく、plotlyに近い、パイプ演算子で繋いでいくタイプのライブラリです。leafletパッケージでのマップ作製は、まずsfオブジェクトをleaflet関数の引数とするところからスタートします。次に、パイプ演算子でaddTiles関数を繋ぎます。この形で引数を取らずに実行すると、世界地図が示されます。\n\n\n\nleafletの基本：leafletとaddTiles\n\nNara_sfobj |&gt; \n  leaflet() |&gt; \n  addTiles()\n\n\n\n\n\n\n\n\n32.5.2 setView関数\nこのままではズームが引きすぎですし、日本を中心とした形にもなっていません。デフォルトで表示する位置を表示するための関数がsetView関数です。setView関数は、経度・緯度を引数に取り、その位置を中心としたマップを描画するための関数です。zoom引数に数値を設定することで、拡大した地図をデフォルトで表示することもできます。\n\n\n\nsetView関数で位置を調整する\n\nNara_sfobj |&gt; \n  leaflet() |&gt; \n  addTiles() |&gt; \n  setView(137.5, 37.5, zoom = 4)\n\n\n\n\n\n\n\n\n32.5.3 POLYGONを描画する\nここまではsfオブジェクトの内容は何も表示されていません。sfに設定されているPOLYGONを描画するときには、addPolygons関数を用います。addPolygons関数をパイプ演算子でつなぐと、sfオブジェクトに設定されているgeometryに従いマップが表示されます。しかし、今まで表示されていたマップの表示がなくなり、POLYGONだけが表示されるようになります。\n\n\n\naddPolygonsでPOLYGONを表示する\n\nNara_sfobj |&gt; \n  leaflet() |&gt; \n  setView(136, 34.25, zoom = 8) |&gt; \n  addPolygons()\n\n\n\n\n\n\n\n\n32.5.4 背景のマップを描画する\n背景のマップを表示する場合には、addProviderTiles関数を追加します。addProviderTilesでは引数でどのようなマップを表示するかを選択します。マップの種類は、leafletのプレビューを参考に選びましょう。以下の例では、\"OpenstreetMap.Mapnik\"（地名がその地域の原語に従い表示されるOpenstreetMap）を選択しています。\n\n\n\n背景のマップをaddProviderTilesで設定する\n\nNara_sfobj |&gt; \n  leaflet() |&gt; \n  addProviderTiles(\"OpenStreetMap.Mapnik\") |&gt; \n  setView(136, 34.25, zoom = 8) |&gt; \n  addPolygons()\n\n\n\n\n\n\n\n\n32.5.5 POLYGONの表示を整える\nPOLYGONと背景のマップは描画されましたが、どうもPOLYGONの周辺の線が太く、見にくいです。この線の太さや色はaddPolygonsの引数であるweightやcolorを設定することで変更できます。weight=1とするとちょうどよい感じの線の太さになります。\n\n\n\n境界の線の表示を変更する\n\nNara_sfobj |&gt; \n  leaflet() |&gt; \n  addProviderTiles(\"OpenStreetMap.Mapnik\") |&gt; \n  setView(136, 34.25, zoom = 8) |&gt; \n  addPolygons(weight = 1, color = \"blue\")\n\n\n\n\n\n\n\n\n32.5.6 POLYGONの中身の色を変更する\nコロプレス図を作成するためには、POLYGONの中の色が値に従って変化する必要があります。コロプレス図を描画するためには、addPolygons関数のfillcolor引数を指定します。このfillcolorの設定がやや複雑で、まずは色を指定するルールに関する関数を設定する必要があります。\n色を指定する関数には、colorNumeric、colorBin、colorQuantile、colorFactorの4つがあります。colorNumericは数値をそのまま色に変換し、colorBinとcolorQuantileは数値を指定した値の間隔、もしくは分位値に従って色分けし、colorFactorは因子に色を付ける関数です。下の例では、colorQuantileを用いて、domainに人口の対数（log(Nara_sfobj$total_pop)）を取ります。また、n=5を指定することで、人口を分位値で5カテゴリーに分けています。第一引数は色の指定で、赤（\"Reds\"）で値の変化を示すように設定しています。色指定についてはRの色見本を参考に指定します。\nfillcolor引数では、チルダ（~）を用いて上の色指定関数（下の例ではpal）を、コロプレス図に記載したいデータを引数として指定します。下の例ではlog(total_pop)を指定し、人口の対数をコロプレス図として示しています。\n\n\n\nコロプレス図としてPOLYGONに色を指定する\n\n# 色指定のための関数\npal &lt;- colorQuantile(\"Reds\", domain = log(Nara_sfobj$total_pop), n = 5)\n\n# fillcolor引数に色指定関数を設定し、コロプレス図とする\nNara_sfobj |&gt; \n  leaflet() |&gt; \n  addProviderTiles(\"OpenStreetMap.Mapnik\") |&gt; \n  setView(136, 34.25, zoom = 8) |&gt; \n  addPolygons(weight = 1, color = \"blue\", fillColor = ~ pal(log(total_pop)))\n\n\n\n\n\n\n\n\n32.5.7 fillcolorの調整\n上の例では、全体的にコロプレス図の色が薄く、コントラストがよくありません。少し透明度が高すぎるようです。addpolygons関数で色の透明度を指定する場合には、fillopacity引数に値を指定します。fillopacityのデフォルト値は0.2でかなり小さめですので、もう少し大きな値を指定し、透明度を低めにします。透明度を低めに設定することで、コロプレス図のコントラストがはっきりし、分かりやすい図になります。\n\n\n\nfillopacity引数で透明度を調整する\n\nNara_sfobj |&gt; \n  leaflet() |&gt; \n  addProviderTiles(\"OpenStreetMap.Mapnik\") |&gt; \n  setView(136, 34.25, zoom = 8) |&gt; \n  addPolygons(\n    weight = 1, \n    color = \"blue\", \n    fillColor = ~ pal(log(total_pop)),\n    fillOpacity = 0.7)\n\n\n\n\n\n\n\n\n32.5.8 マウスで選択した位置をハイライトする\nleafletでは、インタラクティブなマップの表現として、拡大・縮小だけでなく、マウスで選択した位置をハイライトし、選択している位置を分かりやすくすることができます。このハイライトの設定を行う引数がhighlightOptionsです。highlightoptions引数にはhighlightoptions関数を指定し、このhighlightoptions関数内でハイライトされたときの線の太さ（weight）、色（color）、透明度（fillopacity）、前面に表示するかどうか（bringToFront）等を指定します。\n\n\n\nマウスで選択した位置をハイライト\n\nNara_sfobj |&gt; \n  leaflet() |&gt; \n  addProviderTiles(\"OpenStreetMap.Mapnik\") |&gt; \n  setView(136, 34.25, zoom = 8) |&gt; \n  addPolygons(\n    weight = 1, \n    color = \"blue\", \n    fillColor = ~ pal(log(total_pop)),\n    fillOpacity = 0.7,\n    \n    highlightOptions = highlightOptions(\n      weight = 5,\n      color = \"red\",\n      fillOpacity = 0.3,\n      bringToFront = TRUE))\n\n\n\n\n\n\n\n\n32.5.9 マウスで選択した位置にテキストを表示する\n同様に、マウスで選択した位置にテキストでその位置の情報を表示することもできます。表示するテキストの準備にはaddPolygons関数のlabel引数を用います。label引数には、sfオブジェクトの各列に対応する、表示したい文字列を設定します。\nまた、addPolygons関数のlabelOptions引数を指定することで、表示する文字列の細かな設定を行うことができます。以下の例では、フォントのサイズやウエイト、空白スペースのサイズ、文字列が表示される位置を指定しています。\n\n\n\nマウスで選択した位置にテキストを表示\n\nNara_sfobj |&gt; \n  leaflet() |&gt; \n  addProviderTiles(\"OpenStreetMap.Mapnik\") |&gt; \n  setView(136, 34.25, zoom = 8) |&gt; \n  addPolygons(\n    weight = 1, \n    color = \"blue\", \n    fillColor = ~ pal(log(total_pop)),\n    fillOpacity = 0.7,\n    \n    highlightOptions = highlightOptions(\n      weight = 5,\n      color = \"red\",\n      fillOpacity = 0.3,\n      bringToFront = TRUE),\n      \n    label = paste(Nara_sfobj$N03_004, \":\", (Nara_sfobj$total_pop / 10000) |&gt; round(1), \"万人\"),\n    labelOptions = labelOptions(\n      style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n      textsize = \"15px\",\n      direction = \"auto\"))\n\n\n\n\n\n\n\n\n32.5.10 凡例の表示\nさらに凡例を追加する場合には、addPolygons関数内でaddLegend関数を指定します。addLegend関数には、addPolygons関数にも用いた色指定の関数（以下の例ではpal）、数値（values）、透明度、位置等をaddLegend関数の引数に指定することで、addPolygons関数で指定した色に対応した凡例を追加することができます。\n\n\n\n凡例の表示\n\nNara_sfobj |&gt; \n  leaflet() |&gt; \n  addProviderTiles(\"OpenStreetMap.Mapnik\") |&gt; \n  setView(136, 34.25, zoom = 8) |&gt; \n  addPolygons(\n    weight = 1, \n    color = \"blue\", \n    fillColor = ~ pal(log(total_pop)),\n    fillOpacity = 0.7,\n    \n    highlightOptions = highlightOptions(\n      weight = 5,\n      color = \"red\",\n      fillOpacity = 0.3,\n      bringToFront = TRUE),\n      \n    label = paste(Nara_sfobj$N03_004, \":\", (Nara_sfobj$total_pop / 10000) |&gt; round(1), \"万人\"),\n    labelOptions = labelOptions(\n      style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n      textsize = \"15px\",\n      direction = \"auto\")) |&gt; \n    \n    addLegend(pal = pal, values = ~log(total_pop), opacity = 0.7, title = NULL,\n      position = \"bottomright\")\n\n\n\n\n\n\nleafletには上記の他にも無数の関数が設定されており、駆使することで色々なグラフを作成することができます。leafletの日本語の資料はあまりありませんが（日本語ではこのページが一番詳しいと思います）、leafletのreferenceを読み解きながら作図すれば、思い通りの地図を作成することができます。\n\n\n\n\n\n\nBivand, Roger, Jakub Nowosad, and Robin Lovelace. 2023. spData: Datasets for Spatial Analysis. https://CRAN.R-project.org/package=spData.\n\n\nCheng, Joe, Barret Schloerke, Bhaskar Karambelkar, and Yihui Xie. 2023. Leaflet: Create Interactive Web Maps with the JavaScript ’Leaflet’ Library. https://CRAN.R-project.org/package=leaflet.\n\n\nHijmans, Robert J. 2023. Raster: Geographic Data Analysis and Modeling. https://CRAN.R-project.org/package=raster.\n\n\n———. 2024. Terra: Spatial Data Analysis. https://CRAN.R-project.org/package=terra.\n\n\nPebesma, Edzer. 2018. “Simple Features for R: Standardized Support for Spatial Vector Data.” The R Journal 10 (1): 439–46. https://doi.org/10.32614/RJ-2018-009.\n\n\nPebesma, Edzer, and Roger Bivand. 2023a. Spatial Data Science: With applications in R. Chapman and Hall/CRC. https://doi.org/10.1201/9780429459016.\n\n\n———. 2023b. Spatial Data Science: With applications in R. London: Chapman; Hall/CRC. https://doi.org/10.1201/9780429459016.\n\n\nPebesma, Edzer, Thomas Mailund, and James Hiebert. 2016. “Measurement Units in R.” R Journal 8 (2): 486–94. https://doi.org/10.32614/RJ-2016-061.\n\n\nTennekes, Martijn. 2018. “tmap: Thematic Maps in R.” Journal of Statistical Software 84 (6): 1–39. https://doi.org/10.18637/jss.v084.i06.\n\n\nWickham, Hadley. 2022. Cubelyr: A Data Cube ’Dplyr’ Backend. https://CRAN.R-project.org/package=cubelyr.",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>地理空間情報</span>"
    ]
  },
  {
    "objectID": "chapter33.html",
    "href": "chapter33.html",
    "title": "33  ネットワーク解析",
    "section": "",
    "text": "33.1 ネットワーク解析とは？\nネットワーク解析とは、たくさんの人や都市、ウェブページなどの関係性（ネットワーク）を解析する一連の解析手法のことを指します。ここでのネットワークとは、例えば友人関係やメールの送付、電車の路線での駅同士のつながりや物資のやり取りなど、多岐に渡ります。生物学であれば代謝経路や遺伝子の誘導・抑制の関係性、会社であれば命令系統などもネットワークの例となります。これらのネットワークを表示し、特徴を抽出することでネットワークを評価する手法がネットワーク解析です。\nネットワークの基本は、人や都市などの要素と、そのつながりの2つです。ネットワーク解析では、人や都市などの要素のことをnodeやvertex、つながりのことをlinkやedgeと呼びます。また、このネットワーク全体のことをgraphと呼びます。\nlinkやedge、つまりネットワークのつながりには、大きく分けて2つのタイプがあります。一つは友人関係や線路での結合など、方向性が無いもので、もう一つはメールの送付や物資の輸送などの方向性があるものです。方向性のないつながりのことを無向（undirected）、方向性のあるつながりのことを有向（directed）と呼びます。\n主要なネットワーク解析の目的は以下の通りです。\nこの他にランダムなグラフの作成、グラフの類似性の評価や検定を用いたネットワーク解析もあります。",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>ネットワーク解析</span>"
    ]
  },
  {
    "objectID": "chapter33.html#ネットワーク解析とは",
    "href": "chapter33.html#ネットワーク解析とは",
    "title": "33  ネットワーク解析",
    "section": "",
    "text": "図1：ネットワークの用語\n\n\n\n\nネットワークを作成し、取り扱う\nネットワークを表示する\n重要なnodeを抽出する（中心性）\nnodeをグループ分けする（クラスター化）\nグラフの特徴を評価する\nnodeからnodeへの経路を探索する",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>ネットワーク解析</span>"
    ]
  },
  {
    "objectID": "chapter33.html#rでのネットワーク解析のライブラリ",
    "href": "chapter33.html#rでのネットワーク解析のライブラリ",
    "title": "33  ネットワーク解析",
    "section": "33.2 Rでのネットワーク解析のライブラリ",
    "text": "33.2 Rでのネットワーク解析のライブラリ\nRでのネットワーク解析には、statnet(Handcock et al. 2018; Hunter et al. 2008)系ライブラリとigraph(Csardi and Nepusz 2006; Csárdi et al. 2024)系ライブラリの2系統があります。どちらもネットワーク解析を行うために必要十分な機能を備えていますが、オブジェクトの取り扱いや関数名の特徴が異なります。どちらを使うかは好みで決めてしまってよいですが、igraph系の方が情報が多いため比較的使いやすいと思います。\nstatnetはsna(Butts 2023)やnetwork(Butts 2015, 2008)などの一連のネットワーク解析用ライブラリの総称で、tidyverseのようにinstall.packages(\"statnet\")で一度にインストールし、library(statnet)で一度にロードすることができます。statnetはよくできたライブラリ群だと思うのですが、解説文（Documentation）があまり充実しておらず、なかなか手を付けにくい印象があります。\nigraphはネットワーク解析に必要な関数を一通り備えたライブラリで、RだけでなくpythonやMathematica、Cにも機能を提供しています。ネット上にもigraphの情報はたくさん落ちており、statnetよりは間口が広く学びやすいかと思います。ただし、statnetもigraphもたくさんの機能を備えたライブラリであり、学習コストは高めです。\nこのigraph、非常にたくさんの関数を備えたライブラリではあるのですが、関数の命名規則や引数の形が一定ではなく、そのまま使うとやや使いにくいです。また、tidyverseなどのRの標準的なパッケージとの相性もあまりよくありません。この命名やtidyverseとの整合性を取るためのライブラリがtidygraph(Pedersen 2024b)です。tidygraphはほぼigraphのwrapper（関数名と引数の形を整えたもの）ですが、igraphをそのまま使うよりは使いやすく、パイプ演算子との相性も悪くありません。\nこの章ではまずigraphについて説明し、その後にtidygraphとigraphの関数との対応を説明することにします。\n\n\n\nライブラリのロード\n\npacman::p_load(igraph, tidygraph, tidyverse)",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>ネットワーク解析</span>"
    ]
  },
  {
    "objectID": "chapter33.html#igraph",
    "href": "chapter33.html#igraph",
    "title": "33  ネットワーク解析",
    "section": "33.3 igraph",
    "text": "33.3 igraph\n\n33.3.1 igraphでの用語\nigraphでは、ネットワーク全体をgraph、ノードをvertex、リンクをedgeと呼びます。それぞれをnetwork、node、linkと呼ぶことは基本的にありません（ただし、一部の関数の引数としてnodeを使っていたりします）。\n\n\n\n図2：igraphでの呼び方\n\n\n\n\n33.3.2 グラフを作成する\nigraphでグラフ、つまりネットワークの全体図を作成する方法はいくつかあります。\n\nedge vectorから作成する\nedge listから作成する\nadjacent matrixから作成する\nliteralから作成する\nformulaから作成する\ndata.frameから作成する\n\n単純なグラフを作成するのであればedge vectorやedge listから、vertexやnodeに特性（attribute）を付けた複雑なグラフを作成するのであればdata.frameを用いるのが比較的簡単だと思います。\n\n33.3.2.1 edge vectorから作成する\nまずはベクターから作成する方法を説明します。\nベクターでネットワークを表現する場合には、ベクターに、edgeで繋ぎたいvertex2つをセットで記載します。例えば、c(\"A\", \"B\")であれば、AとBというvertexをedgeで繋いだグラフとなります。edgeでつなぐvertexは必ず2つセットになりますので、もう一つedgeを設定したい場合には、1つ目のedgeを示す2つのvertexの後に、さらに2つのvertexを記載します。つまり、c(\"A\",\"B\", \"A\",\"C\")といった形で表現することで、A-B、A-Cのedgeを持つ、A、B、Cのvertexを表現することができます。このようなベクターをigraphではedge vectorと呼びます。\nとは言っても、edge vectorはただのベクターですので、このedge vectorからグラフを作成する必要があります。グラフの作成には、make_graph関数を用います。edge vectorをmake_graph関数の引数とすることで、グラフを作成することができます。\nedge vectorでは、基本的に1つ目のvertexから2つ目のvertexの方向にedgeを繋ぐ、有向グラフが作成されます。無向グラフを作成する場合には、引数にdirected=FALSEと指定します。\nグラフを作成し表示すると、グラフの情報が示されます。このグラフの情報については後ほど説明します。\n\n# 有向グラフ\nmake_graph(\n  c(1, 2,\n    2, 3,\n    3, 1)\n)\n## IGRAPH 67815ac D--- 3 3 -- \n## + edges from 67815ac:\n## [1] 1-&gt;2 2-&gt;3 3-&gt;1\n\n# 無向グラフ\nmake_graph(\n  c(1, 2,\n    2, 3,\n    3, 1),\n  directed = FALSE\n)\n## IGRAPH 67823ac U--- 3 3 -- \n## + edges from 67823ac:\n## [1] 1--2 2--3 1--3\n\n\n33.3.2.1.1 グラフを描画する\nグラフを描画するには、先ほど作成したグラフをplot関数の引数に取ります。より複雑なグラフの描画方法については後ほど説明します。\n\n\n\nグラフを表示する\n\nmake_graph(\n  c(1, 2,\n    2, 3,\n    3, 1)\n) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\n\n33.3.2.2 edge listからグラフを作成する\nedge listはedge vectorと似ており、edgeでつなぐvertexを1、2列目にそれぞれ記載した行列（edge list）を用いてグラフを作成する方法です。下の例では、A→B、B→C、C→Aのそれぞれのedgeを2列の行列で表現しています。edge listからグラフを作成する場合には、graph_from_edgelist関数を用います。make_graph関数と同様に、無向グラフを作成する場合には引数にdirected=FALSEを指定します。\n\n\n\nedge listからグラフを作成する\n\n# byrow=TRUEを指定すると表記と一致してわかりやすい\nedgelist_matrix &lt;- \n  matrix(\n    c(\"A\",\"B\", \n      \"B\",\"C\", \n      \"C\",\"A\"),\n    ncol = 2,\n    byrow=TRUE\n  )\n\n# edgelistを表示する\nedgelist_matrix\n##      [,1] [,2]\n## [1,] \"A\"  \"B\" \n## [2,] \"B\"  \"C\" \n## [3,] \"C\"  \"A\"\n\ngraph_from_edgelist(edgelist_matrix) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\n33.3.2.3 adjacency matrixからグラフを作成する\nedge vector、edge listを用いないグラフの作成方法として、adjacency matrix（隣接行列）を用いる方法があります。隣接行列は行数と列数が同じ行列（正方行列）で、行名・列名をvertexの名前とした行列です。隣接行列では、行方向に見て0であればedgeなし、1以上であればedgeありとなります。例えば下の例では、Aの行を見ると、A列は0、B列に1、C列に1となっています。これは、AからAはedgeがなく、AからB、AからCへのedgeがあることを示しています。\n隣接行列からグラフを作成するための関数がgraph_from_adjacency_matrixです。graph_from_adjacency_matrix関数では、有向グラフ・無向グラフを指定する引数としてdirectedではなく、modeが用いられます。デフォルトはmode=\"directed\"で、有向グラフが作成されます。無向グラフを作成する場合にはmode=\"undirected\"を指定します。\n隣接行列には1以上の値を設定することができます。1以上の値を設定した場合には、そのedgeが複数、平行なedgeとして設定されます。ただし、weighted=TRUEとした場合には、edgeの数ではなく、edgeのweightという特性（attribute）の値が指定されることになります。\n\n\n\nadjacency matrixからグラフを作成する\n\nmat &lt;- \n  matrix(\n    c(0, 1, 1,\n      1, 0, 1,\n      1, 1, 0),\n    nrow = 3,\n    byrow = TRUE\n  )\n\n# vertex名は行・列名で設定する\ncolnames(mat) &lt;- c(\"A\", \"B\", \"C\")\nrownames(mat) &lt;- c(\"A\", \"B\", \"C\")\n\n# 隣接行列を表示する\nmat\n##   A B C\n## A 0 1 1\n## B 1 0 1\n## C 1 1 0\n\n# 有向グラフ\ngraph_from_adjacency_matrix(mat) |&gt; plot()\n\n\n\n\n\n\n\n\n\n# 無向グラフ\ngraph_from_adjacency_matrix(mat, mode = \"undirected\") |&gt; plot()\n\n\n\n\n\n\n\n\n上の例ではA、B、Cを繋ぐすべてのedgeが両方向になっていますが、片方向にする場合には、例えばA行B列を1、B行A列を0とします。このように設定することで、A→Bのみの有向グラフを作成することができます。また、対角成分（A行A列など）が1以上に設定されている場合には、AからAへのループとなるedgeが設定されます。\n\n\n\nadjacency matrixで方向を設定する\n\nmat2 &lt;-\n  matrix(\n    c(0, 1, 0,\n      0, 0, 1,\n      1, 0, 0),\n    nrow = 3,\n    byrow = TRUE\n  )\n\nmat2\n##      [,1] [,2] [,3]\n## [1,]    0    1    0\n## [2,]    0    0    1\n## [3,]    1    0    0\n\n# 有向グラフ\ngraph_from_adjacency_matrix(mat2) |&gt; plot()\n\n\n\n\n\n\n\n\n\n# vertex自身へのedge（ループ）\nmatrix(\n  c(1, 1, 1,\n    1, 1, 1,\n    1, 1, 0),\n  nrow = 3,\n  byrow = TRUE\n) |&gt; \n  graph_from_adjacency_matrix() |&gt; \n  plot()\n\n\n\n\n\n\n\n\n\n\n33.3.2.4 literalからグラフを作成する\nグラフの表現として、--や-+などの記号を用いる、literalでもグラフを作成することができます。グラフの表現はそれぞれ以下の通りです。\n\n\n\nliteral\ngraph\n\n\n\n\nA – B\nA－B（無向グラフ）\n\n\nA -+ B\nA→B\n\n\nA +- B\nA←B\n\n\nA ++ B\nA↔︎B\n\n\nA —-+ B\nA→B\n\n\n\n要は、+側が矢印の先になるような記法がliteralです。矢印の反対側は-になります。左端と右端の-、+の間には-を複数挟むこともできます。無向グラフと有向グラフを同じグラフに含めることはできませんので、--を用いた場合にはすべてのedgeを--で表現する必要があります。\nこのliteralからグラフを作成する関数がgraph_from_literalです。literalは文字列ではなく、そのまま引数として取り、edgeの表現として必要な分だけコンマで繋ぎます。\n\n\n\nliteralからグラフを作成する\n\ngraph_from_literal(\n  A-+B, B-+C, C-+D, D++A \n) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n33.3.2.4.1 formulaでグラフを作成する\nまた、このliteralに似た表現を用いてグラフを作成する方法もあります。引数としてベクターではなく、チルダ（~）で始まり、edgeとvertexを表現した―と:から成る式（formula）を用いる方法です。グラフの作成にはedge vectorの際に用いたmake_graphを用います。-がedge、:は複数のvertexへの接続を表します。Rでは:の表現が数列（1:3など）と異なり混乱しやすいので、あまりお勧めできる表記方法ではないように思います。\n\n\n\nformulaを用いてグラフを作成する\n\nmake_graph(~ A-B, B-C, C-A:D) |&gt; plot() # C-A、C-Dを設定\n\n\n\n\n\n\n\n\n\n\n\n\n33.3.2.5 data.frameからグラフを作成する\nRで最も頻繁に用いられるデータ型の一つである、データフレームを用いてもグラフを作成することができます。グラフの作成方法はedge listとよく似ていて、1列目と2列目にedgeで接続するvertexを表記したデータフレームを用います。列名はわかりやすいようにそれぞれfromとtoにしておきます。このデータフレームがグラフ作成の基本となります。\nまた、データフレームを用いると、edgeやvertexに特性（attributes）を持たせたいときに便利です。例えば人間関係であれば、edgeにはメールのやり取りの回数であったり、交友関係の深さを設定することがあります。また、人間関係におけるvertex、つまり人には性別や年齢、所属する組織などを設定したい場合もあるでしょう。データフレームからグラフを作成すると、このような特性を比較的簡単にグラフに持たせることができます。\nedgeに特性を持たせたい場合には、上記のfromとtoからなるデータフレームに列を追加します。edgeに設定される主な特性はweightです。上記のメールの数や交友関係の深さなどをweightとして数値で設定します。\n同じように、vertexにも特性を持たせることができます。edgeを示したデータフレームとは別に、vertexを表現するためのデータフレームを準備します。このデータフレームの1列目には、edgeのデータフレームに示したvertexをすべて含める必要があります。また、edgeのデータフレームに含まれないvertexを含めることもできます（edgeによる接続のない、独立したvertexが追加されます）。2列目以降には、vertexの特性、例えば人であれば年齢や性別の列を作成しておきます。\nこの2つのデータフレームを用いて、グラフを作成します。データフレームからグラフを作成するための関数がgraph_from_data_frameです。graph_from_data_frameでは、edgeを表現したデータフレームだけあればグラフを作成することができます。また、vertices引数にvertexを表現したデータフレームを設定することで、edgeとは別にvertexやその特性を設定することができます。\n\n\n\nデータフレームからグラフを作成する\n\n# edgeのデータフレーム（weightは特性）\nd_edge &lt;- data.frame(\n  from = c(\"A\", \"B\", \"C\"),\n  to = c(\"B\", \"C\", \"A\"),\n  weight = c(1, 2, 3)\n)\n\n# vertexのデータフレーム（age、sexは特性）\nd_vertex &lt;- data.frame(\n  name = c(\"A\", \"B\", \"C\"),\n  age = c(20, 25, 30),\n  sex = c(\"F\", \"M\", \"F\")\n)\n\ng &lt;- graph_from_data_frame(d_edge, vertices = d_vertex)\n\n\n\n\n\n\n\n\nattribute\n\n\n\n\n\nattributeについては3章や18章で簡単に説明しています。ベクターの名前（names）や行列の次元（dim）はattributeとして設定されており、関数から呼び出したり、演算に用いたりすることができます。igraphではこのattributeを設定することで、vertexやedgeの性質をリストのように呼び出すことができます。\n\n\n\n\n\n33.3.2.6 グラフの表示とattributes\nここまでで、グラフを作成する方法について述べてきました。作成したグラフはigraphクラスのオブジェクトで、表示させるとedgeの一覧と色々な情報が表示されます。\n\n\n\nigraphクラス\n\nclass(g)\n## [1] \"igraph\"\n\n\n\n\n\nigraphクラスのオブジェクトを表示する\n\ng\n## IGRAPH 67c7b5d DNW- 3 3 -- \n## + attr: name (v/c), age (v/n), sex (v/c), weight (e/n)\n## + edges from 67c7b5d (vertex names):\n## [1] A-&gt;B B-&gt;C C-&gt;A\n\n\nこの表示のうち、1行目のDNW-という部分はこのグラフの性質を示しています。始めのDはDirected（有向グラフ）の略です。無向グラフの場合にはU（Undirected）と表示されます。\n次のNはNamedの略で、vertexに名前（name）の特性（attribute）がついていることを示しています。その次のWはWeightedの略で、edgeにweightが設定されていることを示しています。vertexに名前がついていない場合にはNの位置が-に、edgeにweightが設定されていない場合にはWの位置が―になります。\n最後の―は2部グラフ（Bipartite graph）であるかどうかを示しており、2部グラフの場合はB、2部グラフでない場合には―が表示されます。2部グラフについては後ほど説明します。\n次の3 3の部分はvertexとedgeの数を示しており、前がvertexの数、後ろがedgeの数になります。\n次の行の+ attrは設定されているattributeを示しています。name、sexには(v/c)と表示されています。この(v/c)はvertexのattributeであり、characterであることを示しています。ageは(v/n)、つまりvertexのattributeでnumericであること、weightは(e/n)、edgeのattributeでnumericであることが表示されています。この他にグラフ自体にもattributeを設定することができます。グラフのattributeは(g/c)や(g/n)で示されます。\n最後の行はedgeのリストです。この場合は有向グラフであり、A→B、B→C、C→Aの3つのedgeがあることが示されています。\n\n\n33.3.2.7 edge/vertexをgraphから取り出す\nグラフからedgeを取り出す場合にはE関数、vertexを取り出す場合にはV関数をそれぞれ用います。取り出したedgeやvertexにはattributeが付いたままになっています。\n\n\n\nvertex・edgeを取り出す\n\nE(g)\n## + 3/3 edges from 67c7b5d (vertex names):\n## [1] A-&gt;B B-&gt;C C-&gt;A\nV(g)\n## + 3/3 vertices, named, from 67c7b5d:\n## [1] A B C\n\n\n上記のように、グラフにはattributeを設定することができます。attributeを設定することができるのは、graph全体と、edge、vertexの3種類です。それぞれのattributeはgraph_attr、edge_attr、vertex_attr関数でそれぞれリストとして取り出すことができます。\n\n\n\nattributesを取り出す\n\ngraph_attr(g)\n## named list()\nedge_attr(g)\n## $weight\n## [1] 1 2 3\nvertex_attr(g)\n## $name\n## [1] \"A\" \"B\" \"C\"\n## \n## $age\n## [1] 20 25 30\n## \n## $sex\n## [1] \"F\" \"M\" \"F\"\n\n\n他のRの関数と同様に、graph_attr、edge_attr、vertex_attr関数にベクターやリストを代入することで、グラフに後からattributeを設定することもできます。代入によりattributeを設定する場合には、関数の第一引数にグラフ、第二引数にattributeの名前を文字列で設定します。\n\n\n\nattributeを設定する\n\ngraph_attr(g, \"name\") &lt;- \"ABC\"\nedge_attr(g, \"degree\") &lt;- c(3, 4, 5)\nvertex_attr(g, \"height\") &lt;- c(167, 182, 153)\n\n# attributeが増えている\ng\n## IGRAPH 67c7b5d DNW- 3 3 -- ABC\n## + attr: name (g/c), name (v/c), age (v/n), sex (v/c), height (v/n),\n## | weight (e/n), degree (e/n)\n## + edges from 67c7b5d (vertex names):\n## [1] A-&gt;B B-&gt;C C-&gt;A\n\n\nattributeの取り出しには、graph_attr、edge_attr、vertex_attr関数だけでなく、上記のE関数、V関数を用いることもできます。E関数、V関数の返り値にはattributeがくっついているので、E関数、V関数の後に$ + attribute名をつけることでattributeをリストのように取り出すことができます。attributeを用いて演算を行う場合（たとえばネットワークをplot関数で表示するときのオプション設定にattributeを用いる場合など）にはE、V関数からのattributeの呼び出しを用いることになります。\n\n\n\nedgeのattributeをE関数から呼び出す\n\n# edgeに指定したweightを呼び出し\nE(g)$weight\n## [1] 1 2 3\n\n# edgeの太さをweightに従い決める\nplot(g, edge.width = E(g)$weight)\n\n\n\n\n\n\n\n\n\n同じように、vertexのattributeもノードの色調整などに用いることができます。\n\n\n\nvertexのattributeをV関数から呼び出す\n\nV(g)$sex\n## [1] \"F\" \"M\" \"F\"\n\nplot(\n  g, \n  edge.width = E(g)$weight, \n  # 男性のvertexはlightblue、女性のvertexはlightpinkで表示する\n  vertex.color = if_else(V(g)$sex == \"M\", \"lightblue\", \"lightpink\"))\n\n\n\n\n\n\n\n\n\n\n\n\n33.3.3 ネットワークを描画する\n上記の通り、ネットワークを描画する場合には、plot関数の引数にグラフのオブジェクトを取ります。\n\n\n\nplot関数でネットワークを表示する\n\nplot(g)\n\n\n\n\n\n\n\n\n\nただし、これだけではedgeやvertexの特性をグラフに反映することはできませんし、場合によっては表示が見にくく、ネットワークの構造をきちんととらえることができないこともあります。\nigraphでは、plot関数の引数やlayout（vertexの位置を決める要素）を設定する一連の関数により、ネットワークを自由に描画できるようになっています。以下にplot関数の引数の一覧を示します。\n\n\n\n\n\n\nいくつかの引数を指定した例を以下に示します。いろいろ試してみることで自由にネットワークを表示できるようになるでしょう。\n\n\n\nvertexのグループ化\n\nplot(g, mark.groups=list(c(1, 2), c(3)), mark.col = c(\"red\", \"blue\"))\n\n\n\n\n\n\n\n\n\n\n33.3.3.1 layout\nネットワークを表示する際には、上記のような引数による細かな表示の変更の他に、ネットワーク自体の形を大きく変えるlayoutというものを指定することができます。plot関数内のlayout引数にlayoutを指定するための関数を指定することで、ネットワークの見た目を大きく変えることができます。また、layoutを指定するための関数を前もって宣言しておくことでもlayoutを変更することができます。各layout関数にはそれぞれ引数も設定されているので、同じlayout内で見た目を微調整することもできます。\n\nstartreecirclenicelygridsphererandomlywith_dhwith_frwith_gemwith_graphoptwith_kkwith_lglwith_mdswith_sugiyamawith_drl\n\n\n\nkarate &lt;- make_graph(\"Zachary\")\nplot(karate, layout=layout_as_star(karate))\n\n\n\n\n\n\n\n\n\n\n\nkarate &lt;- make_graph(\"Zachary\")\nplot(karate, layout=layout_as_tree(karate))\n\n\n\n\n\n\n\n\n\n\n\nkarate &lt;- make_graph(\"Zachary\")\nplot(karate, layout=layout_in_circle(karate))\n\n\n\n\n\n\n\n\n\n\n\nkarate &lt;- make_graph(\"Zachary\")\nplot(karate, layout=layout_nicely(karate)) # plotのデフォルト\n\n\n\n\n\n\n\n\n\n\n\nkarate &lt;- make_graph(\"Zachary\")\nplot(karate, layout=layout_on_grid(karate))\n\n\n\n\n\n\n\n\n\n\n\nkarate &lt;- make_graph(\"Zachary\")\nplot(karate, layout=layout_on_sphere(karate))\n\n\n\n\n\n\n\n\n\n\n\nkarate &lt;- make_graph(\"Zachary\")\nplot(karate, layout=layout_randomly(karate))\n\n\n\n\n\n\n\n\n\n\n\nkarate &lt;- make_graph(\"Zachary\")\nplot(karate, layout=layout_with_dh(karate)) # Davidson-Harel layout algorithm\n\n\n\n\n\n\n\n\n\n\n\nkarate &lt;- make_graph(\"Zachary\")\nplot(karate, layout=layout_with_fr(karate)) # Fruchterman-Reingold layout algorithm\n\n\n\n\n\n\n\n\n\n\n\nkarate &lt;- make_graph(\"Zachary\")\nplot(karate, layout=layout_with_gem(karate)) # GEM layout algorithm\n\n\n\n\n\n\n\n\n\n\n\nkarate &lt;- make_graph(\"Zachary\")\nplot(karate, layout=layout_with_graphopt(karate)) # graphopt layout algorithm\n\n\n\n\n\n\n\n\n\n\n\nkarate &lt;- make_graph(\"Zachary\")\nplot(karate, layout=layout_with_kk(karate)) # Kamada-Kawai layout algorithm\n\n\n\n\n\n\n\n\n\n\n\nkarate &lt;- make_graph(\"Zachary\")\nplot(karate, layout=layout_with_lgl(karate)) # Large Graph layout\n\n\n\n\n\n\n\n\n\n\n\nkarate &lt;- make_graph(\"Zachary\")\nplot(karate, layout=layout_with_mds(karate)) # multidimensional scaling\n\n\n\n\n\n\n\n\n\n\n\nkarate &lt;- make_graph(\"Zachary\")\nplot(karate, layout=layout_with_sugiyama(karate)) # Sugiyama graph layout\n\n\n\n\n\n\n\n\n\n\n\nkarate &lt;- make_graph(\"Zachary\")\nplot(karate, layout=layout_with_drl(karate)) # force-directed graph layout\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nネットワークの表記と情報としての正しさ\n\n\n\n\n\nネットワークをグラフとしてプロットすると、何となくそのネットワークが分かったような気がします。ですので、ネットワーク解析においてプロットすること、ネットワークの表記は非常に重要です。一方で、上記のようにネットワークの表記の方法は様々であり、どのようなネットワークの表記がネットワークの正確な理解につながるのかは難しい問題です。\nネットワークに関する論文 (Jones, Mair, and McNally 2018)では、ネットワークの表記において勘違いしやすい点が4点挙げられています。\n\nvertexの位置が近いとvertexの関係が密接で、遠いと密接ではないように思う\nvertexの縦横の位置に意味があるように思う\nネットワークの中心に表記されているvertexが重要だと思う\n2つのネットワークの図が全然違うと、ネットワークは全く異なっていると思う\n\n上記の4点は表記法により正しかったり間違っていたりするため、必ずしも表示されたネットワークがネットワークの正確な情報を伝えているというわけではありません。ネットワークの描画は乱数依存であるため、例えば下図のように同じグラフを2回表示するだけでも、グラフは同じ形には表記されません。\n\n\n\n同じネットワークを2度表示する\n\npar(mfrow = c(1, 2))\nkarate |&gt; plot()\nkarate |&gt; plot() # seedを指定しないと見た目が変わる\n\n\n\n\n\n\n\n\n\n上記で紹介した論文には、ネットワークの情報を正確に伝えるためのプロットの手法について記載されています。ご一読されるとよいでしょう。",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>ネットワーク解析</span>"
    ]
  },
  {
    "objectID": "chapter33.html#zacharys-karate-club",
    "href": "chapter33.html#zacharys-karate-club",
    "title": "33  ネットワーク解析",
    "section": "33.4 Zachary’s karate club",
    "text": "33.4 Zachary’s karate club\n上記のlayoutでは、karate &lt;- make_graph(\"Zachary\")という形でigraphに登録されているネットワークである、\"Zachary\"を読み込んで利用しています。make_graph関数では、igraphに登録されているネットワーク（Notable graphs）を文字列で指定することで、igraphに保存されているネットワークを呼び出すことができます。\nこれらのネットワークの中でも有名なものの一つが上記のZachary’s karate clubです。この空手クラブのデータはZachary et al. (1976)(Zachary 1976)で人類学的な解析に用いられたもので、アメリカの大学の空手クラブにおけるメンバー間の交友関係をネットワークとしたものです。この空手クラブ、1番と34番のメンバーを中心とした2つのグループに別れたことで有名で、ネットワークについての教科書などで頻出するデータとなっています。\n以下のネットワーク図はメンバーが分離した後の2グループを色で示したものになっています。次に説明する中心性の評価、クラスターの評価にはこのデータを用います。\n\n\n\nZachary`s karate club\n\nkarate &lt;- make_graph(\"Zachary\")\n\n# 2つに分離した後のグループ\nkarate_col &lt;- \n  c(\"A\", \"A\", \"A\", \"A\", \"A\", \n    \"A\", \"A\", \"A\", \"A\", \"B\", \n    \"A\", \"A\", \"A\", \"A\", \"B\", \n    \"B\", \"A\", \"A\", \"B\", \"A\", \n    \"B\", \"A\", \"B\", \"B\", \"B\",\n    \"B\", \"B\", \"B\", \"B\", \"B\", \n    \"B\", \"B\", \"B\", \"B\")\n\nset.seed(1)\nplot(\n  karate, \n  vertex.color=\n    if_else(\n      karate_col == \"A\", \n      \"lightblue\", \n      \"orange\"), \n  vertex.size = 25)\n\n\n\n\n\n\n\n\n\n\n33.4.1 中心性\n上記の通り、Zachary’s karate clubのネットワークは1と34のメンバーを中心に2つのグループに分離しました。上のネットワーク図を見ると、確かに1と34にはたくさんのedgeが接続しているように見えます。しかし、実際に1と34がネットワークで中心的な役割があるのかと言われると、グラフだけを見ていてもいまいちよくわかりません。\nネットワークで中心的でかつ重要なvertexを抽出するための手法の一つが、中心性（centrality）の評価です。ネットワーク解析でよく用いられる中心性は以下の4種類です。\n\n次数中心性（degree centrality）\n媒介中心性（betweenness centrality）\n近接中心性（closeness centrality）\n固有ベクトル中心性（eigenvector centrality）\n\n次数中心性は最も単純な中心性で、そのvertexに接続しているedgeの数を表します。igraphではdegree関数で次数中心性を計算することができます。\n媒介中心性はそのvertexが他のvertexの間に存在する頻度を表したものです。igraphではbetweenness関数で媒介中心性を計算することができます。\n近接中心性はそのvertexから他のvertexまでの距離の和を反映したもので、igraphではcloseness関数で近接中心性を計算することができます。\n固有ベクトル中心性は隣接行列から演算できる中心性の指標です。igraphではeigen_centrality関数で固有ベクトル中心性を計算することができます。\nこの他にも様々な中心性の指標はありますが、とりあえずこの4つを比較するとある程度は中心的なvertexを特定することができるでしょう。以下はkarate clubのネットワークでのvertexの中心性を評価したものです。いずれの中心性でも、1と34が高い値を示しており、この2人が重要なvertexであったことがわかります。\n\n\n\n中心性の演算\n\n# 次数中心性\ndegree(karate)\n##  [1] 16  9 10  6  3  4  4  4  5  2  3  1  2  5  2  2  2  2  2  3  2  2  2  5  3\n## [26]  3  2  4  3  4  4  6 12 17\n\n# 媒介中心性\nbetweenness(karate)\n##  [1] 231.0714286  28.4785714  75.8507937   6.2880952   0.3333333  15.8333333\n##  [7]  15.8333333   0.0000000  29.5293651   0.4476190   0.3333333   0.0000000\n## [13]   0.0000000  24.2158730   0.0000000   0.0000000   0.0000000   0.0000000\n## [19]   0.0000000  17.1468254   0.0000000   0.0000000   0.0000000   9.3000000\n## [25]   1.1666667   2.0277778   0.0000000  11.7920635   0.9476190   1.5428571\n## [31]   7.6095238  73.0095238  76.6904762 160.5515873\n\n# 近接中心性\ncloseness(karate)\n##  [1] 0.01724138 0.01470588 0.01694915 0.01408451 0.01149425 0.01162791\n##  [7] 0.01162791 0.01333333 0.01562500 0.01315789 0.01149425 0.01111111\n## [13] 0.01123596 0.01562500 0.01123596 0.01123596 0.00862069 0.01136364\n## [19] 0.01123596 0.01515152 0.01123596 0.01136364 0.01123596 0.01190476\n## [25] 0.01136364 0.01136364 0.01098901 0.01388889 0.01369863 0.01162791\n## [31] 0.01388889 0.01639344 0.01562500 0.01666667\n\n# 固有ベクトル中心性\neigen_centrality(karate)$vector\n##  [1] 0.95213237 0.71233514 0.84955420 0.56561431 0.20347148 0.21288383\n##  [7] 0.21288383 0.45789093 0.60906844 0.27499812 0.20347148 0.14156633\n## [13] 0.22566382 0.60657439 0.27159396 0.27159396 0.06330461 0.24747879\n## [19] 0.27159396 0.39616224 0.27159396 0.24747879 0.27159396 0.40207086\n## [25] 0.15280670 0.15857597 0.20242852 0.35749923 0.35107297 0.36147301\n## [31] 0.46806481 0.51165649 0.82665886 1.00000000\n\n# それぞれをプロットする\npar(mfrow = c(2, 2))\ndegree(karate) |&gt; plot()\ntitle(\"次数中心性\")\nbetweenness(karate) |&gt; plot()\ntitle(\"媒介中心性\")\ncloseness(karate) |&gt; plot()\ntitle(\"近接中心性\")\neigen_centrality(karate)$vector |&gt; plot()\ntitle(\"固有ベクトル中心性\")\n\n\n\n\n\n\n\n\n\n\n33.4.1.1 PageRank\n上記の中心性と似た中心性の評価基準として、PageRankがあります。PageRankはGoogleが検索エンジンにおいてホームページの順位付けをするのに用いた評価方法です。igraphではpage_rank関数でPageRankの演算を行うことができます。\n\n\n\nPageRankによるvertexの評価\n\npage_rank(karate)[[1]] |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\n33.4.1.2 Edge betweenness\nvertexの媒介性ではなく、edgeの媒介性、つまりvertexとvertexの経路の間にあるedgeを評価する方法がedge betweenness（辺の媒介性）です。edge betweennessが高い辺が切れてしまった場合には、ネットワークが大きく分断されることになります。以下の通り、karate clubでは1と32の間のedge betweennessが高く、ココが切れるとネットワークが2つに分離しやすくなります。\n\n\n\nedge betweenness\n\n# edge betweennessを演算\nedge_betweenness(karate)\n##  [1] 14.166667 43.638889 11.500000 29.333333 43.833333 43.833333 12.802381\n##  [8] 41.648413 29.333333 33.000000 26.100000 23.770635 22.509524 25.770635\n## [15] 22.509524 71.392857 13.033333  4.333333  4.164286  6.959524 10.490476\n## [22]  8.209524 10.490476 18.109524 12.583333 14.145238 23.108730 12.780952\n## [29] 38.701587 17.280952  5.147619  4.280952  1.888095  6.900000  8.371429\n## [36]  2.666667  1.666667  1.666667  2.666667 16.500000 16.500000  5.500000\n## [43] 17.077778 22.684921 16.614286 38.049206 13.511111 19.488889 13.511111\n## [50] 19.488889 13.511111 19.488889 33.313492 13.511111 19.488889 13.511111\n## [57] 19.488889 11.094444  5.911111 12.533333 18.327778  3.733333  2.366667\n## [64] 10.466667 22.500000 23.594444  2.542857 30.457143 17.097619  8.333333\n## [71] 13.780952 13.087302 16.722222  9.566667 15.042857 23.244444 29.953968\n## [78]  4.614286\nedge &lt;- karate |&gt; as_edgelist() |&gt; as.data.frame()\n\n# Edge betweennessをグラフで表示\ndata.frame(edge , betweenness = edge_betweenness(karate)) |&gt; \n  mutate(edge = paste0(V1, \"-\", V2)) |&gt; \n  ggplot(aes(x = edge, y = betweenness))+\n  geom_point(size = 3)+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n\n33.4.2 ネットワークのクラスター（コミュニティ）\nネットワーク解析の目的の一つは、ネットワーク上のクラスター（コミュニティ）を明らかにすることです。karate clubの例であれば、2つのクラスターが存在することがあらかじめ分かっていれば、グループが割れないように対策することができたかもしれません。\n28章で説明したようにクラスター解析には様々な方法があります。同じように、ネットワーク解析におけるクラスター解析にも様々なものがあります。igraphに登録されているクラスター解析だけで10種以上あります。どれがいいのかは時と場合によりますが、いずれもigraphでは名前がcluster_から始まる一連の関数で演算することができます。\n以下にigraphが備えているクラスター解析とkarate clubの分離後の2グループを比較したものを示します（一番左のkarateが分離後のグループ）。グラフで左側に示したものほどkarateとの一致度が高くなっています。それぞれの関数には解析方法を調整するための引数が多数準備されているので、うまく調整することでより精度の高いクラスター解析を行うこともできます。したがって、必ずしも以下の例のようにcluster_fluid_communitiesが優れているというわけではありません。時と場合により手法を使い分けるのが良いでしょう。\n\n\n\nネットワークのクラスターの演算\n\n# クラスターを計算\nkarate_clus &lt;- data.frame(\n  vertex = as.character(1:34) |&gt; factor(levels=1:34),\n  karate = if_else(karate_col == \"A\", 1, 2),\n  edge_betweenness = cluster_edge_betweenness(karate)$membership,\n  fast_greedy = cluster_fast_greedy(karate)$membership,\n  fluid_communities = cluster_fluid_communities(karate, no.of.communities = 2)$membership,\n  infomap = cluster_infomap(karate)$membership,\n  label_prop = cluster_label_prop(karate)$membership,\n  leading_eigen = cluster_leading_eigen(karate)$membership,\n  optimal = cluster_optimal(karate)$membership,\n  spinglass = cluster_spinglass(karate)$membership,\n  walktrap = cluster_walktrap(karate)$membership\n) \n\n# 同一クラスターのvertexを同じ色で表示する\nkarate_clus|&gt; \n  pivot_longer(2:11, names_to = \"type\", values_to = \"cluster\") |&gt; \n  mutate( # 見やすいように順番を入れ替え\n    type = \n      fct_relevel(\n        type, \n        c(\n          \"karate\", \n          \"fluid_communities\", \n          \"fast_greedy\", \n          \"leading_eigen\", \n          \"edge_betweenness\", \n          \"walktrap\", \"infomap\", \n          \"label_prop\", \n          \"optimal\", \n          \"spinglass\"))) |&gt; \n  ggplot(aes(x = type, y = vertex, color = factor(cluster), fill = factor(cluster))) +\n  geom_tile()+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n33.4.2.1 クリーク（cliques）\n類似の解析方法として、クリーク（cliques、小集団）という、サブグループを見つけるための解析方法もあります。こちらはすべてのvertexをクラスターに所属させるようなものではなく、内部に存在する小集団（例えば、会社の一部署のメンバーなど）を求める手法となっています。clique_num関数はクリークに含まれる最大のvertex数を返す関数です。このclique_numの返り値をcliques関数のmin引数に取ることで、クリークを比較的簡単に見つけることができます。下の例では、5人のクリークを2つ検出しています。\n\n\n\nクリーク（clique）の演算\n\nclique_num(karate)\n## [1] 5\ncliques(karate, min = 5)\n## [[1]]\n## + 5/34 vertices, from 68db58a:\n## [1]  1  2  3  4 14\n## \n## [[2]]\n## + 5/34 vertices, from 68db58a:\n## [1] 1 2 3 4 8\n\n\n\n\n\n33.4.3 ネットワークの特徴を評価する\n\n33.4.3.1 edgeの密度（edge density）\nネットワーク解析では、ネットワーク全体を評価することもあります。代表的な特徴として、ネットワークの密度（edge density）があります。密度とは、現在のedgeの数の、そのvertex数で実現可能な最大のedgeの数に対する割合を指します。karateの例では、edgeの数は78ですが、34人のネットワークですべての人がedgeでつながっている場合、つまりedgeの最大数はsum(33:1)、つまり561となります。この78と561の比、78/561がedge densityとなります。\nigraphではedge densityをedge_density関数で演算することができます。\n\n\n\nedgeの密度（edge density）\n\nedge_density(karate) # edgeの密度\n## [1] 0.1390374\nE(karate) # 78 edge\n## + 78/78 edges from 68db58a:\n##  [1]  1-- 2  1-- 3  1-- 4  1-- 5  1-- 6  1-- 7  1-- 8  1-- 9  1--11  1--12\n## [11]  1--13  1--14  1--18  1--20  1--22  1--32  2-- 3  2-- 4  2-- 8  2--14\n## [21]  2--18  2--20  2--22  2--31  3-- 4  3-- 8  3--28  3--29  3--33  3--10\n## [31]  3-- 9  3--14  4-- 8  4--13  4--14  5-- 7  5--11  6-- 7  6--11  6--17\n## [41]  7--17  9--31  9--33  9--34 10--34 14--34 15--33 15--34 16--33 16--34\n## [51] 19--33 19--34 20--34 21--33 21--34 23--33 23--34 24--26 24--28 24--33\n## [61] 24--34 24--30 25--26 25--28 25--32 26--32 27--30 27--34 28--34 29--32\n## [71] 29--34 30--33 30--34 31--33 31--34 32--33 32--34 33--34\nE(make_full_graph(n=34)) # full graph(すべてのvertexがedgeでつながっている場合)：561 edge\n## + 561/561 edges from 69a5f9c:\n##   [1] 1-- 2 1-- 3 1-- 4 1-- 5 1-- 6 1-- 7 1-- 8 1-- 9 1--10 1--11 1--12 1--13\n##  [13] 1--14 1--15 1--16 1--17 1--18 1--19 1--20 1--21 1--22 1--23 1--24 1--25\n##  [25] 1--26 1--27 1--28 1--29 1--30 1--31 1--32 1--33 1--34 2-- 3 2-- 4 2-- 5\n##  [37] 2-- 6 2-- 7 2-- 8 2-- 9 2--10 2--11 2--12 2--13 2--14 2--15 2--16 2--17\n##  [49] 2--18 2--19 2--20 2--21 2--22 2--23 2--24 2--25 2--26 2--27 2--28 2--29\n##  [61] 2--30 2--31 2--32 2--33 2--34 3-- 4 3-- 5 3-- 6 3-- 7 3-- 8 3-- 9 3--10\n##  [73] 3--11 3--12 3--13 3--14 3--15 3--16 3--17 3--18 3--19 3--20 3--21 3--22\n##  [85] 3--23 3--24 3--25 3--26 3--27 3--28 3--29 3--30 3--31 3--32 3--33 3--34\n##  [97] 4-- 5 4-- 6 4-- 7 4-- 8 4-- 9 4--10 4--11 4--12 4--13 4--14 4--15 4--16\n## [109] 4--17 4--18 4--19 4--20 4--21 4--22 4--23 4--24 4--25 4--26 4--27 4--28\n## + ... omitted several edges\n\n78 / 561 # edge_densityの結果と同じ\n## [1] 0.1390374\n\n\n\n\n33.4.3.2 次数の分布\n次数（degree）、つまりそれぞれのvertexから出ているedgeの数もネットワークの構造を反映するパラメータとなります。次数をヒストグラムとして表示すれば、edgeの分布やその偏りを図示することができます。igraphでは、degree_distribution関数で次数の頻度を計算することができます。また、この関数の返り値をhist関数の引数とすることで、次数のヒストグラムを表示することができます。\n\n\n\n次数の分布\n\ndegree_distribution(karate) |&gt; hist() # 次数の分布\n\n\n\n\n\n\n\n\n\n\n\n33.4.3.3 その他の評価尺度：vertexの距離・ネットワークの直径\n上記のedgeの密度や次数の分布に加えて、vertex間の平均距離や距離の分布、ネットワークの直径もネットワークの性質を表すパラメータとして用いられています。vertex間の距離の分布はdistance_table関数で、ネットワークの直径はgirth関数で計算することができます。\n\nmean_distance(karate) # vertex間の平均距離\n## [1] 2.4082\ndistance_table(karate) # vertex間の距離の要約\n## $res\n## [1]  78 265 137  73   8\n## \n## $unconnected\n## [1] 0\ngirth(karate) # ネットワークの直径\n## $girth\n## [1] 3\n## \n## $circle\n## + 3/34 vertices, from 68db58a:\n## [1] 2 1 3\n\n\n\n\n33.4.4 経路を探索する\nネットワーク解析では、上記のような中心性やクラスター以外に、vertexからvertexまでの経路を探索することも目的となります。karate clubでは経路を調べる意味はあまりありませんが、例えば鉄道の路線図や飛行機の航路であれば、最短経路や複数の経路を求める必要があるでしょう。\n経路の探索の例として、路線図のデータを利用します。以下は奈良の鉄道（近鉄・JR）の路線のネットワーク（路線図）です。この路線図を利用して経路の探索を説明します。\n\n\n\n奈良の路線図\n\n# 駅同士の接続（d）と駅（vt）のデータを読み込む\nd &lt;- read.csv(\"./data/chapter33_nara_stations.csv\")\nvt &lt;- read.csv(\"./data/chapter33_nara_stations_vertex_list.csv\")\n\n# dとvtからネットワークを作成\nnara_stations &lt;- graph_from_data_frame(d, vertices = vt, directed = FALSE)\n\n# ネットワークの表示\nnara_stations\n## IGRAPH 69c23d3 UN-- 119 120 -- \n## + attr: name (v/c), lat (v/n), lon (v/n), linename (v/c), company\n## | (v/c), linename (e/c), company (e/c)\n## + edges from 69c23d3 (vertex names):\n##  [1] 奈良    --京終     京終    --帯解     帯解    --櫟本     櫟本    --天理    \n##  [5] 天理    --長柄     長柄    --柳本     柳本    --巻向     巻向    --三輪    \n##  [9] 三輪    --桜井     桜井    --香久山   香久山  --畝傍     金橋    --高田    \n## [13] 王寺    --畠田     畠田    --志都美   志都美  --香芝     香芝    --JR五位堂\n## [17] JR五位堂--高田     高田    --大和新庄 大和新庄--御所     御所    --玉手    \n## [21] 玉手    --掖上     掖上    --吉野口   吉野口  --北宇智   北宇智  --五条    \n## [25] 五条    --大和二見 王寺    --三郷     王寺    --法隆寺   法隆寺  --大和小泉\n## + ... omitted several edges\n\n# ネットワークを図にする\nplot(\n  nara_stations, \n  curved = TRUE, \n  layout = cbind(V(nara_stations)$lon, V(nara_stations)$lat), \n  vertex.label = NA, \n  vertex.size = 4)\n\n\n\n\n\n\n\n\n\n\n33.4.4.1 vertex間の距離行列\nvertex間の距離は行列の形で、distances関数を用いることで求めることができます。到達可能性が無いvertexとの間の距離は無限大（Inf）となります。distances関数には到着点（to引数）を設定することができます。\n奈良の鉄道路線の例であれば、田原本線は独立線になっている（王寺-新王寺、西田原本-田原本間は路線としては接続しておらず、別の駅）ので、奈良へは到達不可能（Inf）になっています。\n\n\n\nvertex間の距離を調べる\n\ndistances(nara_stations)[1:5, 1:5]\n##      奈良 京終 帯解 櫟本 天理\n## 奈良    0    1    2    3    4\n## 京終    1    0    1    2    3\n## 帯解    2    1    0    1    2\n## 櫟本    3    2    1    0    1\n## 天理    4    3    2    1    0\ndistances(nara_stations, to=\"奈良\")[40:50,]\n##   信貴山下     新王寺     大輪田   佐味田川       池部       箸尾       但馬 \n##          5        Inf        Inf        Inf        Inf        Inf        Inf \n##       黒田     高の原       平城 大和西大寺 \n##        Inf         15         14         13\n\n\n\n\n33.4.4.2 最短距離の探索\n最短距離の探索には、shortest_paths関数、all_shortest_paths関数を用います。shortest_paths関数は最短距離を1つだけ、all_shortest_paths関数はすべての最短距離を返します。路線ではなかなか最短距離が複数存在する場合はありませんので、下の例ではall_shortest_pathsは一つの経路を返しています。\n\n\n\n最短距離の探索\n\nshortest_paths(nara_stations, from = \"奈良\", to = \"吉野口\")\n## $vpath\n## $vpath[[1]]\n## + 15/119 vertices, named, from 69c23d3:\n##  [1] 奈良     郡山     大和小泉 法隆寺   王寺     畠田     志都美   香芝    \n##  [9] JR五位堂 高田     大和新庄 御所     玉手     掖上     吉野口  \n## \n## \n## $epath\n## NULL\n## \n## $predecessors\n## NULL\n## \n## $inbound_edges\n## NULL\nall_shortest_paths(nara_stations, from = \"桜井\", to = \"吉野口\")\n## $vpaths\n## $vpaths[[1]]\n## + 13/119 vertices, named, from 69c23d3:\n##  [1] 桜井       大福       耳成       大和八木   八木西口   畝傍御陵前\n##  [7] 橿原神宮前 岡寺       飛鳥       壺阪山     市尾       葛        \n## [13] 吉野口    \n## \n## \n## $epaths\n## $epaths[[1]]\n##  [1] 112 111 110  65  66  67  77  78  79  80  81  82\n## \n## \n## $nrgeo\n##   [1] 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0\n##  [38] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 2 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1\n##  [75] 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n## [112] 1 0 1 0 0 0 0 1\n## \n## $res\n## $res[[1]]\n## + 13/119 vertices, named, from 69c23d3:\n##  [1] 桜井       大福       耳成       大和八木   八木西口   畝傍御陵前\n##  [7] 橿原神宮前 岡寺       飛鳥       壺阪山     市尾       葛        \n## [13] 吉野口\n\n\n距離行列・最短距離の探索には、幅優先探索（breadth-first search）や深さ優先探索（depth-first search）などのアルゴリズムが用いられています。また、edgeの特性にweightを設定していた場合には、weightを考慮した評価を行うこともできます。\n\n\n\n33.4.5 その他の分析について\nネットワーク解析には、上記に示した解析方法に加えて、ランダムなグラフの作成、グラフの類似性や検定を用いたネットワーク解析などがあります。\nigraphではランダムなグラフの作成には関数名がsample_から始まる一連の関数が、一定の構造を持つグラフの作成にはmake_ringやmake_star関数などの関数が備わっています。ランダムなグラフの作成では、それぞれの関数に設定されたアルゴリズムに従いネットワークが作成されます。また、make_関数でのグラフ作成では、一定の構造を持つグラフが作成されるため、グラフ作成時の基礎構造を準備するのに便利です。\n\n\n\nランダム・一定の構造を持つグラフの作成\n\ng &lt;- sample_tree(n = 30) # ランダムな木構造型ネットワークを作成\nplot(g, layout=layout_as_tree(g))\n\n\n\n\n\n\n\n\n\nとは言ってもigraphに登録されているsample_関数だけでも10種以上あり、それぞれのアルゴリズムも複雑です。また、グラフの類似性や検定を用いたネットワーク解析に関してはigraphのみでは対応できず、別のライブラリ（statnet、sna）が必要となります。上記のネットワーク解析に関しても詳細な説明は加えていませんので、詳細を理解したい方は教科書（Rで学ぶデータサイエンス ネットワーク分析）を一読されることをおすすめいたします。\n以下にsample_とmake_関数の一覧を示します。\n\nsample_bipartitesample_gnpsample_correlated_gnpsample_degseqsample_dot_productsample_fitnesssample_fitness_plsample_gnmsample_grgsample_growingsample_islandssample_k_regularsample_last_citsample_pasample_pa_agesample_prefsample_sbmsample_smallworldsample_traits_callawaysample_tree\n\n\n\n# ランダムな2部グラフを作成する\nsample_bipartite(10, 10, p = 0.3) |&gt; plot(layout = layout_as_bipartite) # pはedgeの頻度\n\n\n\n\n\n\n\n\n\n\n\ngr &lt;- sample_gnp(20, p = 0.3) # Erdos-Renyi modelに従い作成（20はvertex数、pはedgeの頻度）\ngr |&gt; plot() \n\n\n\n\n\n\n\n\n\n\n\ngr |&gt;  sample_correlated_gnp(corr = 0.2) |&gt; plot() # edgeをランダムに付け加え・取り除く\n\n\n\n\n\n\n\n\n\n\n\nsample_degseq(rep(4, 10)) |&gt; plot() # nodeのdegree（次数、この例では4）を指定したグラフ\n\n\n\n\n\n\n\n\n\n\n\nma &lt;- matrix(runif(90, 0, 0.5), nrow = 9) # matrixを引数に取る\nsample_dot_product(ma) |&gt; plot() # 各列がvertexになる\n\n\n\n\n\n\n\n\n\n\n\nsample_fitness(10, runif(10, 0.1, 0.5)) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\nsample_fitness_pl(10, 15, exponent.out = 2.5) |&gt; plot() # vertexの数、edgeの数、degreeの分布を指定する引数\n\n\n\n\n\n\n\n\n\n\n\nsample_gnm(10, 15) |&gt; plot() # vertexの数、nodeの数を指定\n\n\n\n\n\n\n\n\n\n\n\nsample_grg(10, 0.85) |&gt; plot() # vertexの数、radiusを指定\n\n\n\n\n\n\n\n\n\n\n\nsample_growing(10, m = 3) |&gt; plot() # vertexの数、ランダムに追加するedgeの数\n\n\n\n\n\n\n\n\n\n\n\nsample_islands(5, 3, 0.3, 5) |&gt; plot() # gnpでのvertex3つのグラフを5つつないだもの\n\n\n\n\n\n\n\n\n\n\n\nsample_k_regular(10, 3) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\nsample_last_cit(10, agebins = 5) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\nsample_pa(10) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\nsample_pa_age(10, 3, -0.5) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\nsample_pref(30, 10) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\nsample_sbm(10, pref.matrix = matrix(runif(9, 0.1, 0.3), nrow=3), block.sizes = c(3, 3, 4), directed = TRUE) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\nsample_smallworld(dim = 2, size = 5, nei = 1, p = 0.2) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\nsample_traits_callaway(10, types = 3, edge.per.step = 3) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\ng_tree &lt;- sample_tree(20)\ng_tree |&gt; plot(layout = layout_as_tree(g_tree))\n\n\n\n\n\n\n\n\n\n\n\n\nmake_starmake_ringmake_chordal_ringmake_empty_graphmake_full_graphmake_latticemake_tree\n\n\n\nmake_star(n = 10, mode = \"undirected\") |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\nmake_ring(n = 10) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\nmake_chordal_ring(12, w = matrix(c(2, 4, 6, 8, 10, 12), nrow = 2)) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\nmake_empty_graph(10) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\nmake_full_graph(10) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\nmake_lattice(c(3, 3, 3)) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\nmake_tree(16) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n33.4.6 2部グラフ\n2部グラフ（Bipartite graph）とは、vertexが2つのタイプからなるグラフのことです。この2つのタイプとは、例えば人物と所属するクラブのような、互いに関係性はあるけれども同じタイプ同士のvertex間のつながりは無視できるようなものになります。\n以下に2部グラフの例を示します。2部グラフを作成する場合、専用の関数（make_bipartite_graph）がありますが、この関数を用いるよりはedge listやdata.frameからグラフを作成した後、vertexのtypeというattributeに論理型で2部のどちらであるか（上の例では人物をTRUE、所属するクラブをFALSEで指定）を指定する方が作成しやすいと思います。\n\n\n\n2部グラフ\n\nset.seed(0)\n# edgeを示したデータフレームを作成する\nd_edge &lt;- data.frame(\n  club = sample(c(\"野球\", \"サッカー\", \"バスケットボール\", \"バレーボール\"), 52, replace = TRUE),\n  person = c(LETTERS, LETTERS)\n) |&gt; distinct()\n\n# データフレームから2部グラフを作成する\ng &lt;- graph_from_data_frame(d_edge, directed = F)\n\n# typeのattributeを追加する（TRUE、FALSEで2部のどちらであるかを指定する）\nV(g)$type &lt;- V(g)$name %in% d_edge[,2]\nV(g)$type\n##  [1] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n## [13]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n## [25]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n\n# 2部グラフ（UN-B、BがBipartiteの意味）になっている\ng\n## IGRAPH 6ab4cd3 UN-B 30 48 -- \n## + attr: name (v/c), type (v/l)\n## + edges from 6ab4cd3 (vertex names):\n##  [1] サッカー        --A 野球            --B バレーボール    --C\n##  [4] バスケットボール--D 野球            --E サッカー        --F\n##  [7] 野球            --G バスケットボール--H バスケットボール--I\n## [10] サッカー        --J サッカー        --K バスケットボール--L\n## [13] バスケットボール--M 野球            --N 野球            --O\n## [16] 野球            --P サッカー        --Q サッカー        --R\n## [19] サッカー        --S サッカー        --T バスケットボール--U\n## [22] 野球            --V バスケットボール--W 野球            --X\n## + ... omitted several edges\n\ng |&gt; plot(layout = layout_as_bipartite, vertex.color = c(\"orange\", \"lightblue\")[V(g)$type + 1], vertex.shape = c(\"square\", \"circle\")[V(g)$type + 1])",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>ネットワーク解析</span>"
    ]
  },
  {
    "objectID": "chapter33.html#tidygraph",
    "href": "chapter33.html#tidygraph",
    "title": "33  ネットワーク解析",
    "section": "33.5 tidygraph",
    "text": "33.5 tidygraph\nここまで説明してきたigraphは非常に多機能でよくできたパッケージではありますが、関数名や引数名があまり一定ではなく、使用する際に関数名や引数名をチェックしないとうまく使うことができません。引数の指定方法も多岐に渡っており、統一した手法でグラフを取り扱うことができず、使いにくさがあります。\nこのような問題を解決するためのライブラリがtidygraphパッケージです。tidygraphパッケージは基本的にtibbleを用いてグラフを作成し、tidyverse（特にdplyr）とパイプ演算子を用いてグラフを編集することを目的として構成されています。\nとは言え、igraphが非常に機能豊富なパッケージであったのと同様に、tidygraphも機能豊富で、利用の難易度は高めです。また、解説文等が少ないため、使い方を理解するのが難しい関数もあります。dplyr::mutate関数内以外では使えない関数がたくさんあるなど、使い方もやや複雑です。\n\n33.5.1 tidygraphの基礎とグラフの作成\ntidygraphではグラフはnodeとedgeで表されます。igraphとは異なり、nodeがvertexと呼ばれることはありません。\ntidygraphでは、igraphと同じく、データフレームからグラフを作成します。また、igraphで作成したグラフオブジェクトやedge vector、adjacency matrixからもグラフを作成することができます。データフレームからグラフを作成する場合にはtbl_graph関数、その他のオブジェクトやigraphのグラフからtidygraphのグラフを作成する場合にはas_tbl_graph関数を用います。\n作成したグラフのクラスはigraphとtbl_graphとなっており、表示するとnodeとedgeのデータフレームが示されます。igraphではvertexに指定するデータフレームの2列目以降、edgeに指定するデータフレームの3列目以降はattributeとして登録されますが、tbl_graphではnodeとedgeのtibbleとして表示されます。tbl_graphはigraphのオブジェクトでもあるので、igraphと同じようにattributesとしてtibbleの列を呼び出すこともできます。\n\n\n\ntbl_graphを作成する\n\npacman::p_load(tidygraph)\n\nd &lt;- read.csv(\"./data/chapter33_nara_stations.csv\") # edgeのデータフレーム\nvt &lt;- read.csv(\"./data/chapter33_nara_stations_vertex_list.csv\") # nodeのデータフレーム\n\ncolnames(vt) &lt;- c(\"name\", \"lat\", \"lon\", \"linename\", \"company\") # vertex名はname列から取り込まれる\ncolnames(d) &lt;- c(\"from\", \"to\", \"linename\", \"company\") # edgeはfrom→toになる\n\n# tbl_graphをデータフレームから作成する\ng &lt;- tbl_graph(nodes = vt, edges = d, directed = FALSE) \n\n# igraphオブジェクトをtbl_graphに変換する\nas_tbl_graph(karate)\n## # A tbl_graph: 34 nodes and 78 edges\n## #\n## # An undirected simple graph with 1 component\n## #\n## # Node Data: 34 × 0 (active)\n## #\n## # Edge Data: 78 × 2\n##    from    to\n##   &lt;int&gt; &lt;int&gt;\n## 1     1     2\n## 2     1     3\n## 3     1     4\n## # ℹ 75 more rows\n\nclass(g) # クラスはtbl_graph\n## [1] \"tbl_graph\" \"igraph\"\nV(g)$lat # igraphとして取り扱い、attributeとして2列目以降を呼び出すこともできる\n##   [1] 34.68078 34.66998 34.64340 34.62101 34.60120 34.57420 34.55911 34.54543\n##   [9] 34.52719 34.51347 34.51078 34.50962 34.59772 34.57763 34.56155 34.54335\n##  [17] 34.52765 34.51627 34.48867 34.46466 34.45834 34.45236 34.42085 34.38266\n##  [25] 34.35572 34.58930 34.60150 34.62228 34.64797 34.69332 34.68555 34.67593\n##  [33] 34.66550 34.65655 34.64814 34.64007 34.62917 34.61748 34.60600 34.60099\n##  [41] 34.59775 34.58913 34.58517 34.57857 34.57032 34.56935 34.56830 34.72374\n##  [49] 34.70172 34.69391 34.68151 34.67054 34.65923 34.64620 34.62042 34.60662\n##  [57] 34.59827 34.58458 34.57194 34.55330 34.54179 34.52551 34.51320 34.50925\n##  [65] 34.49337 34.53911 34.53162 34.51647 34.51115 34.50855 34.50694 34.49796\n##  [73] 34.49332 34.48612 34.48344 34.47411 34.46487 34.44984 34.44186 34.43160\n##  [81] 34.40729 34.39511 34.38841 34.38366 34.38612 34.39027 34.39549 34.39022\n##  [89] 34.48940 34.47598 34.69171 34.69411 34.69694 34.69816 34.68543 34.55387\n##  [97] 34.54635 34.54144 34.53485 34.52618 34.51961 34.52069 34.51978 34.51253\n## [105] 34.51292 34.51614 34.52662 34.52975 34.56603 34.60225 34.60100 34.50834\n## [113] 34.34589 34.71070 34.55366 34.37661 34.46474 34.68436 34.57828\n\n\n\n\n33.5.2 node/edgeをactivateする\nigraphではnode（vertex）やedgeを呼び出す場合、V関数とE関数を用いますが、tidygraphではnode・edgeの呼び出しにactivate関数を用います。activate関数はパイプ演算子を用いて呼び出すことが想定されている関数で、パイプ演算子でつないでグラフに適用します。第2引数としてnodesとedgesを用います。activate関数をグラフに適用すると、node・edgeのtibbleに「activate」と表示されます。この状態でさらにパイプ演算子をつなぐと、activateされている側のtibbleを編集することができます。\nnode・edgeのどちらがactiveであるかを調べる場合には、active関数を用います。\n\n\n\nactivate関数\n\n# node・edgeをactivateする\ng |&gt; active() # nodeがactiveになっている\n## [1] \"nodes\"\ng |&gt; activate(edges) # edgeをactiveにする（nodeはactiveではなくなる）\n## # A tbl_graph: 119 nodes and 120 edges\n## #\n## # An undirected simple graph with 2 components\n## #\n## # Edge Data: 120 × 4 (active)\n##     from    to linename       company\n##    &lt;int&gt; &lt;int&gt; &lt;chr&gt;          &lt;chr&gt;  \n##  1     1     2 万葉まほろば線 JR     \n##  2     2     3 万葉まほろば線 JR     \n##  3     3     4 万葉まほろば線 JR     \n##  4     4     5 万葉まほろば線 JR     \n##  5     5     6 万葉まほろば線 JR     \n##  6     6     7 万葉まほろば線 JR     \n##  7     7     8 万葉まほろば線 JR     \n##  8     8     9 万葉まほろば線 JR     \n##  9     9    10 万葉まほろば線 JR     \n## 10    10    11 万葉まほろば線 JR     \n## # ℹ 110 more rows\n## #\n## # Node Data: 119 × 5\n##   name    lat   lon linename       company\n##   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;  \n## 1 奈良   34.7  136. 万葉まほろば線 JR     \n## 2 京終   34.7  136. 万葉まほろば線 JR     \n## 3 帯解   34.6  136. 万葉まほろば線 JR     \n## # ℹ 116 more rows\ng |&gt; activate(edges) |&gt; active() # edgeがactiveになっている\n## [1] \"edges\"\n\n\n\n\n33.5.3 focus\ntidygraphでは、基本的にactivateでnode・edgeのいずれかを選択した後、mutateなどdplyrの関数を用いてグラフの要素であるtibbleを編集していきます。\nmutateなどで編集を行うために、行を選択するための関数がfocusです。focus関数の引数には論理型を用い、TRUEの行のみをdplyrの関数での編集の対象とすることができます。以下の例では、nodeのはじめの5行を選択し、その行だけをmutateでの演算の対象としています。\n\n\n\nfocusで行を選択して編集する\n\ng |&gt; \n  activate(nodes) |&gt; \n  focus(c(T, T, T, T, T, rep(F, 114))) |&gt; # 始めの5つのnodeにfocusする\n  mutate(lat = lat - 50) # 初めの5つのnodeのlatから50を引く\n## # A tbl_graph: 119 nodes and 120 edges\n## #\n## # An undirected simple graph with 2 components\n## #\n## # Focused on 5 nodes\n## # Node Data: 119 × 5 (active)\n##    name    lat   lon linename       company\n##    &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;  \n##  1 奈良  -15.3  136. 万葉まほろば線 JR     \n##  2 京終  -15.3  136. 万葉まほろば線 JR     \n##  3 帯解  -15.4  136. 万葉まほろば線 JR     \n##  4 櫟本  -15.4  136. 万葉まほろば線 JR     \n##  5 天理  -15.4  136. 万葉まほろば線 JR     \n##  6 長柄   34.6  136. 万葉まほろば線 JR     \n##  7 柳本   34.6  136. 万葉まほろば線 JR     \n##  8 巻向   34.5  136. 万葉まほろば線 JR     \n##  9 三輪   34.5  136. 万葉まほろば線 JR     \n## 10 桜井   34.5  136. 万葉まほろば線 JR     \n## # ℹ 109 more rows\n## #\n## # Edge Data: 120 × 4\n##    from    to linename       company\n##   &lt;int&gt; &lt;int&gt; &lt;chr&gt;          &lt;chr&gt;  \n## 1     1     2 万葉まほろば線 JR     \n## 2     2     3 万葉まほろば線 JR     \n## 3     3     4 万葉まほろば線 JR     \n## # ℹ 117 more rows\n\n\n\n\n33.5.4 morph・unmorphとcrystalise\n上記のigraphで説明したクラスター計算では、nodeを各クラスターに分離することができます。ただし、分離したクラスターごとに何らかの演算をしたい場合や、nodeのグループごとに演算を行いたい場合、igraphには簡単に計算する方法はありません。tidygraphでは、このようなグループごとの演算をmorph関数を用いて簡単に行うことができます。\nmorph関数はnode・edgeのtibbleを一時的に変換するための関数です。tidygraphの開発者（Dr.  Thomas Lin Pedersen、patchworkやgganimateの開発者）は、このmorph/unmorph/crystaliseをtidygraphの最も代表的な関数の一つだと考えているようで、使い方を理解すれば非常に便利な関数群です。\n以下の例ではgroup_infomap関数（igraphのcluster_infomap関数のwrapper）でnodeをクラスター分けし、morph関数内ではそのクラスター（group）に従いto_split関数でtibbleを一時的にnestしています（tidyr::nestに関しては16章を参照。複数の要素をtibbleの「セル」として設定する方法のこと）。\nnestしたtibbleに対してgraph_diameter関数（igraphのdiameter関数のwrapper）とcentrality_degree関数（igraphのdegree関数のwrapper）を適用することで、クラスターごとのネットワークの直径、nodeの中心性を演算して行に追加しています。ただし、このままではtibbleがnestされたままです。\nこのnestされたtibbleをもとに戻すのがunmorph関数です。unmorph関数を適用することで、nodeのtibbleのnestが解除される、つまりunnestされて元のグラフに戻ります。\nこのように、morph/unmorphを用いることで、node・edgeのグループごとの演算を簡単に行うことができます。morphでのグループ分けのための関数にはto_subgraph関数（dplyr::filterに近い演算を行うもの）やto_components関数などが準備されています。\n\n\n\nmorph・unmorph関数\n\n# サブグループ内での演算を行うときにはmorph/unmorphを用いる\n# morph内の関数はto_から始まる関数群を用いる\ng |&gt; \n  activate(nodes) |&gt; # nodeをactiveにして\n  mutate(group = group_infomap()) |&gt; # クラスターに分けて\n  morph(to_split, group) |&gt; # グループで一時的に分割・ネストして\n  mutate(\n    group_diameter = graph_diameter(), \n    centrality = centrality_degree()) |&gt; # グループごとに直径を計算して\n  unmorph() # morphをもとに戻す\n## Splitting by nodes\n## # A tbl_graph: 119 nodes and 120 edges\n## #\n## # An undirected simple graph with 2 components\n## #\n## # Node Data: 119 × 8 (active)\n##    name    lat   lon linename       company group group_diameter centrality\n##    &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;   &lt;int&gt;          &lt;dbl&gt;      &lt;dbl&gt;\n##  1 奈良   34.7  136. 万葉まほろば線 JR          2              5          3\n##  2 京終   34.7  136. 万葉まほろば線 JR          2              5          2\n##  3 帯解   34.6  136. 万葉まほろば線 JR          2              5          1\n##  4 櫟本   34.6  136. 万葉まほろば線 JR         11              4          1\n##  5 天理   34.6  136. 万葉まほろば線 JR         11              4          2\n##  6 長柄   34.6  136. 万葉まほろば線 JR          3              6          1\n##  7 柳本   34.6  136. 万葉まほろば線 JR          3              6          2\n##  8 巻向   34.5  136. 万葉まほろば線 JR          3              6          2\n##  9 三輪   34.5  136. 万葉まほろば線 JR          3              6          2\n## 10 桜井   34.5  136. 万葉まほろば線 JR          3              6          2\n## # ℹ 109 more rows\n## #\n## # Edge Data: 120 × 4\n##    from    to linename       company\n##   &lt;int&gt; &lt;int&gt; &lt;chr&gt;          &lt;chr&gt;  \n## 1     1     2 万葉まほろば線 JR     \n## 2     2     3 万葉まほろば線 JR     \n## 3     3     4 万葉まほろば線 JR     \n## # ℹ 117 more rows\n\n\nmorphで変形したグラフをそのまま固定するための関数がcrystallise関数です。crystallise関数を用いると、morphで指定した変形の状態などが固定され、tibbleとしてデータが返ってきます。\n\n\n\ncrystallise関数\n\ng |&gt; \n  mutate(group = group_infomap()) |&gt; # クラスターに分けて\n  morph(to_split, group) |&gt; # グループで一時的に分割して\n  crystallise() # crystalliseして固定してしまう\n## Splitting by nodes\n## # A tibble: 22 × 2\n##    name      graph     \n##    &lt;chr&gt;     &lt;list&gt;    \n##  1 group: 1  &lt;tbl_grph&gt;\n##  2 group: 2  &lt;tbl_grph&gt;\n##  3 group: 3  &lt;tbl_grph&gt;\n##  4 group: 4  &lt;tbl_grph&gt;\n##  5 group: 5  &lt;tbl_grph&gt;\n##  6 group: 6  &lt;tbl_grph&gt;\n##  7 group: 7  &lt;tbl_grph&gt;\n##  8 group: 8  &lt;tbl_grph&gt;\n##  9 group: 9  &lt;tbl_grph&gt;\n## 10 group: 10 &lt;tbl_grph&gt;\n## # ℹ 12 more rows\n\ng |&gt; \n  mutate(group = group_infomap()) |&gt; \n  morph(to_split, group) |&gt; \n  crystallise() |&gt; \n  class() # classからgraph関係のものがなくなり、tibbleになっている\n## Splitting by nodes\n## [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\n\n33.5.5 中心性\nigraphと同様に、tidygraphにも中心性を評価する関数群（centrality_から始まる関数）が設定されています。igraphとの違いは、これらのcentrality_関数群は単独で呼び出すことができず、nodeをactiveにした上でmutate関数の中で呼び出すような使い方をする点です。単独で使用するとエラーが返ってきます。\ntidygraphにはこのcentrality_関数が30個以上も設定されています（igraphの中心性演算の関数に加えて、netrankr(Schoch 2022)パッケージから方法を引用しています）。\n\n\n\n中心性：centrality_関数\n\ncentrality_degree(g) # 直接呼び出せない\n## Error in `private$check()`:\n## ! This function should not be called directly\n\n# nodeをactiveにしてからmutateで呼び出す\ng |&gt; \n  activate(nodes) |&gt; \n  mutate(degree_cent = centrality_degree()) \n## # A tbl_graph: 119 nodes and 120 edges\n## #\n## # An undirected simple graph with 2 components\n## #\n## # Node Data: 119 × 6 (active)\n##    name    lat   lon linename       company degree_cent\n##    &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;         &lt;dbl&gt;\n##  1 奈良   34.7  136. 万葉まほろば線 JR                3\n##  2 京終   34.7  136. 万葉まほろば線 JR                2\n##  3 帯解   34.6  136. 万葉まほろば線 JR                2\n##  4 櫟本   34.6  136. 万葉まほろば線 JR                2\n##  5 天理   34.6  136. 万葉まほろば線 JR                3\n##  6 長柄   34.6  136. 万葉まほろば線 JR                2\n##  7 柳本   34.6  136. 万葉まほろば線 JR                2\n##  8 巻向   34.5  136. 万葉まほろば線 JR                2\n##  9 三輪   34.5  136. 万葉まほろば線 JR                2\n## 10 桜井   34.5  136. 万葉まほろば線 JR                4\n## # ℹ 109 more rows\n## #\n## # Edge Data: 120 × 4\n##    from    to linename       company\n##   &lt;int&gt; &lt;int&gt; &lt;chr&gt;          &lt;chr&gt;  \n## 1     1     2 万葉まほろば線 JR     \n## 2     2     3 万葉まほろば線 JR     \n## 3     3     4 万葉まほろば線 JR     \n## # ℹ 117 more rows\n\n# 4種のcentralityを同時に演算する\ng |&gt; \n  activate(nodes) |&gt; \n  mutate(\n    cent_degr = centrality_degree(),\n    cent_betw = centrality_betweenness(),\n    cent_clos = centrality_closeness(),\n    cent_eigv = centrality_eigen()) \n## # A tbl_graph: 119 nodes and 120 edges\n## #\n## # An undirected simple graph with 2 components\n## #\n## # Node Data: 119 × 9 (active)\n##    name    lat   lon linename    company cent_degr cent_betw cent_clos cent_eigv\n##    &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n##  1 奈良   34.7  136. 万葉まほろ… JR              3      882   0.000728    0.0122\n##  2 京終   34.7  136. 万葉まほろ… JR              2      862   0.000741    0.0166\n##  3 帯解   34.6  136. 万葉まほろ… JR              2      887   0.000755    0.0272\n##  4 櫟本   34.6  136. 万葉まほろ… JR              2      914   0.000770    0.0480\n##  5 天理   34.6  136. 万葉まほろ… JR              3     1244.  0.000796    0.0866\n##  6 長柄   34.6  136. 万葉まほろ… JR              2      904.  0.000798    0.102 \n##  7 柳本   34.6  136. 万葉まほろ… JR              2      910.  0.000802    0.156 \n##  8 巻向   34.5  136. 万葉まほろ… JR              2      918.  0.000807    0.268 \n##  9 三輪   34.5  136. 万葉まほろ… JR              2      928.  0.000814    0.480 \n## 10 桜井   34.5  136. 万葉まほろ… JR              4     1340   0.000822    0.870 \n## # ℹ 109 more rows\n## #\n## # Edge Data: 120 × 4\n##    from    to linename       company\n##   &lt;int&gt; &lt;int&gt; &lt;chr&gt;          &lt;chr&gt;  \n## 1     1     2 万葉まほろば線 JR     \n## 2     2     3 万葉まほろば線 JR     \n## 3     3     4 万葉まほろば線 JR     \n## # ℹ 117 more rows\n\n\n\n\n33.5.6 node・edge・graphの評価\ntidygraphには、igraphと同様にnode、edge、graphを評価するための関数群が設定されています。いずれの関数も単独で呼び出すことはできず、mutate関数内で呼び出して用いることが前提とされています。\n以下にnodeの評価に関わる関数を示します。上記の中心性もこのnodeの評価に関わる関数の一部となります。\n\n\n\nnodeの評価\n\n# 単独では呼び出せない\nnode_efficiency(g)\n## Error in `private$check()`:\n## ! This function should not be called directly\n\ng |&gt; \n  activate(nodes) |&gt; \n  mutate(\n    node_eff = node_efficiency(), # nodeの効率（igraph::local_efficiency）\n    node_core = node_coreness(), # k-core分解（igraph::coreness）\n    node_clos = node_closeness_impact()) # nodeを取り除いたときのclosenessへの影響の大きさ\n## # A tbl_graph: 119 nodes and 120 edges\n## #\n## # An undirected simple graph with 2 components\n## #\n## # Node Data: 119 × 8 (active)\n##    name    lat   lon linename       company node_eff node_core node_clos\n##    &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n##  1 奈良   34.7  136. 万葉まほろば線 JR        0.0108         2     -60.3\n##  2 京終   34.7  136. 万葉まほろば線 JR        0.0323         2     -47.1\n##  3 帯解   34.6  136. 万葉まほろば線 JR        0.0323         2     -49.9\n##  4 櫟本   34.6  136. 万葉まほろば線 JR        0.0323         2     -54.4\n##  5 天理   34.6  136. 万葉まほろば線 JR        0.0417         2     -75.4\n##  6 長柄   34.6  136. 万葉まほろば線 JR        0.0625         2     -34.2\n##  7 柳本   34.6  136. 万葉まほろば線 JR        0.0625         2     -32.2\n##  8 巻向   34.5  136. 万葉まほろば線 JR        0.0625         2     -32.7\n##  9 三輪   34.5  136. 万葉まほろば線 JR        0.0625         2     -35.8\n## 10 桜井   34.5  136. 万葉まほろば線 JR        0.0104         2    -152. \n## # ℹ 109 more rows\n## #\n## # Edge Data: 120 × 4\n##    from    to linename       company\n##   &lt;int&gt; &lt;int&gt; &lt;chr&gt;          &lt;chr&gt;  \n## 1     1     2 万葉まほろば線 JR     \n## 2     2     3 万葉まほろば線 JR     \n## 3     3     4 万葉まほろば線 JR     \n## # ℹ 117 more rows\n\n\nedgeの評価では、edgeの性質を論理型で返すような関数が主に設定されています。edgeの評価に関する関数はそもそも引数にedgeのtibbleを取るように設定されていません。nodeの場合と同じく、edgeの評価の関数もmutate関数内で用いることが想定されています。\n\n\n\nedgeの評価\n\ng |&gt; \n  activate(edges) |&gt; \n  edge_is_multiple() # そもそも引数として設定できない\n## Error in edge_is_multiple(activate(g, edges)): unused argument (activate(g, edges))\n\ng |&gt; \n  activate(edges) |&gt; \n  mutate(\n    multiple = edge_is_multiple(), # 平行するedgeがあるか\n    bridge = edge_is_bridge() # edgeが切断されるとグラフが分離されるか\n  )\n## # A tbl_graph: 119 nodes and 120 edges\n## #\n## # An undirected simple graph with 2 components\n## #\n## # Edge Data: 120 × 6 (active)\n##     from    to linename       company multiple bridge\n##    &lt;int&gt; &lt;int&gt; &lt;chr&gt;          &lt;chr&gt;   &lt;lgl&gt;    &lt;lgl&gt; \n##  1     1     2 万葉まほろば線 JR      FALSE    FALSE \n##  2     2     3 万葉まほろば線 JR      FALSE    FALSE \n##  3     3     4 万葉まほろば線 JR      FALSE    FALSE \n##  4     4     5 万葉まほろば線 JR      FALSE    FALSE \n##  5     5     6 万葉まほろば線 JR      FALSE    FALSE \n##  6     6     7 万葉まほろば線 JR      FALSE    FALSE \n##  7     7     8 万葉まほろば線 JR      FALSE    FALSE \n##  8     8     9 万葉まほろば線 JR      FALSE    FALSE \n##  9     9    10 万葉まほろば線 JR      FALSE    FALSE \n## 10    10    11 万葉まほろば線 JR      FALSE    TRUE  \n## # ℹ 110 more rows\n## #\n## # Node Data: 119 × 5\n##   name    lat   lon linename       company\n##   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;  \n## 1 奈良   34.7  136. 万葉まほろば線 JR     \n## 2 京終   34.7  136. 万葉まほろば線 JR     \n## 3 帯解   34.6  136. 万葉まほろば線 JR     \n## # ℹ 116 more rows\n\n\ngraphの評価に関する関数はigraphに設定されている関数群とほぼ同じですが、やはり直接呼び出して用いることはできません。評価の意味に関しては以下を参照して下さい。\nGeekforGeeksのネットワークに関するページ\nグラフ理論講義ノート#8 井上純一先生（北海道大学 情報科学研究科）\n\n\n\ngraphの評価\n\ng |&gt; graph_diameter() # 直接呼び出せない\n## Error in `private$check()`:\n## ! This function should not be called directly\n\ng |&gt; \n  activate(nodes) |&gt; \n  mutate(\n    g_diameter = graph_diameter(), # グラフの直径（最大の経路長）\n    g_girth = graph_girth(), # グラフの内周（最小の閉路長）\n    g_radius = graph_radius(), # グラフの離心率（igraph::radius）\n    g_size = graph_size() # グラフのedgeの数\n  )\n## # A tbl_graph: 119 nodes and 120 edges\n## #\n## # An undirected simple graph with 2 components\n## #\n## # Node Data: 119 × 9 (active)\n##    name    lat   lon linename       company g_diameter g_girth g_radius g_size\n##    &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;        &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n##  1 奈良   34.7  136. 万葉まほろば線 JR              33      18        4    120\n##  2 京終   34.7  136. 万葉まほろば線 JR              33      18        4    120\n##  3 帯解   34.6  136. 万葉まほろば線 JR              33      18        4    120\n##  4 櫟本   34.6  136. 万葉まほろば線 JR              33      18        4    120\n##  5 天理   34.6  136. 万葉まほろば線 JR              33      18        4    120\n##  6 長柄   34.6  136. 万葉まほろば線 JR              33      18        4    120\n##  7 柳本   34.6  136. 万葉まほろば線 JR              33      18        4    120\n##  8 巻向   34.5  136. 万葉まほろば線 JR              33      18        4    120\n##  9 三輪   34.5  136. 万葉まほろば線 JR              33      18        4    120\n## 10 桜井   34.5  136. 万葉まほろば線 JR              33      18        4    120\n## # ℹ 109 more rows\n## #\n## # Edge Data: 120 × 4\n##    from    to linename       company\n##   &lt;int&gt; &lt;int&gt; &lt;chr&gt;          &lt;chr&gt;  \n## 1     1     2 万葉まほろば線 JR     \n## 2     2     3 万葉まほろば線 JR     \n## 3     3     4 万葉まほろば線 JR     \n## # ℹ 117 more rows\n\n\n\n\n33.5.7 create_関数とplay_関数\nigraphではmake_関数（make_ring関数やmake_star関数など）で形状を指定したグラフを、sample_関数（sample_tree関数やsample_gnp関数など）でアルゴリズムに従ったランダムなグラフを作成することができます。このigraphのmake_関数とsample_関数に当たるものがtidygraphのcreate_関数とplay_関数です。出力がtbl_graphであることと、引数の順序・名前以外にigraphの関数群と大きな差は無いので、igraphの関数に慣れているのであればigraphの関数を用いてグラフを作成した後でas_tbl_graph関数を用いてtbl_graphに変換してもよいでしょう。\n\ncreate_ringcreate_chordal_ringcreate_completecreate_emptycreate_treecreate_starplay_gnmplay_gnpplay_geometry\n\n\n\ncreate_ring(10) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\ncreate_chordal_ring(10, 2) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\ncreate_complete(10) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\ncreate_empty(10) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\ncreate_tree(10, 4) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\ncreate_star(10) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\nplay_gnm(10, 20) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\nplay_gnp(10, 0.25) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\nplay_geometry(10, 3) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n33.5.8 map_関数群\npurrrのmap関数と同様に、node、edgeのtibbleに関数を適用して演算を行う関数がmap_関数群です。\nmap_関数群には大きく分けるとbfs（breath first search）を演算に用いるもの（map_bfs_関数）と、dfs（depth first search）を用いるもの（map_dfs_関数）があります。\nmap_関数も単独では呼び出すことができず、mutate関数内で呼び出すことが想定された関数で、map_関数内で引数（.f引数）として設定する関数は無名関数のみとなります。この.f関数で指定する無名関数については引数が定められていて（node, rank, pathなど）、かなり使い方が複雑です。また、bfs、dfsで到達不可能なパスが存在すると演算ができなくなります。\n以下の例では、bfsによってJR奈良駅から他の駅までの到達に必要な距離を演算しています。valueに駅間の距離や運賃などを正確に設定すれば、map_bfs_dbl関数を用いて到達距離を計算することができます。\n\n\n\nmap_関数\n\ng |&gt; \n  # 離れているとbfsで探索できないので、田原本線をつなげる\n  bind_edges(data.frame(from = \"田原本\", to = \"西田原本\", linename = \"田原本線\", company = \"近鉄\")) |&gt; \n  mutate(value = rep(1, 119)) |&gt;  # 駅間を1としている\n  mutate(value_acc = map_bfs_dbl(1, .f = function(node, path, ...){ \n    sum(.N()$value[c(node, path$node)]) # searchの順に値を足していく（各nodeまでの距離を反映）\n  }))\n## # A tbl_graph: 119 nodes and 121 edges\n## #\n## # An undirected simple graph with 1 component\n## #\n## # Node Data: 119 × 7 (active)\n##    name    lat   lon linename       company value value_acc\n##    &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n##  1 奈良   34.7  136. 万葉まほろば線 JR          1         1\n##  2 京終   34.7  136. 万葉まほろば線 JR          1         2\n##  3 帯解   34.6  136. 万葉まほろば線 JR          1         3\n##  4 櫟本   34.6  136. 万葉まほろば線 JR          1         4\n##  5 天理   34.6  136. 万葉まほろば線 JR          1         5\n##  6 長柄   34.6  136. 万葉まほろば線 JR          1         6\n##  7 柳本   34.6  136. 万葉まほろば線 JR          1         7\n##  8 巻向   34.5  136. 万葉まほろば線 JR          1         8\n##  9 三輪   34.5  136. 万葉まほろば線 JR          1         9\n## 10 桜井   34.5  136. 万葉まほろば線 JR          1        10\n## # ℹ 109 more rows\n## #\n## # Edge Data: 121 × 4\n##    from    to linename       company\n##   &lt;int&gt; &lt;int&gt; &lt;chr&gt;          &lt;chr&gt;  \n## 1     1     2 万葉まほろば線 JR     \n## 2     2     3 万葉まほろば線 JR     \n## 3     3     4 万葉まほろば線 JR     \n## # ℹ 118 more rows",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>ネットワーク解析</span>"
    ]
  },
  {
    "objectID": "chapter33.html#グラフ表示のライブラリ",
    "href": "chapter33.html#グラフ表示のライブラリ",
    "title": "33  ネットワーク解析",
    "section": "33.6 グラフ表示のライブラリ",
    "text": "33.6 グラフ表示のライブラリ\n上記のように、グラフの表示はグラフの理解において非常に重要です。igraphを用いることでグラフを様々な形式で表示することができますが、デザイン的にはggplot2などとは異なり、Rのデフォルトのプロットに近い形での表示となります。Rには、igraphだけでなく、グラフを表示するためのライブラリがいくつかありますので、以下に簡単に紹介します。\n\n33.6.1 ggraph\nggraph(Pedersen 2024a)は上記のtidygraphの開発者が開発した、tbl_graphをggplot2の文法・デザインで描画するためのライブラリです。仕組みは比較的単純で、以下の例のようにtbl_graphをggplot2のグラフ表示に適したtibbleに変形し（create_layout関数）、ggplot2の文法でこのtibbleを表示しています。この変換において、nodeの位置をlayout引数で指定した位置に指定させています。\nlayout引数には\"auto\"、\"igraph\"、\"dendrogram\"、\"manual\"、\"linear\"、\"matrix\"、\"treemap\"などの様々な値を指定することができます。layoutによる違いは後ほど説明します。\n\n\n\nggraph：create_layout関数\n\npacman::p_load(ggraph)\n\ncreate_layout(g, layout = \"tree\")\n## # A tibble: 119 × 10\n##        x     y name    lat   lon linename    company .ggraph.orig_index circular\n##    &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;                &lt;int&gt; &lt;lgl&gt;   \n##  1 -7.97    12 奈良   34.7  136. 万葉まほろ… JR                       1 FALSE   \n##  2 -7.97    13 京終   34.7  136. 万葉まほろ… JR                       2 FALSE   \n##  3 -7.97    14 帯解   34.6  136. 万葉まほろ… JR                       3 FALSE   \n##  4 -7.97    15 櫟本   34.6  136. 万葉まほろ… JR                       4 FALSE   \n##  5 -6.47    16 天理   34.6  136. 万葉まほろ… JR                       5 FALSE   \n##  6 -6.47    17 長柄   34.6  136. 万葉まほろ… JR                       6 FALSE   \n##  7 -6.47    18 柳本   34.6  136. 万葉まほろ… JR                       7 FALSE   \n##  8 -6.47    19 巻向   34.5  136. 万葉まほろ… JR                       8 FALSE   \n##  9 -6.47    20 三輪   34.5  136. 万葉まほろ… JR                       9 FALSE   \n## 10 -3.03    21 桜井   34.5  136. 万葉まほろ… JR                      10 FALSE   \n## # ℹ 109 more rows\n## # ℹ 1 more variable: .ggraph.index &lt;int&gt;\n\n\nggraphの文法はggplot2と非常に類似しています。まず、ggplot2でのggplot関数に当たるggraph関数の引数として、グラフ、layout引数を設定します。layoutによってはこのggraph関数内で追加の引数を設定する必要があります。ggplot2と同様に、このggraph関数に足し算（+）で他のgeom関数を付け加えていくことでグラフを構成していきます。\n以下の例では、nodeを点で表示し（geom_node_point）、node側のtibbleの変数であるname（駅名）をテキストとして重ね書きし（geom_node_text）、edgeを運行会社により色分けして直線でつないでいます（geom_edge_link）。ggplot2のaes関数に関してはgeom_node_関数、geom_edge_関数内で指定します。geom_node_関数内ではnode側のtibble、geom_edge_関数内ではedge側のtibbleの列名を用いて表示する色や大きさを指定することができます。\n\n\n\nggraph：グラフを描画する\n\n# グラフのテーマの設定（ggplot2のthemeをあらかじめ定めておくもの）\nwindowsFonts(Meiryo = windowsFont(\"Meiryo\"))\nset_graph_style(family=\"Meiryo\", text_size = 5, background = \"white\", caption_size = 3)\n\n# x、yで指定した位置にnodeを表示する\nggraph(g, layout = \"manual\", x = lon, y = lat) +\n  geom_node_point() +\n  geom_node_text(aes(label = name)) +\n  geom_edge_link(aes(color = company))\n\n\n\n\n\n\n\n\n\n\n33.6.1.1 ggraphのlayout\nこのggraphのlayout・node・edgeの表示は非常に多種多様で、情報を捉えにくいものも含まれています。開発者がアートに興味があることもあり、ggraphにはどちらかというと現代美術的な、意味よりも見た目重視な表示方法も含まれています。\n以下にlayoutの例を示します。layoutは単にnodeのx・y軸上の位置を定めているだけで、layout自体にはそれほど変わったものはありません。とは言え、特定のnode・edgeの表示とセットで用いることを前提としている、使いにくいものもあります。\nlayoutにはsfをベースにしたもの（layout = \"sf\"）もあるため、上記のような路線図であれば、sfで表示するのもよいでしょう。sfについては32章で説明しています。\n\nautostresssparse_stressigraphbackbonepmdseigencentralityfocusdendrogramunrootedlinearcirclepacktreemappartitioncactustreehtreematrixhivefabricmetro\n\n\n\ng |&gt; ggraph(layout = \"auto\") +\n  geom_node_point() +\n  geom_edge_link() # stressが選択されている\n## Using \"stress\" as default layout\n\n\n\n\n\n\n\n\n\n\n\ng |&gt; ggraph(layout = \"stress\") +\n  geom_node_point() +\n  geom_edge_link() # autoで選ばれているのと同じ\n\n\n\n\n\n\n\n\n\n\n\ng |&gt; \n  bind_edges(data.frame(from=\"田原本\", to=\"西田原本\", linename=\"田原本線\", company=\"近鉄\")) |&gt; \n  ggraph(layout = \"sparse_stress\", pivots = 10) + # 分離したグラフでは表示できない\n  geom_node_point() +\n  geom_edge_link()\n\n\n\n\n\n\n\n\n\n\n\ng |&gt; \n  ggraph(layout = \"igraph\", algorithm = \"grid\") + # igraphのon_gridと同じ\n  geom_node_point() +\n  geom_edge_link()\n\n\n\n\n\n\n\n\n\n\n\ng |&gt; \n  bind_edges(data.frame(from=\"田原本\", to=\"西田原本\", linename=\"田原本線\", company=\"近鉄\")) |&gt; \n  ggraph(layout = \"backbone\") + # 分離したグラフには適さない\n  geom_node_point() +\n  geom_edge_link()\n\n\n\n\n\n\n\n\n\n\n\ng |&gt; \n  bind_edges(data.frame(from=\"田原本\", to=\"西田原本\", linename=\"田原本線\", company=\"近鉄\")) |&gt; \n  ggraph(layout = \"pmds\", pivots = 10) +  # 分離したグラフでは表示できない\n  geom_node_point() +\n  geom_edge_link()\n\n\n\n\n\n\n\n\n\n\n\ng |&gt; \n  bind_edges(data.frame(from=\"田原本\", to=\"西田原本\", linename=\"田原本線\", company=\"近鉄\")) |&gt; \n  ggraph(layout = \"eigen\") +  # 分離したグラフでは表示できない\n  geom_node_point() +\n  geom_edge_link()\n\n\n\n\n\n\n\n\n\n\n\ng |&gt; \n  mutate(cent = centrality_degree()) |&gt; # 中心性に従い位置を決定する\n  bind_edges(data.frame(from=\"田原本\", to=\"西田原本\", linename=\"田原本線\", company=\"近鉄\")) |&gt; \n  ggraph(layout = \"centrality\", centrality = cent) +  # 分離したグラフでは表示できない\n  geom_node_point() +\n  geom_edge_link()\n\n\n\n\n\n\n\n\n\n\n\ng |&gt; # 分離したグラフでは表示できない\n  bind_edges(data.frame(from=\"田原本\", to=\"西田原本\", linename=\"田原本線\", company=\"近鉄\")) |&gt; \n  ggraph(layout = \"focus\", focus = 1) + # JR奈良駅にfocusする\n  geom_node_point() +\n  geom_edge_link()\n\n\n\n\n\n\n\n\n\n\n\ncreate_tree(n=30, children = 4)  |&gt; # 有向グラフにしか適用できない\n  ggraph(layout = \"dendrogram\") + \n  geom_node_point() +\n  geom_edge_link()\n\n\n\n\n\n\n\n\n\n\n\ng  |&gt; \n  ggraph(layout = \"unrooted\") + \n  geom_node_point() +\n  geom_edge_link()\n\n\n\n\n\n\n\n\n\n\n\ng |&gt; \n  ggraph(layout = \"linear\") + \n  geom_node_point() +\n  geom_edge_arc() # 直線ではedgeが見えないのでarcとしている\n\n\n\n\n\n\n\n\n\n\n\nplay_gnm(30, 80, directed = TRUE)  |&gt;  # 有向グラフのみ対応\n  ggraph(layout = \"circlepack\") + \n  geom_node_point() +\n  geom_edge_link()\n## Multiple parents. Unfolding graph\n## Multiple roots in graph. Choosing the first\n\n\n\n\n\n\n\n\n\n\n\ncreate_tree(n=30, children = 4)  |&gt; # 有向グラフにしか適用できない\n  ggraph(layout = \"treemap\") + \n  geom_node_point() +\n  geom_edge_link()\n\n\n\n\n\n\n\n\n\n\n\ncreate_tree(n=30, children = 4)  |&gt; # 有向グラフにしか適用できない\n  ggraph(layout = \"partition\") + \n  geom_node_point() +\n  geom_edge_link()\n\n\n\n\n\n\n\n\n\n\n\ncreate_tree(n=30, children = 2)  |&gt; # 有向グラフでないとnodeが範囲外に出る\n  ggraph(layout = \"cactustree\") + \n  geom_node_point() +\n  geom_edge_link()\n\n\n\n\n\n\n\n\n\n\n\ncreate_tree(n=15, children = 2)  |&gt; # 二分木でないと描画できない\n  ggraph(layout = \"htree\") + \n  geom_node_point() +\n  geom_edge_link()\n\n\n\n\n\n\n\n\n\n\n\ng |&gt; ggraph(layout = \"matrix\") +\n  geom_node_point() +\n  geom_edge_arc() # 直線では見えなくなるのでarcを選択\n\n\n\n\n\n\n\n\n\n\n\ng |&gt; \n  activate(nodes) |&gt; \n  mutate(linename = E(g)$linename[1:119]) |&gt; \n  ggraph(layout = \"hive\", axis = linename) + # linenameを軸として配置\n  geom_node_point() +\n  geom_edge_arc(aes(color=linename)) # 直線では見えなくなるのでarcを選択\n\n\n\n\n\n\n\n\n\n\n\ng |&gt; ggraph(layout = \"fabric\") +\n  geom_node_point() +\n  geom_edge_link()\n\n\n\n\n\n\n\n\n\n\n\ng |&gt; ggraph(layout = \"metro\", x = lon, y = lat) +\n  geom_node_point() +\n  geom_edge_link()\n\n\n\n\n\n\n\n\n\n\n\n\n\n33.6.1.2 nodeの表示\nnodeの表示には、geom_node_関数を用います。geom_node_の後にnodeの形状を示す単語（point、text、tile、voronoiなど）を繋ぐことで、nodeの形状を指定します。geom_node_関数はggplot2のgeom_関数と同様に、ggraph関数に+でつないで用います。\ngeom_node_pointやgeom_node_text、geom_node_labelはどのようなグラフで用いても使いやすいですが、geom_node_voronoiのようにデザイン重視でネットワークの理解にはつながらないものもあります。以下にgeom_node_関数の使用例を示します。\n\npointtextlabeltilevoronoicirclearc_barrange\n\n\n\ng |&gt; \n  ggraph(layout = \"manual\", x = lon, y = lat) +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\n\ng |&gt; \n  ggraph(layout = \"manual\", x = lon, y = lat) +\n  geom_node_text(aes(label = name))\n\n\n\n\n\n\n\n\n\n\n\ng |&gt; \n  ggraph(layout = \"manual\", x = lon, y = lat) +\n  geom_node_label(aes(label = name))\n\n\n\n\n\n\n\n\n\n\n\ng |&gt; \n  ggraph(layout = \"igraph\", algorithm = \"grid\") +\n  geom_node_tile(aes(fill=lon, color = lat, width=0.9, height=0.9))\n\n\n\n\n\n\n\n\n\n\n\ng |&gt; \n  ggraph(layout = \"stress\") +\n  geom_node_voronoi(aes(color=factor(1), fill=factor(lat), alpha = 0.3))+\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\ng |&gt; \n  ggraph(layout = \"manual\", x = lon, y = lat) +\n  geom_node_circle(aes(r = lon/10000, color = factor(lon)))+\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\ncreate_tree(n=30, children = 2)  |&gt; \n  mutate(colors = rep(1:5, 6)) |&gt; \n  ggraph(layout = \"partition\", circular = TRUE) +\n  geom_node_arc_bar(aes(fill = factor(colors))) # 内→外へのtreeになっている\n\n\n\n\n\n\n\n\n\n\n\ng |&gt; \n  ggraph(layout = \"fabric\") +\n  geom_node_range(aes(color = factor(lon)))+\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n33.6.1.3 edgeの表示\nedgeの表示には、geom_edge_関数を用います。geom_edge_関数はgeom_node_関数とほぼ同じように用います。つまり、geom_edge_の後に形状を指定する単語（link、arcなど）を繋いだ関数として用い、ggraph関数に+でつないで用います。\ngeom_edge_link関数やgeom_edge_arc関数のように比較的使いやすいものから、平行するedge（同じnode間をつなぐ複数のedge）を示すときだけに用いるもの（geom_edge_parallel、geom_edge_fan）、ループ（ノードからそのノード自身に接続するedge）を示すときだけに用いるもの（geom_edge_loop）、特定のlayout・nodeと共に用いることが想定されているもの（geom_edge_hive、geom_edge_span）など、特定の場合以外にはほぼ用いないものもあります。\n\nlinkarcparallelfanloopdiagonalelbowbendhivespanpointtiledensitybundle_forcebundle_pathbundle_path\n\n\n\ncreate_tree(n=30, children = 4)  |&gt;\n  ggraph(layout = \"dendrogram\") + \n  geom_node_point() +\n  geom_edge_link()\n\n\n\n\n\n\n\n\n\n\n\nkarate  |&gt;\n  ggraph(layout = \"auto\") + \n  geom_node_point() +\n  geom_edge_arc()\n## Using \"stress\" as default layout\n\n\n\n\n\n\n\n\n\n\n\n# マニュアルの例の通り\ngr &lt;- create_notable('bull') |&gt;\n  convert(to_directed) |&gt;\n  bind_edges(data.frame(from = c(1, 2, 2, 3), to = c(2, 1, 3, 2)))\n \nggraph(gr, 'stress') +\n  geom_node_point(aes(size=1))+\n  geom_edge_parallel(aes(alpha = after_stat(index)))+\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\ngr &lt;- create_notable('bull') |&gt;\n  convert(to_directed) |&gt;\n  bind_edges(data.frame(from = c(1, 2, 2, 3), to = c(2, 1, 3, 2)))\n \nggraph(gr, 'stress') +\n  geom_node_point(aes(size=1))+\n  geom_edge_fan(aes(alpha = after_stat(index)))+\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\ndata.frame(from = c(1, 1, 2, 2, 3, 3, 3), to = c(1, 2, 2, 3, 3, 1, 1)) |&gt; \n  as_tbl_graph() |&gt; \n  ggraph(layout = \"auto\") + \n  geom_node_point() +\n  geom_edge_loop() + # node自身への接続（ループ）を表示する\n  geom_edge_fan()\n## Using \"stress\" as default layout\n\n\n\n\n\n\n\n\n\n\n\ncreate_tree(n=30, children = 4)  |&gt;\n  ggraph(layout = \"dendrogram\") + \n  geom_node_point() +\n  geom_edge_diagonal() # ベジェ曲線\n\n\n\n\n\n\n\n\n\n\n\ncreate_tree(n=30, children = 4)  |&gt;\n  ggraph(layout = \"auto\") + \n  geom_node_point() +\n  geom_edge_elbow()\n## Using \"tree\" as default layout\n\n\n\n\n\n\n\n\n\n\n\ncreate_tree(n=30, children = 4)  |&gt;\n  ggraph(layout = \"auto\") + \n  geom_node_point() +\n  geom_edge_bend()\n## Using \"tree\" as default layout\n\n\n\n\n\n\n\n\n\n\n\ncreate_tree(n=30, children = 4)  |&gt; \n  mutate(group = rep(1:3, 10)) |&gt; \n  ggraph(layout = \"hive\", axis = group) + \n  geom_node_point() +\n  geom_edge_hive() # axis間しか繋がない\n\n\n\n\n\n\n\n\n\n\n\ng |&gt; \n  ggraph(layout = \"fabric\") +\n  geom_node_range(aes(color = factor(lon)))+\n  theme(legend.position = \"none\")+\n  geom_edge_span()\n\n\n\n\n\n\n\n\n\n\n\ng |&gt; \n  ggraph(layout = \"manual\", x = lon, y = lat) +\n  theme(legend.position = \"none\")+\n  geom_edge_point(aes(color = factor(linename)))\n\n\n\n\n\n\n\n\n\n\n\ng |&gt; \n  ggraph(layout = \"matrix\") +\n  theme(legend.position = \"none\")+\n  geom_edge_tile(aes(color = linename, fill=linename))\n\n\n\n\n\n\n\n\n\n\n\ng |&gt; \n  ggraph(layout = \"manual\", x = lon, y = lat) +\n  theme(legend.position = \"none\")+\n  geom_node_point(size = 0.1)+\n  geom_edge_density(aes(fill=linename))\n\n\n\n\n\n\n\n\n\n\n\nmake_graph(\"Zachary\") |&gt; \n  as_tbl_graph() |&gt; \n  ggraph(layout = \"auto\") +\n  theme(legend.position = \"none\")+\n  geom_node_point(size = 0.1)+\n  geom_edge_bundle_force()\n## Using \"stress\" as default layout\n\n\n\n\n\n\n\n\n\n\n\nmake_graph(\"Zachary\") |&gt; \n  as_tbl_graph() |&gt; \n  ggraph(layout = \"auto\") +\n  theme(legend.position = \"none\")+\n  geom_node_point(size = 0.1)+\n  geom_edge_bundle_path()\n## Using \"stress\" as default layout\n\n\n\n\n\n\n\n\n\n\n\nmake_graph(\"Zachary\") |&gt; \n  as_tbl_graph() |&gt; \n  ggraph(layout = \"auto\") +\n  theme(legend.position = \"none\")+\n  geom_node_point(size = 0.1)+\n  geom_edge_bundle_minimal()\n## Using \"stress\" as default layout\n\n\n\n\n\n\n\n\n\n\n\n\n\n33.6.1.4 faceting\nggplot2と同じように、facet関数を用いることで、tbl_graphに含まれている変数（igraphにおけるattribute）を用いてグラフを分割し、表示することができます。facet関数にはfacet_graph、facet_node、facet_edgeの3つの関数があり、それぞれ使用感が少しずつ異なります。\nfacet関数の引数にはチルダ（~）を用い、チルダの右辺、もしくは両辺に変数を指定することで、グラフを分割表示することができます。\nggraphには上に示したものの他に、色や文字等を指定するたくさんの関数が設定されています。\n\n\n\nfaceting\n\ng |&gt; \n  ggraph(layout = \"manual\", x = lon, y = lat) +\n  geom_node_label(aes(label = name, color = company)) +\n  geom_edge_link(aes(, color = company)) +\n  facet_graph(~ company)\n\n\n\n\n\n\n\n\n\n# 上と同じ\ng |&gt; \n  ggraph(layout = \"manual\", x = lon, y = lat) +\n  geom_node_label(aes(label = name, color = company)) +\n  geom_edge_link(aes(, color = company)) +\n  facet_nodes(~ company)\n\n\n\n\n\n\n\n\n# edgeだけが2つに分かれる\ng |&gt; \n  ggraph(layout = \"manual\", x = lon, y = lat) +\n  geom_node_label(aes(label = name, color = company)) +\n  geom_edge_link(aes(, color = company)) +\n  facet_edges(~ company)\n\n\n\n\n\n\n\n\n\n\n\n33.6.2 networkD3\n上記のようにigraphのplot関数やggraphで静的なグラフを準備すれば、論文や出版物、プレゼンテーションで示すグラフとしては十分ですが、Web上ではグラフをインタラクティブに示すことでグラフの構造を読み取りやすくできる場合があります。\nこのようなインタラクティブなグラフの表示を行うためのライブラリがnetworkD3(Allaire et al. 2017)です。networkD3はJavascriptのグラフィックライブラリであるD3.jsをRに持ち込んで、ネットワークの表記ができるようにしたものです。\nD3.jsを用いることができるライブラリにはr2d3(Strayer, Luraschi, and Allaire 2022)もありますが、r2d3との違いはネットワークの表記にのみ対応していることで、r2d3でもネットワークを表記することはできます。ただし、r2d3はデータの準備がかなり独特（r2d3のgithubページを参照。idの列にネットワークの情報を入力）ですので、networkD3の方が比較的使いやすいでしょう。\n\n\n\nライブラリの読み込み\n\npacman::p_load(networkD3)\n\n\n\n33.6.2.1 データの準備\nnetworkD3でのグラフ表記には、nodeのデータフレームとedgeのデータフレームをそれぞれ独立に準備する必要があります。igraphやtidygraphのグラフオブジェクトをnetworkD3で利用する場合には、igraph_to_networkD3関数でデータをリストに変換します。このigraph_to_networkD3関数はigraphのオブジェクトをnodeのデータフレーム、edgeのデータフレーム（名前はlinks）からなるリストに変換してくれるだけの関数です。group引数を指定すると、元のigraphオブジェクトのattributeやベクターをnodeのデータフレームに付け加えることもできます。\n\n\n\nファイルの準備\n\n# dとvtからネットワークを作成\nnara_stations &lt;- graph_from_data_frame(d, vertices = vt, directed = FALSE)\n\nns_D3 &lt;- nara_stations |&gt; \n  igraph_to_networkD3(group = V(nara_stations)$linename)\n\nns_D3$links |&gt; head() # edge_listに似たデータフレーム\n##   source target\n## 1     15     16\n## 2     55     56\n## 3     30     31\n## 4     83     84\n## 5     74     75\n## 6     82     83\nns_D3$nodes |&gt; head() # nodeをまとめたもの\n##   name          group\n## 1 奈良 万葉まほろば線\n## 2 京終 万葉まほろば線\n## 3 帯解 万葉まほろば線\n## 4 櫟本 万葉まほろば線\n## 5 天理 万葉まほろば線\n## 6 長柄 万葉まほろば線\n\n\n\n\n33.6.2.2 simpleNetwork関数\n最も簡単にネットワークを表示するための関数が、simpleNetwork関数です。この関数の引数にedgeを示すデータフレームを設定するだけで、D3.jsを用いたネットワークを表示することができます。このグラフ上では、nodeをドラッグすることでnodeを移動させて表記することができます。\nただし、このsimpleNetworkをそのまま用いるとグラフが拡大されすぎて見えなかったり、nodeの意味がよくわからなくなったりします。グラフが拡大されて見にくい問題は引数にzoom = TRUEすることで拡大・縮小できるようにすることで対処できます。しかし、他の情報を表示するのにはこのsimpleNetwork関数は向いていません。\n\n\n\nsimpleNetwork関数\n\nsimpleNetwork(ns_D3$links, zoom = TRUE)\n\n\n\n\n\n\n\n\n33.6.2.3 forceNetwork\nもう少し情報を詰め込んだグラフを作成するための関数がforceNetwork関数です。この関数ではedgeのデータフレーム（Links引数）とnodeのデータフレーム（Nodes引数）を別に指定することができます。\nこの関数では、ネットワークの接続（edgelistに当たるもの）をSourceとTarget引数に、edgeの太さをValue引数に、ノードに表示される名前をNodeID引数に、色などのグループ分けをGroup引数に指定することで、比較的簡単に情報量の多いインタラクティブなグラフを作成することができます。\n\n\n\nforceNetwork関数\n\nforceNetwork(\n  Links = ns_D3$links,\n  Nodes = ns_D3$nodes,\n  Source = \"source\",\n  Target = \"target\",\n  NodeID = \"name\",\n  Group = \"group\",\n  fontSize = 30, zoom = TRUE\n)\n\n\n\n\n\n\n\n\n33.6.2.4 dendroNetwork\ndendroNetwork関数はネットワークではなく、階層ありクラスタリングの結果を表示するための関数です。引数に取れるのはhclust関数の返り値（hclustクラスのオブジェクト）だけです。dendroNetwork関数を用いることで簡単にインタラクティブな階層ありクラスタリングの結果を表示することができます。\n\n\n\ndendroNetwork関数\n\n# hclustクラスのオブジェクトをプロットする\nhc &lt;- hclust(dist(USArrests))\ndendroNetwork(hc)\n\n\n\n\n\n\n\n\n33.6.2.5 その他の関数\nnetworkD3には上記のforceNetwork、dendroNetworkの他にも円形・階層型のグラフを表示することができるradialNetwork関数やdiagonalNetwork関数、サンキー図を表示するsankeyNetwork関数も備わっています。以下の例ではjsonをjsonline::fromJSON関数でリストにして引数としていますが、sankeyNetwork関数は上記のforceNetworkと同様にedgeとnodeのデータフレームを引数に取ることもできます。\n\n\n\nradialNetwork関数\n\n# JSONのアドレスを読み込み\nURL &lt;- \n  \"https://cdn.rawgit.com/christophergandrud/networkD3/master/JSONdata//flare.json\"\n\n# JSONをリストにする\nFlare &lt;- jsonlite::fromJSON(URL, simplifyDataFrame = FALSE)\n\n# ネットワークを表示\nradialNetwork(List = Flare, opacity = 0.9)\n\n\n\n\n\n\n\n\n\ndiagonalNetwork関数\n\ndiagonalNetwork(List = Flare, opacity = 0.9)\n\n\n\n\n\n\n\n\n\nsankeyNetwork関数\n\n# sankeyNetwork（サンキー図）\nURL &lt;- \n  \"https://cdn.rawgit.com/christophergandrud/networkD3/master/JSONdata/energy.json\"\n\n# データはforceNetworkと同じように準備する（valueがlink側に必要）\nEnergy &lt;- jsonlite::fromJSON(URL)\nEnergy$links |&gt; head()\n##   source target   value\n## 1      0      1 124.729\n## 2      1      2   0.597\n## 3      1      3  26.862\n## 4      1      4 280.322\n## 5      1      5  81.144\n## 6      6      2  35.000\nEnergy$nodes |&gt; head()\n##                   name\n## 1 Agricultural 'waste'\n## 2       Bio-conversion\n## 3               Liquid\n## 4               Losses\n## 5                Solid\n## 6                  Gas\nsankeyNetwork(Links = Energy$links, Nodes = Energy$nodes, Source = \"source\",\n              Target = \"target\", Value = \"value\", NodeID = \"name\",\n              units = \"TWh\", fontSize = 12, nodeWidth = 30)\n\n\n\n\n\n\n\n\n\n33.6.3 visNetwork\nvisNetwork(Almende B.V. and Contributors and Thieurmel 2022)はD3.jsとは異なるJavascriptのビジュアライゼーションライブラリであるvis.jsを用いたインタラクティブなネットワーク描画に関するパッケージです。上記のNetworkD3とは少し違う感じでネットワークが描画されるので、好みの方を用いるとよいでしょう。\n\n\n\nライブラリの読み込み\n\npacman::p_load(visNetwork)\n\n\n\n33.6.3.1 visNetwork関数\nvisNetwork関数は、NetworkD3のforceNetwork関数に近い使い勝手の関数で、forceNetwork関数と同様にnodeとedgeのデータフレームを引数に取る関数です。ただし、forceNetwork関数が引数で色やnode名の指定を行うのに対し、visNetwork関数は引数に取ったデータフレームの列名に従ってネットワークを描画するという特徴があります。Rの他のグラフィックライブラリとは少し使い勝手が異なります。\nnodeに指定するデータフレームにはidという名前の列が、edgeに指定するデータフレームにはfromとtoという名前の列が必要です。この列名を読み取って、visNetworkはグラフを描画します。\n\n\n\nvisNetwork関数\n\nd &lt;- read.csv(\"./data/chapter33_nara_stations.csv\")\nvt &lt;- read.csv(\"./data/chapter33_nara_stations_vertex_list.csv\")\n\ncolnames(d) &lt;- c(\"from\", \"to\", \"linename\", \"company\")\ncolnames(vt) &lt;- c(\"id\", \"lat\", \"lon\", \"linename\", \"company\")\n\nvisNetwork(nodes = vt, edges = d)\n\n\n\n\n\n\nvisNetwork関数にnodeとedgeを指定しただけでは、nodeをドラッグして位置を変えることができる程度で、nodeの情報などは表示されません。nodeをクリックしたときに表示される文字列はtitleという列名に指定します。また、nodeの色を変える場合には、nodeに指定するデータフレームにcolorという列が必要です。このtitleやcolorに指定された値・色を読み取って、visNetwork関数はnodeの情報を変更します。\n\n\n\nnodeの情報を指定する\n\nvt$title &lt;- vt$id # nodeをクリックしたときに表示する文字\nvt$color &lt;- if_else(vt$company == \"JR\", \"red\", \"blue\") # nodeの色\nvisNetwork(nodes = vt, edges = d)\n\n\n\n\n\n\nまた、visNetworkではパイプ演算子（%&gt;%や|&gt;）を用いてグラフの要素を追加することもできます。visNodes関数をパイプで繋ぐことでnodeの編集、visOptionsをパイプで繋ぐことでオプション設定の変更を行うこともできます。\n\n\n\nパイプ演算子でグラフを編集する\n\nvisNetwork(nodes = vt, edges = d) |&gt; \n  visNodes(shape = \"square\") |&gt; \n  # クリックすると連結したノードがハイライトされる\n  visOptions(highlightNearest = TRUE) \n\n\n\n\n\n\n\n\n\n\n\n図1：ネットワークの用語\n図2：igraphでの呼び方\n\n\n\nAllaire, J. J., Christopher Gandrud, Kenton Russell, and CJ Yetman. 2017. networkD3: D3 JavaScript Network Graphs from r. https://CRAN.R-project.org/package=networkD3.\n\n\nAlmende B.V. and Contributors, and Benoit Thieurmel. 2022. visNetwork: Network Visualization Using ’Vis.js’ Library. https://CRAN.R-project.org/package=visNetwork.\n\n\nButts, Carter T. 2008. “Network: A Package for Managing Relational Data in r.” Journal of Statistical Software 24 (2). https://doi.org/10.18637/jss.v024.i02.\n\n\n———. 2015. Network: Classes for Relational Data. The Statnet Project (http://www.statnet.org). https://CRAN.R-project.org/package=network.\n\n\n———. 2023. Sna: Tools for Social Network Analysis. https://CRAN.R-project.org/package=sna.\n\n\nCsardi, Gabor, and Tamas Nepusz. 2006. “The Igraph Software Package for Complex Network Research.” InterJournal Complex Systems: 1695. https://igraph.org.\n\n\nCsárdi, Gábor, Tamás Nepusz, Vincent Traag, Szabolcs Horvát, Fabio Zanini, Daniel Noom, and Kirill Müller. 2024. igraph: Network Analysis and Visualization in r. https://doi.org/10.5281/zenodo.7682609.\n\n\nHandcock, Mark S., David R. Hunter, Carter T. Butts, Steven M. Goodreau, Pavel N. Krivitsky, and Martina Morris. 2018. Ergm: Fit, Simulate and Diagnose Exponential-Family Models for Networks. The Statnet Project (http://www.statnet.org). https://CRAN.R-project.org/package=ergm.\n\n\nHunter, David R., Mark S. Handcock, Carter T. Butts, Steven M. Goodreau, and Martina Morris. 2008. “Ergm: A Package to Fit, Simulate and Diagnose Exponential-Family Models for Networks.” Journal of Statistical Software 24 (3): 1–29.\n\n\nJones, Payton J., Patrick Mair, and Richard J. McNally. 2018. “Visualizing Psychological Networks: A Tutorial in r.” Frontiers in Psychology 9. https://doi.org/10.3389/fpsyg.2018.01742.\n\n\nPedersen, Thomas Lin. 2024a. Ggraph: An Implementation of Grammar of Graphics for Graphs and Networks. https://CRAN.R-project.org/package=ggraph.\n\n\n———. 2024b. Tidygraph: A Tidy API for Graph Manipulation. https://CRAN.R-project.org/package=tidygraph.\n\n\nSchoch, David. 2022. “Netrankr: An r Package for Total, Partial, and Probabilistic Rankings in Networks.” Journal of Open Source Software, no. 77: 4563.\n\n\nStrayer, Nick, Javier Luraschi, and JJ Allaire. 2022. R2d3: Interface to ’D3’ Visualizations. https://CRAN.R-project.org/package=r2d3.\n\n\nZachary, Wayne. 1976. “An Information Flow Model for Conflict and Fission in Small Groups1.” Journal of Anthropological Research 33 (November). https://doi.org/10.1086/jar.33.4.3629752.",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>ネットワーク解析</span>"
    ]
  },
  {
    "objectID": "chapter34.html",
    "href": "chapter34.html",
    "title": "34  R markdown・Quarto",
    "section": "",
    "text": "34.1 マークアップ言語とMarkdown\nマークアップ言語とは、主に組版と呼ばれる、文書や画像を出版・印刷できる形式で出力するために用いられる言語です。組版自体はマークアップ言語が無くても行うことができます（代表的な組版ソフトウェアはAdobe InDesignやQuarkXPress）。これらの有料の組版ソフトはGUIを用いて組版を行うソフトウェアです。同様の機能をCUI、つまりテキストファイルで対応できるようにしたものがマークアップ言語です。マークアップ言語は通常無料で使用することができ、機能的には有料の組版ソフトと大きな差はありません。ただし、学習コストが比較的高めです。\n代表的なマークアップ言語には、TexやMarkdownがあります。Texは昔から論文を書く際に用いられてきた言語で、専用のソフトウェアを用いることでTexファイルをPDF等に変換することができます。\n一方でMarkdown は主にhtmlへの変換を目的として作られたマークアップ言語です。Markdownとhtmlの表記は対応しており、変換ツールを用いることでMarkdown のファイルからhtmlを簡単に作成することができます。Markdownの記法について以下の表1に示します。RmarkdownのcheatsheetやQiitaのチートシートも参考になります。",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>R markdown・Quarto</span>"
    ]
  },
  {
    "objectID": "chapter34.html#r-markdownの発展",
    "href": "chapter34.html#r-markdownの発展",
    "title": "34  R markdown・Quarto",
    "section": "34.2 R markdownの発展",
    "text": "34.2 R markdownの発展\nRは統計に用いる言語ですので、Texを用いた論文にRの統計結果を加えることは昔から重要とされていました。Rが用いられ始めてすぐに、RのスクリプトとTexを合わせることができるRの機能として、SweaveがR Core Teamにより開発されました（2002年頃のようです）。\nまた、このようなRでの流れとは独立に、HTMLを簡単な表記で作成するためのテキスト形式であるMarkdown（2004年）、MarkdownをHTMLやPDFに変換できるファイルコンバータとしてPandoc（2006年）が開発されました。\nRでの開発とは別に、PythonではRと同じような対話的実行システムであるIPython（2001年）が開発され、更にPython、Rなどを対話的に実行・結果を表示しつつ、Markdownでの文書と同時に記載できるWebアプリケーションであるJupyter notebook（2014年頃）が開発されました。\n上記のような流れの中で、RでLaTex、HTML、Markdownなどの文書とコードを作成し、それをRコードを実行した形でLatexやHTMLとして出力するためのライブラリであるknitrが開発されました（2012年頃）。このknitrをさらにPandocと統合し、Rコードから直接PDFやHTML、Microsoft Wordなどのフォーマットの文書を作成できるようにしたものがR markdown（2016年頃）です。R markdownはすぐにRstudio（2011年頃に開発）と統合され、RstudioからR markdown方式の文書を作成し、それをPDFやHTMLに変換できるようになりました。R markdownのExtensionsも整備され、例えばBookdown（R Markdownで本を書くためのツール）が開発されたことでRでHTML形式の本を比較的簡単に作成することができるようになりました。また、Revealjsを 出力することでHTMLベースのプレゼンテーションを作成することもできるようになっています。R studioにはR markdownのVisual mode（Jupyter notebookと見た目が似た形式）も整備され、R markdownを利用することでJupyter notebook風にRを利用することもできます。\n上記のようにRstudioとR markdownは共に発展してきましたが、2010年代には機械学習のライブラリがほとんどPythonで開発されるようになり、RよりもPythonの方がはるかに流行の言語となりました。このPythonユーザーを取り込むためだと思いますが、Rstudio（今はPosit.ioという企業）はR markdownをPythonやJuliaなどの統計学・機械学習で用いられる言語でも使える形とし、Rstudioだけでなく、JupyterやテキストエディタであるVisual Studio Codeでも使えるものとした、Quartoを開発し始めました（おそらく2022年頃）。QuartoがRユーザー以外に注目されているかはかなり疑問ですが、RユーザーとしてはR markdownの機能が単にアップグレードされただけですので、用いない理由はほとんどありません。\nこのテキストもR markdown、BookdownおよびQuartoを利用して作成しています。\n以下ではR markdownについて説明していきますが、RstudioではQuartoもR markdownとほぼ同様に用いることができます。",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>R markdown・Quarto</span>"
    ]
  },
  {
    "objectID": "chapter34.html#ファイルの作成",
    "href": "chapter34.html#ファイルの作成",
    "title": "34  R markdown・Quarto",
    "section": "34.3 ファイルの作成",
    "text": "34.3 ファイルの作成\nR markdownで作成するファイルの拡張子は.rmd、Quartoで作成するファイルの拡張子は.qmdです。Rstudioで.rmd、.qmdファイルを作成する場合、Rstudioの左上のアイコンから、「R markdown…」や「Quarto Document…」を選択します。\n\n\n\nR markdownのファイルを作成する\n\n\nR markdownを選択すると、まず「New R Markdown」というウインドウが表示されます。ここでタイトル、著者、作成日、出力する形式（HTML、PDF、Word）を選択できます。このウインドウで設定していなくても後ほど設定することもできるため、すべてを入力しないといけない、ということはありません。\n\n\n\nR markdownの初期設定\n\n\nR markdownファイルを作成すると、以下のようなR markdownの例が表示されます。この表記法はSourceと呼ばれる、すべてテキストで記載された形です。\n\n\n\nR markdownファイル：Sourceモード\n\n\nまた、上の「Visual」を選択すると、Jupyter notebook風のVisualモードを利用することもできます。やや表示に時間がかかり、レスポンスが悪いため、通常はSourceモードを用いる方が使いやすいでしょう。\n\n\n\nR Markdownファイル：Visualモード\n\n\n最終的には上のアイコンに含まれている「Knit」（毛糸を編む、ニット）の下矢印をクリックし、選択肢から出力したいファイル形式（HTML、PDF、Word）を選ぶことでRを実行した結果を表示した出力ファイルを得ることができます。\n\n\n\nR markdownをknitする",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>R markdown・Quarto</span>"
    ]
  },
  {
    "objectID": "chapter34.html#yamlとchunk",
    "href": "chapter34.html#yamlとchunk",
    "title": "34  R markdown・Quarto",
    "section": "34.4 yamlとchunk",
    "text": "34.4 yamlとchunk\n\n34.4.1 yaml\n上記の「New R Markdown」ウインドウで設定した内容は、文書の一番始め、---に挟まれた領域に記載されています。\n---\ntitle: \"Untitled\"\nauthor: \"xjorv\"\ndate: \"2024-06-29\"\noutput: html_document\n---\nこの---に挟まれた領域には、YAMLと呼ばれるものが記載されています。YAML自体は名前とデータをコロン（:）でつないだだけのデータ形式です。R markdownではこのYAMLを読み込むことで、最終的な出力データに表記する情報・データの出力形式などを設定します。YAMLで設定できる主な要素は以下の表2の通りです。\n\n\n\n表2：YAMLの指定\n\n\nオプション名\n取りうる値\n意味\n\n\n\n\ntitle\n文字列\n文書のタイトル\n\n\nauthor\n文字列\n著者\n\n\ndate\n日付\n作成日\n\n\noutput\nhtml_documentなど\n出力の形式\n\n\ncode_folding\n論理型\nスクリプトを折りたたむ\n\n\ncss\n“style.css”\nCSSの指定\n\n\ndev\n“png”、“pdf”\nグラフィックデバイスの指定\n\n\ndf_print\n“kable”、“tibble”など\nデータフレームの表示方法\n\n\nfig_caption\n論理型\n図のキャプションの有無\n\n\nhighlight\n“tango”、“pygments”など\nコードハイライトの方法\n\n\nlatex_engine\n“lualatex”など\nPDF作成時のLaTeXエンジン\n\n\nreference_docx\n“file.docx”など\nWordのテンプレート指定\n\n\ntheme\nBootswatchのテーマ名\nBootswatchのテーマ選択\n\n\ntoc\n論理型\n目次の表示\n\n\ntoc_depth\n数値\n目次表示するレベルの指定\n\n\ntoc_float\n論理型\n目次をスクロールで移動するか\n\n\n\n\n\nYAMLの指定では、論理型としてtrue/falseという形で、小文字を用います。\n\n\n34.4.2 chunk\nR markdown中では、Rのスクリプトは以下のように`3つで囲まれた領域に書くことになります。このコードのかたまりのことをchunkと呼びます。\n```{r}\nplot(cars)\n```\n\n\n\n\n\n\n\n\n\n.rmd（.qmd）ファイル中にchunkを書くと、knitするときにchunk内のスクリプトは実行され、上のように評価結果が出力ファイル上に表示されます。chunkに書かれている{r}はRのコードであるということを示しています。この{r}の部分には、chunkオプションというものを追加し、評価や表示の方法を指定することができます。chunkオプションのリストを以下の表に示します。\n\n\n\n表3：chunk optionの一覧\n\n\nオプション名\n意味\n\n\n\n\necho\nコードを表示するかどうか\n\n\nerror\nエラーで停止するかどうか\n\n\neval\nコードを評価するか\n\n\nmessagee\nメッセージを表示するか\n\n\nwarning\nwarningを表示するか\n\n\nresults\n結果の表示方法の指定\n\n\nfig.align\n図の位置（“center”など）\n\n\nfig.width\n図の幅\n\n\nfig.height\n図の高さ\n\n\nout.width\n図の出力時の幅調整\n\n\ncollapse\nコードと結果の折り畳み\n\n\nfilename\nチャンク名の設定\n\n\n\n\n\nチャンクオプションは以下のように記載して用います。\n```{r, echo = FALSE, eval = FALSE}\nplot(cars) # チャンクオプションはコンマで区切って記述する\n```",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>R markdown・Quarto</span>"
    ]
  },
  {
    "objectID": "chapter34.html#quarto",
    "href": "chapter34.html#quarto",
    "title": "34  R markdown・Quarto",
    "section": "34.5 Quarto",
    "text": "34.5 Quarto\nQuartoは上記の通り、Rを使う上ではR markdownと大差ないものですが、ファイル名や使い方などが少しずつ異なります。Quartoを使用する場合、まずはCLIをインストールするとよいでしょう。\n\n\n\nQuarto CLIのインストール\n\n\nQuartoの使い方はほぼR markdownと同じですが、CLIをインストールしているとTerminalからQmdファイルをknitできるようになります。また、chunk optionの表記法、YAMLの要素などが少しずつ異なります。詳しくは公式のガイドや日本語の教科書(宋 and 矢内 2020)をご参照下さい。\n\n\n\n\n\nR markdownのファイルを作成する\nR markdownの初期設定\nR markdownファイル：Sourceモード\nR Markdownファイル：Visualモード\nR markdownをknitする\nQuarto CLIのインストール\n\n\n\n宋財泫, and 矢内勇生. 2020. 私たちのr ベストプラクティスの探求. https://www.jaysong.net/RBook/.",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>R markdown・Quarto</span>"
    ]
  },
  {
    "objectID": "chapter35.html",
    "href": "chapter35.html",
    "title": "35  Shiny",
    "section": "",
    "text": "35.1 Shinyとwebアプリケーション\nShinyはwebアプリケーションと呼ばれる、webページ（HTML）の生成（ユーザーインターフェース/フロントエンド）とサーバでの演算（サーバサイド）を行うアプリケーションの一種です。\n通常のwebアプリケーションでは、ユーザーがwebページにアクセスし、情報を入力（例えば検索する文字を入力）すると、情報がサーバへと送られます。サーバでは入力された情報と、サーバー内のデータベースとを比較し、必要な情報を集めてHTMLファイルを作成します。このHTMLがユーザーに送られ、検索結果が表示される、といったような仕組みになっています。\nこのようなタイプのwebアプリケーションを作成するためのツールはたくさんあります。典型的な例として、Ruby on Rails、Djangoなどがあります。これらのツールはwebアプリケーションフレームワークと呼ばれており、我々がよく用いているwebページ・webサービスに用いられています。\nShinyはこれらのフレームワークと比較するとかなり機能が制限されたツールです。Shinyにはユーザーインターフェースとサーバサイドを構築する機能はありますが、演算は基本的にRで行われるためレスポンスは遅めです。また、データベースは必須ではないため、データベースを用いるのであればR上で別途ライブラリを用いる必要があります。データベースではなく、csvなどでデータを準備することもあります。また、セキュリティ面をサポートするツールはほとんどありません。",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Shiny</span>"
    ]
  },
  {
    "objectID": "chapter35.html#データ分析のためのwebアプリケーション開発ツールshiny",
    "href": "chapter35.html#データ分析のためのwebアプリケーション開発ツールshiny",
    "title": "35  Shiny",
    "section": "35.2 データ分析のためのwebアプリケーション開発ツール：Shiny",
    "text": "35.2 データ分析のためのwebアプリケーション開発ツール：Shiny\nShinyはデータを説明することに特化したwebアプリケーション開発ツールで、Rのツール、例えばggplot2やplotly、leafletなどを用いてデータを表示し、統計結果を示すのに適したツールです。Shiny自体は2012年頃から開発され、2017年頃にver.1.0となった、古参のデータ用webアプリケーションツールです。\n最近になってPlotly DashやStreamlitなどの、Pythonを用いる同様のツールが開発され、あっという間にShinyよりメジャーなツールになってしまいました。特にStreamlitは今（2024年）注目されているツールです。現状Shinyの方が完成度は高めですが、Streamlitはたくさんの開発者が寄ってたかって改善している最中ですので、いずれStreamlitの完成度がShinyを上回りそうです。Pythonを使ったShinyも開発されていますが、Streamlitの勢いに勝てるかどうかは疑わしいところです。\nしかし、Rでウェブアプリケーションを作成するのであれば、Shinyはすぐに使えて、ある程度完成度の高いものを作るのも難しくない、良いツールです。ココではShinyでの基本的なWebアプリケーションの作成方法を簡単に説明します。\nShinyはかなり複雑なこともできる、高度なRライブラリの一つです。すべてをココで説明することはできませんので、詳しく学びたい方は教科書（日本語のものや英語のもの）をご一読されることをオススメいたします。\nこの教科書でもShinyで作成したいくつかのWebアプリケーションを統計解析手法の説明に用いています。以下のコードを実行することで、この教科書で用いているWebアプリケーションを起動することができます。また、Webアプリケーションを停止するには、コンソールを選択してEscを押します。\n\n\n\n生存時間解析シミュレーター\n\nif(!require(shiny)) install.packages((\"shiny\"))\nshiny::runGitHub(\"surv_sim\", \"sb8001at\")\n\n\n\n\n\nk-meansのアニメーション\n\nif(!require(shiny)) install.packages((\"shiny\"))\nshiny::runGitHub(\"kmeans_animated\", \"sb8001at\")\n\n\n\n\n\n時系列：ARIMAシミュレーター\n\nif(!require(shiny)) install.packages((\"shiny\"))\nshiny::runGitHub(\"ARIMAsim\", \"sb8001at\")",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Shiny</span>"
    ]
  },
  {
    "objectID": "chapter35.html#shinyの基礎",
    "href": "chapter35.html#shinyの基礎",
    "title": "35  Shiny",
    "section": "35.3 Shinyの基礎",
    "text": "35.3 Shinyの基礎\nShinyのWebアプリケーションをR Studioで作成する場合、まずは左上のNew Fileアイコンから「Shiny Web App…」を選択します。\n\n\n\n図1：Shinyのファイルを作成する\n\n\n「Shiny Web App…」を選択すると、以下のようなウインドウが表示されます。このウインドウでは、Webアプリケーションの名前、ファイルを作成するディレクトリ（フォルダ）に加えて、Web Appを1つのファイルで作成するか（Single File）、複数のファイルで作成するか（Multiple File）を選択します。「Single File」を選択すると、app.Rという1つのファイルが選択したディレクトリ内に作成されます。一方で「Multiple File」を選択すると、ui.Rとserver.Rという2つのファイルが作成されます。\nどちらの形式を用いてもアプリケーションを作成するための関数などは共通していますが、アプリケーション作成に慣れるまでは「Multiple File」を用いるのがおすすめです。この章では、まず「Multiple File」での作成方法を一通り説明した後で、「Single File」で作成する方法を説明します。\n\n\n\n図2：Shinyのファイルを作成する\n\n\n上記のウインドウで「Create」をクリックすると、以下のようにディレクトリにui.Rとserver.Rという2つのファイルが作成されます。このファイルにはWebアプリケーションのスクリプト（サンプルアプリ）が書かれています。\n作成されたui.Rやserver.RをRstudioで開くと、右上に「Run App」というアイコンが出てきます。これを押すとサンプルアプリを実行することができます。\n\n\n\n図3：Shinyアプリの例とRun Appアイコン\n\n\nWebアプリケーション（Shinyアプリ）を実行すると、以下の図のようなページがWebブラウザに表示されます。このページのうち、左の部分（Number of bins:）はマウスで操作することができます。\n\n\n\n図4：Shinyサンプルを起動する\n\n\n実際にNumber of binsを変更し、50としたのが以下の図です。bins、つまりヒストグラムの棒の数の設定を変えると、右のヒストグラムの表示が変化します。\n\n\n\n図5：Number of binsを変更する\n\n\nこのようなShinyアプリの動作は、以下の図のようなメカニズムで構成されています。まず、Shinyアプリのユーザーインターフェース（UI）で入力したデータは、Serverに送られます。Serverでは入力データを取り込んでggplot2でグラフを作成し、グラフを含んだHTMLが作成されます。このHTMLがWebブラウザで表示されることで入力データに従ったグラフが表示されます。\n\n\n\n図6：Shinyアプリのおおまかな仕組み\n\n\n通常のWebアプリケーションフレームワークでは、Rの部分に別の言語（RubyやPythonなど）が入り、さらにデータベースと接続されているのが一般的です。Shinyではデータベースは必須ではありませんが、もちろんデータベースを用いたWebアプリケーションを作成することもできます。データベースを用いたアプリケーションを作成する場合には、データベースを取り使うためのライブラリ（DBI(R Special Interest Group on Databases (R-SIG-DB), Wickham, and Müller 2024)やdbplyr(Wickham, Girlich, and Ruiz 2024)など）を用いることになります。\n上記のUI、Serverをそれぞれ構築するためのファイルが、ui.Rとserver.Rです。ココからはまずui.Rの構築について説明し、その後server.Rについて説明します。",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Shiny</span>"
    ]
  },
  {
    "objectID": "chapter35.html#ui.rユーザーインターフェース",
    "href": "chapter35.html#ui.rユーザーインターフェース",
    "title": "35  Shiny",
    "section": "35.4 ui.R（ユーザーインターフェース）",
    "text": "35.4 ui.R（ユーザーインターフェース）\nui.Rには以下の4点をそれぞれ準備します。\n\nWebページのレイアウト\nHTMLの要素（文章や画像）\n入力\n出力\n\n上記の4つのうち、Webページのレイアウトについては上の図には表現されていない部分です。HTMLの要素は文章のヘッダーや本文、画像などの表示に関わる部分です。入力と出力に関しては、上記の図に示した通り、入力データをserver.Rに送る部分と、server.Rで演算された結果をWebページ上に表示させる部分になります。以下にそれぞれの要素について説明していきます。\n\n35.4.1 Webページのレイアウト\nまずは、Webページ全体のレイアウトをui.Rに指定する必要があります。レイアウトの指定には、以下の表に示す関数が用いられます。\n\n\n\n表：代表的なレイアウト指定用の関数の一覧\n\n\n\n\n\n\n\n関数\n主な引数\n意味\n\n\n\n\nabsolutePanel\nfixed=FALSE\n絶対的な位置を指定したレイアウト（スクロールあり）\n\n\nfixedPanel\nfixed=FALSE\n絶対的な位置を指定したレイアウト（スクロールされない）\n\n\ncolumn\nwidth\n列のレイアウト（widthは最大12で指定）\n\n\nfillPage\npadding\nウインドウのサイズに合わせてコンテンツを表示\n\n\nfixedPage\n―\n固定幅のページのレイアウト\n\n\nfixedRow\n―\n固定幅の行のレイアウト\n\n\nfluidPage\n―\n可変幅のページのレイアウト\n\n\nfluidRow\n―\n可変幅の行のレイアウト\n\n\nnavbarPage\n―\nページ上にタブの表示を作成する\n\n\nsidebarLayout\n―\n左右にサイドバー、メインパネルを配置\n\n\nsidebarPanel\nwidth=4\nサイドバーのレイアウト\n\n\nmainPanel\nwidth=8\nメインパネルのレイアウト\n\n\ntabsetPanel\n―\nその列にタブの表示を作成する\n\n\ntabPanel\ntitle\nタブの中身のレイアウト\n\n\n\n\n\nレイアウトを決める関数にはある程度上下関係があります。最も上位に配置するレイアウトはnavbarPage関数で、全体のページに渡るタブを作成します。\n\n\n\n図7：navbarPageによるタブ\n\n\nnavbarPage関数では、「タブを配置すること」だけしか設定できないため、タブの中身を別途準備する必要があります。タブの中身はtabPanel関数を用いて記載していきます。tabPanel関数の第一引数にはタブの名前（title）を指定します。上記の図では、タブに記載された「textOutput」や「Plot・Table Output」というのがtitleに当たります。\nnavbarPage関数の下位にはfixedPage関数・fluidPage関数を配置するのが一般的です。navbarPage関数はタブを用いない場合には使用しないため、タブなしのページの場合にはfixedPage関数、fluidPage関数が最上位のレイアウトとなります。fixedPage関数、fluidPage関数の差はレイアウトの幅を固定するか（fixedPage関数）、ウインドウの幅に合わせて調整するか（fluidPage関数）の違いです。\nfixedPage関数、fluidPage関数の下位にはsidebarLayout関数やcolumn関数を配置します。sidebarLayout関数の下位にはsidebarPanel関数とmainPanel関数を配置し、それぞれ1/3の幅を持つサイドバーと2/3の幅を持つメインパネルの2つを設定します。以下の図の左側（binsの入力）がサイドバー、右側（グラフ）がメインパネルとなります。\n\n\n\n図8：sidebarLayoutの例\n\n\nこのサイドバーとメインパネルの幅はwidth引数で変更することができます。Shinyでは、R markdownと同様にBootstrapによるデザインが採用されています。Bootstrapでは、Webページの幅全体を12とすることとされていますので、この幅12に従い、サイドバーとメインパネルのwidthの和が12となるように調整します。デフォルトではサイドバーのwidthが4、メインパネルのwidthが8となっています。\ncolumn関数は上記のsidebarPanel関数やmainPanel関数とよく似たものですが、上位にsidebarLayout関数を必要としないものです。column関数もwidth引数で幅指定しますが、やはりすべてのcolumnのwidthの和が12となるように設定します。\ncolumn関数やmainPanel関数にタブを設定するためのレイアウトがtabsetPanel関数です。ちょうどnavbarPanel-tabPanelの関係と同様に、tabsetPanel関数の下にはtabPanel関数を配置します。\n以上のように、Shinyのレイアウトに関する関数はたくさんあり、上下関係が複雑です。上記で紹介していない関数もありますので、実際にはさらに複雑なレイアウトを取ることもできます。\nレイアウトの上下関係は、関数をネストすることで指定することができます。例えば、以下の例ではfluidPageの下にsidebarLayout、sidebarLayoutの下にsidebarPanelとmainPanelを配置し、mainPanelの下にtabsetPanel、tabsetPanelの下にtabPanelを2枚配置しています。\n\n\n\nレイアウトの例\n\nfluidPage(\n  sidebarLayout(\n    sidebarPanel(\n      # サイドバーの中身を記載\n    ),\n    mainPanel(\n      # メインパネルの中身を記載\n      tabsetPanel(\n        tabPanel(\n          title = \"パネル1\"\n          # タブパネル1の中身を記載\n          ),\n        tabPanel(\n          title = \"パネル2\"\n          # タブパネル2の中身を記載\n          )\n      )\n    )\n  )\n)\n\n\nRは関数型言語ですので、すべてのレイアウトは関数、つまりカッコつきのスクリプトになります。また、sidebarPanelや1枚目のtabPanelのカッコの後にコンマがついています。1つのカッコの中に複数の要素がある場合にはコンマが必要です。ただし、カッコ内の最後の要素（上の例ではtabPanel(title = \"パネル2\")）にはコンマは必要ありません。\nShinyのui.Rの記載では、レイアウトに関する関数が多層にネストされ、意味がわかりにくくなりやすいため、「Run App」でアプリを表示し、確認しながら作成するのがよいでしょう。\n\n\n35.4.2 HTMLの要素\nHTMLではヘッダーや改行、パラグラフは以下のように表現されます。\n\n\n\nHTMLの記述\n\n&lt;h1&gt; ヘッダー &lt;/h1&gt;\n&lt;br&gt; # 改行\n&lt;p&gt; パラグラフ（文）&lt;/p&gt;\n\n\nShinyも基本的にはHTMLをRから出力する仕組みとなっているため、Webアプリに文章を追加したい場合などにはHTMLを記述する必要があります。ShinyにはHTMLを直接挿入できるHTML関数が備わっているため、HTMLをそのまま入力することができます。\n\n\n\nHTML関数\n\nHTML(\"&lt;p&gt;HTML直打ち&lt;/p&gt;\")\n\n\nしかし、HTML関数を用いるとHTMLのタグ（&lt;p&gt;など）を入力しないといけないため、やや煩雑です。Shinyには、HTMLを追加するための専用の関数（shiny::tagsに登録されている関数）が備わっています。こちらを用いることで、簡単にヘッダーや文章を追加することができます。\n\n\n\nHTMLを記載するための関数群\n\nh1(\"ヘッダー1\")\np(\"パラグラフ\")\nbr() # 改行\nhr() # 水平線\n\n\nHTMLを追加する関数の一覧はnames(shiny::tags)で確認できます。\n\n\n\nshiny::tags\n\nshiny::tags |&gt; names() |&gt; head(10) # 10個だけ表示\n\n\n [1] \"a\"                \"abbr\"             \"address\"          \"animate\"         \n [5] \"animateMotion\"    \"animateTransform\" \"area\"             \"article\"         \n [9] \"aside\"            \"audio\"           \n\n\n\n\n35.4.3 入力（input）\n静的なHTMLとは異なり、Webアプリケーションではブラウザ上で入力した値に対して演算が行われ、表示が値によって変化するところに特徴があります。Shinyでは、このような入力（input）に対応した各種の部品（control widgets）が備わっています。control widgetsの一覧はShinyのギャラリーに示されています。\n各control widgetsは以下のようなInput関数群を用いることで設定することができます。\n\n\n\nInput関数\n\nnumericInput(\n  inputId = \"numeric_input\", \n  label = \"数値の入力\", \n  value = 10, \n  min = 0, \n  max = 20, \n  step = 2\n)\n\n\nすべてのInput関数は、inputIdを第一引数に取ります。このinputIdには文字列で指定し、server側で入力データを受け取るときに用います。inputIdの使い方についてはserverの解説時に詳しく説明します。第二引数にlabelを文字列として取ります。labelはcontrol widgetsの題名としてwidgetに表示されます。3つ目以降の引数はそれぞれのInput関数で異なっており、numericInputでは初期値（value）、最小値（min）、最大値（max）、増加の幅（step）を引数で設定することができます。\n以下にInput関数の一覧を示します。\n\n\n\n表：代表的なInput関数の一覧\n\n\n\n\n\n\n\n\n関数\n主な引数\n意味\n返り値\n\n\n\n\nactionButton\nicon\nボタンを追加\n数値\n\n\ncheckboxInput\nchoices, selected\nチェックボックスを追加\n論理型\n\n\ncheckboxGroupInput\nchoices, selected\nチェックボックス群を追加\n文字列\n\n\nradioButtons\nchoices, selected\nラジオボタンを追加\n文字列\n\n\nselectInput\nchoices, selected\n選択リストを追加する\n文字列\n\n\ndateInput\nvalue, min, max\n日付の入力を追加\n日付\n\n\ndateRangeInput\nstart, end, format\n期間を指定する入力を追加\n日付\n\n\nnumericInput\nvalue, min, max\n数値を入力するボックスを追加\n数値\n\n\nsliderInput\nvalue, min, max\n数値を選択するスライダーを追加\n数値\n\n\ntextInput\nvalue\n文字列を入力するボックスを追加\n文字列\n\n\npasswordInput\nvalue\nパスワードを入力するボックスを追加\n文字列\n\n\n\n\n\nInput関数で設定したcontrol widgetsに従い、データがserver.Rに送られます。ui.Rには出力（output）も必要となりますが、outputに関してはサーバサイドの説明の後の方が分かりやすいと思いますので、まずはサーバサイドについて説明し、後ほどoutputについて説明します。",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Shiny</span>"
    ]
  },
  {
    "objectID": "chapter35.html#server.rサーバサイド",
    "href": "chapter35.html#server.rサーバサイド",
    "title": "35  Shiny",
    "section": "35.5 server.R（サーバサイド）",
    "text": "35.5 server.R（サーバサイド）\n次に、server.Rを作成していきます。server.Rはfunction(input, output, session){}という関数から始まります。この関数・引数はこのまま変更せずに使用し、functionの{}の中に実行したいコードを記載していきます。\n\n35.5.1 outputIDの準備\ninputで入力されたデータをserver.Rで受け取ったら、server.Rに従い演算を行います。演算結果をoutputとしてHTMLに出力することで、ui.R側でinputに対応したoutputを表示します。server.Rにはこのoutputを準備するためのスクリプトを書くことになります。\noutputを準備するときには、output$outputIdというオブジェクトにrender関数を代入します。以下に例を示します。\n\n\n\noutputをrender関数で準備する\n\noutput$outputId &lt;- renderText(\"Hello world!\")\n\n\nこのoutputIdはui側で読みだして利用します。上記のスクリプトの場合では、outputIdには\"Hello world!\"が入っていますので、ui側でoutputIdを用いて文字列として\"Hello world!\"を出力することができます。\nとは言ってもこれでは単に文字列をui側で表示するだけになり、serverを介している意味がありません。Shinyが動的に動くようにするには、inputIdを用いて演算を行う必要があります。\n\n\n35.5.2 inputIdを利用してoutputIdを準備する\nserver側でinputIdの情報を用いる場合には、input$inputIdと、リストに似た形の変数を指定します。\n\n\n\ninputIdを用いてoutputを準備する\n\noutput$outputId &lt;- renderText(paste(\"Hello world\", input$inputId, \"!\"))\n\n\n上記のような形でoutputIdを準備すると、renderText内のスクリプトが実行されることで、input$inputIdの値（文字列や日付、数値等）に従ってoutput$outputIdが作成されます。この準備したoutputIdをui側で利用してやれば、inputの内容に従ったoutputを表示することができます。\nui側ではInput関数を用いてinputIdを、server側ではrender関数を用いてoutputIdを準備します。inputIdやoutputIdが重複していると、どれが正しいIdなのかわからなくなるため、inputIdやoutputIdが重複することは許されていません。単一の名前をinputId、outputIdに指定する必要があります。また、input$inputIdをui.R内、output$outputIdをserver.R内で用いることはできません。\n\n\n35.5.3 Render関数群\n上記の通り、output$outputIdを準備する際には、render関数群を用います。このrender関数には、outputの種類（テキスト・グラフ・表など）によってそれぞれ専用の関数が準備されています。代表的なrender関数の一覧を以下に示します。\n\n\n\n表：代表的なrender関数の一覧\n\n\n関数\n意味\n\n\n\n\nrenderPlot\nグラフ（プロット）を準備する\n\n\nrenderText\nテキスト（文字列）を準備する\n\n\nrenderImage\n画像を準備する\n\n\nrenderTable\nテーブル（表）を準備する\n\n\nrenderPrint\n文字列（consoleの出力）を準備する\n\n\nrenderUI\nUI（control widget）を準備する\n\n\ndownloadHandler\nダウンロードファイルを準備する\n\n\n\n\n\noutputとして表示したいものがテキストならrenderText、グラフならrenderPlot、表ならrenderTable関数を選択します。\nserver側では通常inputに従いデータを加工して、文字列やグラフ、表を準備します。ただし、このような演算は必ずしも1行のスクリプトで書けるとは限りません。render関数では複数の行に渡るスクリプトを書くことができるようにするため、関数のカッコの内側に中カッコ（{}）を設定できるようになっています。この中カッコの中には複数行のスクリプトを書くことができます。\n\n\n\nrender関数内に複数のスクリプトを記載する\n\n# 1行スクリプトの場合には中カッコが無くても問題ない\noutput$output_text1 &lt;- renderText(\"Hello world!\")\n\n# 2行以上の時に中カッコなしだとエラー\noutput$output_text_error &lt;- \n  renderText(\n    temp &lt;- paste(\"Hello world,\", input$input_name, \"!\")\n    temp\n  )\n\n# 2行以上の時には中カッコを加える\noutput$output_text2 &lt;- \n  renderText({\n    temp &lt;- paste(\"Hello world,\", input$input_name, \"!\")\n    temp\n  })\n\n\nserver.Rには、複数のoutput$outputIdを置くことができます。通常のRスクリプトとは異なり、server.Rの演算は上から下に順番に行われるわけではなく、inputの変更に従って必要な部分が実行される形となっています。また、server.Rでは、演算の部分とテキスト・グラフ・表を準備する部分を分離して記載する方法もあります。この分けて計算する部分（reactiveやobserveなどの関数を用いた演算）に関してはやや複雑ですので、後ほど説明します。",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Shiny</span>"
    ]
  },
  {
    "objectID": "chapter35.html#ui.r",
    "href": "chapter35.html#ui.r",
    "title": "35  Shiny",
    "section": "35.6 ui.R",
    "text": "35.6 ui.R\n\n35.6.1 出力（output）\n上記のように、server.Rでoutput$outputIdを準備します。このoutputIdを準備しただけではUIに表示されないため、ui.R側に出力を準備する必要があります。この出力の準備には、Output関数群を用いることになります。Output関数群の一覧を下の表に示します。\n\n\n\n表：代表的なOutput関数の一覧\n\n\n\n\n\n\n\n関数\n対応するrender関数\n意味\n\n\n\n\ntextOutput\nrenderText\n文字列を出力する\n\n\nverbatimTextOutput\nrenderText・renderPrint\nコード（文字列）を出力する\n\n\nplotOutput\nrenderPlot\n文字列（consoleの出力）を出力する\n\n\ntableOutput\nrenderTable\n表を出力する\n\n\nuiOutput\nrenderUI\ncontrol widgetsを出力する\n\n\ndownloadButton\ndownloadHandler\nダウンロード出力用のボタンを準備する\n\n\n\n\n\nOutput関数はui.Rのレイアウト関連の関数内に記載し、Webページ上に配置していくことになります。Output関数の使い方は単純で、引数にoutputIdを文字列として取るだけです。\n\n\n\nOutput関数\n\ntextOutput(\"outputID\")\n\n\nInput関数→render関数→Output関数の流れができれば、入力に従う出力を返す、Shinyアプリが出来上がります。inputでinputIdを設定し、serverではinput$InputIdを変数として用いてoutput$outputIdを作成します。outputIdはOutput関数の引数とすることでUIに配置します。一連の流れは以下の図のような形となります。\n\n\n\n図9：Input→render→Outputの流れ",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Shiny</span>"
    ]
  },
  {
    "objectID": "chapter35.html#global.rとwwwフォルダ",
    "href": "chapter35.html#global.rとwwwフォルダ",
    "title": "35  Shiny",
    "section": "35.7 global.Rとwwwフォルダ",
    "text": "35.7 global.Rとwwwフォルダ\nShinyでは、ui.Rやserver.R内で変数や関数を設定したり、ライブラリを読み込んだりすることができます。ただし、Shinyのファイルが2つに分かれていることもあり、ui.Rやserver.R中にアプリの準備に関わるコードを書き込んでしまうと理解しにくくなります。\nこのような変数・関数の設定やライブラリの読み込みを分離して記載するために用いられるのがglobal.Rというファイルです。これは通常のRファイルであり、ui.Rやserver.Rを作成する時のようにRStudioの操作で作成するものではありません。作成中のアプリのフォルダ、ui.Rやserver.Rが保管されている場所にglobal.Rを作成し、変数・関数の設定、ライブラリの読み込み等を書き込みます。このglobal.RはShinyアプリを起動する際に実行されるため、ui.Rやserver.Rに余分なスクリプトを書き込む必要がなくなります。\nまた、Shinyで表示するための画像や動画、javascriptのコードなどは、ui.Rやserver.Rと同じフォルダ内にwwwという名前のフォルダを作成し、wwwフォルダ内に保存することで、Shinyで呼び出すことができます。必要に応じてglobal.Rやwwwフォルダを作成することで、コードを整理し、画像等をShinyで取り扱うことができるようになります。",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Shiny</span>"
    ]
  },
  {
    "objectID": "chapter35.html#observerとreactive",
    "href": "chapter35.html#observerとreactive",
    "title": "35  Shiny",
    "section": "35.8 observerとreactive",
    "text": "35.8 observerとreactive\n\n35.8.1 observer\nShinyでは上記の通り、inputが変更されるとserver.Rに書いたスクリプトが自動的に実行されます。Shinyでは、inputに対する変更を読み取り、自動的にそのinputが関与しているserver.R内のコードを実行するようになっています。このような仕組みはobserverと呼ばれるものによって行われています。observerはその名の通り、inputの変更を「観察」していて、変更に応じて必要なコードをすぐに実行するShinyの内部的な機能です。\nこのobserverの代表的なものが、output$outputId&lt;-renderXX()という表現と、observe関数です。output$outputId&lt;-renderXX()は上に示した通り、output$outputIdにrender関数を代入する表現です。この表現が書かれている部分はrender関数内のinputIdの変更を捉えて、変更があればすぐにrender関数内のコードが実行されます。observe関数はそれ自体は何もしませんが、observe関数内に存在するinputIdが変更されるとinputIdに関わるコードを即実行するという機能を持ちます。\nrender関数、observe関数のどちらのobserverもShinyを使っているときにも作成するときにも特に意識する必要はありません。ただし、重めの計算を含むShinyではこのobserverだけを用いていると、Shinyのレスポンスが悪くなってしまいます。\n簡単な例として、以下のui.R、server.RからなるShinyアプリを実行するとします。\n\n\n\nui.R\n\n# 実際にはuiにlayoutが必要\nsliderInput(\"n1\",\"N of rpois 1:\",min = 1000000,max = 5000000,value = 2000000),\nsliderInput(\"n2\",\"N of rpois 2:\",min = 1000000,max = 5000000,value = 2000000),\nverbatimTextOutput(\"output_rpois\")\n\n\n\n\n\nserver.R\n\n#実際にはserverに`function`が必要\nr1 &lt;- input$n1 |&gt; rpois(5)\nr2 &lt;- input$n2 |&gt; rpois(5)\n\noutput$output_rpois({\n  paste(mean(r1), mean(r2))\n})\n\n\n上記は、平均値5のポアソン分布に従う乱数を100万～500万個、2セット作成し、その平均値を文字列として返すだけのShinyアプリです。返ってくる値はほぼ5になるので何の意味もないアプリですが、このShinyを走らせた場合、1つ目のsliderInput（input$n1）を変更すると、1つ目のsliderInputの返り値（mean(r1)）だけでなく、2つ目のsliderInputの返り値（mean(r2)）も計算され、値が変化します。\nだから何なのか、という感じですが、input$n1のみ変更しているのに、input$n1が含まれるr1の演算だけでなく、input$n2のみが含まれるr2の演算も勝手に行われている、ということになります。これがobserverが行っている演算の仕組みで、必要となるコードを自動的に検出し、すべての演算を実行します。図で示すと、以下のような流れで演算が行われていることになります。\n\n\ninput$n1が変更されると、input$n1に依存しているserver.R側のr1が演算されます。\n次に、r1に依存しているoutput$output_rpoisが演算されるわけですが、このoutput$output_rpoisの演算にはr2が必要です。\nそこで、Shinyはr2を読みに行きますが、r2はinput$n2に依存しています。\nですので、次にshinyはinput$n2を読みに行きます。\ninput$n2は変更されていませんが、値はありますので、r2を演算します。\nr1、r2がそろったので、output$output_rpoisを演算します。\n\ninput$n2には変更がなく、r2を演算する必要はなさそうに見えますが、observerは必要なコードをすべて、即時に演算するため、input$n2からr2を演算することになります。\nこのような演算はr2に当たる部分の演算が軽いうちは大きな問題にはなりませんが、r2の演算がとても重いとき、例えばデータベースに問い合わせて大きなデータを読み出し、時系列分析した結果が代入されている、といった場合には演算に非常に時間がかかるようになり、Shinyアプリのレスポンスが悪くなります。ですので、重めの演算はできれば演算回数を減らしたいところです。\n\n\n35.8.2 reactive\n上記のように、observerでは必要のない演算を繰り返し行うことになります。このように演算を繰り返したくない場合に用いるのが、reactive関数です。reactive関数は、\n\nreactive関数内のinput$inputIdに変更があった場合には演算を行う\nreactive関数内のinput$inputIdに変更がない場合は、以前に演算した値（cache）を返す\n\nという特徴を持った関数です。このreactive関数を用いて以下のようにserver.Rを書き直します。\n\n\n\nserver.R（reactive関数を用いた方法）\n\nr1 &lt;- reactive(input$n1 |&gt; rpois(5))\nr2 &lt;- reactive(input$n2 |&gt; rpois(5))\n\noutput$output_rpois({\n  paste(mean(r1()), mean(r2()))\n})\n\n\n上のコードでは、reactive関数の引数としてinput$n1 |&gt; rpois(5)を取り、r1に代入しています。このr1は関数オブジェクトになっており、値を呼び出す場合にはカッコを付ける（r1()）必要があります。同様にr2をreactive関数を用いて準備しています。\nこのようなserver.Rを用いた場合、Shinyの初回起動時にはすべての変数（r1、r2、output$output_rpois）が演算されます。これはreactiveを用いない場合と同じです。\nShinyアプリの起動後に、input$n1を変更した場合には、上記のreactiveを用いない場合とは演算の経路が異なってきます。reactiveを用いた場合の演算の経路を以下の図に示します。\n\n1、2に関してはobserverの時と同じです。output$output_rpoisを準備する際にr2を読みに行きますが、この際にr2がreactiveで包まれていると、前回演算した時のr2（cache）の値をoutput$output_rpoisの準備に用いることができ、r2をinput$n2から再演算しなくなります。\n上記のようなr1、r2の演算コストの低いShinyアプリではreactiveを設定する必要は必ずしもありませんが、reactive関数をうまく用いることでよりレスポンスのよいアプリを作成することができるでしょう。\n\n\n35.8.3 observeEventとeventReactive\n\n35.8.3.1 observeEvent\nreactiveは比較的使い方を理解しやすいのですが、observeは何も返さず、使い方のわからない関数です。これは、observeが他の関数を準備するために作成されたprimitiveな（大元の）関数であるためです。observeをより分かりやすく、実用的に利用するための関数がobserveEvent関数です。observeEvent関数は第一引数にinput$inputId、第二引数にスクリプトを取ります。observeEventは主にactionButtonと共に用い、actionButtonを押した時に後ろに記載したコード実行されるような場合に用います。observeEvent自体は返り値を返さないので、この関数自体をoutput$outputIdに代入することはできません。\n\n\n\nserver.R: observeEvent関数\n\nobserveEvent(input$inputButton1, {message(\"button pressed.\")})\n\n\n\n\n35.8.3.2 eventReactive\n一方で、ボタンを押すなどのイベントによってreactiveに応答を求める時にはeventReactiveを用います。eventReactiveの返り値は関数オブジェクトで、reactiveと同じようにカッコをつけることでserver.R内で呼び出すことができます。\n\n\n\nserver.R: eventReactive関数\n\nbuttonpressed &lt;- eventReactive(input$inputButton1, {print(\"button pressed.\")})\n\n\n\n\n\n35.8.4 reactiveValとreactiveValue\nreavtiveの名前がついている関数は他にもあります（reactiveVal、reactiveValue、reactiveTimer）。名前が紛らわしい上にレスポンスが分かりにくい関数群ですが、それぞれに特徴があります。\nまず、reactiveValとreactiveValuesです。この2つは値を記録しておくために用いる関数ですが、reactiveの特徴（cacheなど）と、参照渡しの特徴を持ちます。\n\n\n\nreactiveValとreactiveValue\n\nx &lt;- y &lt;- reactiveVal(5) # xとyにreactiveVal(5)を代入\nx # xは5（Quartoでは演算されない）\ny # yも5（Quartoでは演算されない）\n\nx(10) # xの値を10に更新\nx # xは10（Quartoでは演算されない）\ny # yも10になる（Quartoでは演算されない）\n\nz &lt;- reactiveValues(a = 10, b = 15) # reactiveValuesには複数の値を設定できる\nz$a # render関数などの中で呼び出さないとエラー\n\n\n値渡し（Rの変数はほぼすべてこちら）とは異なり、上記の例であればxが変更されるとyも変更される、参照渡しが行われます。\nreactiveValは1つの値のみ、reactiveValuesはリストのように複数の値を保存することができます。reactiveValは通常のRのコンソールでも呼び出すことができますが、reactiveValuesはreactive/observerの中でしか呼び出せません。reactiveValuesではリストのように、$を用いて値を呼び出します。\nreactiveValもreactiveValuesもいまいち使い方が難しい関数ですが、数値を一時的に保存する場合には単なるreactiveや通常の変数ではなく、こちらを使うことを想定されているのかもしれません。\n\n\n35.8.5 reactiveTimerとinvalidatedLater\nShinyアプリの作成時には、単にinputに対して応答を求めるようなものだけではなく、一定時間ごとに演算や表示を行ってほしい場合もあります。このように、一定時間ごとに演算を行うような場合には、reactiveTimer関数を用います。reactiveTimer関数は引数に時間（intervalMs、ミリ秒単位）を取ります。reactiveTimer関数を用いることで、引数で指定した時間ごとに演算が行われるような仕組みをShinyに持ち込むことができます。\n\n\n\nreactiveTimer\n\na &lt;- reactiveTimer(2000)\n\noutput$outputId &lt;- renderText({\n  a() # reactiveTimerをrender関数内で呼び出す\n\n  # 2秒ごとに表示される\n  paste0(\"Hello world, \", input$inputId, \"! \", Sys.time()) \n})\n\n\n上記の例では、input$inputIdの変更がoutput$outputIdの更新を引き起こさず、2秒（2000ミリ秒）おきにoutput$outputIdが更新されるようになります。このreactiveTimerと類似した関数として、invalidateLater関数があります。invalidateLater関数はreactiveTimerと同じく初期のShinyから実装されている関数で、より安全でシンプルな関数であるとされています。invalidateLater関数は直接render関数内に書いて用います。ですので、上のコードと同じ演算を以下のような形で実装することができます。\n\n\n\ninvalidatedLater\n\noutput$outputId &lt;- renderText({\n  invalidatedLater(2000)\n  paste0(\"Hello world, \", input$inputId, \"! \", Sys.time())\n})",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Shiny</span>"
    ]
  },
  {
    "objectID": "chapter35.html#app.r",
    "href": "chapter35.html#app.r",
    "title": "35  Shiny",
    "section": "35.9 app.R",
    "text": "35.9 app.R\nココまではShinyアプリをui.R、server.Rの2つのファイルで開発する方法について説明してきました。複雑なShinyアプリを作成したい場合には、この2つのファイルを用いる方法が有効です。一方で、小規模のアプリを作る場合には2つのファイルを行き来するのが煩雑となる場合もあります。小規模アプリの開発では、app.Rという1つのファイルでShinyアプリを作成することもできます。\napp.Rを準備する場合には、上記の図2に示したファイル作成のウインドウで、「Single file (app.R)」を選択します。\n\n\n\n図10：Shinyのファイルを作成する\n\n\napp.Rを作成すると、以下のように1ファイル内にuiとserverが記載されたファイルが表示されます。uiにはfluidPageやfixedPage、TabsetPanelから始まるレイアウトを代入し、この中身にuiのレイアウト、input、Output等を記載していきます。\nserverには、server.Rと同様にfunction(input, output)を代入し、functionの{}の中に実行したいコードを記載していきます。\n最後のshinyApp(ui=ui, server=server)はShinyアプリを実行するための関数です。ですので、app.Rでもui.R/server.Rでも、uiとserverの中身を作成していくことには違いはありません。\n\n\n\napp.Rの構成\n\nui &lt;- fluidPage(\n  # ....コードを記載....\n)\n\nserver &lt;- function(input, output){\n  # .....コードを記載....\n}\n\nshinyApp(ui = ui, server = server)",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Shiny</span>"
    ]
  },
  {
    "objectID": "chapter35.html#shinyに機能を追加するextensions",
    "href": "chapter35.html#shinyに機能を追加するextensions",
    "title": "35  Shiny",
    "section": "35.10 Shinyに機能を追加する（Extensions）",
    "text": "35.10 Shinyに機能を追加する（Extensions）\nShinyには、上記のlayout、Input、Output、renderなどの基本的な関数だけでなく、追加の機能を与えるためのライブラリ（Extensions）が豊富に存在します。以下に代表的なExtensionsの例を示します。\n\nshinythemes(Chang 2021)\n\nShinyのデザインをBootstrapに従って変更するためのライブラリです。\n\nshinydashboard(Chang and Borges Ribeiro 2021)\n\nShinyでダッシュボードを簡単に作成するためのライブラリです。基本的にはShinyにダッシュボード用のレイアウト関数を追加するライブラリとなっています。\n\nbslib(Sievert, Cheng, and Aden-Buie 2024)\n\nshinythemesと同様にShinyのデザインを変更するためのライブラリです。こちらは前章で紹介したR markdown・QuartoのHTML出力のデザインを変更することもできます。また、レイアウトの関数をいくつか備えており、これらのレイアウト関数を用いることでダッシュボードを作成することもできます。shinythemesとshinydashboardはかなり前に開発されたライブラリであるため、このbslibに統合されたような形となっているようです。デザイン性の高いShinyアプリを作成するのであれば、まずこのライブラリを用いることを検討するのがよいでしょう。\n\nDT(Xie, Cheng, and Tan 2024)\n\nShinyやR markdownにJavascript製の表を表示するためのライブラリです。Javascriptで開発され、用いられているDataTablesというライブラリをRに持ち込んだものです。Shinyで用いるための専用のOutput、render関数を備えています。\n\nshinycssloaders(Sali and Attali 2020)\n\nShinyにデータを演算中（ローディング中）であることを示すアニメーションを追加するためのライブラリです。計算が重めのShinyを作成する際に用いるとよいでしょう。\n\nshinymanager(Thieurmel and Perrier 2022)\n\nShinyにIDとパスワードによるログイン機構を追加するためのライブラリです。セキュリティ的には怪しいので、あまり信用はできませんが、社内のシステムで用いるぐらいなら耐えられるかもしれません。\nShinyにはこの他にもたくさんのExtensionsが存在します。このGithubのページに一覧が示されていますので、参考にされるとよいでしょう。\nまた、Shinyの開発を行っている企業であるappsilonは、Shiny開発のフレームワークやデザインに関するライブラリを多数開発しています。ハイエンドなShinyアプリを開発したいのであればチャレンジする価値があるかと思います。",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Shiny</span>"
    ]
  },
  {
    "objectID": "chapter35.html#アプリをデプロイする",
    "href": "chapter35.html#アプリをデプロイする",
    "title": "35  Shiny",
    "section": "35.11 アプリをデプロイする",
    "text": "35.11 アプリをデプロイする\nShinyアプリを作成したら、他の人に使ってもらってデータを共有・説明したいはずです。Shinyアプリを自分のPCで動かすだけであれば、Rから実行するのが最も簡単ですが、Webを通じてShinyアプリを公表したい場合には、アプリをデプロイする必要があります。\nデプロイとは、インターネットでアクセスできるPC（Webサーバー）にWebアプリを実行する環境を整えることを指します。我々が使っている多くのWebサービス（Webアプリ）は、Amazon Web Services（AWS）やGoogle CloudなどのWebサーバーで実行されています。Shinyアプリも同様にWebサーバーにデプロイすることで、Webブラウザからアクセスし、利用することができます。\nShinyの開発元であるPositはShinyアプリを簡単にデプロイするサービスである、shinyapps.ioやPosit Connectを展開しています。また、同じくPositが開発したShiny serverを用いることで、AWSやGoogle Cloudに比較的簡単にデプロイすることができます。\nPosit Connectはエンタープライズ版で、セキュリティ面などがしっかりしています。一方で価格が相当高いので（今は公開されていませんが、昔は$5000/monthぐらいからだったと思います）、個人で安価にデプロイしたいのであればShinyapps.ioかShiny serverの2択となります。\n\n35.11.1 shinyapps.io\n最も簡単に、無料、もしくは安価にShinyアプリを公開したいのであれば、Shinyapps.ioを用いるのがよいでしょう。Shinyapps.ioを用いるためには、まずShinyapps.ioのホームページ上でアカウントを作成する必要があります。shinyapps.ioに移動し、「sign up」からアカウントを作成しましょう。shinyapps.ioのアカウントを作らずに、Googleやfacebookのアカウントを用いてログインすることもできます。\n\nアカウントが作成できたら、Rstudio上で、エディタの右上にある「Publish」のボタンをクリックします。\n\n\n\n図：Publishボタン\n\n\npublishボタンを押すと、初回には2つのライブラリ（packrat(Atkins et al. 2023)とrsconnect(Atkins et al. 2024)）のインストールが求められますので、RStudioの指示に従いライブラリをインストールします。\n次に、接続するアカウントの種類を選択するウインドウが表示されますので、「shinyapps.io」を選択します。\n\n\n\n図：サービスの選択画面\n\n\nshinyapps.ioを選択すると、Tokenを入力するよう指示が出ますので、shinyapps.ioにログインし、アカウント名が表示されている部分からTokenを表示、コピーして貼り付けます。\n\n\n\n図：Tokenを貼り付ける\n\n\nTokenを貼り付け、Connect Accountを選択すると、shinyapps.ioのアカウントとRStudioが繋がり、簡単にShinyアプリをデプロイできるようになります。\nこの状態で再び「Publish」をクリックすると、下のようなダイアログが表示されます。Publishポタンを押せばデプロイは完了です。\n\n\n\n図：PublishでShinyapps.ioにデプロイする\n\n\nPublishした後にWebブラウザからshinyapps.ioにログインすると、以下のようなページが表示されます。Publishしたアプリのリストが表示されていますので、以下の図の赤枠の部分をクリックするとアプリを起動することができます。\n\n\n\n図：アプリケーションの起動\n\n\nこの方法で実行したShinyアプリはローカル（自分のPC）で演算するのではなく、Positが管理しているWebサーバでアプリを実行するようになっています。URLをコピーし、共有したい人にアクセスしてもらうことでShinyアプリをWeb上で実行してもらうことができます。\n\n\n35.11.2 shiny server\n上記のshinyapps.ioを用いる方法は非常に簡単で、お金もかかりませんが、一方で演算速度は遅く、たくさんの人が同時に接続することもできません。また、月あたりの使用時間が制限されています。shinyapps.ioは基本的にすべての人にShinyアプリを公開する形でデプロイするため、秘密情報を含むShinyアプリに利用するのにも向いていません。\nこのようなサーバーの速度・接続時間・秘密情報の問題を解決するには、自前でWebサーバーを立ち上げ、管理する必要があります。自前でサーバーを立ち上げるには、個人や会社のサーバーを利用する方法とWebサーバー（Amazon Web ServicesやGoogle Cloud）を用いる方法がありますが、いずれの方法においてもShinyアプリのデプロイにはShiny serverを用いるのが一般的です。Shiny serverを用いたShinyアプリのデプロイにはコンテナを用いることが多いかと思います。Shiny server、コンテナやコンテナを用いたデプロイの方法はこの入門書の範囲を超えてしまいますので、こちらの記事やこの記事などを参照下さい。\n\n\n35.11.3 GitHubで共有する\n上記の方法では、Webサーバーを用いてRでの演算をしており、自分のPC（ローカル）では演算を行いません。Webサーバーを用いる方法では、サーバーを借りる必要があり、お金がかかります。サーバーを借りず、アプリを使用する方のPCで直接Shinyアプリを実行する方法であれば、このようなサーバーを準備する必要はありません。\nShinyのコードだけを準備して、アプリを使用する方のPCでShinyアプリを実行する場合には、GitHubを用いるのが簡単です。GitHubはGitと呼ばれるバージョン管理システムのうち、リモートレポシトリと呼ばれるものを取り扱うWebサービスです。GitHubには公開・非公開のリモートレポジトリが多数登録されており、他者とコードを共有してプログラミングを行う際の重要なツールとなっています。\nGitやGitHubの詳しい説明は他の参考資料をご参照下さい。\nGitHubでは通常Gitのシステムを用いて、リモートレポジトリを作成・更新・アップロードするようにできていますが、Shinyアプリを共有する場合には、直接GitHubにコードを書き込んでも問題はありません。\nGitHubにShinyアプリのコードを登録すると、Shiny::runGitHub関数でそのアプリを実行できるようになります。この章の一番始めに紹介した以下のコードは、このrunGitHub関数を用いてShinyアプリを実行するものとなっています。\n\n\n\nrunGitHub関数\n\nif(!require(shiny)) install.packages((\"shiny\")) # shinyの読み込み\nshiny::runGitHub(\"surv_sim\", \"sb8001at\") # runGitHub関数で\"surv_sim\"というレポジトリのアプリを読み込み、実行\n\n\n上記の例では、\"sb8001at\"というアカウントのGitHubのレポジトリである\"surv_sim\"を読み込み、Rで実行させるためのコードです。GitHubではこのようなレポジトリを通常sb8001at/surv_simという形で表現します。このレポジトリは公開されているもので、このページでコードを確認することができます。\n\n上記ページの「ui.R」を選択すると、以下のようにui.Rのコードを読むことができます。\n\n上記のrunGitHub関数はこのページのui.R、server.R、global.Rを読み込み、Shinyアプリを実行する関数です。GitHubでのアカウント作成・レポジトリの準備やコードの入力方法に関しては、この教科書の範囲から外れるためココでは詳細を説明しませんので、この記事などを参考にしていただければと思います。\n最後に、Shinyアプリで用いられるUI、Serverのコードと実行時のページをイメージするためのShinyアプリを以下に示します。以下のコードをコピペしてRで実行していただければ、UIやServerのイメージがつかみやすいかと思います。\n\n\n\nShinyのサンプルアプリ\n\nif(!require(shiny)) install.packages((\"shiny\")) # shinyの読み込み\nshiny::runGitHub(\"shiny_sample\", \"sb8001at\")\n\n\n\n\n\n\n\n図1：Shinyのファイルを作成する\n図2：Shinyのファイルを作成する\n図3：Shinyアプリの例とRun Appアイコン\n図4：Shinyサンプルを起動する\n図5：Number of binsを変更する\n図6：Shinyアプリのおおまかな仕組み\n図7：navbarPageによるタブ\n図8：sidebarLayoutの例\n図9：Input→render→Outputの流れ\n図10：Shinyのファイルを作成する\n図：Publishボタン\n図：サービスの選択画面\n図：Tokenを貼り付ける\n図：PublishでShinyapps.ioにデプロイする\n図：アプリケーションの起動\n\n\n\nAtkins, Aron, Toph Allen, Kevin Ushey, Jonathan McPherson, Joe Cheng, and JJ Allaire. 2023. Packrat: A Dependency Management System for Projects and Their r Package Dependencies. https://CRAN.R-project.org/package=packrat.\n\n\nAtkins, Aron, Toph Allen, Hadley Wickham, Jonathan McPherson, and JJ Allaire. 2024. Rsconnect: Deploy Docs, Apps, and APIs to ’Posit Connect’, ’Shinyapps.io’, and ’RPubs’. https://CRAN.R-project.org/package=rsconnect.\n\n\nChang, Winston. 2021. Shinythemes: Themes for Shiny. https://CRAN.R-project.org/package=shinythemes.\n\n\nChang, Winston, and Barbara Borges Ribeiro. 2021. Shinydashboard: Create Dashboards with ’Shiny’. https://CRAN.R-project.org/package=shinydashboard.\n\n\nChang, Winston, Joe Cheng, JJ Allaire, Carson Sievert, Barret Schloerke, Yihui Xie, Jeff Allen, Jonathan McPherson, Alan Dipert, and Barbara Borges. 2024. Shiny: Web Application Framework for r. https://CRAN.R-project.org/package=shiny.\n\n\nR Special Interest Group on Databases (R-SIG-DB), Hadley Wickham, and Kirill Müller. 2024. DBI: R Database Interface. https://CRAN.R-project.org/package=DBI.\n\n\nSali, Andras, and Dean Attali. 2020. Shinycssloaders: Add Loading Animations to a ’Shiny’ Output While It’s Recalculating. https://CRAN.R-project.org/package=shinycssloaders.\n\n\nSievert, Carson, Joe Cheng, and Garrick Aden-Buie. 2024. Bslib: Custom ’Bootstrap’ ’Sass’ Themes for ’Shiny’ and ’Rmarkdown’. https://CRAN.R-project.org/package=bslib.\n\n\nThieurmel, Benoit, and Victor Perrier. 2022. Shinymanager: Authentication Management for ’Shiny’ Applications. https://CRAN.R-project.org/package=shinymanager.\n\n\nWickham, Hadley, Maximilian Girlich, and Edgar Ruiz. 2024. Dbplyr: A ’Dplyr’ Back End for Databases. https://CRAN.R-project.org/package=dbplyr.\n\n\nXie, Yihui, Joe Cheng, and Xianying Tan. 2024. DT: A Wrapper of the JavaScript Library ’DataTables’. https://CRAN.R-project.org/package=DT.",
    "crumbs": [
      "アドバンスな手法",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Shiny</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "おわりに",
    "section": "",
    "text": "ver.0.4 (2025/3/18)\nこの文書をどうするべきか、しばらく悩んでいました。著作権的にはちょっと怪しげな部分があり（helpで表示されるコードとほぼ同じ部分がある、文献は引用はしているはず）、収益性のあるようなものにはできず、自分が勤めている企業のために作成したものであるものの、企業のコンプライアンス的に企業名などを出すのは難しい、しかし自社には読んでくれる人がいない。間違いがあるのも気になるところで、このまま放置してもよかったのですが、せっかく作ったものですので、公開してみることにしました。\nこの文で収益をあげる意思は全くなく、できればこのテキストをきっかけに参考文献・教科書を購入してRコミュニティに貢献してくれる方が増えるとよいなと考えています。\nPythonがRの役割をほぼこなせるようになり、Rの居場所はなくなっていくのかもしれません。しかし、過去のプログラミング言語もなんだかんだで生き残っているものが多いです。Rがしぶとく生き残るために少しでも貢献できるとうれしいです。",
    "crumbs": [
      "おわりに"
    ]
  },
  {
    "objectID": "summary.html#ver.0.4-2025318",
    "href": "summary.html#ver.0.4-2025318",
    "title": "おわりに",
    "section": "",
    "text": "文書を修正し、github pagesで公開しました。",
    "crumbs": [
      "おわりに"
    ]
  },
  {
    "objectID": "summary.html#ver-0.3-20241019",
    "href": "summary.html#ver-0.3-20241019",
    "title": "おわりに",
    "section": "ver 0.3 (2024/10/19)",
    "text": "ver 0.3 (2024/10/19)\n\n33章（ネットワーク解析）を追加しました。 ― 34章（Rmarkdown・Quarto）を追加しました。\n35章（Shiny）を追加しました。\n全体を読み直し、修正しました。\n\nネットワーク解析、Rmarkdown・Quarto、Shinyの解説を書くのに4か月、はじめから読み直して文書やコードを修正するのに2か月かかりました。特にネットワーク解析は一から勉強したのでなかなか大変でした。文章のボリュームが多すぎて、一度読み通すだけでもなかなか大変です。一から学ぶような場合を除けば、興味のある部分から読み進めてもらった方がよいかもしれません。特に地理空間情報、ネットワーク解析、Shinyあたりは使う人・使わない人が大きく分かれる分野のように思います。\nこの教科書は元々社内教育のために作成し始めたものです。大分ボリュームも大きくなりましたが、社内には読んでくれる人がほぼいません。せっかく作ったものですので、オンラインで公開する準備を進めたいと思います。\n2024年のノーベル化学賞・物理学賞にAI関連の技術が選ばれたように、AI開発が花盛りといったところです。AIについては不勉強でよくわからないのですが、基本的には言語モデルであると理解しています。どのAIもGithubなどを学習していると思うので、RのスクリプトもAIに聞けば教えてくれる時代になっていくのだと思います。そのうちAIが機械語を直接書き出すかもしれません。そうなるとAIのやっていることが完全にブラックボックスになってしまうので、未来は面白いことになりそうです。\n将来的にAIで直接統計ができるようになるのは間違いないですが、もうしばらくは統計を行うためにRのスクリプトを教えてもらうような使い方が続くんじゃないかなと思います。また、秘密情報の関係でデータをAIに教えられない場合も多々あります。大企業であれば秘密情報を投げられるAIを契約できても、中小企業や個人経営者、大学の研究者などがそのような契約に大金を支払うのは難しいでしょう。\nそもそもAIはとてつもなく計算力を食います。つまり全くエコではないので、大企業がエコを歌いながらAIを使い倒す、というのも何だか矛盾しているように思います。早く仕事も研究もAIにバトンタッチしたいところではありますが、そこらへんにいるヒトはArtificialではないですが、運動機能付きのIntelligenceです。精々2000 kcal/日ぐらいで動くIntelligenceであるヒトを使う方がエコなので、まだしばらくはヒトが働く時代が続くのでしょう。まあ、エネルギー面以外ではヒトは非エコですが…。\n特に大学の研究者などは、分析をAI任せにはなかなかできません。データを説明可能にすることも研究者の役割の一つです。AIが吐き出してくれた統計のためのスクリプトを理解するために、しばらくはこのような教科書も有用なのではないかと思います。",
    "crumbs": [
      "おわりに"
    ]
  },
  {
    "objectID": "summary.html#ver-0.22024414",
    "href": "summary.html#ver-0.22024414",
    "title": "おわりに",
    "section": "ver 0.2（2024/4/14）",
    "text": "ver 0.2（2024/4/14）\n\n31章（purrr）を追加しました。\n32章（地理空間情報）を追加しました。\n26章にspline回帰と加法モデルについての内容を追記しました。\n\n一般化加法モデル（Generalized Additive Model）については名前は知っていたものの、内容がよくわかっていなかったため以前は記載していませんでした。教科書を読んでわかったことを簡単に表記しています。ただし、スクリプト上ではOzoneが正規分布していないのに正規分布しているようなモデルになっています。いずれ修正します。また、同様によくわかっていなかったpurrrと地理空間情報の取り扱いについても学習し、入門の内容程度のものをまとめました。正直purrrを活用しきれる気があまりしません。apply関数群ですらいまいち使えていないのに…。あと3章（ネットワーク解析、Quartoとrmarkdown、Shiny）ほど書いたらどこかにデプロイしようと思います。",
    "crumbs": [
      "おわりに"
    ]
  },
  {
    "objectID": "summary.html#ver-0.12024219",
    "href": "summary.html#ver-0.12024219",
    "title": "おわりに",
    "section": "ver 0.1（2024/2/19）",
    "text": "ver 0.1（2024/2/19）\nとりあえずRプログラミングの基礎、統計の基礎について最低限の内容は記載したので、公開することとします。内容には（特に統計に関わる24章以降は）間違いがあると思います。できれば手元に統計の教科書（少なくとも統計学入門（基礎統計学Ⅰ）(東京大学教養学部統計学教室 1991)）を置いて、統計的な正しさを確認しながら読んでいただければ幸いです。\nRではここ10年ぐらいで様々なことができるようになりました。このテキストにはまだ記載していませんが、RmarkdownやQuartoといったライブラリを用いればhtmlやwordの文章を、Shinyというライブラリを用いればWebアプリケーションを、Plumberを用いればweb APIを作成することができ、やや「普通のプログラミング言語」に近づいた感じがあります。ただし、RStudioがPositという社名に変更になり、Pythonにも注力し始めたことから、Rが主要な統計プログラミング言語であり続けられるかどうかは微妙なところです。2010年ぐらいまではPythonは2.0から3.0への移行で躓いていたため、統計や機械学習をRで行うのはそれほど不自然ではありませんでしたが、2023年現在では機械学習はほぼPythonで行うものとなり、統計もかなりPythonでできることが増えています。Pythonは汎用言語であり、Rよりもずっと「何でもできる」言語です。RがPythonに立場を完全に奪われるのか、RはRなりに生き延びるのか微妙なところではありますが、このテキストがRを生き延びさせる一助になれば良いなあと考えております。\n教科書を書いて思ったこととしては、我ながらRのことも統計のことも全くわかっていないということです。学べば学ぶほど、よくわからないことが増えるのはどの分野でも同じですが、Rと統計に関してはほとんど独学で、人に学んだ経験がほとんどないため、書けば書くほどよくわからなくなっていく感が強いです。自分の専門であった基礎生物学であれば、細胞の分子生物学を一冊読めばある程度の基礎はわかり、もっと専門的なことは論文を読んでおけば学習はできるのですが、統計は手法ごとに教科書があり、数学的なバックグラウンドを求められるため、なかなか学びを進めるのが難しいものです。\nとはいえ、私が始めに統計を学んだときよりもわかりやすい教科書が増え、勉強がしやすくなったとは感じます。このテキストも入門としては必要最低限のところは抑えているつもりですが、できれば参考文献に記載した教科書や、Amazon等で検索し、教科書を数冊読んでみることをおススメします。このテキストを入口として、Rと統計を学ぶ人が増えればと感じます。\n\n\n\n\n\n\n東京大学教養学部統計学教室, ed. 1991. 統計学入門 (基礎統計学ⅰ). 単行本. 東京大学出版会. https://www.amazon.co.jp/dp/4130420658/.",
    "crumbs": [
      "おわりに"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "参考文献",
    "section": "",
    "text": "Rについての教科書",
    "crumbs": [
      "参考文献"
    ]
  },
  {
    "objectID": "references.html#rについての教科書",
    "href": "references.html#rについての教科書",
    "title": "参考文献",
    "section": "",
    "text": "R-tips(舟尾暢男 2016)\n\n\n\n\n\nまずは、R-tipsから紹介します。R-tipsは2020年ぐらいまではWeb上で見ることができていた、Rの入門にちょうどいいホームページでした。かなり昔から教科書としても販売されていました。Rのプログラミングから統計の基礎まで網羅しており、入門編として必要十分な内容を備えています。\n\n\nRで楽しむ統計(奥村 and 石田 2016)\n\n\n\n\n\nRで楽しむ統計はもう少し統計よりの内容になった、Rの入門の教科書です。著者の奥村先生のホームページにはRのスクリプトを含む情報がたくさんあり、昔からお世話になっていたものです。\n\n\nRによるやさしい統計学(山田, 杉澤, and 村井 2008)\n\n\n\n\n\nこちらも統計よりに近い内容の教科書です。内容はかなり統計よりになっていますが、平易な文章で書かれており、理解しやすいと思います。\n\n\nRによるデータサイエンス(金 2017)\n\n\n\n\n\nこちらも基礎からRを学べる教科書です。上記の教科書よりかなり最近に書かれたものです。\n\n\n私たちのR ベストプラクティスの探求(宋 and 矢内 2020)\n\n\n\n\n\nWeb版の教科書ですが、Rのプログラミング言語とした面について詳しく説明された教科書です。Web版でタダで読めますので、まずはこれでRに触れてみるのがよいでしょう。このテキストでは説明していないQuartoやRmarkdown、Webスプレイピングなどにも触れています。\n\n\n生物統計学\nこちらは昔からお世話になっている、Rに関する統計学的手法を取りまとめたホームページです。こちらを一通り読み通せば、Rや統計について一通りフォローできる内容になっています。\n\n\nからだにいいもの\n表題はともかく、このブログは10年ほど前からいろいろなRのライブラリを紹介し続けてくれているページとなっています。\n\n\n実践的データサイエンス\nこちらはUryuさんという方が書かれているものです。どちらかというとRというよりはデータサイエンスの基礎を押さえたものとなっており、内容は入門編としては少し難しめとなっています。\n\n\nR for Data Science(Wickham, Mine, and Grolemund 2023)\n\n\n\n\n\n英語の教科書では、まずHadley WickhamのR for Data Scienceを読んでみるのが良いでしょう。日本語版も英語の書籍版もありますが、Webサイトから読むと無料で利用できます。Hadley Wickhamはこの他にもWebで教科書を複数公開しており、英語さえできれば教科書を買うことなくRを学ぶことができます。\n\n\nAn Introduction to R\n日本語版\nRのマニュアルもRを学ぶ上で参考になるでしょう。最新のRの使い方（tidyverseやQuarto、Shinyなど）についての記載はありませんが、Rの基礎については十分に説明がされています。日本語版のマニュアルもあるため、一目通しておくとよいでしょう。\n\n\nWelcome to ModernDive\n\n\nHands-On Programming with R\n英語のテキストは無数にあります。上に入門編のテキストから2つを紹介しておきます。日本語のテキストは少なく、どうしても落穂ひろいしてしまうことになりがちですが、英語さえできればほぼ無料で一通りRを学ぶことができます。",
    "crumbs": [
      "参考文献"
    ]
  },
  {
    "objectID": "references.html#ggplot2",
    "href": "references.html#ggplot2",
    "title": "参考文献",
    "section": "ggplot2",
    "text": "ggplot2\n\nRグラフィックスクックブック(Chang 2019)\n\n\n\n\n\nggplot2の教科書では、このRグラフィッククックブックに目を通すのがよいでしょう。ちょっと分厚いですが、ggplot2の端から端までよく記載されている教科書です。\n\n\nggplot2: Elegant Graphics for Data Analysis(Wickham 2016)\n\n\n\n\n\n英語でもよければこちらのHadley Wickham謹製の教科書を読むのがよいでしょう。無料で読めますし、紙の媒体が欲しければAmazonでペーパーバックを購入することもできます。",
    "crumbs": [
      "参考文献"
    ]
  },
  {
    "objectID": "references.html#plotly",
    "href": "references.html#plotly",
    "title": "参考文献",
    "section": "plotly",
    "text": "plotly\n\nRによるインタラクティブなデータビジュアライゼーション: 探索的データ解析のためのplotlyとshiny(Sievert and 株式会社ホクソエム 2022)\n\n\n\n\n\nplotlyに関してはほとんど日本語の資料がないのですが、こちらの教科書はかなり良く書かれていてわかりやすいものとなっています。Webアプリケーション作成ライブラリであるShinyについても少し紹介されています。",
    "crumbs": [
      "参考文献"
    ]
  },
  {
    "objectID": "references.html#統計",
    "href": "references.html#統計",
    "title": "参考文献",
    "section": "統計",
    "text": "統計\n\n統計学入門（基礎統計学Ⅰ）(東京大学教養学部統計学教室 1991)\n\n\n\n\n\n統計の教科書の1冊目には、とりあえずこの教科書を選んでおくと問題ないでしょう。基礎からきちんと説明がされていて、常に手元に置いておくとよい教科書の一つです。東京大学教養学部統計学教室が出版している教科書には他にも2冊ありますので、一通り目を通すだけでも勉強になると思います。\n\n\nデータ分析に必須の知識・考え方　統計学入門(阿部真人 2021)\n\n\n\n\n\n統計学入門よりもう少し簡単な内容で、入門編として読みやすい教科書です。統計も何も知らない方が読んでも読みやすい内容になっています。同様のデザインの教科書がソシムのデータサイエンスというシリーズで出版されており、どれも読みやすく理解しやすい内容となっています。\n\n\n統計学入門\nこちらも昔からお世話になっているホームページで、統計の基礎的なことでわからないことがあればとりあえずココで確認することが多いです。著者は統計の教科書も数冊書かれています。\n\n\nR基本統計関数マニュアル\nRで統計を行うのであれば、とりあえずこのマニュアルに目を通すとよいでしょう。やや長いですが、基礎的な統計に関する関数の説明はほぼすべて記載されています。",
    "crumbs": [
      "参考文献"
    ]
  },
  {
    "objectID": "references.html#回帰",
    "href": "references.html#回帰",
    "title": "参考文献",
    "section": "回帰",
    "text": "回帰\n\nデータ解析のための統計モデリング入門(久保 2012)\n\n\n\n\n\n回帰について基礎から理解したいなら、とりあえずこの教科書を読むとよいでしょう。MCMCに関してはWinBugsという、2006年に開発が終わって、今ではあまり使われていないソフトウェアが紹介されていますが、内容をStanに読み替えれば今でも十分に役に立つ教科書です。\n\n\n統計モデルと推測(松井秀俊 and 小泉和之 2019)\n\n\n\n\n\nこちらはもう少し最近になって出版された教科書です。統計モデルというのは統計を扱ったことがないとよくわからない概念なのですが、こちらを一通り読めばある程度把握できると思います。\n\n\nGeneralized Additive Models: An Introduction with R(Wood 2017)\n\n\n\n\n\nGeneralized Additive Model（GAM、一般化加法モデル）はかなり複雑で、何をやっているのかよくわからない非線形回帰モデルの一つですが、この教科書では入門から計算の要点、mgcvの使い方まで一通り説明されています。GAMの日本語の教科書はあまりなく、この教科書ほど内容が充実しているものは無いように思います。ただし、内容はかなり難しく、行列演算がわからないと何を書いているのかわからない部分も多いです。しかし、現状この教科書より分かりやすいものも無いので、興味のある方は挑戦してみるとよいでしょう。",
    "crumbs": [
      "参考文献"
    ]
  },
  {
    "objectID": "references.html#分類",
    "href": "references.html#分類",
    "title": "参考文献",
    "section": "分類",
    "text": "分類\n\nRによる機械学習入門(金森敬文 2017)\n\n\n\n\n\n機械学習はPythonの領域、といった感じで、Rで機械学習を取り扱うことはそれほど多くないと思いますが、一通り機械学習の手法をRで試すのであればこの教科書を読むとよいでしょう。\n\n\nRによる多変量解析入門 データ分析の実践と理論(川端, 岩間, and 鈴木 2018)\n\n\n\n\n\nこちらも多変量解析、主成分分析や因子分析を始めとする、どちらかというと機械学習的な内容について解説した教科書です。",
    "crumbs": [
      "参考文献"
    ]
  },
  {
    "objectID": "references.html#時系列分析",
    "href": "references.html#時系列分析",
    "title": "参考文献",
    "section": "時系列分析",
    "text": "時系列分析\n\n時系列分析と状態空間モデルの基礎: RとStanで学ぶ理論と実装(馬場真哉 2018)\n\n\n\n\n\n時系列の基礎から応用まで、一通りすべて説明されている教科書です。時系列についてとりあえず一冊買うなら、これを買って試してみるのがよいでしょう。\n\n\nRとstanではじめる　心理学のための時系列分析入門(小森政嗣 2022)\n\n\n\n\n\n上の教科書よりもう少しとっつきやすい感じの教科書がこちらです。ただし、たどり着くところは上の教科書よりやや難しめです。",
    "crumbs": [
      "参考文献"
    ]
  },
  {
    "objectID": "references.html#生存時間解析",
    "href": "references.html#生存時間解析",
    "title": "参考文献",
    "section": "生存時間解析",
    "text": "生存時間解析\n\nApplied Survival Analysis Using R(Moore 2016)\n\n\n\n\n\n生存時間解析を行うことはほとんどないですし、耐久性試験やがんの第II、III相治験にでも関わらない限りそれほど学ぶ理由もないと思うのですが、Rに関連して一冊読むならこの教科書が一番簡単で理解しやすいと思います。もちろん英語の教科書ですが、内容はそれほど難しくなく、生存時間解析の基礎についてRのスクリプトと共によく説明されています。",
    "crumbs": [
      "参考文献"
    ]
  },
  {
    "objectID": "references.html#地理空間情報",
    "href": "references.html#地理空間情報",
    "title": "参考文献",
    "section": "地理空間情報",
    "text": "地理空間情報\n\nGeocomputation with R\n\n\n\n\n\nこちらも地理空間情報の取り扱いについて解説した教科書です。英語の原語版はこちらです。まだまだ情報が少ないsfパッケージの説明、leafletといった地理空間を取り扱うグラフィックライブラリの説明等の内容が充実しています。\n\n\n実践Data Scienceシリーズ Rではじめる地理空間データの統計解析入門(村上 2022)\n\n\n\n\n\nこちらは地理空間情報だけではなく、地理情報を用いた統計の手法を説明した教科書です。地理空間統計には興味があるのですが、あまりにもデータに触ることがないため知識がなく、このテキストにも記載はしていません。この教科書を読むと地理空間統計についてイメージしやすくなるのではないかと思います。",
    "crumbs": [
      "参考文献"
    ]
  },
  {
    "objectID": "references.html#ネットワーク解析",
    "href": "references.html#ネットワーク解析",
    "title": "参考文献",
    "section": "ネットワーク解析",
    "text": "ネットワーク解析\n\nネットワーク分析 第2版 (Rで学ぶデータサイエンス 8) (鈴木 2017)\n\n\n\n\n\nRでネットワーク解析を学ぶのであれば、とりあえずこれを1冊読むとよいでしょう。Rのネットワーク解析ライブラリであるsnaとigraphの両方について、ネットワーク解析の意味や手法を交えて基礎から詳しく記載されています。特にsnaについてはネット上にも情報が落ちていないので、きちんと学ぶのであれば他に選択肢がないように思います。ただし、同じ手法をsnaとigraphを用いて並行して説明されているので、やや読みにくい印象があります。",
    "crumbs": [
      "参考文献"
    ]
  },
  {
    "objectID": "references.html#rmarkdownquarto",
    "href": "references.html#rmarkdownquarto",
    "title": "参考文献",
    "section": "Rmarkdown・Quarto",
    "text": "Rmarkdown・Quarto\n\n再現可能性のすゝめ (Wonderful R 3) (高橋康介. and 石田 2018)\n\n\n\n\n\nRmarkdownについて一冊読むのであれば、この教科書が初心者でも読みやすいでしょう。RstudioとRmarkdownを用いた手法が一通り説明されています。やや独特の言い回しが多いので気になるかもしれませんが、手元に置いておけばRでのレポート制作の役に立つでしょう。\nRmarkdownについての教科書は他にも数冊出ていますので、手に取ってみて肌に合うものを読んでみるとよいと思います。\n\n\nR Markdown: The Definitive Guide (J. J. Allaire and Grolemund 2023)\n\n\n\n\n\n英語でも良ければR markdownの開発者であるDr. Yihui Xie謹製のこちらの教科書を読むのが良いでしょう。この教科書を含め、Posit.ioが公表している教科書はほぼすべてbookdownパッケージ(Xie 2024, 2016)、もしくはこの機能を引き継いだQuartoで作成されています。このR入門もQuartoで作成している教科書です。bookdownで作成された教科書の一覧も公開されていますので、R markdownだけでなく他のRの教科書を探すのにも便利です（ただし、日本語のものは上で紹介したものを除き、ほとんどありません）。\nQuartoについてはあまり良い教科書がありません。QuartoのGuideを読むのが最も簡単に学ぶ方法だと思います。34章や上で紹介した日本語の教科書(宋 and 矢内 2020)から入門するのが最もよいでしょう。",
    "crumbs": [
      "参考文献"
    ]
  },
  {
    "objectID": "references.html#shiny",
    "href": "references.html#shiny",
    "title": "参考文献",
    "section": "Shiny",
    "text": "Shiny\n\nRとShinyで作るWebアプリケーション(梅津 and 中野 2018)\n\n\n\n\n\nRでWebアプリケーションを作成するためのライブラリであるShinyに関する教科書は、特に日本語ではほぼありません。現状これがほぼ唯一の教科書で、Shinyについて学ぶのであればとりあえずこれを読むことになります。唯一の教科書ですが、内容は非常に充実していて、一通り読めば簡単なアプリケーションであればすぐに作成することができます。Shinyを用いれば（統計に関するWebアプリケーションを作る場合）、RubyのRailsや、PythonでDjangoやFlaskなどを学ぶよりも遥かに簡単にWebアプリケーションを作成することができます。とは言ってもPythonにはStreamlitという同等のフレームワークが開発されているため、ShinyよりStreamlitの方が主流になっていくのかもしれません。",
    "crumbs": [
      "参考文献"
    ]
  },
  {
    "objectID": "references.html#その他",
    "href": "references.html#その他",
    "title": "参考文献",
    "section": "その他",
    "text": "その他\n\nRとStanで始める ベイズ統計モデリングによるデータ分析入門(馬場真哉 2019)\n\n\n\n\n\nベイズ統計入門としてはかなり読みやすい教科書になっています。上記の「データ解析のための統計モデリング入門」と共にベイズ入門編としてとても良い教科書だと思います。\n\n\nStanとRでベイズ統計モデリング(松浦 and 石田 2016)\n\n\n\n\n\nベイズ入門後はこちらを読むとよいでしょう。具体的にベイズ統計でどのようなことができるのか、イメージするのに最適です。\n\n\n岩波データサイエンス Vol.1~6(岩波データサイエンス刊行委員会 2015)\n\n\n\n\n\n岩波データサイエンスシリーズは全6冊の薄めのテキストです。6冊それぞれにテーマ（ベイズとMCMC、自然言語処理、因果推論、地理空間、スパース、時系列）があり、テーマに基づいた解説がされています。教科書と連動したページもあります。比較的手に取りやすいので目を通しやすいテキストですが、内容は難しめです。\n\n\n欠測データ処理(高橋将宜. and 渡辺 2017)\n\n\n\n\n\nデータの欠測とそれを補完する手法についてまとめた教科書です。欠測データを埋めるというのは通常の分析ではそれほど行われないと思うのですが、治験ではLOCFやBOCF、回帰モデルを用いた補完などの欠測データ補完が昔からよく用いられています。この教科書ではRを利用した欠測データの補完について解説されています。\n\n\nLead2Amazon\n上記の教科書のReferenceは大体このページを利用してbibtexに変換して登録しています。ですので、Referenceのリンクは大体Amazonの販売ページに繋がっています。このテキストを読むことで、教科書の売り上げが1冊でも増えればいいなと思います。\n\n\n(Rで)マイクロアレイデータ解析\nRの入門時にお世話になったページです。生物系でかつ、マイクロアレイやHiSeqを用いるような方以外にはあまり必要のないものですが、実際の多変量解析で必要となる様々な手順が記載されています。",
    "crumbs": [
      "参考文献"
    ]
  },
  {
    "objectID": "references.html#実行環境",
    "href": "references.html#実行環境",
    "title": "参考文献",
    "section": "実行環境",
    "text": "実行環境\n\nsessionInfo()\n\nR version 4.4.0 (2024-04-24 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 22631)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=Japanese_Japan.utf8  LC_CTYPE=Japanese_Japan.utf8   \n[3] LC_MONETARY=Japanese_Japan.utf8 LC_NUMERIC=C                   \n[5] LC_TIME=Japanese_Japan.utf8    \n\ntime zone: Etc/GMT-9\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.4.0    fastmap_1.2.0     cli_3.6.2        \n [5] tools_4.4.0       htmltools_0.5.8.1 rstudioapi_0.16.0 rmarkdown_2.27   \n [9] knitr_1.46        jsonlite_1.8.8    xfun_0.48         digest_0.6.35    \n[13] rlang_1.1.3       evaluate_0.23",
    "crumbs": [
      "参考文献"
    ]
  },
  {
    "objectID": "references.html#文献",
    "href": "references.html#文献",
    "title": "参考文献",
    "section": "文献",
    "text": "文献\n以下は文献のリストとなります。\n\n\nAllaire, J. J., Christopher Gandrud, Kenton Russell, and CJ Yetman.\n2017. networkD3: D3 JavaScript Network Graphs from r. https://CRAN.R-project.org/package=networkD3.\n\n\nAllaire, JJ, Yihui Xie, Christophe Dervieux, Jonathan McPherson, Javier\nLuraschi, Kevin Ushey, Aron Atkins, et al. 2023. Rmarkdown: Dynamic\nDocuments for r. https://github.com/rstudio/rmarkdown.\n\n\nAlmende B.V. and Contributors, and Benoit Thieurmel. 2022.\nvisNetwork: Network Visualization Using ’Vis.js’ Library. https://CRAN.R-project.org/package=visNetwork.\n\n\nAltman, Naomi, and Martin Krzywinski. 2016. “Points of\nSignificance: P Values and the Search for Significance.”\nNature Methods 14 (1): 3–4. https://doi.org/10.1038/nmeth.4120.\n\n\nAtkins, Aron, Toph Allen, Kevin Ushey, Jonathan McPherson, Joe Cheng,\nand JJ Allaire. 2023. Packrat: A Dependency Management System for\nProjects and Their r Package Dependencies. https://CRAN.R-project.org/package=packrat.\n\n\nAtkins, Aron, Toph Allen, Hadley Wickham, Jonathan McPherson, and JJ\nAllaire. 2024. Rsconnect: Deploy Docs, Apps, and APIs to ’Posit\nConnect’, ’Shinyapps.io’, and ’RPubs’. https://CRAN.R-project.org/package=rsconnect.\n\n\nBache, Stefan Milton, and Hadley Wickham. 2022. Magrittr: A\nForward-Pipe Operator for r. https://CRAN.R-project.org/package=magrittr.\n\n\nBarrett, Tyson, Matt Dowle, and Arun Srinivasan. 2023. Data.table:\nExtension of ‘Data.frame‘. https://CRAN.R-project.org/package=data.table.\n\n\nBates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015.\n“Fitting Linear Mixed-Effects Models Using lme4.” Journal of Statistical\nSoftware 67 (1): 1–48. https://doi.org/10.18637/jss.v067.i01.\n\n\nBenjamin, Daniel J, James O Berger, Magnus Johannesson, Brian A Nosek,\nE-J Wagenmakers, Richard Berk, Kenneth A Bollen, et al. 2018.\n“Redefine Statistical Significance.” Nature Human\nBehaviour 2 (1): 6–10.\n\n\nBivand, Roger, Jakub Nowosad, and Robin Lovelace. 2023. spData:\nDatasets for Spatial Analysis. https://CRAN.R-project.org/package=spData.\n\n\nBoswell, Dustin, and Trevor Foucher. 2012. リーダブルコード\nーより良いコードを書くためのシンプルで実践的なテクニック (Theory in\nPractice). Translated by 角征典. 単行本（ソフトカバー）.\nオライリージャパン. https://www.amazon.co.jp/dp/4873115655/.\n\n\nBouchet-Valat, Milan. 2023. SnowballC: Snowball Stemmers Based on\nthe c ’Libstemmer’ UTF-8 Library. https://CRAN.R-project.org/package=SnowballC.\n\n\nBretz, Frank, Martin Posch, Ekkehard Glimm, Florian Klinglmueller, Willi\nMaurer, and Kornelius Rohmeyer. 2011. “Graphical Approaches for\nMultiple Comparison Procedures Using Weighted Bonferroni, Simes or\nParametric Tests.” Biometrical Journal 53 (6): 894–913.\nhttps://doi.org/10.1002/bimj.201000239.\n\n\nBryan, Jennifer. 2023a. Gapminder: Data from Gapminder. https://CRAN.R-project.org/package=gapminder.\n\n\n———. 2023b. Googlesheets4: Access Google Sheets Using the Sheets API\nV4. https://CRAN.R-project.org/package=googlesheets4.\n\n\nBürkner, Paul-Christian. 2017. “brms:\nAn R Package for Bayesian Multilevel Models\nUsing Stan.” Journal of Statistical\nSoftware 80 (1): 1–28. https://doi.org/10.18637/jss.v080.i01.\n\n\n———. 2018. “Advanced Bayesian Multilevel Modeling\nwith the R Package brms.” The R Journal 10 (1):\n395–411. https://doi.org/10.32614/RJ-2018-017.\n\n\n———. 2021. “Bayesian Item Response Modeling in R with\nbrms and Stan.”\nJournal of Statistical Software 100 (5): 1–54. https://doi.org/10.18637/jss.v100.i05.\n\n\nButts, Carter T. 2008. “Network: A Package for Managing Relational\nData in r.” Journal of Statistical Software 24 (2). https://doi.org/10.18637/jss.v024.i02.\n\n\n———. 2015. Network: Classes for Relational Data. The Statnet\nProject (http://www.statnet.org). https://CRAN.R-project.org/package=network.\n\n\n———. 2023. Sna: Tools for Social Network Analysis. https://CRAN.R-project.org/package=sna.\n\n\nCarpenter, Bob, Andrew Gelman, Matthew D Hoffman, Daniel Lee, Ben\nGoodrich, Michael Betancourt, Marcus Brubaker, Jiqiang Guo, Peter Li,\nand Allen Riddell. 2017. “Stan: A Probabilistic Programming\nLanguage.” Journal of Statistical Software 76 (1).\n\n\nChang, Winston. 2019. Rグラフィックスクックブック 第2版\nーggplot2によるグラフ作成のレシピ集. Translated by 石井弓美子,\n河内崇, and 瀬戸山雅人. 単行本（ソフトカバー）. オライリージャパン. https://www.amazon.co.jp/dp/4873118921/.\n\n\n———. 2021a. R6: Encapsulated Classes with Reference Semantics.\nhttps://CRAN.R-project.org/package=R6.\n\n\n———. 2021b. Shinythemes: Themes for Shiny. https://CRAN.R-project.org/package=shinythemes.\n\n\nChang, Winston, and Barbara Borges Ribeiro. 2021. Shinydashboard:\nCreate Dashboards with ’Shiny’. https://CRAN.R-project.org/package=shinydashboard.\n\n\nChang, Winston, Joe Cheng, JJ Allaire, Carson Sievert, Barret Schloerke,\nYihui Xie, Jeff Allen, Jonathan McPherson, Alan Dipert, and Barbara\nBorges. 2024. Shiny: Web Application Framework for r. https://CRAN.R-project.org/package=shiny.\n\n\nChen, Tianqi, Tong He, Michael Benesty, Vadim Khotilovich, Yuan Tang,\nHyunsu Cho, Kailong Chen, et al. 2023. Xgboost: Extreme Gradient\nBoosting. https://CRAN.R-project.org/package=xgboost.\n\n\nCheng, Joe, Barret Schloerke, Bhaskar Karambelkar, and Yihui Xie. 2023.\nLeaflet: Create Interactive Web Maps with the JavaScript ’Leaflet’\nLibrary. https://CRAN.R-project.org/package=leaflet.\n\n\nConsortium, Japanese Archipelago Human Population Genetics. 2012.\n“The History of Human Populations in the Japanese Archipelago\nInferred from Genome-Wide SNP Data with a Special Reference to the Ainu\nand the Ryukyuan Populations.” Journal of Human Genetics\n57 (12): 787–95. https://cir.nii.ac.jp/crid/1523106605673180672.\n\n\nCsardi, Gabor, and Tamas Nepusz. 2006. “The Igraph Software\nPackage for Complex Network Research.” InterJournal\nComplex Systems: 1695. https://igraph.org.\n\n\nCsárdi, Gábor, and Jim Hester. 2024. Pak: Another Approach to\nPackage Installation. https://CRAN.R-project.org/package=pak.\n\n\nCsárdi, Gábor, Tamás Nepusz, Vincent Traag, Szabolcs Horvát, Fabio\nZanini, Daniel Noom, and Kirill Müller. 2024. igraph: Network Analysis and Visualization in\nr. https://doi.org/10.5281/zenodo.7682609.\n\n\nDragulescu, Adrian, and Cole Arendt. 2020. Xlsx: Read, Write, Format\nExcel 2007 and Excel 97/2000/XP/2003 Files. https://CRAN.R-project.org/package=xlsx.\n\n\nFeinerer, Ingo, Kurt Hornik, and David Meyer. 2008. “Text Mining\nInfrastructure in r.” Journal of Statistical Software 25\n(5): 1–54. https://doi.org/10.18637/jss.v025.i05.\n\n\nFriedman, Jerome, Robert Tibshirani, and Trevor Hastie. 2010.\n“Regularization Paths for Generalized Linear Models via Coordinate\nDescent.” Journal of Statistical Software 33 (1): 1–22.\nhttps://doi.org/10.18637/jss.v033.i01.\n\n\nFritsch, Stefan, Frauke Guenther, and Marvin N. Wright. 2019.\nNeuralnet: Training of Neural Networks. https://CRAN.R-project.org/package=neuralnet.\n\n\nGabry, Jonah, Rok Cesnovar, and Andrew Johnson. 2023. Cmdstanr: R\nInterface to ’CmdStan’. https://mc-stan.org/cmdstanr/.\n\n\nGagolewski, Marek. 2022. “stringi:\nFast and Portable Character String Processing in\nR.” Journal of Statistical Software 103\n(2): 1–59. https://doi.org/10.18637/jss.v103.i02.\n\n\nGrolemund, Garrett, and Hadley Wickham. 2011. “Dates and Times\nMade Easy with lubridate.”\nJournal of Statistical Software 40 (3): 1–25. https://www.jstatsoft.org/v40/i03/.\n\n\nHadfield, Jarrod D. 2010. “MCMC Methods for Multi-Response\nGeneralized Linear Mixed Models: The MCMCglmm\nR Package.” Journal of Statistical Software\n33 (2): 1–22. https://www.jstatsoft.org/v33/i02/.\n\n\nHandcock, Mark S., David R. Hunter, Carter T. Butts, Steven M. Goodreau,\nPavel N. Krivitsky, and Martina Morris. 2018. Ergm: Fit, Simulate\nand Diagnose Exponential-Family Models for Networks. The Statnet\nProject (http://www.statnet.org). https://CRAN.R-project.org/package=ergm.\n\n\nHelske, Jouni. 2017. “KFAS: Exponential Family State\nSpace Models in R.” Journal of Statistical\nSoftware 78 (10): 1–39. https://doi.org/10.18637/jss.v078.i10.\n\n\nHijmans, Robert J. 2023. Raster: Geographic Data Analysis and\nModeling. https://CRAN.R-project.org/package=raster.\n\n\n———. 2024. Terra: Spatial Data Analysis. https://CRAN.R-project.org/package=terra.\n\n\nHunter, David R., Mark S. Handcock, Carter T. Butts, Steven M. Goodreau,\nand Martina Morris. 2008. “Ergm: A Package to Fit, Simulate and\nDiagnose Exponential-Family Models for Networks.” Journal of\nStatistical Software 24 (3): 1–29.\n\n\nIshida, Motohiro, and Taku Kudo. 2023. RMeCab: Interface to\nMeCab.\n\n\nIzrailev, Sergei. 2023. Tictoc: Functions for Timing r Scripts, as\nWell as Implementations of \"Stack\" and \"StackList\" Structures. https://CRAN.R-project.org/package=tictoc.\n\n\nJ. J. Allaire, Yihui Xie ahd, and Garrett Grolemund. 2023. R\nMarkdown: The Definitive Guide.\n\n\nJones, Payton J., Patrick Mair, and Richard J. McNally. 2018.\n“Visualizing Psychological Networks: A Tutorial in r.”\nFrontiers in Psychology 9. https://doi.org/10.3389/fpsyg.2018.01742.\n\n\nKaratzoglou, Alexandros, Alex Smola, and Kurt Hornik. 2023. Kernlab:\nKernel-Based Machine Learning Lab. https://CRAN.R-project.org/package=kernlab.\n\n\nKaratzoglou, Alexandros, Alex Smola, Kurt Hornik, and Achim Zeileis.\n2004. “Kernlab – an S4 Package for Kernel Methods in\nR.” Journal of Statistical Software 11 (9):\n1–20. https://doi.org/10.18637/jss.v011.i09.\n\n\nKassambara, Alboukadel, Marcin Kosinski, and Przemyslaw Biecek. 2021.\nSurvminer: Drawing Survival Curves Using ’Ggplot2’. https://CRAN.R-project.org/package=survminer.\n\n\nKnudson, Christina. 2022. Glmm: Generalized Linear Mixed Models via\nMonte Carlo Likelihood Approximation. https://CRAN.R-project.org/package=glmm.\n\n\nKomsta, Lukasz. 2022. Outliers: Tests for Outliers. https://CRAN.R-project.org/package=outliers.\n\n\nKrispin, Rami. 2023. TSstudio: Functions for Time Series Analysis\nand Forecasting. https://CRAN.R-project.org/package=TSstudio.\n\n\nKuhn, Max, and Hadley Wickham. 2020. Tidymodels: A Collection of\nPackages for Modeling and Machine Learning Using Tidyverse\nPrinciples. https://www.tidymodels.org.\n\n\nKuznetsova, Alexandra, Per B. Brockhoff, and Rune H. B. Christensen.\n2017. “lmerTest Package: Tests in\nLinear Mixed Effects Models.” Journal of Statistical\nSoftware 82 (13): 1–26. https://doi.org/10.18637/jss.v082.i13.\n\n\nLeisch, Friedrich, and Evgenia Dimitriadou. 2021. Mlbench: Machine\nLearning Benchmark Problems.\n\n\nLiaw, Andy, and Matthew Wiener. 2002. “Classification and\nRegression by randomForest.” R News 2 (3): 18–22. https://CRAN.R-project.org/doc/Rnews/.\n\n\nLiland, Kristian Hovde, Bjørn-Helge Mevik, and Ron Wehrens. 2023.\nPls: Partial Least Squares and Principal Component Regression.\nhttps://CRAN.R-project.org/package=pls.\n\n\nLupi, Claudio. 2009. “Unit Root CADF Testing with\nR.” Journal of Statistical Software 32 (2):\n20.\n\n\nMatsumoto, Makoto, and Takuji Nishimura. 1998. “Mersenne Twister:\nA 623-Dimensionally Equidistributed Uniform Pseudo-Random Number\nGenerator.” ACM Trans. Model. Comput. Simul. 8 (1):\n3–30. https://doi.org/10.1145/272991.272995.\n\n\nMeyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and\nFriedrich Leisch. 2023. E1071: Misc Functions of the Department of\nStatistics, Probability Theory Group (Formerly: E1071), TU Wien. https://CRAN.R-project.org/package=e1071.\n\n\nMoore, Dirk F. 2016. Applied Survival Analysis Using r (Use r!)\n(English Edition). Kindle版. Springer. https://www.amazon.co.jp/dp/B01FKDTW3W/.\n\n\nMorgan, Martin, and Marcel Ramos. 2023. BiocManager: Access the\nBioconductor Project Package Repository. https://CRAN.R-project.org/package=BiocManager.\n\n\nMüller, Kirill, and Lorenz Walthert. 2023. Styler: Non-Invasive\nPretty Printing of r Code. https://CRAN.R-project.org/package=styler.\n\n\nMurdoch, Duncan, and Daniel Adler. 2023. Rgl: 3D Visualization Using\nOpenGL. https://CRAN.R-project.org/package=rgl.\n\n\nNewman, D. J., S. Hettich, C. L. Blake, and C. J. Merz. 1998. “UCI\nRepository of Machine Learning Databases.” University of\nCalifornia, Irvine, Dept. of Information; Computer Sciences. http://www.ics.uci.edu/~mlearn/MLRepository.html.\n\n\nOlson, Matthew. 2017. JOUSBoost: Implements Under/Oversampling for\nProbability Estimation. https://CRAN.R-project.org/package=JOUSBoost.\n\n\nOoms, Jeroen. 2014. “The Jsonlite Package: A Practical and\nConsistent Mapping Between JSON Data and r Objects.”\narXiv:1403.2805 [Stat.CO]. https://arxiv.org/abs/1403.2805.\n\n\nOoms, Jeroen, Kornel Lesi?ski, and Authors of the dependency Rust\ncrates. 2023. Gifski: Highest Quality GIF Encoder. https://CRAN.R-project.org/package=gifski.\n\n\nPaux, Gautier, and Alex Dmitrienko. 2019. Mediana: Clinical Trial\nSimulations. https://CRAN.R-project.org/package=Mediana.\n\n\nPebesma, Edzer. 2018. “Simple Features for R:\nStandardized Support for Spatial Vector Data.”\nThe R Journal 10 (1): 439–46. https://doi.org/10.32614/RJ-2018-009.\n\n\nPebesma, Edzer, and Roger Bivand. 2023a. Spatial Data Science: With applications in R.\nChapman and Hall/CRC. https://doi.org/10.1201/9780429459016.\n\n\n———. 2023b. Spatial Data Science: With\napplications in R. London: Chapman; Hall/CRC. https://doi.org/10.1201/9780429459016.\n\n\nPebesma, Edzer, Thomas Mailund, and James Hiebert. 2016.\n“Measurement Units in R.” R Journal 8\n(2): 486–94. https://doi.org/10.32614/RJ-2016-061.\n\n\nPedersen, Eric J, David L Miller, Gavin L Simpson, and Noam Ross. 2019.\n“Hierarchical Generalized Additive Models in Ecology: An\nIntroduction with Mgcv.” PeerJ 7: e6876.\n\n\nPedersen, Thomas Lin. 2023. Patchwork: The Composer of Plots.\nhttps://CRAN.R-project.org/package=patchwork.\n\n\n———. 2024a. Ggraph: An Implementation of Grammar of Graphics for\nGraphs and Networks. https://CRAN.R-project.org/package=ggraph.\n\n\n———. 2024b. Tidygraph: A Tidy API for Graph Manipulation. https://CRAN.R-project.org/package=tidygraph.\n\n\nPedersen, Thomas Lin, and David Robinson. 2022. Gganimate: A Grammar\nof Animated Graphics. https://CRAN.R-project.org/package=gganimate.\n\n\nPetris, Giovanni. 2010. “An R Package for Dynamic\nLinear Models.” Journal of Statistical Software 36 (12):\n1–16. https://www.jstatsoft.org/v36/i12/.\n\n\nPetris, Giovanni, Sonia Petrone, and Patrizia Campagnoli. 2009.\nDynamic Linear Models with r. useR! Springer-Verlag, New York.\n\n\nPfaff, B. 2008. Analysis of Integrated and Cointegrated Time Series\nwith r. Second. New York: Springer. https://www.pfaffikus.de.\n\n\nPfaff, Bernhard. 2008. “VAR, SVAR and SVEC Models: Implementation\nWithin R Package vars.”\nJournal of Statistical Software 27 (4). https://www.jstatsoft.org/v27/i04/.\n\n\nPinheiro, José C., and Douglas M. Bates. 2000. Mixed-Effects Models\nin s and s-PLUS. New York: Springer. https://doi.org/10.1007/b98882.\n\n\nPinheiro, José, Douglas Bates, and R Core Team. 2023. Nlme: Linear\nand Nonlinear Mixed Effects Models. https://CRAN.R-project.org/package=nlme.\n\n\nPolack, Fernando P., Stephen J. Thomas, Nicholas Kitchin, Judith\nAbsalon, Alejandra Gurtman, Stephen Lockhart, John L. Perez, et al.\n2020. “Safety and Efficacy of the BNT162b2 mRNA Covid-19\nVaccine.” New England Journal of Medicine 383 (27):\n2603–15. https://doi.org/10.1056/NEJMoa2034577.\n\n\nProkhorenkova, Liudmila, Gleb Gusev, Aleksandr Vorobev, Anna Veronika\nDorogush, and Andrey Gulin. 2017. “CatBoost: Unbiased Boosting\nwith Categorical Features.” https://arxiv.org/abs/1706.09516.\n\n\nR Special Interest Group on Databases (R-SIG-DB), Hadley Wickham, and\nKirill Müller. 2024. DBI: R Database Interface. https://CRAN.R-project.org/package=DBI.\n\n\nRichard A. Becker, Original S code by, Allan R. Wilks. R version by Ray\nBrownrigg. Enhancements by Thomas P Minka, and Alex Deckmyn. Fixes by\nthe CRAN team. 2023. Maps: Draw Geographical Maps. https://CRAN.R-project.org/package=maps.\n\n\nRinker, Tyler W., and Dason Kurkiewicz. 2018. pacman: Package Management for\nR. Buffalo, New York. http://github.com/trinker/pacman.\n\n\nSali, Andras, and Dean Attali. 2020. Shinycssloaders: Add Loading\nAnimations to a ’Shiny’ Output While It’s Recalculating. https://CRAN.R-project.org/package=shinycssloaders.\n\n\nSarkar, Deepayan. 2008. Lattice: Multivariate Data Visualization\nwith r. New York: Springer. http://lmdvr.r-forge.r-project.org.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz\nMarbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2023. GGally:\nExtension to ’Ggplot2’. https://CRAN.R-project.org/package=GGally.\n\n\nSchoch, David. 2022. “Netrankr: An r Package for Total, Partial,\nand Probabilistic Rankings in Networks.” Journal of Open\nSource Software, no. 77: 4563.\n\n\nShi, Yu, Guolin Ke, Damien Soukhavong, James Lamb, Qi Meng, Thomas\nFinley, Taifeng Wang, et al. 2024. Lightgbm: Light Gradient Boosting\nMachine. https://CRAN.R-project.org/package=lightgbm.\n\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with\nr, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n\nSievert, Carson, Joe Cheng, and Garrick Aden-Buie. 2024. Bslib:\nCustom ’Bootstrap’ ’Sass’ Themes for ’Shiny’ and ’Rmarkdown’. https://CRAN.R-project.org/package=bslib.\n\n\nSievert, Carson, and 株式会社ホクソエム. 2022.\nRによるインタラクティブなデータビジュアライゼーション:\n探索的データ解析のためのplotlyとshiny. Translated by 輿石拓真,\n今井康貴, 髙木誠二, 和田尚樹, and 株式会社ホクソエム. 単行本. 共立出版.\nhttps://www.amazon.co.jp/dp/4320124863/.\n\n\nSignorell, Andri. 2023. DescTools: Tools for Descriptive\nStatistics. https://CRAN.R-project.org/package=DescTools.\n\n\nSimon, Noah, Jerome Friedman, Robert Tibshirani, and Trevor Hastie.\n2011. “Regularization Paths for Cox’s Proportional Hazards Model\nvia Coordinate Descent.” Journal of Statistical Software\n39 (5): 1–13. https://doi.org/10.18637/jss.v039.i05.\n\n\nSimpson, Gavin L. 2024. gratia: Graceful\nggplot-Based Graphics and Other Functions\nfor GAMs Fitted Using mgcv. https://gavinsimpson.github.io/gratia/.\n\n\nSjoberg, Daniel D., Mark Baillie, Charlotta Fruechtenicht, Steven\nHaesendonckx, and Tim Treis. 2023. Ggsurvfit: Flexible Time-to-Event\nFigures. https://CRAN.R-project.org/package=ggsurvfit.\n\n\nStan Development Team. 2023. “RStan: The\nR Interface to Stan.” https://mc-stan.org/.\n\n\nStrayer, Nick, Javier Luraschi, and JJ Allaire. 2022. R2d3:\nInterface to ’D3’ Visualizations. https://CRAN.R-project.org/package=r2d3.\n\n\nTay, J. Kenneth, Balasubramanian Narasimhan, and Trevor Hastie. 2023.\n“Elastic Net Regularization Paths for All Generalized Linear\nModels.” Journal of Statistical Software 106 (1): 1–31.\nhttps://doi.org/10.18637/jss.v106.i01.\n\n\nTeam, Stan Development. 2023. Stan Modeling Language Users Guide and\nReference Manual (version 2.33). https://mc-stan.org.\n\n\nTennekes, Martijn. 2018. “tmap:\nThematic Maps in R.” Journal of Statistical\nSoftware 84 (6): 1–39. https://doi.org/10.18637/jss.v084.i06.\n\n\nTerry M. Therneau, and Patricia M. Grambsch. 2000. Modeling Survival\nData: Extending the Cox Model. New York: Springer.\n\n\nTherneau, Terry M. 2023. A Package for Survival Analysis in r.\nhttps://CRAN.R-project.org/package=survival.\n\n\nThieurmel, Benoit, and Victor Perrier. 2022. Shinymanager:\nAuthentication Management for ’Shiny’ Applications. https://CRAN.R-project.org/package=shinymanager.\n\n\nTrapletti, Adrian, and Kurt Hornik. 2023. Tseries: Time Series\nAnalysis and Computational Finance. https://CRAN.R-project.org/package=tseries.\n\n\nUshey, Kevin, Jim Hester, and Robert Krzyzanowski. 2021. Rex:\nFriendly Regular Expressions. https://CRAN.R-project.org/package=rex.\n\n\nVanderkam, Dan, JJ Allaire, Jonathan Owen, Daniel Gromer, and Benoit\nThieurmel. 2018. Dygraphs: Interface to ’Dygraphs’ Interactive Time\nSeries Charting Library. https://CRAN.R-project.org/package=dygraphs.\n\n\nVaughan, Davis, Jim Hester, Tomasz Kalinowski, Will Landau, Michael\nLawrence, Martin Maechler, Luke Tierney, and Hadley Wickham. 2023.\nS7: An Object Oriented System Meant to Become a Successor to S3 and\nS4. https://CRAN.R-project.org/package=S7.\n\n\nVenables, W. N., and B. D. Ripley. 2002. Modern Applied Statistics\nwith s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nWand, Matt. 2023. KernSmooth: Functions for Kernel Smoothing\nSupporting Wand & Jones (1995). https://CRAN.R-project.org/package=KernSmooth.\n\n\nWarnholz, Sebastian. 2017. Aoos: Another Object Orientation\nSystem. https://CRAN.R-project.org/package=aoos.\n\n\nWickham, Hadley. 2007b. “Reshaping Data with the Reshape\nPackage.” Journal of Statistical Software 21 (12). https://www.jstatsoft.org/v21/i12/.\n\n\n———. 2007a. “Reshaping Data with the reshape Package.” Journal of\nStatistical Software 21 (12): 1–20. http://www.jstatsoft.org/v21/i12/.\n\n\n———. 2011. “The Split-Apply-Combine Strategy for Data\nAnalysis.” Journal of Statistical Software 40 (1): 1–29.\nhttps://www.jstatsoft.org/v40/i01/.\n\n\n———. 2014. “Tidy Data.” Journal of Statistical\nSoftware 59 (10): 1–23. https://doi.org/10.18637/jss.v059.i10.\n\n\n———. 2016a. Ggplot2: Elegant Graphics for Data Analysis.\nSpringer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\n———. 2016b. Ggplot2: Elegant Graphics for Data Analysis (Use\nr!). ペーパーバック. Springer. https://www.amazon.co.jp/dp/331924275X/.\n\n\n———. 2022a. Cubelyr: A Data Cube ’Dplyr’ Backend. https://CRAN.R-project.org/package=cubelyr.\n\n\n———. 2022b. Rvest: Easily Harvest (Scrape) Web Pages. https://CRAN.R-project.org/package=rvest.\n\n\n———. 2023a. Forcats: Tools for Working with Categorical Variables\n(Factors). https://CRAN.R-project.org/package=forcats.\n\n\n———. 2023b. Httr2: Perform HTTP Requests and Process the\nResponses. https://CRAN.R-project.org/package=httr2.\n\n\n———. 2023c. Pryr: Tools for Computing on the Language. https://CRAN.R-project.org/package=pryr.\n\n\n———. 2023d. Stringr: Simple, Consistent Wrappers for Common String\nOperations. https://CRAN.R-project.org/package=stringr.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy\nD’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019.\n“Welcome to the tidyverse.”\nJournal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWickham, Hadley, and Jennifer Bryan. 2023. Readxl: Read Excel\nFiles. https://CRAN.R-project.org/package=readxl.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis\nVaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Maximilian Girlich, and Edgar Ruiz. 2024. Dbplyr: A\n’Dplyr’ Back End for Databases. https://CRAN.R-project.org/package=dbplyr.\n\n\nWickham, Hadley, and Lionel Henry. 2023. Purrr: Functional\nProgramming Tools. https://CRAN.R-project.org/package=purrr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2023. Readr: Read\nRectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWickham, Hadley, Jim Hester, Winston Chang, and Jennifer Bryan. 2022.\nDevtools: Tools to Make Developing r Packages Easier. https://CRAN.R-project.org/package=devtools.\n\n\nWickham, Hadley, Evan Miller, and Danny Smith. 2023. Haven: Import\nand Export ’SPSS’, ’Stata’ and ’SAS’ Files. https://CRAN.R-project.org/package=haven.\n\n\nWickham, Hadley, Cetinkaya-rundel Mine, and Garrett Grolemund. 2023.\nR for Data Science: Import, Tidy, Transform, Visualize, and Model\nData. ペーパーバック. O’Reilly Media. https://www.amazon.co.jp/dp/1492097403/.\n\n\nWickham, Hadley, Davis Vaughan, and Maximilian Girlich. 2023. Tidyr:\nTidy Messy Data. https://CRAN.R-project.org/package=tidyr.\n\n\nWiesweg, Marcel. 2022. survivalAnalysis: High-Level Interface for\nSurvival Analysis and Associated Plots. https://CRAN.R-project.org/package=survivalAnalysis.\n\n\nWoo, Mason, Jackie Neider, Tom Davis, and Dave Shreiner. 1999.\nOpenGL Programming Guide: The Official Guide to Learning OpenGL,\nVersion 1.2. Addison-Wesley Longman Publishing Co., Inc.\n\n\nWood, S. N. 2017. Generalized Additive Models: An Introduction with\nr. 2nd ed. Chapman; Hall/CRC.\n\n\nWood, S. N. 2003. “Thin-Plate Regression Splines.”\nJournal of the Royal Statistical Society (B) 65 (1): 95–114.\n\n\n———. 2004. “Stable and Efficient Multiple Smoothing Parameter\nEstimation for Generalized Additive Models.” Journal of the\nAmerican Statistical Association 99 (467): 673–86.\n\n\n———. 2011. “Fast Stable Restricted Maximum Likelihood and Marginal\nLikelihood Estimation of Semiparametric Generalized Linear\nModels.” Journal of the Royal Statistical Society (B) 73\n(1): 3–36.\n\n\nWood, S. N., N., Pya, and B. S\"afken. 2016. “Smoothing Parameter\nand Model Selection for General Smooth Models (with Discussion).”\nJournal of the American Statistical Association 111: 1548–75.\n\n\nWuertz, Diethelm, Yohan Chalabi, Tobias Setz, Martin Maechler, and\nGeorgi N. Boshnakov. 2023. fGarch: Rmetrics - Autoregressive\nConditional Heteroskedastic Modelling. https://CRAN.R-project.org/package=fGarch.\n\n\nXie, Yihui. 2016. Bookdown: Authoring Books and Technical Documents\nwith R Markdown. Boca Raton, Florida: Chapman;\nHall/CRC. https://bookdown.org/yihui/bookdown.\n\n\n———. 2023. formatR: Format r Code Automatically. https://CRAN.R-project.org/package=formatR.\n\n\n———. 2024. Bookdown: Authoring Books and Technical Documents with r\nMarkdown. https://github.com/rstudio/bookdown.\n\n\nXie, Yihui, J. J. Allaire, and Garrett Grolemund. 2018. R Markdown:\nThe Definitive Guide. Boca Raton, Florida: Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown.\n\n\nXie, Yihui, Joe Cheng, and Xianying Tan. 2024. DT: A Wrapper of the\nJavaScript Library ’DataTables’. https://CRAN.R-project.org/package=DT.\n\n\nXie, Yihui, Christophe Dervieux, and Emily Riederer. 2020. R\nMarkdown Cookbook. Boca Raton, Florida: Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown-cookbook.\n\n\nZachary, Wayne. 1976. “An Information Flow Model for Conflict and\nFission in Small Groups1.” Journal of Anthropological\nResearch 33 (November). https://doi.org/10.1086/jar.33.4.3629752.\n\n\nZeileis, Achim, and Gabor Grothendieck. 2005. “Zoo: S3\nInfrastructure for Regular and Irregular Time Series.”\nJournal of Statistical Software 14 (6): 1–27. https://doi.org/10.18637/jss.v014.i06.\n\n\n久保拓弥. 2012. データ解析のための統計モデリング入門\n一般化線形モデル・階層ベイズモデル・MCMC (確率と情報の科学).\n単行本. 岩波書店. https://www.amazon.co.jp/dp/400006973X/.\n\n\n大森敏明. 2015. “使える!統計検定・機械学習-v :\n回帰問題への機械学習的アプローチ :\nスパース性に基づく回帰モデリング.” システム／制御／情報\n59 (4): 151–56. https://doi.org/10.11509/isciesci.59.4_151.\n\n\n奥村晴彦, and 石田基広. 2016. Rで楽しむ統計 (Wonderful r 1).\nEdited by 市川太祐, 高橋康介, 高柳慎一, and 福島真太朗. 単行本.\n共立出版. https://www.amazon.co.jp/dp/4320112415/.\n\n\n宋財泫, and 矢内勇生. 2020. 私たちのr ベストプラクティスの探求.\nhttps://www.jaysong.net/RBook/.\n\n\n小森政嗣. 2022. RとStanではじめる　心理学のための時系列分析入門\n(Ｋｓ専門書). Kindle版. 講談社. https://www.amazon.co.jp/dp/B0BLHBPTWT/.\n\n\n山田剛史, 杉澤武俊, and 村井潤一郎. 2008.\nRによるやさしい統計学. オーム社. https://www.amazon.co.jp/dp/B00E06CJP4/.\n\n\n岩波データサイエンス刊行委員会, ed. 2015. 岩波データサイエンス\nVol.1. 単行本（ソフトカバー）. 岩波書店. https://www.amazon.co.jp/dp/4000298518/.\n\n\n川端一光, 岩間徳兼, and 鈴木雅之. 2018. Rによる多変量解析入門\nデータ分析の実践と理論. 単行本（ソフトカバー）. オーム社. https://www.amazon.co.jp/dp/4274222365/.\n\n\n川野秀一. 2017.\n“スパース正則化に基づく回帰モデリングとその計算アルゴリズム.”\n計算機統計学 30 (2): 173–86. https://doi.org/10.20551/jscswabun.30.2_173.\n\n\n村上大輔. 2022. 実践Data Scienceシリーズ\nRではじめる地理空間データの統計解析入門 (Ks情報科学専門書).\n単行本（ソフトカバー）. 講談社. https://www.amazon.co.jp/dp/406527303X/.\n\n\n東京大学教養学部統計学教室, ed. 1991. 統計学入門 (基礎統計学ⅰ).\n単行本. 東京大学出版会. https://www.amazon.co.jp/dp/4130420658/.\n\n\n松井秀俊, and 小泉和之. 2019. 統計モデルと推測\nデータサイエンス入門シリーズ. Edited by 竹村彰通. Kindle版. 講談社.\nhttps://www.amazon.co.jp/dp/B08543S1LQ/.\n\n\n松浦健太郎, and 石田基広. 2016. StanとRでベイズ統計モデリング\n(Wonderful r 2). Edited by 市川太祐, 高橋康介, 高柳慎一, and\n福島真太朗. 単行本. 共立出版. https://www.amazon.co.jp/dp/4320112423/.\n\n\n梅津雄一, and 中野貴広. 2018.\nRとShinyで作るWebアプリケーション. 単行本（ソフトカバー）.\nシーアンドアール研究所. https://www.amazon.co.jp/dp/4863542577/.\n\n\n武冨奈菜美, and 山本和嬉. 2023.\n“生存時間解析・信頼性解析のための統計モデル.”\n日本統計学会誌 52 (2): 69–112. https://doi.org/10.11329/jjssj.52.69.\n\n\n舟尾暢男. 2016. The R Tips 第3版\nデータ解析環境Rの基本技・グラフィックス活用集.\nオーム社. https://www.amazon.co.jp/dp/B0719QS6KG/.\n\n\n野村俊一. 2016. カルマンフィルタ\nーrを使った時系列予測と状態空間モデルー (統計学One Point 2).\n単行本. 共立出版. https://lead.to/amazon/jp/?op=bt&la=ja&key=4320112539.\n\n\n金明哲. 2017.\nRによるデータサイエンス(第2版):データ解析の基礎から最新手法まで.\n単行本（ソフトカバー）. 森北出版. https://www.amazon.co.jp/dp/462709602X/.\n\n\n金森敬文. 2017. Rによる機械学習入門. 単行本. オーム社. https://www.amazon.co.jp/dp/4274221121/.\n\n\n鈴木努. 2017. ネットワーク分析 第2版 (Rで学ぶデータサイエンス\n8). Edited by 金明哲. 単行本. 共立出版.\n\n\n門田幸二. 2022. バイオインフォマティクス:\nWeb連携テキスト基礎から応用. 培風館. https://www.amazon.co.jp/dp/4563078328/.\n\n\n阿部真人. 2021.\nデータ分析に必須の知識・考え方　統計学入門　仮説検定から統計モデリングまで重要トピックを完全網羅.\nKindle版. ソシム. https://www.amazon.co.jp/dp/B09M81WRHT/.\n\n\n馬場真哉. 2018. 時系列分析と状態空間モデルの基礎:\nRとStanで学ぶ理論と実装. 単行本. プレアデス出版. https://www.amazon.co.jp/dp/4903814874/.\n\n\n———. 2019.\n実践Ｄａｔａ　Ｓｃｉｅｎｃｅシリーズ　ＲとＳｔａｎではじめる　ベイズ統計モデリングによるデータ分析入門\n(Ｋｓ情報科学専門書). Kindle版. 講談社. https://www.amazon.co.jp/dp/B07WFD5RFS/.\n\n\n高橋将宜, and 渡辺美智子. 2017. 欠測データ処理:\nRによる単一代入法と多重代入法 (統計学One Point 5). 単行本.\n共立出版. https://www.amazon.co.jp/dp/4320112563/.\n\n\n高橋康介, and 石田基広. 2018. 再現可能性のすゝめ (Wonderful r\n3). Edited by 高橋康介, 市川太祐, 高柳慎一, 福島真太朗, and\n松浦健太郎. 単行本. 共立出版.",
    "crumbs": [
      "参考文献"
    ]
  }
]